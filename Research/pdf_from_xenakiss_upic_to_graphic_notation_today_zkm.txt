FROM XENAKIS’S

UPIC

TO GRAPHIC

NOTATION

TODAY

FROM XENAKIS’S
UPIC TO GRAPHIC
NOTATION TODAY

FROM XENAKIS’S

UPIC

TO GRAPHIC

NOTATION

TODAY

PREFACES

THE UPIC:
HISTORY,
INSTITUTIONS,
AND
IMPLICATIONS

18

PETER WEIBEL			

24

LUDGER BRÜMMER		

36

SHARON KANACH			

94

ANDREY SMIRNOV

		

UPIC’S PRECURSORS
118

GUY MÉDIGUE 			

THE EARLY DAYS OF THE UPIC
142

ALAIN DESPRÉS

		

THE UPIC: TOWARDS A PEDAGOGY OF CREATIVITY
160

RUDOLF FRISIUS

THE UPIC―EXPERIMENTAL MUSIC PEDAGOGY―
IANNIS XENAKIS
184

GERARD PAPE

COMPOSING WITH SOUND AT LES ATELIERS
UPIC/CCMIX
200

HUGUES GENEVOIS			

ONE MACHINE—
TWO NON-PROFIT STRUCTURES
216

CYRILLE DELHAYE			

CENTRE IANNIS XENAKIS:
MILESTONES AND CHALLENGES
232

KATERINA TSIOUKRA 		

ESTABLISHING A XENAKIS CENTER IN GREECE:
THE UPIC AT KSYME-CMRC
246

DIMITRIS KAMAROTOS

THE UPIC IN GREECE: TEN YEARS OF LIVING
AND CREATING WITH THE UPIC AT KSYME

TABLE
OF
CONTENTS

290

RODOLPHE BOUROTTE

PROBABILITIES, DRAWING, AND SOUND
SYNTHESIS: THE MISSING LINK

COMPOSERS
EXPERIENCING
THE UPIC

312

JULIO ESTRADA		

THE LISTENING HAND
336

RICHARD BARRETT			

THE UPIC
AND
UTOPIA

528
540

MEMORIES OF THE UPIC: 1989–2019
354

562

FRANÇOIS-BERNARD MÂCHE		
TAKEHITO SHIMAZU			

574

BRIGITTE CONDORCET (ROBINDORÉ)

590

416

RONALD SQUIBBS		
PIERRE COUPRIE			

ANALYTICAL APPROACHES TO
TAURHIPHANIE AND VOYAGE ABSOLU DES
UNARI VERS ANDROMÈDE
460

REFLECTIONS

486

610
628

HENNING LOHNER		

JULIA JASMIN ROMMEL			

ZWISCHENRAUM (INTERSPACE)
646

LUKAS NOWOK

FROM THE SYMBOLIC TO THE REAL:
GRAPHIC NOTATION AS SYMBOLIC AND
TECHNOLOGICAL MEDIUM

PETER WEIBEL		

THE ROAD TO THE UPIC.
FROM GRAPHIC NOTATION TO
GRAPHIC USER INTERFACE

MARCIN PIETRUSZEWSKI		

THE DIGITAL INSTRUMENT AS AN ARTIFACT

IANNIS XENAKIS, ROBOTS, AND THE UPIC―
“THE GREATEST ROBOT SHOW THE WORLD
NEVER SAW”

THE ROAD
TO THE UPIC

KOSMAS GIANNOUTAKIS

EXPLORING VISUALIZATION METHODS OF THE
DYNAMIC BEHAVIORS IN COMPUTER-BASED
MUSICAL WORKS

MYCÈNES ALPHA: A LISTENER’S GUIDE
434

JULIAN SCORDATO		

NOVEL PERSPECTIVES FOR GRAPHIC
NOTATION IN IANNIX

BEYOND THE CONTINUUM:
THE UNDISCOVERED TERRAINS OF THE UPIC

XENAKIS
AND
THE UPIC

VICTORIA SIMON

UNFLATTERING SOUNDS: PARADIGMS OF
INTERACTIVITY IN TACTILE INTERFACES FOR
SOUND PRODUCTION

THE UPIC FOR A JAPANESE COMPOSER
396

CHIKASHI MIYAMA			

THE UPIC 2019

THE UPIC UPSIDE DOWN
380

KIYOSHI FURUKAWA 		

THE UPIC AND UTOPIA

APPENDIX

660

BIOGRAPHIES

668

SUPPLEMENTARY CREDITS

670

COLOPHON

Full publication available for download

WWW.ZKM.DE/UPIC

PREFACES

PETER WEIBEL
LUDGER BRÜMMER
SHARON KANACH

19

INTRODUCTION
1.

Viewed from certain perspectives, Iannis Xenakis is
not only a singular figure in twentieth-century music
history, he is probably the most revolutionary, for he
was not only a composer of grandiose works of a
“strangeness in the proportion”,[1] which is how Francis
Bacon defined beauty. But like Arnold Schoenberg,
Karlheinz Stockhausen, Pierre Boulez, and John Cage,
he was also the author of theoretical music writings
of the highest order. He was an independent architect
for many years and worked for Le Corbusier from 1947
to 1959. He created an extensive architectural oeuvre,
also manifested in many texts on architecture. In
addition, Xenakis was a mathematician, inventor, and
engineer. G.W. Leibniz defined music in 1712 as “an
unconscious exercise in arithmetic in which the mind
does not know it is counting,”[2] and there is probably
no other composer as close to this understanding of
music as Xenakis.[3]

FIG. 1 Iannis Xenakis,

PETER WEIBEL
CHAIRMAN AND CEO
ZKM | KARLSRUHE

Philips Pavilion,
1958, drawing
© Iannis Xenakis Family

Francis Bacon, “There is no
excellent beauty that hath
not some strangeness in the
proportion,” F. Bacon, “Of
Beauty,” in Essays (1625).
2.

G.W. Leibniz in a letter to
Christian Goldbach, April 27
1712: “Musica est exercitium
arithmeticae occultum
nescientis se numerare
animi,” in Oliver Sacks, The
Man Who Mistook His Wife
for a Hat (New York: Summit
Books, 1985).
3.

See Xenakis’s collection of
essays “Musiques formelles,”
in La Revue musicale 253,
254 (1963); Formalized Music
(Bloomington, IN: Indiana
University Press, 1971).

20

Let us consider, for example, his critique of serial
music in 1955 “La crise de la musique serielle” (The
Crisis of Serial Music),[4] his text “Theory of Probability
and Music” (Wahrscheinlichkeitstheorie und Musik)[5] of
1956, his work on stochastic music from 1958, and his
compositions from 1957 to 1962 in the electroacoustic
music studio of the GRM (Groupe de Recherches
Musicales) directed by Pierre Schaeffer from 1960–
1974 as part of the French broadcasting agency ORTF
(Office de Radiodiffusion-Télévision Française).
The development of New Music made the search
for a new kind of notation necessary in the 1950s—
from Darmstadt to Donaueschingen, from New York to
Gravesano.[6] A well-known example of this is Xenakis’s
sketch for Metastasis of 1954.[7] It is typical of Xenakis
that he varies these musical figures and uses them as
the basis for the hyperbolic forms of his architecture
of the Philips Pavilion for Expo 1958 in Brussels, in
which Edgard Varèse’s Poème électronique for tape, Le
Corbusier’s multimedia projections, and Xenakis’s own
tape piece Concret PH could be heard and seen.
The glissando curves of the strings become bold
architectural curves that anticipate deconstructivist
architectural forms à la Zaha Hadid. Sound curves
transform into building curves.
With his novel compositional ideas Xenakis paved
the way for computer music. He began to research the
relationship between music and computers already
in 1956 at the laboratory of IBM France. From 1956
to 1962, Xenakis wrote compositions whose score
data had been calculated using IBM computers. In the
beginning, it was computer programs whose results
the composer transcribed for traditional instruments.
Later, Xenakis produced synthetic sounds with the
computer. His passion for mathematics eventually
led him to the UPIC. In 1966, Xenakis founded
EMAMu, better known since 1972 as CEMAMu (Centre
d’Etudes de Mathématique et Automatique Musicales).

21

FIG. 2 Iannis Xenakis,

4.

Iannis Xenakis, “La
crise de la musique
serielle,” in Hermann
Scherchen’s Gravesaner
Blätter. Musikalische,
elektroakustische und
schallwissen­schaftliche
Grenzprobleme, 1, 1
(1955): 2–4.
5.

Iannis Xenakis,
“Wahr­schein­lichkeitstheorie
und Musik,” in Hermann
Scherchen’s Gravesaner
Blätter. Musikalische,
elektro­­akustische und
schallwissen­schaftliche
Grenzprobleme, 2, 6
(1956): 28–34.
6.

See Earle Brown, Morton
Feldman, Mauricio Kagel,
Anestis Logothetis, Roman
Haubenstock-Ramati, and
others.
7.

See Fig. 1 in Robindoré,
this volume: Iannis Xenakis,
Metastasis, 1954, graphic
sketch.

Mycènes Alpha, 1978,
UPIC score page
© 1978 Editions Salabert—
Paris, France, reproduced
by kind permission of Hal
Leonard Europe S.r.l.—Italy

22

With the UPIC, he combined two important
revolutions of twentieth-century music, namely, a
revolutionary notation with a revolutionary instrument:
graphic notation produced with the computer. The
composer no longer needed to write complicated
programs, but was able to fix the sounds graphically
and render the graphics audible with the help of the
computer. The UPIC is a revolutionary composition
device; a music machine that enables sounds to be
generated directly via self-designed graphic structures.
The idea of a graphic input mode, “drawn” music,
after the end of the conventional notation system,
had already been developed technically by many
pioneers­­—from Rudolf Pfenninger to Daphne Oram.
With the UPIC, musical ideas are drawn on paper with
pencils, and then redrawn on a graphics tablet with an
electromagnetic pen-like stylus. The drawn music is
stored page by page. These drawings and the graphic
input are played back simultaneously on two screens.
One screen is used for graphic (analog) representation,
the other for alphanumeric (digital) representation.
This information is sent to a 16-bit minicomputer,
analog-to-digital sound converter (ADC), and RAM
storage devices. The digitally captured information of
the graphic coordinate system is read at high speed by
a computer via ADC on the drawing tablet, converted
into numerical information, and processed into sound
material by the computer. The sound leaves the
computer via digital-to-analog sound converter (DAC)
and is made audible via amplifier and loudspeaker.[8]
The ZKM | Center for Art and Media is a museum
with the usual remit of collecting works of art and
presenting them in exhibitions. It is a museum of
all genres and media, both spatial and time-based
arts. It is therefore interactive, participative, and
performative. However, the ZKM is more than just a
museum. It is also a research center. It develops and
produces its own works of art together with guest

23

8.

See Fig. 1 in Mâche,
this volume: setup of the
UPIC (Unité Polyagogique
Informatique du CEMAMu),
an invention by Iannis
Xenakis, schematic drawing.

artists and staff. With its symposia and publications,
ZKM conducts scientific research and contributes
to a multidisciplinary discourse on art, science, and
technology.
Music is the mother of all time-based arts and
therefore plays a special role at the ZKM. Music
provides an excellent example for recognizing and
understanding the transformations of art through
technological innovations. Music is the scene of
perhaps the most daring artistic and technical
revolution of the twentieth century. Xenakis is a
master of twentieth-century music. Hardly any other
composer has worked as universally and ahead of
his time as Xenakis: as a theorist, musician, and
architect. With his pavilions for music, from the Philips
Pavilion in Brussels (1958) to Diatope (1978) in front
of the Centre Pompidou in Paris, he paved the way
to spatial music, sound spaces, and spatial sounds.
With his computer-based music, Xenakis has thought
beyond the boundaries of music, beyond traditions
and schools. He has revolutionized the traditional
tonal orders. He is one of the most radical musical
innovators as a thinker, composer, architect, engineer,
and inventor. With the UPIC, his reflections and visions
culminated in an incunabulum. For this reason Xenakis
and the UPIC are of seminal interest to the ZKM.
To all participants of the symposium, authors
of this publication, and my two coeditors Ludger
Brümmer and Sharon Kanach, as well as the graphic
designer Uta Kopp and the editor Lisa Bensel, I would
like to express my deepest thanks for the fact that a
long cherished desideratum, the scientific processing
of the UPIC project, could, at the highest level, finally
be realized.
PETER WEIBEL

25

DIGITAL
AVANTGARDIST
XENAKIS—
THE UPIC'S
IMPULSES FOR
THE FUTURE

LUDGER BRÜMMER
HEAD OF DEPARTMENT
ZKM | HERTZ-LAB

This publication tracks the development of the sound
synthesis and composition instrument UPIC developed
by Iannis Xenakis, describing not only its beginnings
from the planning phase to the present day, but also the
traces it has left behind. And the publication itself has
a long history behind it. In various ways—in exhibitions,
concerts, and installations—the ZKM | Karlsruhe and
the former Institute for Music and Acoustics of the
ZKM, today the Hertz-Lab,[1] has engaged with the
oeuvre of Iannis Xenakis for many years—whether
through the performance of his compositions, the
presentation of installations and documentation
materials by Xenakis, or through new works by other
artists that refer to Xenakis.
In 2006, the ZKM presented for the first time
the architectural context of Iannis Xenakis’s work
with reference to the Philips Pavilion for Expo ’58 as
part of the exhibition The Museum of Time-Based
Art, a collaboration with the Bavarian Chamber of
Architecture.
The UPIC itself, with its hardware and
artifacts, was exhibited in 2013 and 2018 in the
ZKM exhibitions Soundart and Art in Motion: 100
Masterpieces with and through Media. Most recently,
the idea of Xenakis’s Polytopes was elaborated in

1.

The ZKM | Hertz-Lab
operates as a
transdisciplinary research
and development platform
at the interface of media
arts, science, and society. It
was formed in 2017 from the
ZKM’s existing institutes for
visual media (Bildmedien)
and for music and acoustics
(Musik und Akustik).

26

Chris Salter’s work N-Polytope and presented in
2018 in the subspace of the ZKM_Cube, the blue
architectural landmark of the ZKM. Peter Weibel was
the curator of these presentations.
The Institute for Music and Acoustics, of which I
was artistic director, supplemented these exhibition
projects with concerts or defined its own focuses in
the context of several festival series. The concerts
given in the series Quantum Leaps, later renamed
Con:temporaries, which have been fantastically
interpreted by musicians from the International
Ensemble Modern Academy Frankfurt (IEMA), should
be mentioned here, as well as the concert series
Piano+, curated by Catherine Vickers, in which many
compositions by Xenakis were interpreted in a firstclass manner. These included compositions that
demand enormous skill from the performers, such
as the duet Dikhthas for piano (Catherine Vickers)
and violin (Jacek Klimkiewicz) Xenakis composed in
1979. Symposia framed and enhanced some of those
performances. A complete overview of all events
on Iannis Xenakis organized by the ZKM to date
concludes this foreword.
The idea of reflecting more profoundly on
Xenakis’s work was first articulated by Peter Weibel
during the exhibition Iannis Xenakis: Music and
Architecture in 2006. The idea began to take shape
later in exchanges with musicologists Makis Solomos
and Sharon Kanach, especially in discussions after the
symposium Paranoia: Limit Experiences of Electronic
Music in the Context of Iannis Xenakis’s Work in
2012. However, it only took on a concrete form when
I held planning discussions with the project manager
Christos Carras for Interfaces, a Creative Europe
project supported by the European Union. The project
deals with new models and practices for Audience
Development in Contemporary Music, and for the first
time this created the framework for a longer-term

27

discussion with the UPIC. In further conversations with
Sharon Kanach, it became clear that the publication
needed to revolve around the historical experiences
and testimony of contemporary witnesses, and at
the same time take a look at the traces left by the
UPIC, which have undergone further development in
connection with technological advances.
In the autumn of 2018, artists, scholars, and
scientists were invited to follow these traces and
reflect on them in musical and textual contributions
during a two-day conference entitled UPIC: Graphic
Interfaces for Notation at the ZKM in order to identify
the most important thematic areas. The conference
was organized in collaboration with the Centre Iannis
Xenakis (CIX), of which Sharon Kanach is the vicepresident. In addition, the ZKM | Hertz-Lab invited
artists Julia Jasmin Rommel, Marcin Pietruszewski,
Lukas Nowok, and Kosmas Giannoutakis for a
residency to develop new electroacoustic compositions
resulting from the digital, real-time interpretation of
graphics. All artists, contemporary witnesses, and
lecturers were invited to present their material as a
collection of ideas for the planned publication. The
editors hoped not only to get an overview of the existing
narrative strands and the wealth of subject areas, but
also to develop a strategy, to review the content of
the concept, and to adjust it, which in the course of
numerous additions also led to the necessary scope of
the present publication. The narrative strands resulted
in a historical section for this publication, for which
Sharon Kanach is mainly responsible. The archives of
the Centre Iannis Xenakis enabled her to connect with
numerous witnesses contemporaneous with the birth
of the UPIC. This section is discussed in the first three
chapters of the publication and explained separately in
her preface. Further, there is a contemporary section
of the publication that I compiled. It is also divided into
three chapters which I will go into below.

28

The aforementioned symposium Paranoia. Limit
Experiences of Electronic Music in the Context of
Iannis Xenakis’s Work, from which the decisive impulse
to realize this publication emanated, was held at the
end of May 2012. In this context, Xenakis’s Polytope
Persepolis was performed in the Schlossgarten
Karlsruhe, the park of Karlsruhe Castle, as a
reconstruction of the original performance by Daniel
Teige. One of the topics discussed at the symposium
were the unsettling, impressive, and extreme aspects
of Xenakis’s work. What does “unsettling” mean in
this context? Well, for example, there are descriptions
of the first performance of Bohor, where Xenakis
presented the composition at a very high volume. This
is something that Xenakis has in common with the
performances of electroacoustic music conducted
by Karlheinz Stockhausen. However, Bohor differs
from Stockhausen’s compositions: the work has
no dramatic fluctuations in volume, and its texture
remains dense and complex over a period of 22
minutes. This means that a high volume is disturbing
to the listener, straining their hearing to the limit and
beyond. The term “paranoia” was intended to express
these overexcited sensory impressions, which Xenakis
provokes in other works and musical parameters.
In his works, Xenakis always distanced himself
very far from the mainstream taste of a given period,
and it is interesting to see how he was able to induce
rejection and a strong fascination simultaneously.
His transgression of aesthetic boundaries may have
its roots in biographical aspects that have been
sufficiently discussed, such as his war experiences.
Of decisive importance, however, was the fact that
his tonal and compositional thinking made use of
new concepts and new tonal ideas, with which he
radically set himself apart from his colleagues within
serial music and developed alternative methods. It
is noteworthy in this context that Xenakis had joined

29

the Groupe de Recherche de Musique Concrète (later
GRM) in 1954, from which, in the course of time,
incredibly heterogeneous aesthetic models such as
those of Pierre Henry or Eliane Radigue developed,
and which in turn influenced composers such as
Karlheinz Stockhausen. The contrast between the
aesthetics of all these composers could not be greater.
Also noteworthy is the fact that Xenakis, in
addition to his thematic fields of sound pavilions,
sound installations, compositions, and composition
theory, also used mathematical methods to develop
digital tools for composition and sound generation.
After all, he had already started composing with
computers in 1956. He brought together the financial
and human resources for a composition center and
then for an entire composition system. This is not
possible without the political context, the openness to
the visions of society. But we need people like Xenakis
who recognize and implement opportunities and
necessities. In addition, Xenakis succeeded not only
in enabling composers to use the system right after
the completion of the first UPIC prototype in 1977, but
also in creating understanding among young people
for technological composition.
To explain the context in which the UPIC was
created, one should bear in mind that the electronic
studio of the Technical University of Berlin, one of the
most advanced studios in Germany for example, would
only invest in computer music years later, from 1984
onwards. But of course Xenakis’s idea for the UPIC
was not formed in isolation. Rather, it evolved from
concepts and technical modules that already existed.
For example, Max Mathews had already developed a
usable version of the sound programming languages,
MUSIC V, at the Bell Labs in 1966. A few years later,
Fernando von Reichenbach completed his Convertidor
Gráfico Analógico[2] in Buenos Aires, a machine that
could be used to convert drawings done on paper

2.

R. Dal Farra, Historical
aspects of Electroacoustic
Music in Latin America: From
the Pioneering to the Present
Days (France: Digi-Arts
UNESCO Knowledge Portal,
UNESCO, 2003).

into sound. Compositions have been created with
this system since 1970; but this was a purely analog
system based on the existing sound synthesis methods.
In 1972, John Chowning had already produced his
work Turenas with a digital system (the DEC PDP-10),
but if one considers these contemporary technological
developments, it becomes clear how ambitious
Xenakis was to combine these individual inventions
or to develop them from scratch in order to create a
completely digital composition tool with elaborated
digital sound synthesis and a graphical user interface.
Without a doubt, Paris was the hot spot of digital music
in Europe and Xenakis a pioneer with his ideas. When
the IRCAM opened, Boulez hired a group of American
composers and software developers, including Max
Mathews, John Chowning, and Jean Claude Risset, a
US-based researcher, to start digital music production.
But the UPIC was already working a couple of months
after IRCAM opened in 1977!
The fourth chapter of this publication begins
with a comprehensive contextualization of the UPIC.
The text by Peter Weibel has its own section titled
THE ROAD TO THE UPIC, as Peter Weibel goes into
considerable detail in his text to establish the
interconnections between technological, artistic,
visual, and scientific thinking in Xenakis’s work. As the
list of exhibitions and presentations accompanying
this foreword shows, since 2006 Peter Weibel has
repeatedly initiated exhibitions which, among other
things, have dealt intensively with the work of Iannis
Xenakis and he has thus placed Xenakis at the center
of the ZKM’s music-centered activities.
Once the UPIC existed, its effect was able to
unfold. Many composers were able to work with the
system and the radically new concept significantly
influenced their thinking. For Gerard Pape, contact
with the UPIC opened new spheres of thought such
that he was the only private individual to purchase

his own UPIC system. For Curtis Roads, the handling
of sound composition learned with the UPIC triggered
the development of granular synthesis. The UPIC
concepts also left a number of traces in many future
developments; they were a model for a number
of compositional technique ideas, which later, as
technology became more affordable and easier to
master, led to new software and hardware. This aspect
is discussed in the chapter THE UPIC AND UTOPIA, in
texts that are oriented on the ideas of the UPIC and
develop them further with regard to current software or
hardware. The title is borrowed from the text by Kiyoshi
Furukawa.
The book’s concluding chapter is titled
REFLECTIONS. It brings together authors who discuss
compositional, cultural, and creative aspects of the
UPIC on an abstract level.
CONCERTS WITH WORKS
BY IANNIS XENAKIS
PRESENTED AT ZKM

THE ROAD TO THE UPIC. FROM GRAPHIC
NOTATION TO GRAPHIC USER INTERFACE

31.10.2003

PETER WEIBEL presents in his text the development of

Listen and Watch, Orient
Occident for tape, 1960,
by Iannis Xenakis
04.10.2006

Accompanying programme
for the exhibition Iannis
Xenakis: Music and
Architecture:
Audio and video simulation
of the TU Berlin for the
Philips Pavilion at the
Brussels World Exhibition,
1958
DVD launch Iannis Xenakis:
Mythos und Technik by
Peider Defilla, WERGO
14.02.2008

Quantum Leaps VI:
Plektò (Flechte) for 6
instruments, 1993, by
Iannis Xenakis

musical instruments in the twentieth century which
led to the UPIC. At the beginning, around 1900, there
were the synaesthetic dreams of color pianos, of the
connection between sound and color, of music and
painting. In the 1920s, interest shifted to research on
the interdependence of light and sound, to synthetics,
to the synthetic generation of sounds and images.
It was at this historic moment that cinematography
came into play, which used music drawn on film strips
as optical sound in abstract or absolute film. The
graphic notation of sound, which began in music in the
1950s, had already been sketched out 20 years earlier
in abstract film. With this optophonetic turn, numerous
composers began to overcome the boundaries of
traditional music notation and expand the cosmos of
sound. A variety of electrical, electromagnetic, electrooptical, electromechanical, and electronic instruments

06.11.2008

László Hudacsek: Looping
on the Ghost Train of Time:
OKHO pour trois djembés
et une peau africaine de
grande taille, 1989, by
Iannis Xenakis
20.05.2010

LUX VOCAT. Through the
Night to Light:
Aroura for strings ensemble,
1971, by Iannis Xenakis
Nuits for 12 voices, 1967, by
Iannis Xenakis
24.11.2011

Piano+/IMATRONIC “Xenakis
today”:
Concret PH for two-channel
tape, 1958, by Iannis
Xenakis
À.r.(Hommage à Ravel) for
piano, 1987, by
Iannis Xenakis
Herma for piano, 1960/61,
by Iannis Xenakis
Bohor for multi-channel tape,
1962, by Iannis Xenakis
Dikhthas for piano and violin,
1979, by Iannis Xenakis
Six Chansons for piano,
1951, by Iannis Xenakis
Orient-Occident for fourchannel tape, 1960,
by Iannis Xenakis
Evryali for piano, 1973,
by Iannis Xenakis
Mists for piano, 1981,
by Iannis Xenakis
Diamorphosis for tape, 1957,
by Iannis Xenakis
11.03.2012

Quantum Leaps XIV:
Diamorphosis for tape, 1957,
by Iannis Xenakis

were developed, until finally the computer arrived.
These replaced paper as the medium of notation with
screens, whether oscilloscopes or monitors. They
replaced the composer’s hand with pens or keyboards,
musical notation with programs and graphic notation
with graphical user interfaces. Music, which had
always been a temporal code, now became a code
programmed by machines and algorithms. Traditional
music notation was instructions for people to operate
instruments. The digital code is at once instructions for
music machines and the execution of the same.
THE UPIC AND UTOPIA

In his text, KIYOSHI FURUKAWA refers to the experiences
made with his interactive composition software Small
Fish with regard to a system between composition,
score, instrument, and performance. Although the
UPIC was not able to completely eliminate these
categories, for the first time they were combined
in one tool. Relics from the previously necessary
division into necessary steps of the creation process
of a composition could now only be recognized
to some extent in the course of working with the
UPIC. Furukawa goes further in his comments
on these categories and asks to what extent it is
necessary to fix a composition at all, and whether the
implementation and configuration of information in an
interactive system is not already sufficient.
CHIKASHI MIYAMA’S chapter places the UPIC in
the context of the current developments that have
resulted. He works as an actor with live electronics
and visuals with audiovisual particle systems. In his
text “UPIC 2019,” he gives a systematic overview of
the currently available programs related to the UPIC
system, and shows to what extent these systems
could possibly be extended with the help of the
latest hardware and software. Based on the fact that
nowadays a UPIC system with camera, sound input,

31.05.–02.06.2012

Symposium: Paranoia. Limit
Experiences of Electronic
Music in the Context of
Iannis Xenakis’s Work:
Persepolis, 1971, by Iannis
Xenakis at Schlossgarten
Karlsruhe
Voyage absolu des Unari
vers Andromède, 1989,
by Iannis Xenakis
22.02.2013

Portrait concert Arturo
Fuentes:
Charisma for clarinet and
cello, 1971, by Iannis
Xenakis
04.03.2016

ZKM presents 4DSOUND:
Points on the Curve:
Orient-Occident for fourchannel tape, 1960, by
Iannis Xenakis
19.03.2016

con:temporaries
Phlegra for 11 instruments,
1975, by Iannis Xenakis
22.09.2017

con:temporaries:
Plektò (Lichen) for 6
instruments, 1993, by Iannis
Xenakis
01.09.–23.10.2018

Installation N-Polytope:
Behaviors in Light and
Sound After Iannis Xenakis
by Chris Salter
06.04.2019

Sculptural Aspects in
Loudspeaker Music in the
framework of the exhibition
Negative Space:
Diamorphosis for tape, 1957,
by Iannis Xenakis

sound output, and a mouse is already included in
every laptop, he designs ideas that go beyond these
possibilities by composing with head tracking and
3D systems. With the programs Rotating Scores
and Rhythm of Shapes, he has already developed
possibilities in the past—in collaboration with Anton
Himstedt and myself—to generate sound with rotating
signs or to translate live generated photographic
contents.
VICTORIA SIMON focuses on tactile interaction
with the UPIC, which she describes as a tool. From
Xenakis’s thinking, she develops the suggestion
that tactile interaction with the sound should be as
direct as possible. Every device, even the mouse, or
any programming language is an obstacle to direct
communication between a listener or composer and
the sound. Therefore, a way of interacting directly with
the sound via graphical notation would bring progress
in this direction. It presents the touch screen as a
further step that, unlike the pen, as is the case with
the UPIC system, enables a more direct and intuitive
interaction with the sound via fingers and palms.
She demonstrates its advantages by means of the
Borderlands notation software and the UPISketch app
as examples.
JULIAN SCORDATO examines the software IanniX
for the further development of the ideas created in
UPIC. In particular, he describes the possibilities of
IanniX with regard to the manifold possibilities of a
“score” called data representation, and interprets, as
an expert and codeveloper of IanniX, the potentials
created therein as well as the role of the user. He
sees this not only as a composer, but also as
a programmer who is capable of extending the
functionality of the software. IanniX was developed
as an open environment that invites extensions. This
aspect develops the implementation of UPIC further in
essential points and brings it up to date.

LECTURES AND SYMPOSIA
ADDRESSING WORKS BY
IANNIS XENAKIS HELD AT
ZKM
24.06.2011

Symposium: Art. Archives.
architectures:
Cyrille Delhaye: The Archives
of the Centre Iannis Xenakis,
or the Sources Heterogeneity
such as Documentary
Richness
24.11.2011

Symposium: Xenakis,
Algorithms, Electronics:
Makis Solomos: The Notion
of Space in Xenakis’s Music
Daniel Teige: Performing the
music of Xenakis’s Polytopes
Reinhold Friedl: The
Multiple Being of Xenakis’s
“la legende d’eer”: The
Necessity of Critical Editions
of Electroacoustic Music

KOSMAS GIANOUTAKIS describes an interesting
experiment in his text: An algorithm used
compositionally is visualized and in the next step
its sound result is influenced by manipulations
of the visual object. Through rotation, stretching,
and compression in three-dimensional space, the
parameters of the algorithm—and thus the resulting
sound—are changed. He adds a kind of feedback
loop to Xenakis’s idea of sonifying graphical
elements, but their manipulation, in accordance with
the UPIC, is carried out on the graphical level.

REFLECTIONS
MARCIN PIETRUSZEWSKI highlights the relationships

between the synthesis possibilities of the UPIC
system and the pulsar synthesis developed from it
giving concrete examples. Pulsar synthesis is also
used by the pioneer of granular synthesis, Curtis
Roads, who owes his main impulse for this to his work
with the UPIC. Pietruszewski adds another option
to pulsar synthesis with its proprietary granular
synthesis software New Pulsar Generator. But he
also points out that the tools used influence both the
composers and the compositions.
LUKAS NOWOK’s essay is devoted to the role
of notation, which he develops as a reduction or
quantization of the concrete. He endeavors to break
up the rigid relationship between idea, translation
into notation, and transformation into sound, which is
functionally encoded in the notation.
In her text, JULIA JASMIN ROMMEL presents an
artistic project that deals with acoustic space
measurement in close relation to graphic notation and
cartography. An observation that Xenakis realized in a
similar way by using architectural drawings as sketches
for musical ideas, as in Metastasis. In this context she
touches on the specifics of the application of graphic
notation by Dieter Schnebel, Cornelius Cardew, and

31.05.–02.06.2012

Symposium: Paranoia.
Boundary Experiences of
Electronic Music in the
Context of Iannis Xenakis’s
Work:
Bill Dietz: Interactions
with Listening Mind −
Maryanne Amacher’s Glial
Instrumentations
Werner Dafeldecker, Valerio
Tricoli: Williams Mix Extended
Rudolf Frisius: Musik
als Formverlauf?
Form und Struktur in
der instrumentalen und
elektroakustischen Musik
von Iannis Xenakis
Daniel Teige: Dead or
alive: Performance and
interpretation aspects on
Xenakis Polytopes
Leopoldo Siano, Tobias
Hünermann, Christoph von
Blumröder and Matthias
Nowakowski: Iannis Xenakis
Künstlerische Physiognomie
und kompositorisches Umfeld
Rodolphe Bourotte: Limits
and perspectives of the
computer-assisted sound
drawing experience
Makis Solomos: Pour la Paix
Sharon Kanach: Iannis
Xenakis: Construction and
Sensation
Thomas Troge: Genie oder
Paranoia − Musikdenken
bei Xenakis unter dem
Aspekt der Kognitions- und
Gehirnforschung
Daniel Teruggi: Did Iannis
Xenakis ever compose
“Musique concrète”?

György Ligeti by the graphic artist Rainer Wehinger.
She emphasizes the necessity of drawing for notation
in general as a subset of information, touches on the
aesthetics of the sign, and refers to the neurological
connection of hearing, sight, and the sense of balance
that per se is responsible for spatial orientation.
I would like to express my thanks to everyone
who has contributed to this very extensive project.
My special thanks go to Lisa Bensel, who brought
and held together the incredible puzzle of numerous
texts, images, and information for the realization of
this publication, to Sharon Kanach, who managed
to win over so many contemporary witnesses for the
publication and to Peter Weibel for his continuous
soft pressure leading to this work.
As a special feature, this publication is published
simultaneously in printed form by Hatje Cantz and in
a digital version, which can be downloaded free of
charge from WWW.ZKM.DE/UPIC.
Since this publication was financed by the
Creative Europe programme of the European Union
and by ZKM | Karlsruhe donors, it is of great concern
to us to make the knowledge about the work of
Xenakis, which has been collected here for the first
time in this breadth, contains previously unpublished
archive material, and can establish itself as a standard
work on graphic notation and the UPIC, unrestrictedly
accessible to the public. We follow the contemporary
credo “Public Money, Public Book.” While the book
form fulfills the necessary and sustainable role of
presence in a public or private library and stands
alone as a physical object, the digital version is aimed
primarily at students, scholars, scientists and a
digitally networked worldwide readership.
LUDGER BRÜMMER

28.–29.09.2018

Conference UPIC—Graphic
Interfaces for Notation
with lectures by Cyrille
Delhaye, Alain Després, Guy
Médigue, Julian Scordato,
Julio Estrada, Marcin
Pietruszewski, FrançoisBernard Mâche, Mark
Pilkington, Chikashi Miyama,
Rudolphe Bourotte,
Sharon Kanach

EXHIBITIONS WITH WORKS
BY IANNIS XENAKIS
PRESENTED AT ZKM
09.09.–04.10.2006

Iannis Xenakis: Music
and Architecture, part
of the exhibition The
Museum of Time-Based
Arts in collaboration with
the Bavarian Chamber of
Architecture
01.03.–26.07.2009

Notation: Calculation
and Form in the Arts with
drawings by Xenakis
17.03.2012–06.01.2013

Soundart with the original
UPIC hardware and visual
documentation

14.07.2018 AND 20.01.2019

Art in motion: 100
Masterpieces with and
through Media with the
original UPIC hardware and
visual documentation

37

THE UBIQUITOUS
UPIC
For LAF, whose
patience, support, and
understanding
never cease to
astound and inspire …
reciprocation. And
beyond… There.

SHARON KANACH
VICE-PRESIDENT,
CENTRE IANNIS XENAKIS

If you ask people “What one word does the name
Xenakis evoke?” you get answers such as “Metastasis,”
or “stochastics,” or “polytope,” or “Formalized Music,”
or even “Le Corbusier”; but rarely does “UPIC” spring
first to anyone’s mind. However, if the question is
posed the other way round, “What one word does the
UPIC evoke?” a vast majority will reply “Xenakis.” This
machine, this tool, its very idea, is inextricably linked
to the creator who conceived it. Over forty years have
passed since its first prototype was publicly introduced
in 1977—which we discover in this volume was initially
called simply Polyagogia,[1] (poly, meaning many,
an indefinite number; agogics, referring both to the
expressive qualities of musical time and to the concept
of education).[2] This publication is the opportunity
to both retrace its history (verifying it with its primary
actors, for the first time), and to project its possible
future iterations as a compositional tool with today’s
(and tomorrow’s) technology, as well as in terms of
the future of graphic notation at large. The twentyseven essays in this volume, penned by distinguished
authors/artists from eleven different countries, are
living testimony to the UPIC’s history, scope, influence,
and, ultimately, potential.
We have chosen to divide this volume’s contents into
six sections, and this preface serves mainly as an
introduction to the first three: The UPIC: Its History,
Institutions, and Implications; Composers Experiencing
the UPIC; and Xenakis and the UPIC. My esteemed
colleague LUDGER BRÜMMER’s preface addresses both
the genesis of this volume and recounts ZKM’s own
history with Xenakis as well with as the UPIC over
the past fourteen years. Furthermore, he specifically

1.

See Dimitris Kamarotos’s
chapter, this volume.
2.

However, in an interview
with the journalist Georges
Charbonnier broadcast on
France Musique on August
26, 1982, Xenakis states
“Polyagogic is a neologism
I introduced that means a
sort of multiple pedagogy.”
(Source: INAthèque,
PHD99256553; 3'28''–
3'36'')

38

39

addresses the contributions under the three final
chapters, covering the prospective future of the UPIC
and its implications in the broader realm of graphic
notation. ZKM’s scientific and artistic director,
PETER WEIBEL’s contribution contextualizes Iannis
Xenakis in the context of the history of 20th century
music. Of course, each individual text can be read
independently and in any given order indeed, as a
book, from beginning to end.
BACK TO THE DRAWING BOARD
THE UPIC: ITS HISTORY, INSTITUTIONS,
AND IMPLICATIONS

What was ultimately called the UPIC (Unité
Polyagogique I nformatique du C EMAMu, the
CEMAMu being Xenakis’s research lab where the
system was originally developed: C entre d’Etudes de
M athématique et Automatique MU sicales), maintaining
the concept of polyagogics is, in a word, a musical
drawing board. Xenakis often reverted to making
sketches as part of his poietic process of composition
for a multitude of reasons,[3] and this volume offers
some handsome examples; in particular, excerpts of
previously unpublished preliminary sketches for the
first work composed solely on the UPIC: Xenakis’s
Mycènes Alpha (1978).[4] But the UPIC was not the
first nor the only attempt by composers/creators to
imagine audio computing devices, as revealed by
ANDREY SMIRNOV’s valuable contextualization “UPIC’s
Precursors”. However, unlike most if not all of its
predecessors, the UPIC not only thrived for decades,
its influence and potential continue to inspire. This is
manifest in the graphic notation softwares developed,
in particular UPISketch, developed by RODOLPHE
BOUROTTE for the Centre Iannis Xenakis in partnership
with the European University Cyprus in the context of
Interfaces, a project in the framework of the Creative
Europe Programme of the EU.

3.

See, for example: Sharon
Kanach, [...] “Xenakis’s
Hand, or The Visualization
of the Creative Process,”
Perspectives of New Music
40, 1 (2002): 190–97;
Sharon Kanach, “Music to
be seen: Tracing Xenakis’s
Creative Process,” in Iannis
Xenakis: Composer, Architect,
Visionary (exhib. cat. (New
York: The Drawing Center
(Drawing Papers 88, 2010),
95–127, available online:
https://issuu.com/
drawingcenter/docs/
drawingpapers88_xenakis

It is generally considered, and Xenakis himself
has stated, that the then future UPIC germinated in
the composer’s mind while working on his breakout
orchestral work Metastasis (1953–54) and led to his
founding first of MYAM in 1961, an informal group
(with strong GRM connections: Abraham Moles,
Pierre Barbaud, Roger Blanchard, and Michel
Philippot);[5] then, more formally, to the creation of the
EMAMu, in 1967 (with mathematicians Marc Barbut,
François Genuys, Georges-Théodule Guilbaud), later
renamed the CEMAMu in the early 1970s, designating
it as a center for research. It is interesting to note
that the founding of the EMAMu in Paris corresponds
precisely with the start of Xenakis’s part-time tenure
at the University of Indiana at Bloomington, where
he was promised the means to create a “Center for
Mathematical and Automated Music” (CMAM).[6]
Between 1967 and 1972, when he resigned from
that position due to lack of real support in developing
the CMAM, Xenakis must have been expending

4.

See François-Bernard
Mâche’s chapter (Fig. 3),
Brigitte Robindoré’s chapter
(Fig. 3), and the preface by
Peter Weibel (Fig. 2), this
volume for score sketches of
Mycènes Alpha.

FIG. 1 A precursor of
Xenakis’s UPIC, 1963. In
“Des machines à penser?”,
screenshot from video taken
at 56:37. Courtesy of Edition
Point de vues © INA

5.

See Olga Touloumi, “The
Politics of Totality: Iannis
Xenakis’s Polytope de
Mycènes,” in, Xenakis
Matters: Contexts, Processes,
Applications, ed. Sharon
Kanach (Hillsdale, NY:
Pendragon Press, 2012).
MYAM, sometimes spelled
MIAM seems to be an
acronym of the main
protagonists’ initials: Michel
Philippot, Yannis (or Iannis)
Xenakis, Abraham Moles.
6.

See Charles Turner, Xenakis
in America (Tappan, NY:
One Block Avenue, 2014),
75–101. Available as
a free download here:
https://monoskop.org/
log/?p=12791

40

considerable energy in Paris during the several
months he was not on campus in the mid-West USA,
gearing up to launch the CEMAMu officially in early
1972.
However, our own research on a seemingly
unrelated topic, “Xenakis and film,”[7] reveals that
already in the early 1960s, Xenakis knew the UPIC
would include a “musical drawing board.” In Xenakis’s
personal archives, we find a trace of a letter dated
December 12, 1961, when the composer was
active at the GRM, from the studio’s director Pierre
Schaeffer, inviting Xenakis to a meeting about
“Thinking machines.”[8] Indeed, two years later, a film
was produced for a French public television series
Visa pour l’avenir (Visa for the future) on the subject
of “Des machines à penser?”[9] (thinking machines),
which not only includes excerpts of Xenakis’s music
in the soundtrack, but also shows a precursor to the
UPIC drawing board being approached by a robot
with a writing instrument in its “hand” during the last
minutes of this one-hour documentary (see Fig. 1).
Perhaps it is therefore not a simple coincidence that
some twenty-five years later, Xenakis revisits this
combination of robots and the UPIC in his previously
unknown (because alas unrealized) visionary project,
Ballet for Emancipated Robots, revealed here by
HENNING LOHNER , who attempted to produce it in
Germany, at Xenakis’s request, in the late 1980s.
However, even well before that, we know Xenakis
had reverted to making graphic transcriptions of works
from the repertoire, as Bálint András Varga recounts
in a comment during his interview in 1980 with the
composer:
Xenakis rose and produced some thick folders
from a bookshelf. Suddenly, unexpectedly, he came
face to face with himself of thirty years before. […]

41

FIG. 2 Iannis Xenakis,
graphic transcriptions of
excerpts from Ravel’s
Douze Chants (p. 36) and
Chopin’s Nocturne,
op. 9 no. 1, undated
© Iannis Xenakis Family

7.

See Sharon Kanach,
“Xenakis et le film: la face
cachée du compositeur,” in
Xenakis et les Arts, ed. P.A.
Castanet, S. Kanach (Rouen:
Editions Point de vues,
2014), 128–145.
8.

Source: Iannis Xenakis
Archives, catalogued under
OM 16/4 while on deposit at
the Bibliothèque national de
France. At the end of 2014,
Xenakis’s heirs withdrew this
collection from the BnF (cf.
Reinhold Friedl’s interview
with Mâkhi XenakisKlatzmann on WDR on May
13, 2015: Archivnummer
5189 962).
9.

See:
https://www.ina.fr/video/
CPF86656441

42

43

Another piece of paper showed a Bach fugue
with the structure shown in different colours on
squared graph paper. This was also a product of the
student years. (Manuscripts from 1955 and then from
December 1949).[10]
While compiling the general inventory of Xenakis’s
personal archives for the Bibliothèque de France soon
after they were deposited there, with Benoît Gibson
and Makis Solomos, we never came across this colored
graph of Bach; however, we did discover a similar
document, also a graphical treatment of passages from
Chopin and Ravel (see FIG. 2).

10.

Bálint András Varga,
Conversations with Iannis
Xenakis (London: Faber &
Faber, 1996), 27–28.

FIG. 3 Le Corbusier (left)
and Xenakis (right) in the
former’s studio in Paris ©
Lucien Hervé

Finally, Xenakis permanently adopted the
“occupational deformation” of working while standing
that he had acquired during the twelve years in Le
Corbusier’s studio (1947–1959),[11] a habit he never
lost, even when composing instrumental music in
traditional notation.
For the first time ever, in this book, we get
to relive “The Early Days of the UPIC,” the actual
conception of the UPIC, from the pen of the engineer
who personally worked side by side with Xenakis to
create the first official prototype, both inside and
out, GUY MÉDIGUE . We not only discover what choices
were made and why, but also gain an insight of
their race against the clock that perhaps caused
some of the limitations of this first realization and
which subsequently became inherent in its future
iterations.[12]
ALAIN DESPRÉS was the first director of Les Ateliers
UPIC, the entity created by Xenakis in 1985 specifically
to promote the system beyond the confines of his
research lab CEMAMu to the broadest public possible.
In his article “UPIC: Towards a Pedagogy of Creativity,”
we learn of the UPIC’s odysseys throughout Europe,
twice to Japan, and a grand tour spanning from Mexico
to Quebec. Little by little, we witness UPIC’s profile
being defined independently yet simultaneously as a
pedagogic tool for initiating music training and as a
tool for professional composers.
RUDOLF FRISIUS specifically addresses Xenakis’s
UPIC as a tool for Experimental Music Pedagogy and
appraises it within the tradition of European post-WWII
music education at large and also within the approach
of “notation reform” that was happening concurrently.
In the context of such societal transformations, he
addresses Xenakis’s own work directly involving the
UPIC, originally conceived as a radio play (but later
adapted for several distinct concert versions), Pour la
Paix (1981).

11.

See Iannis Xenakis and
Sharon Kanach, Music
and Architecture, Book 1
(Hillsdale, NY: Pendragon
Press, 2008), 3–124.

12.

Specifically, so far there have
been eight distinct versions
derived from the UPIC:
1977 = UPIC A
1983 = UPIC B (Intel 8086
version)
1986 = UPIC C (real time
version)
1991 = UPIC (Windows
version)
2001 = UPIX (software
version)
2014 = UPIX2014
(experimental UPIX update)
2018 = UPISketch 1.0 (for
mobile iOS devices)
2019 = UPISketch 2.0 (for
mobile iOS devices, OS,
and Windows)

44

The person who succeeded Després at Les
Ateliers UPIC for the following sixteen years (1991–
2007) was also the only private individual to ever
own an original, first-generation UPIC (which still
functions!). In his interview “Composing with Sound…”,
the American composer GERARD PAPE divulges to us
his reasons for enlarging Les Ateliers UPIC’s focus
to embrace other compositional tools alongside the
UPIC. In 2000, it was Pape, with Xenakis’s consent,
who renamed Les Ateliers UPIC the Centre de Création
Musicale Iannis Xenakis (CCMIX) to honor its founder.
In 2007, a new team was appointed by the
French Ministry of Culture to run the CCMIX, which
was rapidly and simply renamed Centre Iannis Xenakis
(CIX), as it is still called today, with a stated mission
to refocus, very specifically, on the “artistic and
intellectual legacy of Xenakis and the UPIC.”[13] One of
the first tasks we accomplished at CIX was to create
a general inventory and begin cataloguing our unique
collection of archival items accumulated over a long
time span and by so many (sometimes confusingly)
articulated institutions. CYRILLE DELHAYE , responsible
for the CIX’s archives and their dissemination,
recounts in his essay “Milestones and Challenges”
in this volume what we have accomplished so far,
some of the challenges we still confront, and offers a
casestudy of what research in our archives can yield.
It is also thanks to Delhaye’s preliminary work in the
CIX archives that we were able to identify and contact
key figures in our history, such as Guy Médigue and
Alain Després, amongst others, as well as several
composers included in this volume such as Richard
Barrett, Takehito Shimazu, Dimitris Kamarotos, and
so on. VICTORIA SIMON’s chapter “Unflattering Sounds…”
also originates in part from a three-month research
residence in 2016 in the CIX Archives in Rouen that
she did while a PhD candidate at McGill University,
Montreal.

45

13.

See: Fernand
Vandenbogaerde, Rapport
d’inspection du CCMIX,
unpublished, December
2006 (CIX Archives,
uncatalogued)

During the important stages of UPIC’s
development, HUGUES GENEVOIS was at the French
Ministry of Culture overseeing research activities,
and he offers a behind-the-scenes and personal
perspective on how and why certain decisions were
made that impacted life both at the CEMAMu and
Les Ateliers UPIC. He also offers an enlightening
contextualization in relation to other institutions
in France at the time; let us not forget that IRCAM
opened in 1977, the same year the first UPIC was
launched. Finally, to end this historical part of our
book, one of the best-kept secrets of the Xenakian
community is finally revealed: the same year Les
Ateliers UPIC was founded, Xenakis also opened the
KSYME (Contemporary Music Research Center) in
Athens, Greece, with local colleagues, which was the
only public music center and studio outside France
to possess and utilize a UPIC both for educational
purposes and as a tool of creation. KATERINA TSIOUKRA
meticulously explains the genesis of this project, and
even how Xenakis proposed to the then Greek President
Karamanlis that he could return permanently to Athens
to head this center. Then follows the rich and unique
testimony of DIMITRIS KAMAROTOS, who was intensely
involved with all of KSYME’s UPIC-related activities,
offering us detailed accounts and appreciation of the
creative life of and within this institution. After being
dormant for several years, the KSYME has recently
integrated the Athens Conservatoire, and its invaluable
archives are now entrusted to that library. The CIX and
KSYME have already begun a close cooperation and our
goal is to mutualize our archives to streamline future
Xenakian and UPICian research, without borders.[14]
THE BLANK PAGE:
COMPOSERS EXPERIENCING THE UPIC

Xenakis always intended the UPIC to be a neutral
space, where either the uninitiated or experienced

14.

This aspect of our
cooperation is also
addressed in Cyrille
Delhaye’s chapter,
this volume.

46

composers could have free rein to express themselves
without any aesthetic impositions made by the system
itself. Of course, this was rather utopian, especially
given the technological limitations at the time, but it
was his goal.
The entries comprising the second section can
be seen as “user reports” about some of the most
original individual approaches made with the UPIC.
We start with JULIO ESTRADA , who was initially invited
to take over the CEMAMu after Xenakis’s death
in 2001, before the French Ministry of Culture
decided simply to close it down in 2002. His prior
experience with the UPIC, both as a composer
and as an instructor, notably with groups of blind
children, provided him with the hands-on knowledge
necessary for outlining future directions for the
system, which he publicly shares here for the first
time. Furthermore, he develops his fascinating
transformation of his important, yet only work on the
UPIC, eua‘on (1980), into a work for large orchestra,
eua‘on‘om (1995).[15] Finally, his compositional
experience with the UPIC was fundamental to
the development of his theory of continuum–
discontinuum which he discusses here as well.
RICHARD BARRETT composed his stunning The
Unthinkable in 1989 at Les Ateliers UPIC. We discovered
a poignant “user’s report” written by him at the time in
the CIX archives which I dared to ask him to revisit for this
volume. His acceptance of the challenge and reflections
on a work from thirty years ago is moving, telling, and
informative. In his original report, he included eight
suggestions for improvements to the system, several of
which were indeed implemented in subsequent versions
of the UPIC. But especially today he describes what
working on this piece taught him as a composer, when
those “miraculous accidents” occur, which led him to
seek out spontaneity rather than obsessive control. He
invites us to do a comparative listening between The

47

15.

Interestingly, Xenakis also
noted in an unpublished
recorded interview with
Alain Després (undated)
how his Mycènes Alpha
(1978), composed on the
UPIC, influenced his work
for large orchestra and
chorus, Anemoessa (1979)
(See: CIX Archives, item
0477–01, at ca. 5'.) Due to
copyright restrictions, only
the first three minutes of
this informative interview (in
French) can be consulted
online here:
http://www.centre-iannisxenakis.org/items/show/105
See also Benoît Gibson,
The Instrumental Music
of Iannis Xenakis: Theory,
Practice, Self-Borrowing
(Hillsdale, NY: Pendragon
Press 2011), 208. Gibson, in
his impressive “Genealogy
of Xenakis’s Works” at the
end of his book, indicates
that there Xenakis “borrows”
from Mycènes Alpha
in Anemoessa, without
specifying any instances.

Unthinkable and a very recent electronic work, disquiet
(2019) to discover for ourselves any similarities, and it is
certainly revealing.
One of Xenakis’s closest and oldest friends,
FRANÇOIS-BERNARD MÂCHE, was probably the first other
composer to use the UPIC as a tool for composition.
His pioneering approach ended by turning it “upside
down,” generating several remarkable works such
as Tithon (1980) and Hypérion (1981). He was
also one of the first, if not the very first, to combine
acoustic instruments with UPIC-generated tape in
compositions such as Nocturne (1981) for piano and
tape. Furthermore, as director of the Primus sound
lab at the Université de Strasbourg, Mâche purchased
a UPIC in 1987, and fully integrated its mastery in
the first ever (in France) specific training program for
sound engineers.
In all, Les Ateliers UPIC made two tours of Japan
under the direction of Alain Després, the first one
taking place in 1984. In early 1990, the Japanese
composer TAKEHITO SHIMAZU was first introduced to the
UPIC in Paris. Immediately upon his return to Japan,
Shimazu began organizing a second UPIC tour of his
country, which took place in October of the same
year, managed by Després and Les Ateliers UPIC.
Later Shimazu invited Les Ateliers UPIC (then under
Gerard Pape’s directorship) to participate in the ICMC
(International Computer Music Conference) conference
hosted in Tokyo in 1993. Shimazu's unique approach
of integrating traditional Japanese ideas in his UPIC
compositions, whether for tape (Monodie IV, 1990),
mixed (Monodie IVa, 1990) for tape and percussion,
or Illusion in Desolated Fields (1994) for tape and the
traditional Japanese string instrument sangen, are
distinctly personal and refreshing.
As the author of the internal “User’s Guide” for the
real time version of the UPIC in the early 1990s,[16]
BRIGITTE ROBINDORÉ certainly knows—inside out—what

16.

Brigitte Robindoré,
The UPIC User's Guide and
Tutorial, 1992, Université de
Rouen, CIX Archive 4/224.

48

that last hardware iteration of the UPIC was capable of
producing, as well as its inherent limitations. Despite
the hundreds of composers’ forays into the UPICian
universe, the subtitle alone of her chapter—“The
Undiscovered Terrains of the UPIC” is extremely
intriguing, and we at CIX are now in close contact with
Jean-Michel Raczinski, the main architect of that version,
to attempt to restore to full working order at least one of
our UPIC mainframes. It is rather encouraging to think
that the historic UPIC has still not said its final word!
XENAKIS AT THE UPIC

Although Xenakis wrote only five works on the UPIC
(and ultimately pulled the last one, Erod (1997)
from his catalogue), they are part of his opus of
electroacoustic works, which itself is proportionately
small in relation to his entire musical output, around
ten percent, yet among his most influential and
pioneering works. His UPIC works represent roughly
one-third of that category and, aside from the very
first work ever to be created using only the UPIC,
Mycènes Alpha in 1978, the remaining three works
were all composed in the 1980s. Like the UPIC itself,
these works can be approached and analyzed in an
infinite number of ways. RUDOLF FRISIUS’s sociological
approach to Pour la Paix (1981) has already been
mentioned. RONALD SQUIBBS offers a “Listener’s guide”
to the very first work ever to be created using only the
UPIC, and which is perhaps the most iconic UPIC work
to date, Mycènes Alpha (1978). Unlike his other UPIC
works, Xenakis provided his publisher, Salabert, with
the UPIC score for publication. Therefore, it is readily
available online for consultation while listening to this
work and, after reading Squibbs’s analysis, identifying
repetitions and various structural and temporal
perspectives, we are surely able to better comprehend
Xenakis’s focus on the actual listening experience of
this masterpiece.

49

The attraction of the relatively new realm of digital
musicology becomes apparent in PIERRE COUPRIE’s
analysis which covers the two remaining UPIC works by
Xenakis: Taurhiphanie (1987) and Voyage absolu des
Unari vers Andromède (1989). Couprie’s proprietary
software iAnalyse offers stunning and insightful new
perceptions that complement the meticulous archival
research of both the drawings and the audiotapes that
the composer has left us. Unprecedented visualizations,
in vivid colors, enable us to see what, in fact, the
composer was doing, either intuitively or consciously,
and therefore increase our appreciation of his work.
Occasionally, unearthing or rediscovering
unrealized projects can shed enormous light on
a creator’s most profound intentions. Often, they
reveal wildest dreams, an utopian vision, a drive to
surpass one’s own limits, and this is indeed the case
with Xenakis’s unrealized “Ballet for Emancipated
Robots.” HENNING LOHNER, who as mentioned above,

FIG. 4 Group photo taken
in a Greek restaurant in
Karlsruhe, September 28,
2018, from left to right:
Guy Médigue, Cyrille
Delhaye, Rodolphe Bourotte,
Alain Després, FrançoisBernard Mâche, Marie-Luce
Staib-Mâche
© Marie-Luce Staib-Mâche,
photo: Sharon Kanach

50

51

was solicited by Xenakis to try to get this project off
the ground in Germany after his own failures in France
and in Italy, recounts with passion his adventure and
why it ultimately had to be shelved. His comparative
chronology between the advent of robots and
Xenakis’s own life resounds eerily like it is more than
a simple coincidence.

Cocurating this book has been a journey on
which I learned many new things, although I’ve been
on the “inside” for decades. I truly hope our readers,
too, will be enlightened through the discovery of little
or previously unknown facts about the UPIC. Like all
major breakthroughs, Xenakis’s initial intuition required
incredible teamwork, institutional cooperation and
support, plus dedicated users to enable it to become
a reality, thrive, dwindle, and then thrive again over
nearly half a century. Although authoritative, this book
was never intended to be exhaustive; it is rather an
invitation for future research showing that different
perspectives can yield multiple and unforeseeable
horizons. May this publication, too, be a prelaunch of
centenary celebrations of the life and work of this great
yet humble man, Iannis Xenakis.

STATE OF THE ART

Innumerable lives have been transformed by either
brief or extended encounters with the revolutionary
UPIC system, and hundreds of works have been
composed using it. This volume, a first scholarly
approach to the subject under many of its historical,
current and future aspects, hopefully also renders
palpable the creative, human, and even emotional
impact it has made—not only on those of us who
knew and worked closely with Xenakis over the years.
Even our own recent meeting—for the first time—with
the actual people behind the myths that their auras
have generated in the UPICian universe, such as Guy
Médigue and Alain Després, in Karlsruhe during the
conference Graphic Interfaces for Notation which the
Hertz-Lab at ZKM | Karlsruhe organized cooperatively
with the CIX as a prelude to this book in late 2018,[17]
felt like a “welcome home” celebration.
My sincere gratitude to all our authors who
willingly accepted the challenge to commit to paper
their experience which will now enter the annals
of verified history. Profound thanks, too, to MarieEmmanuèle Verrier, secretary of the CIX, who knew
how and when to save the day by transcribing some
of the oral testimony gathered while compiling this
volume. Also, we at CIX welcome this opportunity
for our modest association, that runs on extremely
limited financial resources, but is a treasure trove of
memories, experience, and commitment, to cooperate
with the important institution ZKM | Karlsruhe.

SHARON KANACH

FIG. 5 Iannis Xenakis at the

CCMIX, 1995 © Curtis Roads

17.

https://zkm.de/en/
event/2018/09/upicgraphic-interfaces-fornotation-conference

THE UPIC:
HISTORY,
INSTITUTIONS,
AND
IMPLICATIONS
ANDREY SMIRNOV
GUY MÉDIGUE
ALAIN DESPRÉS
RUDOLF FRISIUS
GERARD PAPE
HUGUES GENEVOIS
CYRILLE DELHAYE
KATERINA TSIOUKRA
DIMITRIS KAMAROTOS
RODOLPHE BOUROTTE

UPIC’S
ANDREY SMIRNOV

PRECURSORS

97

ANDREY SMIRNOV

UPIC’S PRECURSORS

ANDREY SMIRNOV

The UPIC (Unité Polygogique Informatique du CEMAMu) is a computerized
system designed and implemented in 1977 by Iannis Xenakis and the
engineers at CEMAMu, and made for a Solar computer mainframe.[1]
It consists of a digitizing tablet connected to a computer, which has a
vector display. It is not an instrument to sonorize drawings, but rather
a tool for composition which allows one to translate drawings into a
musical piece by means of a graphical approach that replaces traditional
music notation. The UPIC was also a digital synthesizer, capable of
working mainly with additive synthesis and frequency modulation. The
system allows for real-time performance by moving the stylus across
the tablet, and it enabled not only the definition of the score but also its
execution. As Xenakis put it: “Anybody, even myself, or you, or children,
can draw lines or graphics with an electromagnetic ballpoint, and they
are transformed by computer directly into sound.”[2] It was an “interactive
composing environment based on drawing and manipulation of images
of waveforms, envelopes, and sonographic spectra,”[3] revealing new
musical possibilities as harmonic or temporal events are shaped over
time and woven into a musical narrative. Which, in its turn, opens up
a way to explore the conceptual and perceptual boundaries between
timbre and harmony, frequency and pitch, rhythm, duration, form, and the
evolution of processes implied by the physical properties of sound. The
UPIC is therefore closely allied with technological developments in the
field of audio analysis and synthesis, psychoacoustics and the perception
of music, engaging these phenomena as a fundamental aspect of new
musical discourse.
The first known attempts to realize this idea were undertaken as
early as the first half of the twentieth century by various mechanical,
optical, and, later, electronic means when researchers involved in sound
synthesis faced growing mountains of controls and related parameters
or, in the case of audio computing techniques, tedious, repetitive
calculations. Arithmometers and abacuses were widespread, but too slow
and outdated. Artists and inventors around the world—often unaware of
each other yet following parallel paths—tackled the challenge.
In 1938 Percy Grainger, an Australian-born polymath—a pianist,
composer, conductor, ethnomusicologist, inventor, artist, and polyglot—
decided to create his first technical device to compose “free music:”
music that was free from scales, fixed intervals, rhythmic constraints, and
other conventions. As he put it: “It seems to me absurd to live in an age of
flying, and yet not be able to execute tonal glides and curves.”[4] In 1944

99

ANDREY SMIRNOV

Grainger met a scientist, Burnett Cross, and they began a collaboration
to build the Free Music Machine. Cross describes the project:
Granger wanted a composer’s machine, not one for the concert
hall. As he said, he wanted to hear in actuality the sound he had
heard in his mind for many years [...] The Free Music Machine had
to be able to play any pitch within its range. It was to be free of
the limitations of speaking in half tones, or quarter tones, or eigth
tones for that matter [...] The machine had to be able to go from
pitch to pitch by way of a controlled glide as well as by a leap [...]
The machine had to be able to perform complex irregular rhythms
accurately, rhythms much too difficult for human beings to execute
[...] The machine had to be workable by the composer. It was not to
require a staff of resident engineers.[5]

FIG. 1 Percy Grainger and Burnett Cross working on a Free Music tone-tool experiment
at White Plains, ca. 1950. Courtesy and © Grainger Museum Collection, University of
Melbourne
FIG. 2 Kangaroo-pouch Tone-tool Free Music experiment created by Percy Grainger

and Burnett Cross, created after 1955. Courtesy and © Grainger Museum Collection,
University of Melbourne

Perhaps the most famous of Grainger’s and Cross’s machines was
the “Hills and Dale” or “Kangaroo Pouch method of synchronizing and
playing eight oscillators,” which had rolls of paper, with the edges cut
in a wavy pattern, made to turn on a roller. The final version of the Free
Music Machine, called “Electric Eye Tone Tool,” was, however, purely
electronic. It was completed in the mid 1950s and in its last version,
the cut paper outlines were replaced by patterns painted on rolls of
clear plastic. A row of spotlights shone through the plastic projected
light beams onto an array of photocells, which in turn controlled the
oscillators. The inventors were working on this device at the time of
Grainger’s death (1961).[6]
While Grainger considered his concept of “Free Music,” as well as
the experimental machines to create it, to be “his only truly valuable and
original contribution to music,”[7] his attempts produced no follow-up;
they were quickly overtaken and nullified by new technological advances.
At the end of World War II, when planes were being
decommissioned, a Canadian physicist, composer, and instrument
builder, Hugh Le Caine, began collecting parts from these planes,
especially the oscillators used in wing de-icers, which produced
sine tones. In 1957, Le Caine took up this idea again and produced
the “sine bank.” Between 1957 and 1959 Le Caine created a bank
of 108 oscillators, which he designed to work with his tool called the
Spectrogram, which used 100 photocells to read a graphic score
(although only 24 were functional in the McGill Electronic Music Studio).
A composer with an idea, using 10”-wide graph paper, would use
India ink to completely blacken a track (2,5 mm wide) or part of a track
on the paper. When the paper passed under the light emitted from

100

the 300-watt bulb, no signal would pass lightened sections, but when
darkened sections of the score passed the photocells, the specified
oscillators would sound.
In 1961 Le Caine created two smaller Oscillator Banks with
variable waveforms, operated by touch-sensitive keyboards. The final
version of the Spectrogram controlled 25 separate output lines, each
of which could be fed to an oscillator or to another device. It was used
with the smaller oscillator banks, but the size of the graph paper makes
it clear that the Spectrogram had originally been designed for a larger
number of generators.
It was a tiresome process to do anything that was going to be
controlled in any detailed way. The paper roll could be moved at various
speeds, with a 12” (30,5 cm) drawing passing under the light in one to four
seconds. Thirty cm of “score” could easily take several hours to draw with
the result often being poor and frustrating. Few people had the time to
devote to getting more than a few seconds of the sequenced sine tones.[8]
During her BBC training in 1947, the British composer and electronic
musician Daphne Oram encountered a cathode ray oscilloscope which
shows a visual image of sound waves. Her intention was to reverse the
process so that if you paint the shape of the sound wave you want to
hear on 35 mm film, determining the pitch, vibrato, timbre, and so on,
scanners could read and convert that into layered sound. This idea led to
the development in 1957 of a drawn sound technique called Oramics. The
machine was further developed in 1962 after receiving a grant from the
Gulbenkian Foundation.
Oramics is audiovisual in nature; that is, the composer draws onto
a synchronized set of ten 35 mm film strips which overlay a series of
photoelectric cells, generating electrical signals to control amplitude,
timbre, frequency, and duration. Daphne said of Oramics, “I visualize the
composer learning an alphabet of symbols with which he will be able to
indicate all the parameters needed to build up the sound he requires.
These symbols, drawn freehand on an ordinary piece of paper, will be
fed to the equipment and the resultant sound will be recorded onto
magnetic tape.”[9]
As the playwright Isobel McArthur pointed out, “That gestural
interface means all people become composers, conceivably, which ties
back into her philosophy which says that, at a molecular level, we are
sounds. We are all made up of noisy atoms and vibrations—sound is at the
core of who we are. I find that really inspiring.”[10]
However, after Daphne left the BBC (in 1959), her research, including
Oramics, continued in relative secrecy. Although for many years Oram was
rejected by the establishment, written out of the male-dominated

UPIC’S
PRECURSORS

FIG. 3 Hugh Le Caine, Spectrogram, 1954 © National Research Council Canada Archives
FIG. 4 Hugh Le Caine, Spectrogram, 1954 © National Research Council Canada Archives

103

ANDREY SMIRNOV

history of electronic music, recent years have started to throw new light
in her direction.
Perhaps the most fascinating story relates to the invention of the
photoelectronic musical instrument called the ANS Synthesizer (its
name was derived from the initials of influential composer Alexander
Nikolayevich Scriabin), which was built and patented by the inventor
Evgeny Murzin in 1957 in Moscow. The story starts as early as in the
summer of 1917 in Petrograd when the young inventor Evgeny Sholpo,
inspired by the ideas of the composer and theorist Arseny Avraamov,
wrote a science fiction essay entitled “The Enemy of Music” in which he
described a sound machine named the Mechanical Orchestra, capable
of synthesizing any sound and producing music according to a special
graphical score without any need for a performer.
In his essay, Sholpo describes the activities of an imagined friend—
a sort of polymath, combining the skills of a musician, composer, and
analyst on the one hand, and a scientist, technologist, mathematician, and
psychophysiologist on the other—who “fulfilled the dream of a mechanical
orchestra, of full mastering of timbres [...] And compositions in the form of
graphical diagrams [...].”[11]
According to Sholpo’s description, the instrument was an exact
prototype of the future ANS Synthesizer, built forty years later by Evgeny
Murzin. The instrument incorporated a set of sine wave oscillators, based
on numerous Helmholtz tuning forks, adjusted on fixed frequencies,
forming a discrete microtonal scale, covering the whole audible range
with intervals between successive pitches imperceptible to the human
ear. Control over the process of sound synthesis was to be carried out
by means of a special graphical score with the diagram, representing
the spectrum of a sound by means of cut-out transparent strips having
appropriate shape and slopes, read by a special optical system, based on
selenium photocells.

FIG. 5 Daphne Oram working at the Oramics machine at Oramics Studios for

Electronic Composition in Tower Folly, Fairseat, Kent, ca. 1950. Courtesy and ©
Daphne Oram Trust

The bulky construction occupies half a room, with black paper tape
stretching from one wall to another with a diagram of music made up
of cut-out longitudinal holes similar to those of a pianola, a network of
electric cables, and a set of megaphones—all of which can be justified
technically, but its basic principles were simply too complicated. Each
electromagnetic tuning fork equipped with a resonator had a constant
pitch and could be switched on irrespective of the others. Thus, a number
of audio frequency generators made rather fractionally tempered scales
in a range from low basses up to the highest overtones. […] Owing to the
divisibility of a pitch scale, glissando appears to be almost ideally smooth,
having no audible intervals between successive tones. [...] The intensity

UPIC’S
PRECURSORS

104

of separate sounds, both in a melody and in chords, was set by adjusting
a width of cuts of the diagram through which light beams, produced by
a special light source and could reach the selenium elements of the
conductors that lead an electric current to the magnets of the generator
tuning forks.[12]
In fact, Sholpo offered not simply a new technique, but a new
concept for the reconstruction of the technical basis of music, capable
of bringing about a paradigm shift in musical thinking, and demanding
new theoretical substantiation. It anticipated future approaches of
electroacoustic and spectral music. Sholpo writes:
Arbitrary access to timbres brings forth a whole arsenal of new laws,
previously unavailable to us. […] I have begun my research with
the elementary things—rhythm, melody, and harmony (i.e., the new
harmony, based on overtone combinations).[13]
In fact, Evgeny Sholpo was not the only inventor envisioning a
graphical user interface as the best way to replace the classic musical
score to control the process of musical performance as a kind of
preprogrammed acoustical process. A little later, in 1926, the inventor I.
Sergeev patented the Electro-Optical Musical Instrument—a sort of sound
synthesizer, based on a rotating disc with discrete concentric optical
soundtracks consisting of transparent holes, with the frequency of each
track increasing from the disc’s center to its periphery. Control over the
process of sound synthesis and music production was carried out by
means of a graphical score.
Meanwhile, in 1929, the method of Graphical (Drawn) Sound was
discovered by Arseny Avraamov, Evgeny Sholpo, and Michail Tsekhanovski.
It was a way of creating artificial graphics of a movie soundtrack, based on
data of acoustics and mathematical calculations. It was a consequence of
the newly invented sound-on-film technology, which made possible access
to sound as a visible graphical trace in a form that could be studied and
manipulated, which permitted to synthesize difficult polyphonic works
without any participation by performers.
Among the Graphical Sound pioneers was the young painter and
acoustician Boris Yankovsky, who established his own laboratory in
Moscow in 1932. In 1935, in one of his unpublished manuscripts,
Yankovsky wrote:
It is important now to conquer and increase the smoothness of
tone colours, flowing rainbows of spectral colours in sound, instead

FIG. 6 I. Sergeev, Electro-Optical Musical Instrument, image from the USSR patent
N12625, applied in 1928. © Andrey Smirnov Archive

UPIC’S
PRECURSORS

106

of monotonous colouring of stationary sounding fixed geometric
figures [wave shapes], although the nature of these phenomena
is not yet clear. The premises leading to the expansion of these
phenomena—life inside the sound spectrum—give us the nature of
the musical instruments themselves, but ‘nature is the best mentor’
(Leonardo da Vinci). […] The new technology is moving towards the
trends of musical renovation, helping us to define new ways for the
Art of Music. This new technology is able to help liberate us from
the cacophony of the well-tempered scale. [...] Its name is
Electro-Acoustics and it is the basis for Electro-Music and Graphical
Sound.[14]
Boris Yankovsky’s intention was to study structural similarities and
distinctions among spectra of sounds of different character to limit as far
as possible the number of calculations needed for additive synthesis of
various complex sounds. His method was based on pure audio computing
techniques and possessed properties very common in digital technologies,
such as discretization and quantization of audio signals and related
spectral data, manipulation with ready-made parts, and operations
with selections from databases of the basic primitives (templates) that
distinguish it from the methods of analog signal processing. His “spectral
templates” were in fact semiotic entities that could be combined to
produce sound hybrids, based on a type of cross synthesis. The purpose
of his research was to fill the gaps between orchestral sounds by means
of developing new types of intermediate tone color production. As options,
Yankovsky developed several sound processing techniques including pitch
shifting and time stretching.
From the start, Yankovsky intended to work with a modified animation
stand called the Vibroexponator, shooting still images of artificially
drawn sound waves by means of a rostrum camera. This meant that the
discretization of the time scale was predetermined by twenty-four frames
per second, with each successive frame containing one stable sample—
a sort of momentary snapshot of the constantly changing sound. The
change in sound was enabled by cross-fades between successive frames.
Another part of the Vibroexponator incorporated a special multi-segment
mask to produce fast envelopes with discretization, equal to three steps
per frame, to produce amplitude and spectral vibrato. The final processing
included using the top part of the Vibroexponator to produce slow
graphical envelopes. [15]
Despite its beautiful concept, Yankovsky’s method lacked any
appropriate user interface. To get at least very rough results without
a computer, a researcher had to spend enormous efforts and time,

107

ANDREY SMIRNOV

incompatible with a single human life. The solution was found in 1938
when Yankovsky met Evgeny Murzin, a young inventor fascinated by the
idea of a universal tool for sound synthesis. By 1939 the concept of the
new instrument had been developed and, finally, the photo-electronic tool
called the ANS Synthesizer was built in 1957 by Evgeny Murzin without
any institutional support, only thanks to the help of his family and friends.
For two years the instrument was based at Murzin’s summer house in a
suburb of Moscow until it was hosted in 1959 by the Scriabin Museum in
Moscow. The first composers who had access to the machine were Andrey
Volkonsky and, somewhat later, Eduard Artemiev and Stanislav Kreichi.
Based on the Graphical Sound approach the ANS was remarkably
close to the concept of Evgeny Sholpo’s Mechanical Orchestra. The
instrument incorporated a set of optical sine wave oscillators, adjusted on
fixed frequencies, forming a discrete scale, and covering the whole audible
range with intervals between successive pitches imperceptible to the
human ear. Four discs, used in the first version of the instrument, could
produce simultaneously 576 sine waves with frequencies covering the
whole audible range with an accuracy of seventy-two steps per octave or
1/6 of a semitone. This number of pure tones makes it possible to obtain a
smooth variance of pitch. The second version of the ANS was constructed
in 1964 and generated 720 tones covering the entire audible frequency
range.[16] To obtain pure sinusoidal tones the instrument incorporated
twenty half-octave bandpass filters with about one hundred vacuum tubes.
It was the first (and last) industrial sample of the instrument, built for a
special occasion: the Soviet Industrial Exhibition in Genoa, Italy, which took
place in 1964.
ANS could produce the sounding result in real time, permitting a
composer to manipulate the spectrum of sound instead of the waveform.
Control over the system and the process of sound synthesis was carried
out by means of a special graphical score with a diagram, representing
a spectrum of a sound by means of drawn transparent strips with
appropriate shape and slopes.
Working with the ANS, the composer etched onto a large sheet of
glass covered with a tar-like, non-drying mastic, a sonogram—a dynamic
spectrum of sound developed in time. The glass was then cranked (by
hand or by motor) across light beams. Scraping off a part of the mastic
at a specific point on the plate allowed light from the corresponding
optic phonogram to penetrate the reading device and be transformed
into a sound.
The performance tempo depended on the score-reading rate and
could be varied without changing the pitch and timbre of the sounds. The
graph of the coded composition resembled its notation in music in that

109

FIG. 7 Evgeny Murzin with the first version of the ANS Synthesizer, Moscow, 1962
© Andrey Smirnov Archive
FIG. 8 Optical disc for the ANS Synthesizer containing 144 soundtracks
© Andrey Smirnov Archive

ANDREY SMIRNOV

the horizontal axis represented time while the vertical denoted pitch. The
speed of the score could also be smoothly regulated, all the way to a
complete stop. All this made it possible for the composer to work directly
and materially with the production of sound.
In 1962 a special commission was formed to develop a new version
of the ANS Synthesizer and to start its production. It included among
others Leon Theremin, Boris Yankovsky, Andrey Volodin (inventor of the
Ekvodin Synthesizer), and Andrey Rimsky-Korsakov (one of the inventors
of Emiritone). The possibilities of the instrument should be extended
so that it would be able to digitize, store, and automatically retrieve
the graphic score by means of a newly constructed automated coder
and other electronic and mechanical means as well as magnetic-core
memory (predominant form of random-access computer memory from
1955 to 1975). According to the initial plan, the ANS would be based at
the studio (yet to be organized) at the Moscow State Conservatory, but in
the end the plan was changed: the instrument was never extended, and
in 1967, the studio of electronic music was established at the Scriabin
Museum in Moscow in affiliation with the record company “Melodia.”
The ANS Synthesizer was at its core. The composers and researchers
working with the ANS included Alfred Schnittke, Sofia Gubaidulina, Edison
Denisov, Eduard Artemyev, Stanislav Kreichi, Alexander Nemtin, Pyotr
Meschaninov, Oleg Bouloshkin, and Sandor Kalloś. The instrument
was used for scoring many films, in particular, several films by Andrei
Tarkovsky (for example, Solaris (1972) and Stalker (1979) with music
composed by Eduard Artemyev).
After Evgeny Murzin’s death in 1970 the studio was closed in the mid
1970s and the ANS was moved to Stanislav Kreichi’s studio at Moscow
State University. From 2004 to 2007 the ANS was based at the Theremin
Center at the Moscow State Conservatory, and in 2007 it entered the
collection of the State Museum for Musical Culture named after Glinka,
where it resides to this day and is maintained in good working order.
The ANS was one of the most successful graphic-based composition
machines available until it was superseded by early digital instruments.
In the realm of early computer music technology an approach similar to
that of the UPIC was experienced in the 1960s by Max Mathews with the
Graphic 1—a “remote graphical display console system” created by William
Ninke (plus Carl Christensen and Henry S. McDonald) at Bell Laboratories
in 1965. It was a large console containing a small control computer (the
DEC PDP-5) and, among other things, light pen and trackball input devices.
This console was connected to an IBM 7094 mainframe and a StrombergCarlson microfilm printer in another room. In 1968, the Graphic 1 system
was used by Max Mathews and Lawrence Rosler to develop the interactive

FIG. 9 The ANS score with the coder and controls. © Andrey Smirnov Archive
FIG. 10 Stanislav Kreichi, Graphical score of the ANS, ca. 1980 © Andrey Smirnov Archive

THE STREAM Alfred Schnittke, 1968, 5’55”, composed with ANS Synthesizer at the
Experimental Studio for Electronic Music at Skriabin Museum, Moscow, Russia, from
Electroshock Records – ELCD 011 Electroacoustic Music Volume IV Archive Tapes
Synthesizer ANS 1964–1971, 1999, excerpt from 3'03'' to 4'31'' © Alfred Schnittke

112

UPIC’S
PRECURSORS

graphical sound system on which one could draw figures using a light
pen that would be converted into sound thus simplifying the process
of composing computer generated music.[17] Also in 1970, Mathews
and F. Richard Moore developed the GROOVE (Generated Real-time
Output Operations on Voltage-controlled Equipment) system,[18] the
first fully developed music synthesis system for interactive composition
and real time performance using 3C/Honeywell DDP-24 (or DDP-224)
minicomputers. The GROOVE used a cathode ray tube (CRT) display to
simplify the management of music synthesis in real time, 12-bit D/A
for real time sound playback, an interface for analog devices, and even
several controllers, including a musical keyboard, knobs, and rotating
joysticks to capture real-time performance.[19]
Today, when numerous achievements of musical technology of the
early digital era are common and seem ordinary to us, inventions that
were invented before the computer age often seem extraordinary and
unexpected by comparison. Even in cases when their connection to UPIC
does seem particularly relevant, they nevertheless function as important
steps in establishing gravitational centers for future musical discourse. In
fact Iannis Xenakis’s UPIC was a long-awaited physical embodiment of the
idea of an interactive environment intended for a sound-oriented, multiscale approach to the composition of music, “when all levels of temporal
organization are freely composable at all steps in the compositional
process.”[20] Apparently, it was the first successful attempt to develop
a universal graphical interface for both sound synthesis and music
composition, based on the most recent computer technology at the time.

FIG. 11 The second version of the ANS Synthesizer. © Andrey Smirnov Archive

UPIC’S
PRECURSORS

114

FOOTNOTES
1.
See Médigue, this volume.
2.

Joel Chadabe, Electric Sound. The Past and Promise of Electronic Music (Upper
Saddle, NJ: Prentice Hall, 1997), 214.

3.

Curtis Roads, Composing Electronic Music: A New Aesthetic (New York, NY: Oxford
University Press, 2015), 17.

4.

Percy Grainger, Statement on Free Music, 1938, Grainger Museum, University of
Melbourne, Australia, quoted in John Bird, Percy Grainger (London: Elek Books,
1976), 283.

5.

http://www.percygrainger.org/prognot3.htm

6.

https://percygraingeramerica.org/blog/6987441

7.

Thomas P. Lewis, A Source Guide to the Music of Percy Grainger (White Plains, NY,
Pro-Am Music Resources, 1991), 153.

8.

https://econtact.ca/17_2/austin_lecaine.html

9.

Jo Hutton, “Daphne Oram: Innovator, Writer, and Composer,” in Organised Sound, 8
(2003), 49–56.

10.

http://www.bbc.com/culture/story/20170522-daphne-oram-pioneered-electronicmusic

11.

Evgeny Sholpo, “The Enemy of Music”, unpublished manuscript, Marina Sholpo
family archive. Translation by the author.

12.

Boris Yankovsky, “Analiz i sintez tembra” (Analysis and Synthesis of Timbre),
March 1935, Moscow. Unpublished article, Theremin Center Archive. p. 35.
Translation by the author.

13.

Ibid.

14.

Ibid.

15.

Andrey Smirnov, Sound in Z: Experiments in Sound and Electronic Music in Early
20th-Century Russia (Cologne: Walther König, and London: Sound and Music,
2013), 208–226.

16.

Stanislav Kreichi, “The ANS Synthesizer: Composing on a Photoelectronic
Instrument,” in Leonardo Music Journal, 28, no. 1 (1995), 59–62.

17.

http://120years.net/graphic-1-max-mathews-lawrence-rosler-usa-1968/

18.

https://en.wikipedia.org/wiki/Max_Mathews

19.

Ibid.

20.

Curtis Roads, Composing Electronic Music: A New Aesthetic (New York, NY: Oxford
University Press, 2015), 19.

THE
EARLY DAYS

GUY MÉDIGUE

0F THE
UPIC

121

GUY MÉDIGUE

THE EARLY DAYS
OF THE UPIC
After having worked as a computer engineer for nearly eleven years at
SEMA-METRA International,[1] then at CERCI,[2] which subcontracted me
out for several years to participate in the IRIA CYCLADES[3] project (French
premises of the Internet), I realized that I really wanted to work in the field
of computer music. I first applied to IRCAM, but without success. One of
my colleagues at CYCLADES, Jean Lebihan, told me at the beginning of
1976 that Iannis Xenakis, the director of the CEMAMu, was looking for
an experienced computer engineer to assist him in his projects. I applied
and was interviewed by Alain Profit, then director of the CNET[4] in Issyles-Moulineaux, who was likewise a founding member of the CEMAMu. He
expressed a favorable opinion to Xenakis.
So, in March 1976, Iannis Xenakis asked me to analyze and implement
the first version of a conversational system for composing music. He had
a commitment with the city of Bonn to present the system, which he was
to baptize Unité Polyagogique Informatique de CEMAMu (UPIC), at the
Beethoven Festival in May 1977.[5] Fearing he might not be able to meet the
deadline, Xenakis needed a professional computer engineer to jumpstart
the system’s implementation. My eleven years of prior experience was
immediately put to task as of March 1976 by analyzing and coding the first
version of the UPIC system, UPIC A, already in May 1976.
I worked with Xenakis at the CEMAMu until the end of 1980. In this
essay, I will briefly describe the context of hardware and computer music at
that time, and what exactly my contribution was at the CEMAMu and to the
development of the first UPIC.
BRIEF HISTORICAL OVERVIEW: HARDWARE

The mid to late 1970s was the era of minicomputers, although
microprocessors were not yet widespread in France (the very first INTEL
ones arrived in France in 1971). The level of hardware performance was
far from what it is today; for example, the minicomputer SOLAR 16–40,
ordered by the CEMAMu for the future UPIC, had the following features:

GUY MÉDIGUE

– words of 16 bits;
– 32K words of main memory;
– one fixed disk and a removable one of 2.5 Mbytes each;
– one million instructions per second (if I recall correctly);
– floating point unit.

THE EARLY
DAYS OF THE
UPIC

122

COMPUTER MUSIC, COMPOSERS, AND INSTITUTIONS

It is beyond the scope of this essay to describe the various and often very
complex ways that people in computer music had for making music at the
time. Below, however, is a list of the various teams I knew quite well and
that were working at the same time in France:
BBK led by Pierre Barbaud,[6] from 1976 at IRIA. Barbaud was one
of the first people in France to be passionate about computer music
(algorithmic music).
GRM: Pierre Schaeffer[7] and his disciples
ACROE: Claude Cadoz[8] and his team (Grenoble)
GRAME: Pierre-Alain Jaffrennou[9] and his team (Lyon)
CEMAM : Created in 1972 as the successor of the EMAMu (created by
Iannis Xenakis in 1966), the goals of this association (not-for-profit,
law of 1901), as stipulated in its by-laws, were:
U

– research on musical and graphic composition;
– easy to use computer tools;
– research on pedagogy for using the above tools;
– various users (no discrimination).
At the beginning of 1976 the team of the CEMAMu was composed
of: Cornelia Colyer, who worked (very hard!), mainly on creating
stochastic programs needed for Xenakis’s own research (pieces using
laws of stochastic processes, programs in FORTRAN on mainframe
computers); Patrick Saint-Jean,[10] who was helping Xenakis define
a conversational system using a large graphic tablet connected to a
minicomputer (the future UPIC).
IRCAM: The French government created this important center with
Pierre Boulez in 1974.[11] Some composers (Xenakis, Jean-Claude
Eloy, as well as others) quickly reacted against the monopoly position
of IRCAM. However, I personally thought that there was some very
interesting research being conducted there at the time, and it
surely continues to this day. I had contact in particular with Xavier
Rodet and Jean-Claude Risset and was very interested then in their
research. Risset was a subtle user of the MUSIC V software then
in vogue at IRCAM, and he made synthetic trumpet sounds that
even fooled professionals on the instrument. Rodet was especially
interested in the human voice, and with his CHANT algorithm, he
generated disturbing examples (vocalizations of “Queen of the Night”
by a synthetic singer). In 1978, Pierre Boulez invited the CEMAMu
team (Xenakis, Cornelia Colyer,[12] and me) for a drink at his large

123

GUY MÉDIGUE

apartment at the top of the Perspective II high-rise apartment
complex along the River Seine. On that occasion, he made an
appointment with me to come to CEMAMu to work with the UPIC,
however, he never showed up.
My personal feeling is that the tools created by these teams were
often difficult for composers to use who were not scientists familiar with
computers. In addition, the time needed to hear the result of any work was
too long to allow reactivity and empirical choices.
SOME BASIC ACOUSTICS: ANY SOUND

In the following, I will point out some basic acoustics that underlie the
technical development of the UPIC and its interface. The parameters
that can be changed by users of the UPIC can be traced back to the
characteristics of different sound waves.
A sound is no more than a variation of pressure of the air which
makes the eardrum vibrate. Therefore, collecting sound pressure values
at very close regular time intervals gives a good description of a sound.
These numbers are called samples. Subsequently, a computer is able to
process a sound. The number of samples per second is the sampling rate
(for example, and in general, 44,100 for a CD).
I remember that choosing the sampling rate for processing and
outputting digital sounds was a source of controversy between Xenakis
and IRCAM.[13] Xenakis thought that it was necessary to work with a
sampling rate far higher than the sampling rate strictly needed to hear
audible harmonics. Later, experiments were conducted at IRCAM on this
subject (with notes of a harpsichord). It seems that Xenakis was right.
A SOUND WITH A PITCH

A sound with a pitch is roughly a periodic vibration: this means that the
sound wave consists of the same pattern that repeats itself over time. FIG. 1
– This pattern is called the waveform and its occurrence a cycle.
– The duration of a cycle is called the period.
– The number of periods per second is the frequency.
The pitch of a periodic sound is linked with its frequency as shown
in FIG. 2 (for two consecutive octaves; the frequency of the higher is twice
the frequency of the lower one).

Two examples of
waveforms.

FIG. 3 Sine waveform (pure sound without harmonics) © Guy Médigue
FIG. 4 Letter A (in French) waveform © Guy Médigue

FIG. 1 A waveform and its duration © Guy Médigue

FIG. 5 An envelope describes the evolution of the amplitude of the sound pressure over
the duration of a sound © Guy Médigue

FIG. 2 How pitch and frequency correspond © Guy Médigue

FIG. 6 Two examples of envelopes © Guy Médigue

THE EARLY
DAYS OF THE
UPIC

126

127

GUY MÉDIGUE

EXAMPLE OF AN ACOUSTIC SOUND WITH A PITCH

FOURIER SERIES DECOMPOSITION

Below is an example of an acoustic sound with a pitch: a note of a
classical guitar with the duration of half a second. We can see that the
sound wave, which is complex at the beginning, becomes more and more
simple and smooth.

The sound pressure for any sound is the sum of sine vibrations as
shown below:

p=

Name

Frequenc

Fundamental

F

+ a2*sin(2vt+w2)

Harmonics 2

2*F

+ a3*sin(3vt+w3)

Harmonics 3

3*F

Harmonics n

n*F

a1*sin(vt+w1)

+ ....
+ an* sin(nvt+wn)

We notice that after half a
second, the waveform is
simpler but not yet a sine
wave.

FIG. 7 Classical guitar note (attack) © Guy Médigue
FIG. 8 Same classical guitar note (after half a second) © Guy Médigue

FIG. 9 Decomposition of sound into a sum of sinusoidal vibrations (here no phase
shifts) © Guy Médigue
FIG. 10 The sum of the pressure values corresponding to the sinusoidal vibrations of the
harmonics, reconstitutes the original sound © Guy Médigue

THE EARLY
DAYS OF THE
UPIC

128

For an acoustic sound, the fundamental and each of its harmonics
have their own envelopes. The particular timbre of an instrument
is essentially due to the various amplitudes of its harmonics, and
the variations of these amplitudes specified by their envelopes. And
everything can change with the pitch of the note! (There are some
stationary strengthened frequencies called “formants” and linked to each
instrument’s morphology). The drawing below illustrates this point:

We notice that the
envelope is shorter
when the order of the
harmonics increases.
So, at the end of the
sound, we hear only
the fundamental (the
waveform is a sine
wave).

FIG. 11 The envelopes of the harmonics for a medium-range note of an oboe
© Guy Médigue

129

GUY MÉDIGUE

WHAT WERE XENAKIS’S WISHES?

For me, at the beginning it was not easy to guess what Xenakis actually
wanted! However, I had two orientations for my work:
1. The program of activities the CEMAMu proposed in 1976 to the DGRST
(Délégation Générale de la Recherche Scientifique et Technique), which
was at once very ambitious and very imprecise. The main objectives of the
system to be built were listed in this report as follows:
– recording and storage of graphic forms and sounds in a database;
– visualize and listen to forms from the database;
– analyze given forms;
– simulate given forms;
– create forms artificially;
– research on software modules to transform forms;
– ease of use;
– research on creating an elementary pedagogy pertaining to visual
or sound structures.
2. The ideas coming from our meetings (with Xenakis, Patrick Saint-Jean,
and me) to define the system. I quickly made up my mind to keep only the
simple and clear ideas that I was able to understand:
– easy to use conversational system;
– basic objects drawn on the graphic tablet and recorded in “banks”
(waveforms, envelopes);
–“time*pitch arcs” drawn on the tablet and associated with 3
parameters (“labels”):
– a waveform from the bank of waveforms;
– an envelope from the bank of envelopes;
– a maximum amplitude chosen from the classical list: ppp to fff;
–“page of music”: set of time*pitch arcs drawn on the graphic tablet;
– computation of the “resulting wave” corresponding to a page.
This drastic reduction of the objectives was in fact necessary; first,
because of the hardware possibilities at that time, and second, because
of the deadline for Bonn: we had to be able to show a first version of the
system by May 1977 (Bonn Festival, see[5] and[8]).

THE EARLY
DAYS OF THE
UPIC

130

131

GUY MÉDIGUE

HARDWARE ORDERED

IMPLEMENTATION OF THE UPIC A: LOWERING OF AMBITIONS

This is the list of the hardware the CEMAMu then ordered to build the system:
– minicomputer SOLAR 16–40 with its disk unit (TELEMECANIQUE,
then CII);
– graphic tablet 100 cm*80 cm (TEKTRONIX 4954) with 4096*4096
addressable points;
– display console (TEKTRONIX 4014) with 4096*4096 addressable
points;
– imager (TEKTRONIX 4631);
– digital to analog converter 16 bits (DATEL DAC-HR16B): a specific
interface was needed, because Xenakis wanted to output sounds at
the rate of 52,000 samples per second;
– analog to digital converter 12 bits (TELEMECANIQUE AMH-080);
– tape drive (KENNEDY 9000, 800/1600 bpi, 75 IPS): a specific
interface with the SOLAR was needed.

Due to technical limitations of the equipment available at the time, we
were forced to revise our initial goals. Hardware constraints:
1. It was not possible to record many acoustic sounds into a bank
because of the size of disks (with 2.5 Mbytes you could record only
100 seconds at a rate of 25,000 samples per second). Nevertheless,
we had a bank of “sound waves,” in particular for sound waves
resulting from the computation of pages of music.
2. Because of the small size of the main memory, I had to code in
assembly language and divide the program into partitions, which
were loaded into the main memory only when it was useful (overlays).
3. In addition, we had a lot of problems at the beginning. The
minicomputer SOLAR was finally replaced before or around the end
of 1976 by a SOLAR 16–65.
BONN FESTIVAL DEADLINE:

At the beginning of May 1976, no hardware components had yet been
delivered and the analysis of the system was not completed. I told
Xenakis that it was impossible to have an operational version of the
system by May 1977. Mika Salabert, Xenakis’s publisher and friend,
donated 100,000 Francs[14] to enable us to hire a someone temporarily
to help me with the coding. I was very fortunate! A former colleague from
CERCI, Pierre de Bailliencourt,[15] had just come back from a sabbatical
year in America and was looking for a temporary job in France. He was
a computer engineer, too, and quickly became interested in the UPIC
system.
HARDWARE

FIG. 12 Hardware configuration for the UPIC A © Guy Médigue

We needed to make two specific adaptations to make the hardware
function according to our specifications:
– Digital to analog converter:
As mentioned above, this 16-bits converter was a DATEL DACHRB16B and completely passive. Xenakis wanted to output sounds
at a rate of 52,000 samples per second. It was a tough problem.
TELEMECANIQUE proposed a GPI32 coupling, which would have
made it possible to adapt to this prerequisite. Former colleagues
of mine from CERCI, very familiar with these kinds of problems,
proposed a “FIFO buffers solution,” and even suggested the
appropriate device: Advanced Microdevices 3341/2841. Patrick
Saint-Jean was in charge of the implementation of this adaptation.
But I also must mention the very efficient help provided to us by
the CNET bureau in Lannion, Brittany. Our last debugging was

THE EARLY
DAYS OF THE
UPIC

132

accomplished thanks to J. Génin at the CNET in Lannion, when
Patrick Saint-Jean was no longer at the CEMAMu.
– Tape drive:
The interface with the minicomputer was analyzed and implemented by
TEKELEC using an asynchronous coupler of TELEMECANIQUE (ASV01),
but the CEMAMu had to test it with the help of TELEMECANIQUE.

133

GUY MÉDIGUE

We chose min (dtp, dta) as the duration of the current step. Then, we
assumed that the pitch and the amplitude are constant during the step
(values at t time). However, notice that we did not take into account the
evolution of the waveform over the duration of a sound (when it roughly
becomes a sinusoid at the end). This explains the rather aggressive aspect
of the sounds of Mycènes Alpha, for example.

SOFTWARE WRITTEN AT CEMAMU

HOW TO USE THE UPIC A? THE GRAPHIC TABLET

The following section focuses on the core of the application, which is the
interface and its usability for the composer. The drivers and hardware
adaptations that were needed to reach this stage will be neglected since
this is not so essential in the context of this essay.
Our goal was to compute the samples of a “resulting wave”
corresponding to a “page of music” comprised of a set of “time*pitch arcs,”
each having a “label” (a waveform, an envelope, a maximum amplitude).
To compute the samples produced by a time*pitch arc (samples to be
added to the current resulting wave), we had to divide the duration of the
time*pitch arc into small steps. At instant t, the duration of the next step
was computed using two parameters of the system: a “pitch grain” (pg)
which is the smallest variation of pitch we wanted (half a comma, for
example), and “amplitude grain” (ag) which is the smallest variation of
amplitude we wanted.
Using the time*pitch arc and the envelope at t time, we then compute
the corresponding time intervals dtp and dta, as shown in the drawings below:

The composer uses solely the electronic pen of the graphic tablet for
expression. The composer can draw waveforms, envelopes, time*pitch
arcs, or point at the boxes of menus to select an object from one of the
banks or to request an action. The graphic tablet is divided into three parts:
1. The largest part is devoted to drawing on a system of reference with
two axes. The horizontal axis is always time; the vertical axis can be
the sound pressure (drawing of waveforms or envelopes) or the pitch
(drawing of a time*pitch arc).
2. The second part is devoted to public menus (actions, services,
various parameters, validation).
3. The third part is private, devoted to the objects of the user (personal
bank menus).

The box 0 of each bank
is devoted to temporary
objects (not yet recorded in
respective banks).
FIG. 13 Computation of the time intervals dtp and dta corresponding to pg and ag
© Guy Médigue

FIG. 14 Organization of the graphic tablet © Guy Médigue

THE EARLY
DAYS OF THE
UPIC

134

SESSION, PROJECT, ILLUSTRATIONS

Only one user at a time could work on the UPIC A. The time allotted to a
user is “a session.” During a session, the user can work on one or several
“projects,” each one corresponding to a particular set of private objects.
For each project, the user has a sheet of tracing paper which is adjusted
on the graphic tablet; on each sheet, the identifiers of the banks’ objects—
specific to each project—are written. At the beginning of the session, the
user can open a new project or an old one that they want to complete. In
this last case, the tape corresponding to this project has to be mounted
on the tape drive. Then the user can draw new basic objects (waveforms
and envelopes) on the graphic tablet. Each current object is tested, can
be changed as many times as desired, and if the user is happy with it, this
object is kept and saved in the appropriate bank. One can open a page
of music of any personal project and draw time*pitch arcs on the graphic
tablet or correct old ones. Before drawing a time*pitch arc, the user has to
define its “label,” that is, by choosing a waveform from the personal bank
of waveforms, an envelope from the bank of envelopes, and a maximum
intensity from the classical list (ppp, pp, p ... ff, fff). Some illustrations of
the ways the UPIC A was used are given below:

The user can hear the waveform at
the desired pitch (for a duration of
5 seconds).

The user chooses an identifier of two
characters. By pointing at “OK” the
waveform is displayed on the console
with its identifier and the box where the
user has to write it (for example,
G2 box 4).

The user can open a new page or an old
one they wish to complete. The page is
displayed on the screen of the console,
which unfortunately was far too small at
the time (eventually resolved with larger
terminals).

The user points the
electronic pen at the box
“Draw a waveform,” and then
draws one anywhere on the
graphic tablet. When the
user points at the box “OK,”
the waveform is displayed
on the graphic console and
recorded as the new current
waveform (not yet in the
bank of waveforms).

FIG. 15 How to hear the drawn waveform © Guy Médigue
FIG. 16 Saving the drawn waveform into the bank of waveforms © Guy Médigue
FIG. 14 How to draw a waveform © Guy Médigue

FIG. 17 How to open a page of music © Guy Médigue

137

The user has to define first the label of
the arc (including intensity, waveform,
envelope), then point to “no label” (or
“label” to see the label close to the arc
on the display console). Then the user
draws the arc (no validation necessary).
The arc is displayed on the screen
without (or with) its label. If the label is
displayed close to the arc, the intensity
is the last parameter (G2/EX/2p).

The user defines the unit of time desired
(for example, 10 seconds on the time
axis), then the sampling rate to use for
the computation. The duration of the
computation may be long if the user has
drawn many arcs on the page (despite
careful coding in assembly language).
The resulting wave is the new temporary
sound wave (box 0 of the sound waves’
bank).

Various utilities were added over time
(often thanks to multiple users) as well
as the functions corresponding to the
use of the analog to digital converter.
Some of these will certainly be treated
by colleagues in the pages of this volume,
so I will not expound on them here.

FIG. 18 How to add a time*pitch arc to a current page © Guy Médigue
FIG. 19 How to calculate the samples of the page just created © Guy Médigue
FIG. 20 How to listen to the page just calculated © Guy Médigue

GUY MÉDIGUE

The limitations for one project were as follows:
– 32 waveforms;
– 55 envelopes;
– 2000 time*pitch arcs per page;
– 24 pages per project.
For this first version of the UPIC A, it was not very realistic to have the
sampling rate of 52,000 that Xenakis wanted. We were obliged to propose
two lower sampling rates to the user: 25,000 and 38,460.
CONCLUSION

The relative success of the UPIC A among composers had mainly to do with
its ease of handling. Here is the list of composers who came to CEMAMu to
work on the UPIC A and whom I remember (my apologies to the composers
I have regrettably forgotten!):
– Pierre Barbaud (BBK team): he came sometimes but not regularly.
– André Dubost.[16]
– Jean-Claude Eloy[17]: a composer fascinated by Japan, who worked
extensively with the UPIC A.
– Julio Estrada.[18]
– Wilfried Jentzsch.[19]
– Candido Lima.[20]
– François-Bernard Mâche[21]: fond of birdsong, and used particularly
the rhythms of birdsong.
– Frédéric Nyst.[22]
– P. Perio and F. Wu: from the Cristallography Laboratory of ORSAY,
who used their knowledge about periodic crystal structure to make
music with UPIC A.
– Iannis Xenakis: the very first completed composition with the UPIC
A, Mycènes Alpha.
The main events at the time that I remember, because I was working very
hard on them, were the following:
– Bonn; Beethoven Festival in May 1977
– Aix-en-Provence: Centre Acanthes in the summer of 1978
– Lille: Music Festival in October 1980
In conclusion, considering that the timbre of a sound with a pitch is
only described by its waveform was an enormous simplification, both for
coding and for the user, yet necessary in view of our time constraints. Who
knows whether we would have come up with other solutions, had we been
afforded the luxury of more time? The resulting music, often a little “rustic,”
although Xenakis, for one, tried to offset this by overlaying a great number
of time*pitch arcs with various waveforms and sophisticated envelopes, is
what, in fact, gave the UPIC its sonic identity.

THE EARLY
DAYS OF THE
UPIC

138

Today, I am very pleased that some talented and young people are
pursuing further research on and about the UPIC using the extraordinary
potential of current computer technology. As a UPIC “ancestor,” I am
delighted to contribute a historical perspective that may enlighten related
present and future research.

LIST OF ABBREVIATIONS
ACROE

(Association pour la Création et la Recherche sur les Outils d’Expression) –
founded in 1976 by Claude Cadoz, Annie Luciani, and Jean-Loup Florens, in the National
Polytechnic Institute of Grenoble (Grenoble INP) with the support of the French Ministry of
Culture and Communication. http://www.acroe-ica.org/en

BBK

(Barbaud Brown Klein group) – founded by Pierre Barbaud, Frank Brown, and Geneviève Klein
http://www.associationpierrebarbaud.fr/biographie4.html

CEMAMu

(Centre d’Études de Mathématique et Automatique Musicales) – founded by Iannis Xenakis
in 1972, which grew out of the EMAMU (Équipe de Mathématique et Automatique Musicales,
also founded by Xenakis but in 1966).

139

GUY MÉDIGUE

5.

Every three years, from 1961 to 1992, the city of Bonn hosted a Beethoven Prize,
which was actually an orchestral competition. Iannis Xenakis had been honored
three years earlier in Bonn, in 1974, with a major retrospective comprising some
ten concerts at which thirty of his works were performed and several peripheral
events also took place (exhibition, films, talks, etc.). In 1977, Xenakis was awarded
that year’s Beethoven Prize for his piano concerto Erikhthon, which had received
its German première in 1974 in the aforementioned festival.

6.

Pierre Barbaud (1991–1990), French composer widely considered to be the
inventor of algorithmic music.

7.

Pierre Schaeffer (1910–1995), French composer widely considered to be the
inventor of musique concrète.

8.

Claude Cadoz, French composer considered a pioneer in physical modelling for
sound synthesis and computer gestural interactions.

9.

Pierre-Alain Jaffrennou (*1939), French composer with a particular interest in
spatial sound production and stage direction.

10.

Patrick Saint-Jean (*1949), musician, mathematician worked for the CEMAMu
between 1974 and 1976.

11.

In fact, the founding of IRCAM dates back to 1970, contemporaneous with the
decision by President Pompidou to create the National Contemporary Arts Center,
also called Beaubourg. However, construction on the site only got underway
beginning in 1974 and it opened in late 1977.

CERCI

Compagnie d’Etudes et de Réalisations en Cybernétique Industrielle

GRAME

(originally called the G.R.A.M.E.: Groupe de Réalisation et de recherche Appliquée en Musique
Electroacoustique) – founded in 1982 by Pierre Alain Jaffrennou and James Giroudon

12.

Cornelia Colyer (1947–2003), long-time collaborator of Xenakis who oversaw
much of the computer programming at CEMAMu.

GRM

(Groupe de Recherches Musicales) – founded in 1951 by Pierre Schaeffer, originally as GRMC
(Groupe de Recherches de Musique Concrète).

13.

IRCAM

(Institut de Recherche et Coordination Acoustique/Musique) – IRCAM was founded in 1970 by
the French President Georges Pompidou who invited Pierre Boulez to direct the center, which
opened in 1977 in Paris.
(Institut de Recherche en Informatique et Automatique), later became INRIA (Institut National
de Recherche en Informatique et en Automatique).

Initially, President Pompidou (rather naively?) suggested that IRCAM be codirected
by Boulez and Xenakis. See this video https://medias.ircam.fr/xbe8660
where archival resources have revealed the premises of IRCAM under a joint
Xenakis–Boulez configuration—especially, from 11'45''.

14.

The equivalent of 100,000 French Francs in 1976 was roughly 15,250 Euro; the
equivalent today is roughly 68,250 Euro.

15.

Pierre de Bailliencourt later became the founder and president of ARC Informatique:
see https://www.pcvuesolutions.com/

16.

André Dubost (*1935), composer who later became an inspector at the French
Ministry of Culture.

17.

Jean-Claude Eloy (*1938), composer and close friend of Xenakis, composed, in
particular, Etude IV: Points, Lignes, Paysages (1980), 21' on the UPIC.

18.

Julio Estrada (*1943), composer and close friend of Xenakis, composed, in
particular, eua'on (1980), 7' on UPIC, which he later transcribed for orchestra,
as eua'on’ome (1995), 10'. Soon after Xenakis’s death, in 2001, Estrada was
summoned to France from his native Mexico to run the CEMAMu. Unfortunately,
this did not come about and the French Ministry of Culture simply closed down the
research lab. See Estrada, this volume.

19.

Wilfried Jentzsch (*1941), German composer and media artist, who studied with
Xenakis in Paris from 1976 to 1981.

20.

Candido Lima (*1939), Portuguese composer, who studied with Xenakis in Paris
during the late 1970s to early 1980s.

21.

François-Bernard Mâche (*1935), composer, teacher, philosopher of music, one of
Xenakis’s closest friends for decades. See Mâche, this volume.

22.

Frédéric Nyst (1939–2011), Belgian composer.

IRIA
UPIC

(Unité Polyagogique Informatique CEMAMu).

FOOTNOTES
1.
SEMA-METRA International, Subsidiary of METRA International, the only IT

company of European scope at the end of the 1960s, where I analyzed and
developed traffic software.

2.

CERCI was developing real-time industrial systems. I mainly designed, developed,
and maintained a simulation system on a mainframe for the development of such
systems (SCEPTRE).

3.

CYCLADES was a project initiated by the Institut de Recherche en lnformatique
et en Automatique (IRIA): Several years of research supervised by Louis Pouzin
with relatively substantial resources, represented a prelude to the Internet as an
alternative to the ARPANET with the development and full-scale testing of software
for a network of French minicalculators distributed in France and Canada, and
according to principles that were ultimately those retained by posterity.

4.

The main bureau of the CNET (Centre National d’Étude en Télécommunication),
located in Issy-les-Moulineaux right outside of Paris, housed the CEMAMu.

THE

UPIC:
TOWARDS A
PEDAGOGY OF

ALAIN DESPRÉS

CREATIVITY

145

ALAIN DESPRÉS

THE UPIC: TOWARDS
A PEDAGOGY OF
CREATIVITY
I have been away from the UPIC since 1991 so my contribution to this
volume is that of someone who has likely forgotten some details and
whose memory may be “selective” at times. However, I shall devote
my chapter to the educational aspects of the UPIC and also retrace a
more historical perspective; that is, UPIC’s first steps around the world.
Furthermore, I would like to stress that if indeed the UPIC was born from
Xenakis’s brilliant intuition, without Guy Médigue [1] it would never have
become a reality.
TOWARDS A PEDAGOGY OF CREATIVITY:
MY PERSONAL CHRONOLOGY WITH THE UPIC

ALAIN DESPRÉS

My first encounter with the UPIC was in no way random. In 1979, I had just
been hired by the Atelier Régional de Musique du Nord (ARM). For several
years, I had already been very involved in a professional approach based
on the conviction that every more-or-less normal human being possesses,
at one and the same time:
– a significant artistic sensitivity, in one field or another, or in several,
– and a real aptitude—possibly unsuspected—for artistic creativity.
I was convinced that music was an area where things could really
move in that direction and had experienced this many times at the Maison
de la Culture in Nevers where I had previously worked. In 1979, like every
year in autumn, the Lille Festival was one of the highlights of musical life
in France. Its director at the time, Maurice Fleuret, invited the ARM to
participate in the organization of the 1980 Festival, where Xenakis was to
be the guest of honor. Maurice Fleuret told us about the composer (who
was also his close personal friend), and about the UPIC, which he wanted
to take out of its Parisian research lab and invite to Lille. He needed to
appoint someone to be in charge of the project. I didn’t hesitate a second,
I jumped at the opportunity. And I certainly never regretted it.
The mission actually seemed quite simple: first of all to discover the
machine for myself, to perceive how it could be a formidable tool, usable
by everyone, and to construct a specific pedagogy around it. Xenakis
expressed in his own way my personal convictions mentioned above: “[W]
e want to develop this system in such a way as to put the UPIC within the
reach of the entire population of the globe so that man can manifest his

146

supreme capacity for abstraction because that is his most interesting
power.”[2] Understandably, it didn’t take much for us to convince each
other!
For the presentation of the UPIC in Lille, with Iannis and his assistant,
Cornelia Colyer, we decided to organize five very different groups, each of
which would come daily over two weeks to work on the machine. One of
these groups, comprised solely of visual artists, produced a short piece of
four or five minutes that we had the audacity to enter in an electroacoustic
music competition in Paris. To everyone’s surprise, it won first prize!
Such gratifying experiences allowed me to continue the adventure
with Iannis. Then, Iannis and I worked together to imagine a more precise
educational approach which would prove that the UPIC was indeed an
exceptional tool allowing anyone to develop their own musical creativity.
I would like to stress that the UPIC itself helped us a lot: its approach
to musical conception was so innovative that everyone was, at first,
very confused: adults, however, more than youngsters, and composers
more than non-musicians. In short, the UPIC forced its users to question
everything they had previously learned. That was also Iannis’s leitmotif:
when an aspiring composer came to him for advice, I repeatedly heard him
say, “You’ve taken your classes, so now forget everything you’ve learned.”
The UPIC imposed this, from the very beginning.
Another strong point of the system—at least in its first version—was
the fact that it was impossible to “cheat” with the UPIC. To obtain an
interesting result with the machine, it was hard work: one had to acquire
the basic foundations of acoustics, understand the technical notions of
timbre, dynamic envelope, pitch/time plane, micro and macro form; in
short, all the sound parameters, the notion of sound object, a beam of
glissandi, or a cloud of short sounds, etc. Furthermore, at the end of the
1970s, the UPIC trained us to think carefully before acting. It even forced
us to do this, by affording us the time we needed. For example, when a
user finished drawing a page of music lasting, say, one minute, it could
take from 3 to 8 hours of calculation before hearing the result! Such a
constraint forces you to think carefully, to make the right choices from
the start, so you don’t have to recalculate everything and go back to
square one!
When teaching the UPIC system, it was important to give users,
whether adults or children, musicians or not, adequate time to digest
this new approach. Whenever possible, we designed sessions longer
than those in Lille; three weeks, ideally, during which small groups of
only four to six people worked at a time, regardless of age or previous
musical experience. Each group worked together with the goal of
creating a common work. Each group had daily access to the UPIC for

THE UPIC:
TOWARDS A
PEDAGOGY OF
CREATIVITY

147

ALAIN DESPRÉS

two to three hours, depending on their age. This type of organization also
afforded people the rest of the day and night to think about what they
would do next.
A typical session was conducted in the following manner: after
briefly explaining how the machine worked and letting users do some
experiments, we asked them to imagine either a story (when working
with small children), or an atmosphere, a sound landscape, or even a
simple musical construction for the more experienced. As soon as some
first elements were built, we calculated and listened to the result: always
surprising, of course, but is it good or poor? How can we transform or just
improve it? We made corrections, restarted the calculation, listened to
the differences, decided either to save it or try something else. Then, we
continued, another construction, and another one... And then stopped, a
pause at some point: we have retained some first elements, now we will
have to make them live together. But is that enough to make a “beautiful
piece of music”? Then we approached the notions of macroform, of
evolution, possibly of symmetry, of classical form or not, of dramatic
progression... How do we want the piece to end? In any case, we are
composing. Even with small children, these concepts could be addressed
through the UPIC. FIG. 1
With each workshop, we suggested forming at least one new type
of group, which so far had not been formed elsewhere: after the visual
artists in Lille, a group composed only of women in Tokyo, blind people
in Mexico, dancers here, or mathematicians there. And, it always worked!
However, it was almost systemic that one group had more difficulties
than all the others: musicians with classical training, students from music
schools. Sometimes, it is harder to unlearn than to learn afresh! FIG. 2
I must confess, today I feel a certain nostalgia for this “archaic”
period; I actually preferred it to the next one and the arrival of the realtime UPIC. The compositional tool it had been back then was transformed
into a digital musical instrument, almost like any other. It had immense
possibilities, but was much more difficult to master. With Peter Nelson[3]
and Pierre Bernard,[4] two true UPIC pioneers, the three of us created Un
Alliage Rituel, in 1990, a beautiful collective work that I do not deny, far
from it, but I also know that it was difficult for the audience to perceive.
They didn’t understand anything about the interventions we made with
the tip of the pen on the UPIC table and what they were seeing on stage.
FIGS. 3, 4

By that time, in 1990, it was time for me to turn the page. All along, I
had had a secret garden, and I stored stones there. So, I left Les Ateliers
UPIC to embark on other adventures, which are also very exciting. Today, I
am a sculptor.

FIG. 1 UPIC workshop for children in Mexico City, Mexico, 1988 © Alain Després and

CIX Archives

FIG. 3 Pierre Bernard (right), Peter Nelson and Alain Després (left) performing Un
Alliage Rituel at the world première at the International Computer Music Conference
ICMC), Glasgow, UK, 1990

FIG. 2 UPIC workshop for female participants in Yokohama, Japan, 1984 © Alain Després

FIG. 4 Pierre Bernard, Peter Nelson and Alain Després performing Un Alliage Rituel at

and CIX Archives

the world première at the ICMC, Glasgow, UK, 1990

150

1979–1990: UPIC’S FIRST TRIPS

Organizing a UPIC trip in the late 1970s was no easy task. Today, it is
difficult to imagine that a truck was needed to transport the machine. In
1979, every element of the computer was like a large piece of furniture.
A disc was 40 cm in diameter and 38 cm high, it had a capacity of
one short minute of music! The magnetic tapes were installed in two
untransportable cabinets around 2 meters tall. At the time, the UPIC was
a laboratory object; experimental, designed to be multiplied and travel,
but still very fragile. Taking it out of the Centre d’Etudes de Mathématique
et Automatique Musicales (CEMAMu) to transport it to Lille, then later to
Japan, was sheer madness. It was necessary in an almost systematic way to
plan for a lot of time to reinstall the system after each trip, and also a repair
service, whose timing was always random. Generally, everything was usually
in order just a few minutes before the first workshop or concert. Yet the UPIC
travelled far and wide.
Here, I will try to reconstruct UPIC’s adventures during the period when
I was in close contact with it, between 1979 and 1990. Fortunately, I have
kept some paper documents and some slides. I finally found traces of about
sixty more or less significant events. To list them all here would be tedious,
so I will simply highlight only a few key moments.
Until 1984, only the CEMAMu had any UPIC systems. Yet finally, in
February 1984, thanks to a grant from the French government, the ARM (of
which I had become director in the meantime) was able to acquire its own
UPIC in a version of delayed time but of more reasonable dimensions. The
whole installation fit into a van, and only the graphic table remained like the
original one. FIG. 5
Three months later, the CEMAMu organized a first UPIC tour in Japan.
Two locations were chosen, Tokyo and Yokohama, and Xenakis asked me to
accompany the team on this adventure. FIGS. 6, 7
Xenakis was the guest composer of the Centre Acanthes in Aix-enProvence during the summer of 1985, an annual event for young
professional musicians from all over, focusing on an internationally
renowned composer and his main performers who gave master classes.
That year, three locations were selected: the UPIC went from Aix-en-Provence
to the Mozarteum in Salzburg, and then on to Delphi. FIG. 8
In December 1985, at Xenakis’s request, I left the ARM to create Les
Ateliers UPIC. Iannis was the honorary president and François-Bernard
Mâche, our chairman. We set up our offices and our work studio in what
later became the Cité de la Musique at the Parc de la Villette in Paris.
Composers from many countries came to work there on the UPIC. We
received significant and generous support from the French Ministry of
Foreign Affairs, as well as from the French Ministry of Culture. Thanks to

THE UPIC:
TOWARDS A
PEDAGOGY OF
CREATIVITY

151

ALAIN DESPRÉS

these grants, about thirty composers were able to participate in these
various events. Amongst them were some Russians and Albanians who
could leave their country for the first time, thanks to the fact that the
borders were just beginning to open. FIG. 9
In October 1987, Les Ateliers UPIC were awarded the Fiat-France
Foundation, Institut de France Patronage Prize. On this occasion, a film
was made about our work by an Italian production company. We also
received a large sum of money, which enabled us to organize an extensive
tour throughout North America and Mexico the following year. The tour
began in San Diego, thanks to Iannis’s longtime friend and colleague
Roger Reynolds, and we installed the UPIC in the Project for Music
Experiment at the University of California San Diego (UCSD) for eleven days,
where we held composition master classes every day and gave a concert.
After some adventures with the U.S. customs officers, we went to
Mexico where we were hosted by Julio Estrada and his university. FIG. 10
Then a jump by airplane took the UPIC to the Banff Center of Fine
Arts near Calgary, Canada, with a subsequent stop in Montreal at the
Conservatoire. We ended our tour of almost three months in Toronto,
where workshops for all age groups and a concert were organized. FIG. 11
1990 was a landmark year for Les Ateliers UPIC: we moved to more
spacious premises in Massy, just outside of Paris, and we also received a
new machine, lighter, and above all, in real time, from the CEMAMu team.
Around the same time, initiated by Takehito Shimazu and Shigehiro
Yamamoto, two Japanese composers whom we had previously invited to
work on the UPIC in France, we organized another tour in Japan in October
1990. We presented the new real-time machine and the same spectacle
Un Alliage Rituel in Tokyo, Kofu, Fukui, and Fukuoka. Some master classes
were also organized. FIG. 12
This succinct overview of the nearly sixty events we organized,
including the ten or so major milestones, sums up what we did, in addition
to our daily life in the studio when the UPIC was in Paris. Besides the
outreach workshops we held for children or amateurs, we always managed
to add master classes for composers from the country hosting us.
Therefore, many professionals were able to experiment with the machine
and some subsequently came to pursue their UPIC work in Paris. Thus,
around fifty composers created one or several pieces of music; over eighty
UPIC works were created during that decade alone.
During our trips, we always met “the people who mattered” in the
local musical scene, by Xenakis when he was there, or by us when he
could not be present, the machine was presented in front of local political
and cultural personalities and the press. We participated in numerous
radio and television programs. Several films were made: the machine was

FIG. 5 UPIC’s own transporter the Atelier Régional de Musique du Nord (ARM), 1984
© Alain Després and CIX Archives
FIG. 6 UPIC workshop setup in Yokohama, Japan, 1984 © Alain Després and CIX Archives
FIG. 7 A participant who arrived one day to a UPIC workshop in a traditional dress stands in front

of the travel version of the UPIC, Yokohama, Japan, 1984 © Alain Després and CIX Archives

FIG. 8 Iannis Xenakis (front) at the Centre Acanthes with Rudolf Frisius (far left), Aix-en-Provence,

France, 1985 © Alain Després and CIX Archives

FIG. 9 Peter Nelson (second from right) during a class at the UPIC composition studio at

La Villette, Paris, France, 1986 © Alain Després and CIX Archives

FIG. 10 UPIC workshop led by Julio Estrada, Mexico City, Mexico, 1988 © Alain Després and
CIX Archives
FIG. 11 UPIC workshop with children, Toronto, Canada, 1988 © Alain Després and CIX Archives
FIG. 12 UPIC workshop, Tokyo, Japan, 1990 © Alain Després and CIX Archives

154

installed on the set of a popular TV show when we were at the Barbican
Centre in London FIG. 13, it figures prominently in a film directed by French
filmmaker Chris Marker, The Owl’s Legacy, (Episode 8 of the 13-episode
series); and today, a UPIC is on permanent display at the Museum of Music
at La Philharmonie in Paris.
While we were at Les Ateliers UPIC studio, working an average of
seventy hours a week during the 1980s, we just had the feeling that we
were living a beautiful adventure. It is only today that I have become aware
that, thanks to Xenakis of course, I have also been able to make a very
modest contribution to the history of twentieth century music. FIG. 14

THE UPIC:
TOWARDS A
PEDAGOGY OF
CREATIVITY

TIMELINE OF UPIC’S PRESENTATIONS 1977–1990
EVENTS MANAGED BY THE CEMAMU:

1977 May
		
1978 June
1978 Sept.
		
		

Bonn, Germany, Presentation of the first UPIC prototype 		
at the World Music Days
Paris, France, UNESCO: Presentation of the UPIC machine
Mycenae, Greece, Mycènes Alpha, Iannis Xenakis, world 		
premiere of the first UPIC work, in Xenakis’s Polytope de 		
Mycènes, recorded on tape

UPIC EVENTS MANAGED BY THE ARM (IN COLLABORATION WITH THE CEMAMU):

1980 Oct.– Nov.
		
Nov.
1981 June
Oct.
		
1982 Jan.
Feb.
Feb.

UPIC’S FIRST TRIP OUTSIDE OF PARIS:

Lille, France, Festival de Lille (concert, workshops)
Bordeaux, France, Sigma Festival (concert, workshops)
Paris, France, Forum des Halles (concert, workshops)
Bar le Duc, France, Colloqui Informatica Musicale (CIM)		
(concert, workshops)
Chambery, France, Orchestre de Savoie (concert, workshops)
Nice, France, Festival MANCA (concert, workshops)
Marseille, France, Conservatoire (presentation)

May
UPIC’S FIRST TRIPS OUTSIDE OF FRANCE:
		
Lisbon, Portugal, Gulbenkian Foundation (concert, workshops)
June
Middelburg, Netherlands Festival nieuwe muziek (concert, workshops)
Oct.
Gruson, France, Festival du Pévèle Mélantois (concert, workshops)
Nov.– Dec. Albi, France, Rencontres “Technologie du future” (concert, workshops)
1983 May
Orsay, France, Université Paris Sud (concert, workshops)
June
Bourges, France, Cours du Palais Jacques Coeur (International 		
		
Festival of the Groupe de musique expérimentale de Bourges) 		
		
(concert, workshops)
Nov.
Paris, France, Magasin Ham (concerts, workshops)
Dec.
Paris, France, Auditorium du Conservatoire Paris 12éme (concert,
		
workshops)
1984 Feb. 18
l’Atelier Régional de Musique (ARM) acquires its own UPIC

FIG. 13 Peter Nelson presenting the UPIC on a television set, London, UK, 1989
© Alain Després and CIX Archives
FIG. 14 Iannis Xenakis presenting the UPIC at La Villette, Paris, France, ca. 1985
© Alain Després and CIX Archives

THE UPIC:
TOWARDS A
PEDAGOGY OF
CREATIVITY

156

1984 May

CEMAMU-ARM: UPIC'S FIRST TOUR IN JAPAN

Yokohama, Japan, Scientific Cultural Center (concerts, workshops)
June
Tokyo, Japan, Institut Français (concerts, workshops)
July
Boulogne s/Mer, France Festival Côte d’Opale (concert, workshops)
1985 Feb.–March Nevers, France,Maison de la Culture (concert, workshops)
April–May Besançon, France, Espace Planoise (concert, workshops)
June–Aug. Iannis Xenakis Guest of Honor at the Centre Acanthes
July
Aix-en-Provence, France Conservatoire de musique(master classes,
		
concerts)
July–Aug. Salzburg, Austria, Mozarteum (master classes, concerts)
Aug.
Delphi, Greece, European Center (master classes, concerts)
1985 Nov.–Dec. Clermont Ferrand, France Conservatoire National de Région (concert,
		
workshops)
1985 Dec.
Inauguration of Les Ateliers UPIC at La Villette, Paris, France
		
(ARM donates its UPIC to the new association)
EVENTS MANAGED BY LES ATELIERS UPIC:

1986 Jan.
Paris, France, launch of the French government’s Informatics at
		
School campaign
April–May St Sever, France, Cloître des Jacobins (concert, workshops)
April
Blanc-Mesnil, France Centre Musical Erik Satie (concert, workshops)
June
Rennes, France, Maison de la Culture (concert)
Oct.
Toulouse, France, Festival FAUST (demonstrations) Concert
Oct.
Romans, France, Théâtre (concert, workshops)
Dec. 4
Limoges, France, Auditorium CCSM (concert, workshops)
1987 March
Dijon, France, DRAC (concert, workshops)
May
Valencia, Spain, Palau de la Musica (concert, workshops)
May–June Soissons, France, École de musique (concert, workshops)
July
Paris, La Villette First International UPIC Workshop.
		
12 composers, 12 countries represented
Sept.–Oct. Stockholm, EMS Fylkingen Kulturhuset Riksradion
1987 Oct.
Château de Chantilly, Fondation Fiat France – Institut de France
Oct.
Caen, Conservatoire (concert, workshops)
Nov.
Huddersfield, Contemporary Music Festival (concert, workshops)
Nov.
Les Ateliers UPIC receive “Les sphères du Mécénat” award from the
		
FIAT Foundation
1988 May
Paris, France, La Villette Conference “Towards an Interactive Culture”
Sept.
Berlin, Germany, Technischen Universität (concert, workshops)
Sept.
Turin, Italy, Festival Settembre Musica (concert, workshops)

157

ALAIN DESPRÉS

1988 Oct.
		
Nov.
		
Nov.
Nov.
Dec.
Dec.
Dec.

LES ATELIERS UPIC: UPIC'S TOUR IN USA, MEXICO, CANADA

1989 Jan.
Jan.
March
Sept.
		
Dec.
1990 May
		
Sept.
		
		
		

Paris, France, Second International UPIC Composition Workshop
London, UK Barbican Center (concert, workshops)
Lyon, France Musée St. Pierre Contemporain (concert, workshops)
Valmy, France, Bicentenary of the French Revolution (participation in a
spectacle)
Geneva, Switzerland, Musée Rath (concert, workshops)
Massy, France, Inauguration of Les Ateliers UPIC new premises
Third International UPIC Composition Workshop
Glasgow. UK, International Computer Music Conference (concert,
workshops)
World première of Un Alliage Rituel by Pierre Bernard, Alain Després,
and Peter Nelson (first real-time work composed on UPIC)

		

LES ATELIERS UPIC: UPIC'S SECOND TOUR IN JAPAN

Oct.
Oct.
Oct.
Nov.

San Diego, USA. PME of UC San Diego (concert, masterclass)
Mexico City, Mexico, Institut Français d’Amérique Latine (IFAL)		
(concert, workshops)
Banff, Canada, Banff Center of Fine Arts (concert, workshops)
Montreal, Canada, Conservatoire de Musique (concert, workshops)
York, Canada, York University, Dept. of Music (demonstration, concert)
Toronto, New Music Concerts (concert)
Toronto, St. George’s College (concert, workshops)

Tokyo, Japan, Institut de France
Kofu, Japan Yamanashi University
Fukui, Japan International Media Art Festival (concert, workshops)
Fukuoka, Japan, Kyushu University of Acoustics (conference and concert)

FOOTNOTES
1.
See Médigue, this volume.
2.

See Xenakis in the UPIC Promotional Video here: http://www.centre-iannisxenakis.org/items/show/674 (especially from 0:48).

3.

Peter Nelson is a composer and currently Professor of Music and Technology at
the University of Edinburgh. He worked closely with Xenakis in the 1980s and was
Editor in Chief of the prestigious journal Contemporary Music Review from 1986
to 2014.

4.

Pierre Bernard, composer and regular collaborator at Les Ateliers UPIC and at
CEMAMu.

THE UPIC—
EXPERIMENTAL

MUSIC

PEDAGOGY­­—

RUDOLF FRISIUS

IANNIS XENAKIS

163

RUDOLF FRISIUS

THE UPIC—
EXPERIMENTAL MUSIC
PEDAGOGY—
IANNIS XENAKIS
OLD AND NEW KEYWORDS

RUDOLF FRISIUS

Four letters, a keyword, and a composer, united in a headline:
At first sight, this combination may seem strange, not only to the
generally interested reader but also to the specialist: as a collage of
music technology, music pedagogy, and musicology.
The UPIC (Unité Polyagogique Informatique CEMAMu) is a device
for anyone who wants to open up new pathways to music: those who
use it can sketch something onto the device’s drawing board, and then
have it transformed digitally into sound by the machine. The idea of
inventing such a device came from a composer who often used his
drawings as prompts for his own work: The Greek composer Iannis
Xenakis neither studied music at a young age nor worked as a musician,
but instead earned his living for many years as an employee of world
famous architect Le Corbusier. After some time he found out that not
only architecture, but also music can emerge from precisely recorded
designs: lines on the drawing surface as pictures of sustained or moving
tones in the tonal space. This thought, which was very simple in its
basic approach, was thought through so thoroughly that it was able to
serve as the starting point for completely new and surprisingly complex
music. This music was so rich and interesting, and at the same time
also so obvious in its basic approach that it could stimulate new ideas,
which led not only to new compositions, but also to new approaches to
musical learning: If everyone were able to draw sounds—not just a highly
specialized composer—then composing would no longer be a specialty
reserved for the very few. Everyone could be inspired in this way to invent
music: a composer became the stimulus of new ways of music in new,
experimental music education.
This chapter deals with substantive relationships between music
technology, music pedagogy, and the thinking and working of a
prominent exponent of New Music after 1945. Iannis Xenakis’s music
pedagogical approach is shown as a consequence of historical, musical,
and political references. Also illustrated are the creations and work of
the Greek composer and architect in the context of contemporary history

164

and the development of his digital learning tool UPIC; that is, a general
learning tool for all ages and levels of education used in his research
center CEMAMu (Centre d’Etudes de Mathématique et Automatique
Musicales), which was founded in the 1960s and active until Iannis
Xenakis's death in 2001.
MUSIC AND THE HISTORY OF MUSIC IN THE HISTORY-CHANGING
PROCESSES OF THE TWENTIETH CENTURY

The search for alternatives to traditional music education (which focused
on singing and instrumental music, on notation and music theory, as well
as on works and composers of the past) began relatively late in the age
of new music. In Germany, it did not begin concurrently with the radical
musical innovations of the early twentieth century before the First World
War. The new way of pedagogical thinking only began several years later,
after the catastrophe of the First World War and at the same time as
the democratic new beginning in the years of the Weimar Republic. New
approaches developed in the conflict between the old and the new, in
years that were also overshadowed by economic crises and political
radicalization. In the years of the National Socialist dictatorship and
World War II, this radicalization then led to the narrowing down of music
lessons to nationalistic and militaristic singing and traditional national
music.
Only with the political and cultural new beginning from 1945 could
innovative musical development begin again in the former sphere of
power of the National Socialists. This development was also ready to be
open to the world, and internationally accessible (e.g., at the Summer
Courses for New Music which were founded in Darmstadt in 1946
and rapidly internationalized). Already in the first post-war years this
development had extended beyond the field of moderate modernity.
Examples are Hindemith, Bartók, and Stravinsky; the music and
music education of Carl Orff, who in spite of using recently developed
instruments and playing techniques as well as new, partly improvisational
practices of collective singing and making music, still remained largely
trapped in traditional patterns of melody, harmony, and rhythm.
However, the transition from Hindemith, Bartók, Stravinsky, and Orff
to more radical musical innovators took place more rapidly in music life
after 1945 than in music education. Due to the promotion of new music
at the Darmstadt Summer Courses and by progressive organizers, radio
stations, and publishers, a wider interest in new music developed during
the first post-war years. This interest sought to escape the shadows of
the past by detaching itself from the bonds of traditional (and traditionally
strained) tonality.

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

165

RUDOLF FRISIUS

The trend toward innovation had to overcome considerable
resistance in the realm of still largely traditional musical life, and above
all in the field of music education. It became clear, especially in Germany
at that time, that the resistance to radical musical modernism, which had
been outlawed by the National Socialists, also had something to do with
the unresolved issues of coming to terms with the recent past (evidenced,
for example, by the long-term survival of many politically tendentious
songs in school singing lessons). This situation only changed after
Theodor W. Adorno challenged traditional music education in the 1950s
with radical ideological criticism.
In his essay Kritik des Musikanten (1956), Adorno called for
abandoning a pedagogically simplified tonal way of thinking, unreflected
singing, and playing “music-educational music (Musikpädagogische
Musik).” The alternative he suggested was to engage thoroughly with
more sophisticated musical works; not only within the confines of a
traditional canon of art, but also incorporating more recent art music
beyond traditional tonality, such as works by Arnold Schoenberg and
composers from his Viennese school. However, in the 1950s (and even in
the following decade) the traditionally trained music educators were not
prepared for this openness, especially not in the field of musical practice,
where simple tonal songs and instrumental pieces could not be easily
replaced by atonal or twelve-tone music. Music educators who wanted to
incorporate such works into their music lessons were not able to teach
this type of music as they had learned it—especially in the field of music
practice. Even their knowledge of traditional musicology only helped to
a limited extent in dealing with newer approaches and works, since if
taught only in a traditionalist manner it could lead to the new style of
music being weakened (whether in favor of alleged or actual tonal twelvetone music, such as Alban Berg, or in transferring traditional methods
of work analysis to newer works; for example, focused on approaches of
traditional motif and form theory, since they have indeed remained largely
effective in the music of Schoenberg and his students).
In traditional music education after 1945, attempts at traditional
mastering of the non-traditional could only be successful as long as
the most radical current music remained at least partially connected to
old traditions. This was true even for music by Schoenberg, Berg, and
Webern, but only to a limited extent for the percussion music of Varèse
and the young Cage or for important rhythmic and multiparametric
innovative works by Olivier Messiaen (especially his piano etude Mode
de valeurs et d’intensités of 1948, which at the time when it was created
impressed many younger composers, including Boulez, Stockhausen, and
Xenakis).

166

The “latest music” of Boulez, Nono, Stockhausen, Xenakis, and
others, which prevailed since the 1950s, could not be learned at traditional
education institutions during that period, but only through direct contact
with leading composers; for example, at the Darmstadt Summer Courses,
where innovative composers communicated with each other as well as with
musicians and music lovers. An important part played in this was that in the
1950s, many radio broadcasters contributed significantly to the distribution
of radical new music (e.g., by commissioning compositions, organizing
concerts and broadcasts, especially in France and Germany).
Both in public events as well as in broadcasts and printed publications,
a variety of information was offered that was theoretically available to the
wider public, but actually, in the still largely traditional music business
from the 1950s to the early 1960s, was initially used by only a few music
educators. That is why it took many years before new music finally gained
more attention in musical life as a whole, and especially in music education.
This was also due to the fact that important innovations in the field
of “serious music” were initially made largely independent of the field of
popular music: The radical avant-garde music of the 1950s didn’t distance
itself less from the (at the time also radically innovative) rock and pop music
than it did from the then “moderately modern” and traditional “classical”
music. This changed only in the course of the music development of the
1960s; in a period of manifold crossovers between both areas. It was not
until this time of generational change that a more effective rapprochement
between the areas of “new music” and “music education” took place, in
the course of which music pedagogy, which was at that time (and still is)
geared towards traditional or classical modern works of art, could radically
redefine itself as experimental music education—as a pedagogy that not only
made itself available for newer composers and works, but also sought new
ways of dealing with music creatively. In this situation it was significant that
innovations in music education did not happen, as often before, according
to the structures and methods of traditional musical life, musicology and
musical pedagogy (vocal and instrumental music or the traditional musical
analysis and interpretation), but in close connection with contemporary
compositional developments and with innovative, prominent composers
dealing with ideas, who, in the context of important social and political
changes in the 1960s, and then in the general musical history context, have
received more attention.
IANNIS XENAKIS AS AN INNOVATOR IN MUSIC
AND MUSIC EDUCATION

Iannis Xenakis holds a special position among post-1945 composers who
were interested in social openness and committed to music education

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

167

RUDOLF FRISIUS

relatively early. Xenakis belongs to a generation that was shaped
decisively by the catastrophe of the Second World War and its political and
social consequences. Its most important representatives after the end of
the war had to break new ground and work on (and possibly overcome) the
past. Xenakis himself often stressed how important this was for his first
internationally known work. In 1978, in conversation with Bálint András
Varga, he specified this more precisely:
Metastasis, that starting point of my life as a composer, was inspired
not by music but rather by the impressions gained during the Nazi
occupation of Greece. The Germans tried to take the Greek workers to
the Third Reich—and we staged huge demonstarions against this and
managed to prevent it. I listened to the sound of the masses marching
towards the centre of Athens, the shouting of slogans and then, when
they came upon Nazi tanks, the intermittent shooting of the machine
guns, the chaos. I shall never forget the transformations of the regular,
rhythmic noise of a hundered thousand people into some fantastic
disorder... I would never have thought that one day all that would
resurface again and become music: Metstasis. I composed it in 195354 and called it (my) starting point because that was when I introduced
into music the notion of mass [...] Almost everybody in the orchestra is
a soloist, I used complete divisi in the strings which play large masses
(of) pizzicato and glissando.[1]
Even the first idea of the form for the beginning of the piece was quite
unusual: Many musicians should start at the same time, all on the same note.
Everyone should then move away from that tone, but each in their own
way—and all in a different way than in traditional music; namely, in glissando:
– the one ascending in a straight line,
– the others descending in a straight line.
All sliding sound moves stop at the same time. Each tone line has
reached a different target tone at this breakpoint, so that a very dense,
cluster-like chord results, whos​e sounds are held rigid for a long time, then
pause together, then revive in rhythm and color. FIG. 1
At that time, the young Xenakis had no way of technically implementing
this forming process in a studio. Instead, he wanted to show that such
an unusual sound process could be realized even with a conventionally
instrumented orchestra. The only conventional orchestral instruments that
could be used for long-range glissando movements, as Xenakis envisioned
them, were the stringed instruments. The starting point for the widening sound
movements was the deepest tone of the higher strings, the G of the violins.
Xenakis did not first write down the individual tones differently in traditional

169

FIG. 1 Xenakis’s Metastasis in the context of experimental arts and music pedagogy,
Stuttgart, Germany, 1980. In Bewegungen im Tonraum (Movements in Tonal Space),
in Rudolf Frisius et al., Notation und Komposition: Unterrichtsmaterialien für die
Sekundarstufe I Materialheft (Stuttgart, Klett, 1980), 2-3 © Rudolf Frisius and
Gabriele Sprengler

RUDOLF FRISIUS

musical notation, but in graphical notation on graph paper (which was obvious
to him since he was employed at the time by the architect Le Corbusier).
Thus, one of the first (initially) unconventionally notated compositions
of new music was created. Xenakis, however, then quickly recognized
that the music as he had originally (graphically) notated it, could not be
performed because the orchestra musicians at that time (and often later)
could only play traditionally notated scores. Since Xenakis desperately
wanted his orchestral piece to be performed, he had to rewrite his graphic
notation as a conductor-legible and traditionally notated score (on which
basis traditionally notated orchestral material could be made). Thus, it
became possible for many highly specialized musicians to realize a
completely new type of music in terms of sound, and that the entire piece,
consisting of extremely dense and complicated sound movements of
many individual instruments, produced a concise and meaningful forming
process for the listener.
The paradox that here the music had to be performed according to
different notation than according to the original score, Xenakis explained
later plausibly, for example, in 1984 in Karlsruhe, during the introductory
lecture to a concert on 28.2.1984 at Winter Music ‘84, which was
dedicated to him, with the title Music: Moving Architecture (Musik: Bewegte
Architektur). Xenakis said that the graphic notation is readable, but not
playable, whereas the multiline traditional score is playable, but unreadable.
Especially in the most famous parts of the orchestral piece
Metastasis, at the beginning and in the final section,[2] the relationships
between a graphically noted fixation of the compositional idea and details
fixed in a traditional score for their detailed execution are so precise
that even someone who does not know the graphic output notation of
the composer can reconstruct it from the traditional score, and that the
conclusion traditionally noted in the score can easily be compared with
Xenakis’s later published graphic notation.
Traditional and graphical notation present themselves here as
different variants of production notation (which concentrate on the intial
compositional idea and on precise instructions for its aural realization).
Both notations are different, but serve the same purpose and are thus
substantially different from the purpose of reception notation of the
same music, which attempts to determine how the notated music actually
sounds in a particular performance or recording, and which, in turn, can
be compared with representations of the sound reproduction on the
screen of a computer.
The distinction between different functions of the notation and,
associated with it, the detachment from the primacy of the traditional
notation, which was allegedly equally binding for composers, performers,

170

and listeners, was one of the first radical ideas of reform in music
development after 1945 that was far from traditional thinking.
Notation reform developed in various stages. Since the early 1950s,
it has become concrete in experimental compositions. This began in
1952 in instrumental and technically produced pieces by John Cage—for
example, in the very detailed but in the tonal details indefinite score
Williams Mix (1952–53)—or in works by members of the New York School
such as Earle Brown’s aural and interpretatively indefinite graphic notation
December 1952.
From 1953–54, Iannis Xenakis began with precisely graphically
recorded compositional designs, which were later rewritten into
traditionally notated scores for performance-related reasons. The new
approaches of graphically notated new music, especially the approaches of
the New York School and those that followed later in new European music,
since the 1970s have led to replacement of the primacy of traditional
notation in the field of music education. This furthered the shift away from
traditional, well-established production- and reception-oriented music
education, focused on making music and listening to traditionally recorded
music, to newer forms of notation, which also give young people and
non-musicians their own ways of listening to and playing newer sounds
and music. In doing so, students either write down newly invented sounds
and music intended for aural realization using words or characters, or
they describe words or signs that have been heard, possibly also visually
observable sounds and music on the computer screen.
Design notation and performance instruction, audio recordings,
and computer presentation may present themselves in many works
of contemporary music, especially in many of Iannis Xenakis’s works,
with varying degrees of precision and ambiguity. For example (and in
particular), Xenakis’s music in many cases already demonstrates what
different possibilities arise when one compares the beginnings of various
compositions, for example, the beginnings of various pieces with which
Xenakis caused a sensation in the 1950s:

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

Metastasis for orchestra (1953–1954) FIG. 3 in comparison with
Diamorphoses electroacoustic music for 4-track tape (1957) FIG. 4
Pithoprakta for orchestra (1955–1956) in comparison with
Concret PH electroacoustic music (1958)
The first two pieces, Metastasis and Diamorphoses, begin with
long-range and straight-line movements of sliding sounds; the following
two, Pithoprakta and Concret PH, with densely massed impulses

FIG. 2 Musical scores of schoolchildren to sound examples by Xenakis (Diamorphoses),
Jimi Hendrix (EXP), and Agitation Free (Second), Stuttgart, Germany, 1976. In Rudolf
Frisius et al., Sequenzen: Musik Sequenzen, Musik Sekundarstufe 1, 2. Folge,
Tonbeispiele. The audio scores were created in teaching experiments at the Realschule
(teacher: Klaus Maichel)

172

(sound points). The production notation of the two orchestral pieces are
published as traditional scores, that is, as precise instructions for the
performers (they are also comprehensible for the score reader familiar
with traditional notation). The composer did not publish scores with
comparably precise details of the two electroacoustic compositions,
which is why it seems reasonable to assume that the four pieces,
especially their beginnings, are not based on precise information given
by the composer, but on the sound impression, possibly incorporating
computer screen representations and reception notations. The results
of experimental music pedagogy (see FIG. 2) could also be used for
this purpose as these are not based on the traditionally fixed notation
dictation, but rather attempt to stimulate listening and listening and
imitating of unknown music, as this can be done in general education
schools with students without special musical training, if these students
find the music interesting and they are able to compare the music heard
with other, known everyday sounds and describe the music examples
(see FIG. 3: sonogram Diamorphoses).
In these notations by school children, the sounds and sound
movements are graphically notated based on an auditory impression and
supplemented with words related partly to the music (e.g., volume and
information about the instruments) and partly to associated or actually
heard noises. These reception-based notations refer to technically
produced music, which—even in the case of the piece by Xenakis—does
not originate from a composer’s score, but from sounds and sound
structures created, recorded (and, especially by Xenakis, technically
processed) directly in the recording studio, and which cannot be
preserved by traditional notation methods—and which also for Xenakis’s
music, beyond known instruments, is notably exceptional.
A characteristic example of reception notation in the field of
experimental music education is published in the teacher’s manual for a
textbook from the 1970s (see FIG. 2): three notations from pupils of heard
music examples, each notated as audio score (reception notation):
– The beginning of a piece by Xenakis (Diamorphoses)
and two excerpts from pop records popular at the time:
– Jimi Hendrix, Electric Ladyland
– Agitation Free, Second
Based on their auditory impression, the sounds and sound
movements are graphically notated in these schoolchildren’s notations
and supplemented with words that are partly related to the music (e.g.,
volume and instrument information), and partly to associated or actually
heard noises, which cannot be fixed exactly in traditional notation, and
which are also, even for Xenakis, unusual instruments.

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

173

RUDOLF FRISIUS

Similar to the beginning of the composition of Metastasis and
Pithoprakta, and also in many later (mostly instrumental) works, Xenakis
first noted precisely and graphically important compositional ideas, and
then rewrote them in traditional notation which can be executed by
interpreters—in full knowledge that the graphical design notations for
describing his compositional ideas were usually much better suited than
examples from traditionally notated scores. There was much to suggest
that new musical thinking would be easier to enforce here and elsewhere
in connection with new notation methods, even beyond narrower avantgarde circles.
Since the 1960s, Xenakis had been thinking in that sense whether
his method, which leads from precise graphics to concrete sound, could
also stimulate others to deal creatively with sounds—whether other people
(e.g., children or non-musicians) could also invent and (graphically) notate
sounds and sound structures, so that a detailed “notational” sound
realization would be possible. The path from the graphics to the resulting
sound would no longer be conveyed by the traditionally notated score, but
by computer technology that enabled the immediate transformation of the
drawing into real sound.
Xenakis imagined that even children could make such drawings and
familiarize themselves with the (computer-assisted) sound results. He
assumed that musical creativity is not only a privilege for the few, for
example, only appreciated and promoted by specially trained people,
but rather a broad potential without limitation based on individual age
or educational levels. In the 1960s, in order to create the necessary
institutional and technological conditions, Xenakis founded a research
group (EMAMu: Equipe de Mathématique et d’Automôme Musicales/
Research Group for Musical Mathematics and Automatics) and later a
research center (CEMAMu, the center assigned to the group/Research
Center), and he developed ideas for the technical equipment for the
research. This initially focused on the invention of a device that allows
the digitally-mediated transformation of drawings into sounds and is also
usable by children and amateurs: Emanating from graphic notation and
computer-generated sounds, his learning system UPIC presents itself as
a modern alternative to the Orff-Schulwerk, which is based on traditional
notes, songs, and instruments, and as a learning tool for the creation
of aural realization of music, not for the reproduction of already existing
music.
Xenakis had high hopes that his invention of a simple learning and
production device would inspire the enjoyment of sounds and music
in many people, including children and non-musicians. However, unlike
Pierre Schaeffer (the founder of musique concrète) and his collaborators,

174

Xenakis did not want to start with sound experimentation, but with
drawing, as is common in childhood. He also insisted on this in a lengthy
interview with Francois Delalande, a musicologist who worked in the
research group GRM (Groupe de Rechercherches Musicales) founded
by Schaeffer, and who sympathized with his empirical sound research.
Xenakis, however, preferred a different starting point:

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

If you draw lines on a blackboard, you can [...] create sounds and
music (with some rules that can be learned very quickly). Not just
sounds, but also developments of rather complex sounds, that is to
say, of music. [...]
And drawing is an ability of every human with a hand and a brain;
the hand is the organ closest to the brain. [...]
Giving everyone the opportunity to compose music leads to a double
result: on the one hand, you make the creative activity available
to everyone, and on the other hand, there is no longer this abyss
between any avant-garde (there are always avant-gardes) and the
rest of the audience.
Rather, it’s about building bridges and being able to think music,
meaning creating music with everything that comes with it. [...]
For everyone. From the age when the child can hold a pencil and
listen, to adulthood and until death.[3]
This understanding of music can lead to the question of and to
what extent the composer, who expresses himself in this way, wants
to position himself in a concrete social situation. This question poses
itself with Xenakis, not only for his early sensational Metastasis and
its contemporary historical context, but also for later works in which
he uses his pedagogically oriented UPIC system compositionally—for
example, in the radio play Pour la Paix (1981): music with narrative texts,
choral passages and UPIC sounds leading to a radio play text by his
wife Françoise, who, like him (but in another country), was active in the
resistance during the Second World War against invading aggressors.
After a short introduction with violent electronic sliding sounds, the
Une guerre.					
Voici dans son horreur, la guerre.
Atrocités, massacres, torture,		
infinie souffrance des hommes, des femmes.
Nous sommes n´importe où.			
Là où on pend, fusille, massacre.
The war.
Abomination, massacres, torture.		
We are somewhere.			

There it is, in [all] its cruelty, the war.
Endless suffering of men, of women.
There, where one hangs, shoots, massacres.

175

RUDOLF FRISIUS

radio play begins with the following text (here quoted from the taped
recording of the radio play):[4]
Contemporary historical references, which Xenakis specifically
addressed for his early work Metastasis in subsequent commentaries, not
in the music itself, are heard here directly as components of the radio play
text. This changes the listening perspective for the rest of the piece—for
example, in explosive impulsive sounds that might remind one of echoing
gunshots, or in an exploding grenade sound that accompanies the radio
play’s report on the death of a young soldier.
Unlike in the early orchestral pieces Metastasis and Pithoprakta, the
UPIC sounds do not appear primarily as a representation of abstractly
introduced sound structures, but as a direct appeal to extra-musical
listening experiences; as an open illustration of what had remained even
more ambiguous in the constructive encryption of older orchestral pieces.
In the early orchestral pieces, this can be interpreted as an attempt at
the constructive processing of years of traumatic war experiences in
the past; in the radio play as confronting the looming threat of nuclear
war at the time it was written (1981). The more illustrative sounds and
sound sequences in the radio play could be understood in such a way
that Xenakis no longer wanted to speak primarily to a select avant-garde
audience, but to a broader public, which he tried to engage in new sound
worlds with the UPIC, and also wanted to encourage in his compositions
to develop a modern, possibly musical mindset capable of facing current
threats—but within the limits of a then and still largely traditional musical
life, in which contemporary developments had difficulty finding their place
and often laboriously had to deal with competing tendencies in their own
areas.
Developed since the early 1960s, Xenakis’s approaches to digitized
sound production and music training—and also at the spreading of
such music—found competition in France from the early 1970s with
the activities of an institute for (mainly live electronic) computer music
more focused on a musical elite, as Pierre Boulez was then planning and
later realized with the support of the then conservative French President
Pompidou. The competition between the antagonistic approaches of
Xenakis and Boulez also shaped the ensuing years of politics and culture
in France, even a later presidential campaign during which conservative
presidential candidate Chirac publicly favored the Boulez-led IRCAM in
1980, while Xenakis, who favored a more broad-based music policy—as
did the later victorious candidate Mitterand—criticized the IRCAM’s
concept and spoke out for alternative approaches. Although Mitterrand
won the presidential election, Xenakis and the research center CEMAMu
were unable to bridge the gap to the preferred IRCAM in the long term,

176

especially in the years that saw a return to a conservative government
majority.
Xenakis, in 1989 in a conversation with Bálint András Varga,
complained that his research activities, especially his efforts to create a new,
scientifically sound-based, far-reaching cultural endeavor, were hindered by
various external obstacles, not least for reasons of cultural policy:
It was much better during the first socialist government because we
were helped by the director of music, Maurice Fleuret. Then a rightwing government came to power and subsidies were cut by half. We
have to reapply every year. This means that people working there
have no security. They perservere nevertheless because they're
really devoted to their work. [...] It also means we can't have the best
equipment, nor can we employ as large a staff as we need.[5]
In his preliminary remarks to the interview cited above, Bálint A.
Varga, Iannis Xenakis’s most important interviewer, gave a more precise
account of the concrete effects of the difficulties faced by the composer
and director of the CEMAMu and the UPIC project. In 1989, when he
visited the composer in Paris for newer interviews, he visited the UPIC
studio together with Xenakis and later described some difficulties that
were obvious there (in preliminary remarks to the second part of his
interview book):
The premises—three rather cramped rooms in a modern block—
provided ample explanation for the composer's bitterness about
the meagre funds placed at his disposal. The contrast with the
underground phalanstery of IRCAM is all too stark. The actual UPIC
machine is housed in a small, narrow room.[6]
Varga also described some difficulties working with the UPIC as an
untrained layman. Regarding the operation of the drawing device, he
writes: “I had expected its operation to be child's play after hearing how
simple and straightforward it was.”[7]
However, difficulties arose during simple recording attempts:
I had to start several times for I kept forgetting that I was
supposed to move the electric pencil in one direction only. Another
requirement I was hard put to observe was that each parameter
(such as, for instance, the tempo) of my ‘piece’ had to be separately
fed into the equipment, by bringing the pencil in contact with
different points of a diagram.[8]

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

177

RUDOLF FRISIUS

What remains an obstacle to disseminating Xenakis’s musical
thinking and related music education ideas (including the use of his
learning tool UPIC in music education) is the still too great distance
between music-related reform ideas and policy frameworks. Only in a
few but important exceptional cases has it been possible to document
accurately and evaluate thoroughly both concrete planning ideas as well
as compositional, music pedagogical, and musicological results developed
on their basis—also as a basis for future, generally usable updates and
further developments.
It is worth remembering that Xenakis did not consider music,
musicology, and music pedagogy as isolated disciplines in his musical
thinking or in his musicological and music pedagogic activities, but as
interdisciplinary networks with many other disciplines. In this regard, he
was active in the 1960s; for example, in 1968 in Paris. At the spectacular
festival programmed by Maurice Fleuret, Les journées de musique
contemporaine de Paris (Paris Days of Contemporary Music), Xenakis did
not only appear as a compositional innovator, but also as a music political
and music pedagogical stimulator, who developed new, interdisciplinary,
and diversely connected ideas for music education and musicology (at an
event accompanying several spectacular concerts with his music).
In the Paris Festival’s 1969 publication La Revue Musicale, Xenakis
cited several reference disciplines for the interdisciplinary activities of the
working group founded and chaired by him: “Psychoacoustics, acoustics,
room acoustics, electronics, psychology, musicology, music education,
mathematics, physics, computer science.”[9]
In interdisciplinary contexts, not only the artistic and scientific ideas
developed by Xenakis, but also his music policy activities (to establish the
UPIC in international musical life and in particular to modernize music
education), can be understood: not in the sense of specialization in a
particular technology, but as an impulse for the renewal of music thinking
in an epoch of interdisciplinary connections, in which previously isolated
areas such as music and music education should be included in larger,
also contemporary historical cohesions and developments.
This approach has remained up to date—and the endeavor to realize
its musical, technological, music pedagogical, and music political mission
remains to this day.

FIG. 3 Sonogram Metastasis,
beginning (compare with
graphic notation Fig. 1)

Xenakis on Taurhiphanie (1989):
I was asked to create a work which would involve bulls and
horses of the Camargue. Now, bulls are linked with ancient
religious traditions in Crete.
[...]
I accepted the commission on the understanding that the
performance would take place in the Roman amphitheatre of
Arles, where at one time Christians were slaughtered. I asked
for a hundred bulls but the organizers got cold feet and only
gave me twenty...
[...]
We built a wooden tower in the middle of the amphitheatre and
on top of it, about two or three metres above ground, was a
table. The UPIC equipment was placed beneath it, inside the
tower, so that I could improvise as the performance was going
on. This is now possible with the system. I also had control of
the speakers.[10]

FIG. 4 Sonogram
Diamorphoses, beginning

FIG. 5 Sonogram Pour la
paix, beginning

FIGS. 3–6 Representation of pitch gradients on the computer screen (sonograms):

Orchestral music (Fig. 3)—technically produced music (Figs. 4, 6)—music produced
technically with UPIC sounds (Figs. 5, 6) © ZKM | Center for Art and Media Karlsruhe,
images: Hans Gass

FIG. 6 Sonogram Taurhiphanie, beginning © ZKM | Center for Art and Media Karlsruhe,

image: Hans Gass

THE UPIC—
EXPERIMENTAL
MUSIC
PEDAGOGY—
IANNIS
XENAKIS

180

181

RUDOLF FRISIUS

ADDITIONAL NOTES

FOOTNOTES
1.
Bálint András Varga, Conversations with Iannis Xenakis (London, Faber & Faber,

1996), 52.

2.

Metastasis begins with long-range tone movements: starting from a common
initial tone of all 46 strings;
– in the superposition of 46 different glissandi extending in the sound space;
– sliding sounds upwards from the higher strings, downwards from the lower
strings; with consistently different starting times and speeds;
– opening into a dense and spacious chord (after a simultaneous stop of all
glissandi), which then revives afterwards.
The piece ends with the opposite form process: the transition from spacious
tonal layers to the common final tone (again in the middle position, one semitone
higher than at the beginning).

3.

Iannis Xenakis, in François Delalande, Il faut toujours être un immigré: Entretiens
avec Iannis Xenakis (Paris: Buchet/Chastel, 1997), 141.

4.

In the radio play Xenakis used text excerpts from books by Françoise Xenakis:
Ècoute. roman-récit (Paris: Gallimard, 1972) and Et alors les morts pleureront
(Paris: Gallimard, 1974).

5.

Bálint A. Varga, op. cit. 197.

6.

ibid, p. 194.

7.

ibid.

8.

ibid.

9.

La Revue Musicale, Special Issue, no. 265–266 (1969), 57.

10.

Bálint A. Varga, op. cit. 192f.

The music pedagogically related illustrations are taken from the following publications,
oriented towards school practice and teacher training. They were produced based on
teaching experiments in collaboration with teachers:
– Rudolf Frisius in collaboration with Rolf Kalmbach, Franjörg Krieg, Günter
Klüh, Hildegard Schmidt-Frisius: Sequenzen: Musik Sequenzen, Musik
Sekundarstufe 1, 2. Folge, 3. Teil: Musik aus dem Lautsprecher (Stuttgart
1976), 197.
– Rudolf Frisius in collaboration with Helmut Hesse, Rolf Kalmbach, Gänter
Klüh, Klaus Maichel, Alexander Schwan and music publishing office/Gisela
Kiehl: Notation und Komposition, (Stuttgart, 1980), 2–4.
Starting from and following those publications, numerous radio broadcasts were
produced about Iannis Xenakis (see the essay by R. Frisius in Musik-Konzepte 55/56,
pp. 91–60 on this subject - also related to several weeks of analysis seminars by the
author, organized by the Centre Acanthes 1985 in Aix-en-Provence, Salzburg and Delphi)
and about the auditive structure und presentation of his music (DLF, HR, SWR, WDR:
on rhythm, tonal space, sound media and aspects of meaning in Iannis Xenakis as well
as a series of school radio broadcasts by Hessischer Rundfunk inspiring new practical
music activities. At that time Alexander Schwan had founded a working group with
secondary school pupils which performed four group compositions at a music festival
dedicated to Xenakis in Karlsruhe (Wintermusik ‘84 Iannis Xenakis, February 27–28
1984 at the Pädagogische Hochschule Karlsruhe) in the presence of the (surprised
and quite satisfied) composer. Alexander Schwan has worked on the practical musical
work with his pupils and the Karlsruhe workshops dedicated to these pieces in the
program booklet of the festival and in his dissertation: Improvisation und Komposition
im Musikunterricht in allgemeinbildender Schulen der Sekundarstufe I, Frankfurt 1991.
Recent teaching practice-oriented publications that incorporate the music of Xenakis
have appeared in the series RAAbis Musik by the Stuttgarter Raabe Verlag, including
Geräusche aus Natur und Umwelt (2005), Rhythmmusik von und frei nach Xenakis —
Erfinden, Spielen, Hören, Beschreiben (Cl. 5–7, 2010). Recordings of analytical
introductions and related performances were made in 1984 at the Pädagogische
Hochschule Karlsruhe and in 2017 at the Musikhochschule Karlsruhe (concert with
Leonie Klein with Xenakis's Psappha and other contemporary solo pieces [Stockhausen,
Lachenmann, Cage]).

COMPOSING WITH

SOUND

AT LES ATELIERS

GERARD PAPE

UPIC/CCMIX

187

GERARD PAPE

COMPOSING WITH
SOUND AT LES
ATELIERS UPIC/CCMIX
Gerard Pape (in conversation with Rodolphe Bourotte and Sharon Kanach[1] )

GERARD PAPE

SK How and when did you, Gerard, as an American composer living in
the States hear about the UPIC?
GP For me, it all began when I read the article about the UPIC
published in Computer Music Journal in 1986.[2] I was living in Ann Arbor,
Michigan, at the time and had just begun to create my own studio in my
home. I had always been attracted to the idea of drawing music but was
unaware of the UPIC until then. In my studio, I already had a Fairlight CMI
Series II synthesizer with which one could draw waveforms and envelopes,
although it didn’t carry the idea of creating a score. It had a regular
keyboard like other MIDI or digital synthesizers of the 1980s.
I was already an admirer of Xenakis and when I read about the UPIC,
I wanted to learn more, to experience its possibilities. I thought the best
way of going about it would be to call Xenakis on the phone. I asked him
whether it would be possible for me to come to Paris and see/hear the
UPIC because I might be interested in purchasing one. He was astonished
and said, “Sure, come whenever you like!” We agreed on a date for me to
come to the Centre d’Etudes de Mathématique et Automatique Musicales
(CEMAMu) in 1987. Les Ateliers UPIC already existed at the time, and
some composers worked there while others worked at CEMAMu. I got to
see the UPIC at the CEMAMu, not at Les Ateliers UPIC. At Jean-Claude
Eloy’s CIAMI,[3] I was fortunate to be given a long demonstration of the
UPIC by the composer Patrick Butin. I was immediately struck by the
large architect’s table, and therefore the possibility of making very large
A1 format drawings. Also, the fact that it was a compositional tool that
produced a score, while being at the same time a synthesizer with a
graphic interface, really appealed to me. Following that initial introduction,
I spent a few more days at CEMAMu trying things out on the UPIC,
discussing its possibilities with the engineers working there, and also
asking Xenakis some questions. The only UPICs at that point in time, aside
from those at Les Ateliers UPIC and the CEMAMU, were at the Université
de Strasbourg, thanks to François-Bernard Mâche,[4] and in the KSYME
center in Athens.[5] However, none of these UPICs were generating sound
in real time. When I asked the engineers whether it would be possible

188

to have a UPIC system built for me, they were, of course, surprised, but
also very encouraging. They told me they were perfecting a new real-time
version that had just come out, and that it would be worth my purchasing
that version. They showed me a prototype of this 1987 real-time version.
After hearing some of the stories about how long one needed to wait for
the system to calculate complex pages on the non-real-time versions of
1978 and 1983, I was convinced it was worth waiting for the new model,
which took about two years to build and was only delivered in April 1989
to my home studio in Michigan. I had founded a contemporary music
festival in Ann Arbor in 1986 called the TWICE Festival, and in 1989, I
invited Xenakis and George Crumb to be the guest composers. So, it was a
double occasion: to install the first UPIC in the States, to show the studio
to Xenakis, and for him to come as an invited guest of this festival. It was
quite special because he came to my house and saw the UPIC set up in
my home studio and exclaimed “Ah, ça c’est formidable!” He was truly
delighted because it was the first and, finally, the only one ever to be
installed in the whole of North and South America.
SK You installed the UPIC in your home studio and not in any

institution or university environment?
GP Before I lived in this house, it belonged to my composition teacher,
George Cacioppo,[6] and when he died, I purchased it and turned the
basement into a computer music studio. I called it “Sinewave Studio,” a
name originally proposed by my friend, the composer Gerald Brennan who,
in 1980 founded a series of concerts that I participated in which were
called the “Sinewave Sessions” (a name taken from Thomas Pynchon’s
novel Gravity’s Rainbow). The composers who came to work there were
members of the “Sinewave Studios” collective. It was a bit like my current
collective of composers, the Cercle pour la Libération du Son et de l’Image
(CLSI), which I founded as a non-profit association/ensemble in Paris in
2007.[7]
RB Who were the other composers?

GP We were a small collective of composers based in Michigan,

but with no affiliation to the University of Michigan at that time. All the
composers in the collective were independent and used my home studio
precisely because they didn’t have their own home studios or access
to academic institutions for their creative work. (I personally did study
electronic and computer music at the University of Michigan, and had
taken composition lessons with the head of the composition department,
William Albright, after the death of George Cacioppo.) One of the reasons
I was attracted to my first teacher, Cacioppo, was because he was part of

COMPOSING
WITH SOUND AT
LES ATELIERS
UPIC/CCMIX

189

GERARD PAPE

the Once Group[8] that held a famous festival in Ann Arbor in the 1960s. All
of their founding members were university music students in composition
who rebelled against serial music’s academicism and were much closer
to John Cage, Morton Feldman, and the American “sound-based” avantgarde. One of the composers in the Sinewave group who composed a
number of purely electronic works on the UPIC was Kurt Carpenter, who
had graduated from the University of Michigan with a Master’s degree
in composition. My challenge at the time was to see if we could make
Ann Arbor the location of “ONCE again,” thus, TWICE, a center for avantgarde music the way it had been in the 1960s. We invited many famous
composers, some of whom had been cofounders of the ONCE Festival:
Robert Ashley, John Cage, Luciano Berio, György Ligeti, Iannis Xenakis,
George Crumb, and Gordon Mumma. When Xenakis was our guest, I was
particularly happy. The Arditti Quartet played Ikhoor, Tetras and Akea. I
remember two Ann Arbor chamber ensembles/orchestras played Waarg,
as well as Jalons.
RB Are you from Michigan yourself?

Oh no, I was born in Brooklyn, New York, but I went to Ann Arbor to
study psychoanalysis and musical composition. But I have to add, from the
moment I went to Paris and to the CEMAMu, I started dreaming of moving
to Paris one day. I stayed in touch with the engineers at the CEMAMu
between 1989 and 1991, after two of them installed the UPIC in my
studio and Xenakis attended the Festival. Then, one day, out of the blue,
Jean-Michel Raczinski, head hardware engineer of the CEMAMU, called
me and said that the Ministry of Culture was looking for a new director
for Les Ateliers UPIC. I needed to write up a project quickly and travel to
Paris to discuss this project with the Ministry of Culture to be considered
a candidate. My project was chosen, and I became director of Les Ateliers
UPIC in September 1991. When I arrived in Paris, the Ministry said that
they were giving me a six-month contract and would closely monitor the
progress of my project and, that after that trial period, they would make
the decision to either continue Les Ateliers UPIC with me as director, or
they would simply close it. Fortunately for the center, after six months, they
liked what I was doing, decided to keep the center going, and increased
their financial support for the center significantly over my first five years.
GP

RB Can you tell us more about your initial project?

Yes: in a word, my project was to integrate the UPIC as a serious
and powerful tool of computer music, affirming its place in that realm at
large. Another goal was to get as many composers, from as diversified
backgrounds as possible, to work on the machine so that the UPIC would
GP

190

be taken more seriously and generally accepted, and no longer be seen
simply as a tool for Xenakian composers and for initiating children into
music. Also, I was keen on developing possibilities of using the UPIC not
only for purely electronic music, but also to combine it with instruments
or voices. We had already explored such possibilities with the UPIC
in Michigan. The Ministry accepted this project and that’s what we
immediately set out to do. As a consequence, in 1992 and in 1994, we
presented four concerts at Radio France in collaboration with Claude
Samuel, who was then the Radio France’s music director. In 1992, for
Xenakis’s 70th birthday, we had concerts for ensemble and UPIC as well
as percussion and UPIC with Rohan de Saram and Michael Pugliese as our
guest soloists. In 1994, the theme was the UPIC and string quartet with
the Arditti Quartet as our special guests. I commissioned François-Bernard
Mâche (Moires) and Roger Reynolds (Ariadne’s Thread) to make new
works for string quartet and UPIC. Xenakis very graciously also accepted
my request to make a new Gendyn piece called S709, which was partially
composed at CEMAMu and partially at Les Ateliers UPIC. The other theme
in 1994 was pieces for UPIC and non-western instruments. The guest
composers from Japan were Yuji Takahashi and Takehito Shimazu.[9] There
were also some extraordinary purely electronic works that I commissioned
which were composed by Bernard Parmegiani and Daniel Teruggi, among
others. Teruggi and Parmegiani combined UPIC sounds with the processing
of these sounds by Groupe de recherches musicales (GRM) tools. I have
to say, I was not shy about discussing the UPIC’s limitations with those
composers who I just mentioned. In the beginning, we focused really on
timbre, how to improve the timbres the UPIC could produce.
Did you discuss this with the engineers at the CEMAMu?
Brigitte Robindoré,[10] the first person I hired as a musical
assistant, came from a more musique concrète orientation. She filled me
in about how composers from that realm felt about the UPIC. For them,
the idea of drawing a waveform was not credible, because how could one
know how to really draw a waveform? So, we started making samples,
which, in fact, Xenakis had already done for his piece Taurhiphanie.[11]
UPIC samples, at the time, were short and not really samples but
pasted waveforms taken from samples. A waveform that was able to be
extracted from a sample was the equivalent to 1/10th of a second of
sampled sound. So, we made many experiments regarding how to make
the UPIC sound richer. The idea behind UPIC that no other system had
was the idea that composing a graphic score involves controlling 64
oscillators of additive synthesis. This is the aspect we really wanted to
preserve; that one actually shapes the sound in its interior by drawing its
SK

GP

COMPOSING
WITH SOUND AT
LES ATELIERS
UPIC/CCMIX

191

GERARD PAPE

micro and macro parameters. This is where I found a connection between
the approaches of Scelsi and Xenakis. I tried to bring in a kind of Scelsian
orientation to Les Ateliers UPIC because I thought that combining their two
respective points of view would be something very rich, compositionally
speaking. I introduced the idea that when you are drawing a page on the
UPIC, you are not necessarily drawing a complex score, a large sound
mass, like the graphic score of Metastasis, but that a UPIC page could
be the interior of a single sound. For example, I experimented by drawing
64 arcs within a small frequency range to create beats and interferences
between the oscillators, thus creating something like a Scelsian tone
cluster. That approach actually worked quite well in my piece Two ElectroAcoustic Songs for soprano voice, flute, and UPIC tape.[12] Still, I didn’t
impose my solution as the only one. The main guideline I gave to those
who came to work on the UPIC was: “Make the machine work for you.
There is no right or wrong way to use it.” It is a tool which is there to help
composers compose what they want to compose, and it was adaptable
to their aesthetic. For our research on the problem of the timbre of the
UPIC, there was interaction between Les Ateliers UPIC and CEMAMu.
We met with the engineers there frequently. They had put out the new
Windows version of UPIC in September 1991, which coincided with my
arrival. In fact, one of the first things that happened when I arrived in
Paris in September 1991 was that my own UPIC, which I had brought with
me from the USA and put at the disposal of Les Ateliers UPIC for free,
was updated to become a Windows system. I still have this instrument
at home, with the original Windows 3.0 computer still working and the
original real-time additive synthesis cards developed at CEMAMu still
working as well! We were discussing all the time with CEMAMu about
how to make the timbre richer. Still, this was not the only possible
solution. In 1992, Jean-Claude Risset came to work on the UPIC at my
invitation to write a piece celebrating Iannis’s 70th birthday. Risset used
the drawings of Metastasis to make a piece for saxophone and UPIC
called Saxatile, premiered by Daniel Kientzy, which has now become a
classic piece for saxophonists.[13] Others would use the UPIC to generate
raw material that they would then transform further with other computer
music tools. The whole point was for every composer to use the UPIC
to their and its best advantage. And this corresponded precisely with
Xenakis’s approach: he never wanted to have “disciples;” in fact, he
vehemently discouraged that. What he thought and that we at the
center promoted was at once an ethical philosophy and a compositional
discipline: each composer must find his or her own voice, above and
beyond our promoting the UPIC. In our studio, it was one tool among
several that could be used.

192

Another important musical event that occurred when I arrived in
September 1991 was that it coincided with Xenakis’s completion of his
great work, GENDY3, based on his Dynamic Stochastic Synthesis. Hearing
this piece gave me a new idea for the UPIC: I composed, playing the UPIC
in real time, by redrawing the UPIC waveforms in real time and recording
them. It wasn’t using stochastic functions because I was drawing the
changes by hand. My ears and my hands replaced mathematics in this
case. This led to my electronic work Varesian Variations.[14]
SK How did you go about recruiting composers for the center’s
sessions and workshops? Were there open calls?
GP People were contacting me all the time—phone calls, letters,
messages… There were far more people who wanted to come and work
than we could accommodate. Sometimes, it was a tough call deciding who
would get a residency and who wouldn’t. For our courses (the 8-month
cursus or our 1-month summer sessions), there were open, public calls for
students. These were, however, paid courses, not free, like the one-month
composition residencies.
RB Did you hold both types of sessions (short and long) from the
beginning of your tenure?
GP No, at the beginning, only short UPIC Workshops, the same way
as my predecessor, Alain Després, operated;[15] we were often travelling
with the new real-time UPIC: to Arnhem, Stockholm, Vienna, Salzburg,
Munich… many places. Sometimes we were invited along with Xenakis, for
example, to Greece, in Delphi and then later in Athens. The vast majority
of these UPIC workshops and concerts were short and mainly for young
professional composers studying computer music.

These were 2-week workshops?
No, much less—maximum 1-week, or less; workshops followed
by concerts. We also went to Japan twice—for the 1993 International
Computer Music Conference (ICMC) and then again, some years later.
In general, my goal was to get people to take the UPIC more seriously,
because its reputation was suffering due to the timbral limitations we
discussed earlier. I was convinced that the more people could hear about
the machine’s possibilities and then get hands-on experience with it, the
more it would be respected. Also, once we openly admitted that timbre
was a problem, and one we were aware of and working on, the more
composers would see it as a challenge to compose on the UPIC: how to
work around this limitation and figure out a way, for themselves, to make
it their own. Working with the UPIC was also taught as an ethic, a way
SK

GP

COMPOSING
WITH SOUND AT
LES ATELIERS
UPIC/CCMIX

193

GERARD PAPE

of being, something that Xenakis personified in his rigorous way of being
himself, like no one else. When he came to speak with the students for our
8-month course in computer music and composition, he emphasized only one
thing: freedom; that each composer needs to remain free. With freedom, the
composer becomes responsible to make sure that their work is original. Iannis
didn’t believe in improvisation—it wasn’t that kind of freedom he meant.
Rather, it was music composition as “cold fire,” as he called it: something very
powerful you pull out of yourself as an ek-stasis, a going beyond oneself. At the
same time, composition, as an act, needs to be treated with extreme ethical
rigor. That, in a nutshell, was the philosophy of what was taught at the center.
Whether you compose with the UPIC or with something else, the Xenakian
compositional ethic still stood. How to find your own compositional path, to
compose music that no one else but you could compose.
RB It’s true, when at the Centre Iannis Xenakis (CIX) we started
doing UPIC workshops again, even with the 2001 PC version, some
newcomers to the system produced very interesting results. I don’t
know of any other tool from that era that can say the same.
GP There are other tools people have developed, thinking they were
following Xenakis’s vision or direction, but actually, they were not because
they got confused by this idea of “drawing.” Drawing on the UPIC is just a
method, not the goal; it never was and never should be. The idea behind
the UPIC is not to turn an image into a sound; you have to first start with
composing the sound. The image per se is unimportant. You can have a
completely uninteresting image but that creates a rich sound. It doesn’t
matter what the sound looks like.
SK I agree, of course, but what about UPIC as a pedagogic tool,
where notation is demystified by the simple act of drawing, something
that basically anyone can do? And, it is certainly effective in breaking
down the solfège barrier. In particular with UPISketch, we’ve seen it
happen: in literally 10 minutes, kids who never thought they could
make music, start composing, thinking about what that means,
appropriating the tool, all thanks to drawing.
GP If you get them young enough, children can still use their
imagination without fear or preconception. A little older, they might try to
imitate what they already have been taught is “music.”
RB Little kids can bang on a piano, and have fun making sound, but
they’re not listening, they’re not making something. Drawing music
seems to impose on them a compositional thrust that makes them
want to create a piece they can call their own.

194

GP Getting back to Xenakis insisting on freedom and originality, it is
actually one of the reasons I proposed to rename Les Ateliers UPIC the
CCMIX: Centre de Création Musicale Iannis Xenakis in 2000. It was to
emphasize more of an affiliation with Xenakis as a creator and thinker,
generally, rather than being exclusively focused on the UPIC. Musical
creation—with or without the UPIC—that was indeed what we tried to
encourage at the CCMIX. Some composers-in-residence were shown the
UPIC but decided that the UPIC was not for them. The other tools available
at the center were very Scelsian, enabling one to enter into the “heart of
sound,” as Scelsi said, and as the UPIC indeed did, too. Students at the
CCMIX could not only use various tools in addition to the UPIC, but also
learn how to use them from the very designers of these tools: Kyma with
Carla Scaletti, Composers Desktop Project with Trevor Wishart, Pulsar
Generator and Cloud Generator with Curtis Roads, and ChaoSynth with
Eduardo Miranda. Xenakis himself composed with many different tools or
approaches at different moments, depending on what he was researching.
The GENDYN program, for example, was the last.

But Iannis developed GENDYN!
Of course, but if he needed that, it’s because it was what
interested him at the time. GENDYN goes in a different direction than
the UPIC. Rather than combining many arcs derived from combining
drawn waveforms or ones copied from samples, as in the UPIC, GENDYN
creates stochastically generated waveforms that you can combine. The
UPIC, quite different than GENDYN, has other advantages. It allows one
to operate differently on the micro level (waveforms, envelopes), the
meso level (whether you compose a tone, a harmonic series, a cluster,
or a noise depending on how you combine your arcs), and on the macro
level of texture (order, disorder, chaos). I chose, as director of CCMIX,
but also as a composition teacher of our students, in the context of our
8-month or our 1-month course in “Computer Music and Composition” to
study all of Xenakis’s book Formalized Music and not just the part about
the UPIC. We discussed the whole gamut of Xenakis’s research and
compositional approaches.The UPIC is fascinating, but it is not his sole
musical achievement. The theme of our courses, in general, was composing
with sound. Often, the musicologist Harry Halbreich, in his lectures to our
students, analyzed not just Xenakis’s scores, but also those of Scelsi, Nono,
Varèse, and Claude Vivier—all composers who composed with sound itself.
SK

GP

RB If we go back to your idea that the UPIC as a tool resembles the
personality behind it, I have to say I beg to disagree, because if at CIX
today we can and do have the ambition to pursue and further develop

COMPOSING
WITH SOUND AT
LES ATELIERS
UPIC/CCMIX

195

GERARD PAPE

this idea and tool, it is possible because there’s something there, at
the base, that goes beyond the personal and rather touches upon
the universal. As UPISketch’s main developer, what I’m striving for is,
in fact, even greater universality. One of our goals in this direction is
incorporating Dynamic Stochastic Synthesis in this tool.
GP I was speaking about Xenakis’s compositional ethic, the rigor of
his compositional thought, and did not intend to evoke the sound of his
music, as such. To not imitate other composers, no matter how much you
love their music, is a fundamental Xenakian ethical principle. The UPIC
was always destined to be a tool for the graphical representation of the
inner life of sound, in a very broad sense, not necessarily and uniquely
through drawing and indeed, there are many ways of generating such
graphical representations.

197

GERARD PAPE

FOOTNOTES
1.
This exchange took place in Paris on November 17, 2018.

FIG. 1 Group photo at the CCMIX studio, 1996, from left to right: Harry Halbreich,
Ron Fein, Gerard Pape, N.N., Iannis Yenakis, Curtis Roads, N.N., Leon Milo, Brigitte
Robindoré, Bernhard Gander © CIX Archives

2.

In fact, two entries appeared in the Winter 1986 edition of CMJ related to the
UPIC: Henning Lohner, “The UPIC System: A User’s Report,” in Computer Music
Journal 10 (1986), 42–49 and Henning Lohner and Iannis Xenakis, “Interview
with Iannis Xenakis,” in Computer Music Journal 10, 4 (1986), 50–55.

3.

CIAMI (Centre d’Informatique Appliquée à la Musique et à l’Image): founded in
1981 by Jean-Claude Eloy at the request of Maurice Fleuret, the then newlyappointed Music Director of the French Ministry of Culture under François
Mitterand. This Center, in a sense a response to IRCAM’s publicly alleged
despotism ruled by Pierre Boulez, aimed to create a well-equipped alternative
studio (including IRCAM’s 4X, GRM’s Syter, and a UPIC) where composers such
as Pierre Henry, Xenakis, and Eloy could work free of any aesthetic hegemony.
Located in the outer suburbs of Paris, in Rueil-Malmaison, the Center’s goals and
missions were never to be fulfilled, forcing Eloy to resign in 1988. The CIAMI was
ultimately disbanded in 1990 by the French government.
http://www.eloyjeanclaude.com/Ciami-info.html

4.

See Mâche, this volume.

5.

See Kamarotos and Tsioukra, both this volume.

6.

For more about George Cacioppo (1926–1984), see
http://www.moderecords.com/profiles/georgecacioppo.html

7.

See http://clsimusic.free.fr/

8.

ONCE Group, a 1960s Ann Arbor composing collective that included Robert Ashley,
Gordon Mumma, Donald Scavarda, Roger Reynolds, and Robert Sheff.

9.

See Shimazu, this volume.

10.

See Robindoré, this volume.

11.

Xenakis’s Taurhiphanie (1987–1988), in its two-channel version, is available on
the Neuma CD 450–86 from 1994.

12.

Pape’s Two Electro-Acoustic Songs (1993) can be found at CIX Archives under
(id951).

13.

A recording of Risset’s Saxatile is available on the CCMIX - Paris New
Electroacoustic Works, 2-CD set released in 2001 by Mode Records (99–99).

14.

Pape’s Varesian Variations (1992) can be found at CIX Archives under (id493).

15.

See Després, this volume.

ONE MACHINE—

TWO

NON-PROFIT

HUGUES GENEVOIS

STRUCTURES

203

HUGUES GENEVOIS

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES
Hugues Genevois in conversation with Sharon Kanach
SK Hugues, when Les Ateliers UPIC were created, were you already
working at the Ministry of Culture?
HG I arrived at the Ministry just after the Les Ateliers UPIC association
was founded, in 1986. I was first a scientific advisor for music research
until 1989, when I created a music and dance research council. After that
department merged with the theater department, I was then in charge
of the office dealing with writing and research (which included music
commissions, drama writing grants, etc.)
SK Did you already know Xenakis at the time?

HG I was at the Ministry from 1986 to 2004, but I met Iannis before
I joined the Ministry, as a participant in the Centre Acanthes during the
summer of 1985. At the time, I was working for an aircraft manufacturer
as a software developer. But I practiced music as well, so I was following,
with interest, the research that was being done in new music. When the
opportunity arose to participate in the Centre Acanthes’s sessions in Aix-enProvence and Delphi, I jumped at it!
SK

You did both sessions?

HG Yes, both, and that’s where I met Makis Solomos, who was still

a student at the time, and where I got to know other people, such as
François Picard who is a professor at the Sorbonne Université. It was
a great event and I think I was probably the only one there who had an
engineering background at the time.
SK

Iannis must have liked that!

HG Yes, he liked to talk about his relationship to science and

HUGUES GENEVOIS

technology. This was my first real and direct contact with Xenakis before
I joined the Ministry of Culture, which happened about a year later. From
that summer’s experience, I made every effort to make sure that this
scientific universe, my tastes and musical activities would somehow meet.
One day, I saw a job advertisement in the paper by the Ministry seeking
someone to coordinate research and creation. At the time, there were

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES

204

so-called “research centers,” but still no mention of any “national centers
for musical creation.” There were quite a few of these research centers
throughout France at the time and the Ministry decided it needed to take
stock of their activities. Mind you, many of them were not really research
centers but rather creative studios. It was at that moment that I was finally
able to bring together the two worlds that had been quite separate for me
until then, but not completely. In fact, I had done my Master’s degree in
physics in Marseille where, Jean-Claude Risset was my professor. So, we
obviously talked, became friends, but my other teachers advised me to
pursue an engineering degree instead. I noticed that there was one school,
Télécom/Paris, that offered a “sound and image” major. So, I focused on this
school, where I was accepted, and took this major with a particular focus on
everything that was acoustic: signal response, image analysis, and so on.
SK

I can just imagine Iannis rubbing his hands!

HG I rubbed my hands, too! Furthermore, I had participated in other

courses of the Centre Acanthes, notably with Pierre Henry, but it was a little
complicated. Iannis, however, was someone who was open, without barriers;
his class was very pleasant, like him and all the teachers. At the time I played
the cello and taking classes at the Centre Acanthes was quite something!
SK

Musically, were you already composing or “just” playing?

HG I was playing. There was this instrumental side and another, an

electroacoustic side, and they were two separate worlds for me at the time.
Electroacoustics was not yet doable in real time, that was unthinkable, and
so I felt a little torn between the pleasure of playing with others and the
solitary activity of a studio. Alone in the studio we try to act as if at the end
of the creative process, we give the illusion of a gesture, of an agogic, yet
completely constructed. At the time, all my research focused on this: how
to make sure that sounds that attracted me—which were not instrumental
sounds but rather noise, or sounds of nature and the like—I could play as if
they were a musical instrument.
And, for over ten years now, that has actually become possible. But at
that time, I was being pulled in two different directions: on the one hand
my scientific competence, and on the other, my musical appetite—the two
had trouble joining together. And, in making music, the pleasure of playing
with others and my preferences led me towards musique concrète, world
music, and things that could not be played with others live.
SK

At Acanthes in 1985 the UPIC was there?

HG Yes, there was notably the UPIC plus several workshops around

the string quartets with the Arditti Quartet; percussion with Sylvio Gualda;

205

HUGUES GENEVOIS

and piano with Claude Helfer. We were surrounded by absolutely incredible
people! I find it extremely unfortunate that all this has stopped now,
because being in direct contact with performers of that level, all of whom
were quite approachable, it was really fantastic! We talked, we had coffee
together, we worked: it was unique and extraordinary.
SK I’ve been told by other participants that basically all of those
sessions were well documented and recorded. What an incredible
treasure trove of unique, first-hand material that has to be. I, as
well as several colleagues, have been unsuccessful in our attempts
to consult these. It’s a real pity that all the recordings made during
those sessions are not publicly available today.
HG However, there was no shortage of approaches at the time. At
the Ministry, we were wondering about the sound archives of the creation
centers, and we approached the then director of Acanthes, Claude Samuel,
several times. I believe he wanted to try to publish them at one point, and
that’s why he kept everything. But this never happened.
SK I am rather shocked by such stories about archives. The French
government gave so much tax-payers’ money for creation, and
especially for Acanthes, doesn’t it have the power to say that these
archives belong to the public?
HG No, because we supported associations, which therefore remain
the owners of their own collections. Some have taken good care of
their archives, such as Bourges, which had an archiving policy from the
beginning, while others did not plan anything. One exception is Pierre
Henry, who really took care of such things and kept all his many reels.
Today, what is valued is to create something new all the time. To
question the past, apart from a few exceptions, we don’t know how
to do this work of memory. Bourges, for example, knows how to make
retrospectives: 20 years of creation, fascinating stories, the birth of
movements in 1975 to 1980, and transversely, with different branches of
history. Otherwise, we stay with our noses stuck in the present, without
taking a step back, and it’s a great pity, especially when it comes to
unwritten music, like electroacoustics.

Indeed, this is a real problem. We are lucky, at Centre Iannis
Xenakis (CIX), to be in close contact with many of Iannis’s former
collaborators, and everyone is very grateful to him for having given
so much and are happy to know that we are trying to perpetuate
his work and his memory. We have received several unique and
significant bequests from them for our archives. But, as you well
SK

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES

206

know, it costs a lot of money to digitize and maintain such archives
with technologies that evolve so quickly.
HG In general, for twentieth-century musicology, access to sources
and data is a real problem. This costs money and, above all, it is not
valued: it is the centers that must strive to keep a living trace of the past.
SK Let’s get back to your joining the Ministry. Was there competition

for the position? Not being a trained “civil servant,” did you have to
take some sort of equivalency test?
HG In 1986, a very long time elapsed between when I saw the
ad and wrote up—the very next day!—my file and CV, and when I was
actually hired: it took over six months. On the one hand, there were a lot
of candidates and, on the other, the position had not yet been created!

SK Maurice Fleuret was the Director of Music within the Ministry at
the time, right?
HG Yes. I think I was chosen because I had a letter of support from
Jean-Claude Risset and one from Iannis, too, which must have counted.
There were other profiles similar to mine. But the fact that I was in contact
with these great figures in computer music must have counted. Plus, I got
along well with Maurice Fleuret. For me, he remains the musical giant in
this Ministry’s history. He had an immense curiosity for all kinds of music,
a fierce appetite, insatible... for music. After him, the administrators who
were there could have just as easily been in any other Ministry...
My tenure there enabled me to acquire a fairly complete overview of
the entire French musical landscape and of what was then called “music
research,” but which was not always research! This was sometimes due
to the endowments that made it possible to purchase equipment. It
became necessary to clarify things and separate what was an activity
that could be evaluated in terms of research and was supported by a
studio from what was unrelated. And there were not so many real places
for music research; there was of course IRCAM, with which I always
had difficulties—and I am not the only one; difficulties related to its
institutional and almost philosophical positioning at the time.
I remember Laurent Bayle’s speech when he became the head of
IRCAM and echoed a Boulezian idea as an act of allegiance: “IRCAM is
something extraordinary that embodies music research. Of course, before,
there were handymen, like Pierre Schaeffer and Xenakis [...].” Besides the
fact that it seemed historically unfounded to me, I could accept that he
considered Schaeffer and Xenakis as being experimenters, different, but
not handymen! “Experimental” does not mean tinkering: someone who
experiments rubs up against reality and welds together sound material.

207

HUGUES GENEVOIS

If no risks are taken, what is the purpose of research? Can we, at the
Ministry, support such a discourse or institutional posture? Can the State
justify investing in a single team, a single institution?
It was disproportionate from the beginning.
HG Yes, IRCAM alone received 75% of the research budget, so it
was indeed extremely disproportionate. What happened next was that
Pierre Boulez, the founding director of IRCAM in 1970, had a tremendous
organizational capacity that others did not. Iannis, as he freely admitted
himself, was not an organizer and at the CEMAMu, sometimes it was
complicated. He didn’t really know how to get rid of certain people and I
was made to understand that we had to do it because he wasn’t up to it.
Ideally, there should have been someone between him and the team, an
administrator, a person in charge of running the operation; he was in too
direct contact and it was delicate; the situation became untenable and it
caused problems several times. For example, at the time, the CNET, which
was in Issy-les-Moulineaux, housed the CEMAMu in two not very large rooms,
and no one from the CNET really cared about them. I had kept in touch with my
Telecom engineering school and the man who was in charge of acoustics told
team, which would be an opportunity for all to have art trainees available.”
Iannis’s team worked at their own pace, with no one bothering them, a little
marginal, and producing results rather slowly. One or two members of the team
welcomed the idea but Iannis was not able to impose this on the whole team.
SK

SK This intersects with several things, in fact... I've been working
quite a bit lately with Alain Després, who was the first director of Les
Ateliers UPIC and whom you must have known.[1] He confessed to me
that one of the reasons why he threw in the towel, even if he never
counted his hours and was as enthusiastic about the UPIC as Iannis,
was that when the UPIC won the FIAT prize, 500,000 French francs,
which was quite a bit of money, the CEMAMu thought that the award
should go to them. But Iannis decided to give it to Les Ateliers UPIC,
which enabled them to make a major tour of North America, Mexico,
and Canada as well as a second tour of Japan; enough to really
launch the UPIC on an international level. And the CEMAMu team
was furious and tried putting obstacles in his way. Iannis depended
on them, he wasn’t the one who developed the UPIC system, the
engineers did, but the team was getting nowhere.
HG Furthermore, they were absolutely not looking to build
relationships with the engineers on CNET’s site, which could have certainly
expedited a lot of tasks. There were surely other people, too, musicians,
who would have been interested in participating in the adventure. I asked

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES

208

Iannis for permission to go there to work with the UPIC because writing files
about it for the Ministry is one thing, but I wanted hands-on experience
with it, too, so I proposed a creation. Iannis accepted and from the moment
I arrived the first morning, there was basically no exchange with them,
apart from with Jean-Michel Raczinski, who was very open and competent.
Basically, they were cut off from the academic world of research, from any
flow of trainees and young people, and from the possibilities of theses
and doctorates, so they lived a bit in a closed circuit. They were not in the
creative world because they were engineers, not creators, and they cut
themselves off from their original environment—science and technology.
You know, we’re trying to restore our old UPIC units at CIX, so we
took a shot a contacting Raczinski, after all these years, to see if he
was interested. This past February, I received a reply from him: “I
have almost unlimited esteem and admiration for Xenakis. I was lucky
enough to be able to work with him for almost 18 years. It was a unique
and exceptional experience. He gave me the opportunity to think out of
the box, to push the limits, my limits. So, I would be very happy now to
renew these years, or at least try.”[2]
HG If it had only been Raczinski, the CEMAMu would have moved to
Telecom and who knows what could have been developed there then? But
the others joined forces against him.
SK

SK Although it is true that Iannis was not an organizer, he was so
perseverant. When working with him on Music and Architecture,[3] I
was amazed at how much trouble he took writing, for example, tons
of letters trying to organize places for his Diatope to tour, not to
mention several other projects that ultimately never worked out. I’m
surprised he didn’t bang his fist on the table and say, “Guys, we’re
going to Telecom!”
HG Maybe he was already tired... But above all, I think that an artist
cannot be his own agent. At some point you need someone who can say
“No! Not like that!”—someone who is not in a relationship of admiration.
SK Do you know why or understand why there were two independent
structures—the CEMAMu, on the one hand, for developing the UPIC
system, and Les Ateliers UPIC, on the other, to promote the tool? I
always found it rather difficult, at the time, to comprehend who did
what.
HG Now, I have to admit I don’t know. When I arrived in 1986, Les
Ateliers UPIC already existed. Why this split when other groups did not
work like that? Lyon, Arles, Marseille…all had activities of production,

209

HUGUES GENEVOIS

research, diffusion, pedagogy; there were exchanges among teams inhouse. I was not convinced it was a good idea to separate research and
Les Ateliers UPIC. The developers were already cut off from everything...
Under one and the same roof, they might have been forced to get more
involved. In retrospect, separating the two activities under two different
structures was absurd. Even though the CEMAMu team worked every day,
it was a small team compared to other computer developers. But then, it
wasn’t as easy as nowadays. When you think of what existed at the time,
even IRCAM’s 4X, they were huge machines that were slow to develop.
SK And with inconceivable limitations, especially in terms of memory.
Guy Médigue, who worked on the first UPIC prototype, says that the
first machine had a memory of 32K![4]
HG Before joining the Ministry, the planes I was working on had a
memory of 64K! To save more space, we didn’t use much graphic language,
they were codes and we exploited the processor up to the last few digits.
With 64K, we had all the software of an aircraft with management, radars,
displays for pilots, controls. We could do things with very little, but in real
time, it became very complicated. At one point, a processor’s cadence, its
speed of processing information, is an unavoidable frontier. For the realtime UPIC, they had to develop a card, as most software manufacturers
did at the time who wanted to do real-time audio. The first protocols also
worked with a card that needed to be put in your computer because you
couldn’t only rely on the processor. And there were not many who could
develop a card. When I came in contact with the CEMAMu there were
four engineers; it was a microscopic team that could have been more
efficient had they been more in touch with the scientific and technological
community of their time. Especially, at the time, it was relatively easy to
motivate institutions—Xenakis was not just anyone!—and the contacts with
Telecom had gone well, young interns were numerous there, so there was
a potential workforce... Once again, I think that a creator who finds himself
alone in front of his developers must have a particular character, and this
was not the case with Iannis. We needed someone who would have been in
charge of management, human management, presence...
SK

Did you suggest that to Iannis?

HG Yes, on several occasions I told him... It was problematic for him...

but at the same time I think that by going to the CEMAMu studio, he felt
like he was part of the team and young. Maybe I’m fantasizing… He would
not have liked to have the position of the great Manitou, a big shot, even if
he was one, in fact. There, he was relatively relaxed, he never imposed his
authority.

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES

210

SK

He was not a boss.

HG Not at all! He was someone who was searching, I’m not saying

someone who doubted, but someone who was looking, ready to exploit
things, to abandon them, to go back to the drawing board.
SK By hiring a manager would he have been obliged to cut another
position? Was it a problem of resources?
HG At the time, between 1986 and 1988—everything changed
after that—we were still in an era where, if it had been necessary to
create even half a position for an administrator, it would have been
feasible. Frankly, he could have succeeded in convincing Fleuret; all he
had to do was present a project, defending the necessity to reorganize
things. There was a time when the Ministry said: “In creative centers you
need real managers.” More recently, the Ministry has gone back on that
policy; well, in fact, it changes all the time. I have the impression that the
formula that does not work too badly is one that foresees both. There is
nothing extraordinary about that, it’s like that everywhere; creators must
be helped by being free of administrative tasks, otherwise they become
exhausted or don’t do the job well.

Did you ever suggest that the two structures be merged?
HG No, it was like that, and everyone seemed so convinced that it was
a good idea... and on the spot, I didn’t understand. I thought it could be
problematic, but it was only after the fact that I understood that it was, in
fact, absurd.
And then we arrived at a period, quite quickly, when it became
difficult to redirect the activities of a center because we had set up
research evaluation tools with a desire to be open: not only computer
music, but other activities too, dance, etc.... and my job was to allocate
public funding to research, distributing it where it would be most effective.
But in fact, I quickly realized that when I was able to save some money in
one place, that money would disappear in the process! So, it was getting
very difficult. How can you try to build a policy if you don't have control
over your financial envelope, and research is clearly no longer a priority?
There had been a research department, which was effective for several
years, but it ceased to exist when Frédéric Mitterand was the Minister
of Culture. Moreover, I am one of the rare survivors: in 1986 my position
was the last one created in the field of music at the Ministry of Culture.
Afterwards, and since then, no positions were created; I was the last one.
There is still a framework agreement between the Ministry of Culture and
the CNRS[5] but it is freewheeling because there is no longer any political
volition. Artistic research is clearly no longer prioritized in France.
SK

211

HUGUES GENEVOIS

SK Was yours really the last new position created in the Ministry of
Culture? Ever since 1986?
HG In the musical field, yes.
The one who could have developed an activity because he was a
recognized figure in the field, but who could not do so either, was JeanClaude Risset. He was at the very heart of the CNRS institution with a
prominent position in computer music, an emblematic figure... but he was
not a leader either and he had a microteam. He never fought for his team
to develop, even when he could have afforded it. So, there were many
missed opportunities!
For example, here at the LAM,[6] we are twelve permanent
employees, it’s not that big a deal, but twelve salaries: a subsidy of
that amount would never be possible! And in addition, the premises,
equipment, etc...
SK But the LAM, which you direct, is housed at Sorbonne Université,
at Jussieu. Don’t you receive financial support from the university
too?
HG Like all public research labs, we are under the supervision of
our university and the CNRS, so all the partners contribute a little money,
distributed on a per capita basis, if I may say so. We have a small grant
from the Ministry of Culture, it’s better than nothing, and the rest are
contracts: ANR[7] grants, the Fondation de France, for example. As a
public lab, we can hope to create a position from time to time, because
at the University, even if things are going poorly, teachers are a vital
necessity; while an association has no vital need! So, we must be able to
preserve our autonomy and creative spirit and at the same time have a
little institutional anchoring: very general considerations that go beyond
just the UPIC’s scope! But it gives a general picture of how things have
evolved. To think of research outside the university framework is to take
the risk of weakened research, not necessarily of lower quality, but which
will not be able to be maintained in a sustainable manner.
That is why I had campaigned for the CEMAMu to be hosted by
Télécom. There were some very strong people there at the time in signal
processing. The acoustics teacher was very musical, very interested. The
buildings belonged to the Post Office, which vacated an entire floor...
SK In what year did all this happen?

HG 1993–94 or maybe slightly before. Frankly, I felt Iannis was a
little demotivated. And perhaps there was some pressure from his wife
Françoise, too...

ONE MACHINE—
TWO NON-PROFIT
STRUCTURES

212

SK I remember, around that same time, Iannis called me one morning
and said, “If you are free tonight, come to dinner, the Brendels will be
here!” We had already met and got along well and I was indeed free.
So, we were all there, waiting… and no Iannis! This was before cell
phones! In fact, he was at the CEMAMu, must have become absorbed
in his work and completely forgot about us and dinner! When he finally
arrived, at around 9:30, we were all relieved to see him, finally. And
Françoise said to him, “So, did you at least discover your unheard-of
sound?” He looked down and simply shook his head: no.
HG I think she, Françoise, had a strong animosity against CEMAMu
and realized that the team, whose members she vaguely knew, was not up
to snuff. So, at one point, Iannis just gave up.
SK How was the money distributed between the CEMAMu and Les
Ateliers UPIC?
HG The CEMAMu received a much larger subsidy than Les Ateliers
UPIC, mainly because it financed four or five, not ridiculous, salaries of
developers and engineers. Their subsidy was around one million French
francs. Some years, operating and equipment grants were combined. They
didn’t have to pay rent but there were other expenses.
Apart from IRCAM’s grant, it was one of the biggest at the time. Why?
Because the other centers were co-supported by the Ministry and local
authorities. But for the CEMAMu, 100% of their subsidy came from the
French government.
SK

And the Ministry agreed to that?

HG At the time, yes. Today, IRCAM is still a special case: the city of

Paris does not contribute a cent! But then, IRCAM has its own resources
generated by international contracts and they are active in this area.
So, Les Ateliers UPIC were getting much less?
HG Yes, their subsidy covered basically a salary and a half, which was
not commensurate with the positions and seniority at the time. CEMAMu,
on the contrary, was one of the better payers.
SK

Finally, Les Ateliers UPIC were, in good part, self-financed, with
workshops, residencies, etc?
HG Yes, and they had to generate income, if only to pay the rent!
SK

After Iannis died, were you the one at the Ministry who
commissioned Thierry Coduys to explore whether or not to pursue
CEMAMu’s activities?
SK

213

HUGUES GENEVOIS

HG No, not me. Thierry had his structure, La Kitchen, at the time and
knew the Ministry’s inspectors well. Like all directors of creative centers,
he was constantly on the lookout for any opportunities to recoup funding.
I did meet him at that time and he was very energetic. He probably hoped
for a consulting activity and to recover the CEMAMu, but that structure’s
inherent problems would not have been solved. Thierry did receive funding,
though, to finance the first version of UPIX, inspired by the UPIC but
extrapolating other tracks too.[8] There was a graphic idea still behind it,
certainly, but in the end, it had little to do with the UPIC.
SK Apparently, Iannis received significant financial support from the
Gulbenkian Foundation in Lisbon, in particular for CEMAMu’s first digitalto-analog converter. Why, how Gulbenkian? Do you have any idea?
HG I think Gulbenkian provided support on several occasions, not
only at the very beginning of CEMAMu, but also for a tour, and perhaps for
other things. Remember, they had commissioned Iannis’s Nuits, already
back in the 1960s and continued to commission him into the 1990s, so
he obviously had some great contacts there.
SK It’s true, I remember that Luís Pereira Leal, who was for a very
long time the head of the Foundation’s music department, revered Iannis.
In a way, he personified that Foundation’s statement of purpose at the
time: “The results of research are unpredictable, as are all pioneering
projects, but the important thing is that the research is done. There is
always a risk to be taken in scientific investigations, this risk being the
price of any progress.”[9]

FOOTNOTES
1.
See Després, this volume.
2.

Email exchange between Jean-Michel Raczinski and Sharon Kanach, February 9
2019.

3.

Iannis Xenakis and Sharon Kanach, Music and Architecture: Architectural
Projects, Texts, and Realizations (Hillsdale, NY: Pendragon Press, 2008).

4.

See Médigue, this volume.

5.

CNRS—Centre National de Recherche Scientifique (National Scientific Research
Center).

6.

LAM—Lutheries, Acoustique, Musique research team, headed by Hugues
Genevois, housed at Sorbonne Université, Paris, Jussieu.

7.

ANR - Agence Nationale de la Recherche (National Research Agency).

8.

See Scordato, this volume, for more about UPIX and IanniX.

9.

“E.m.a.mu. (Equipe de Mathématique et Automatique Musicales)”, La Revue
Musicale, Special Issue 265–266 (1969), 53–59, here 53.

CENTRE IANNIS

XENAKIS:

MILESTONES

AND
CYRILLE DELHAYE

CHALLENGES

219

CYRILLE DELHAYE

CENTRE IANNIS
XENAKIS: MILESTONES
AND CHALLENGES
The history of the Centre Iannis Xenakis (CIX) dates back to the founding by
Iannis Xenakis of Les Ateliers UPIC in 1985[1] to promote the UPIC system
internationally, followed by the renaming of that institution in 2000 as
the Centre de Création Musicale Iannis Xenakis (CCMIX)[2]. Then, in 2007,
in response to an audit by the French Ministry of Culture,[3] the CCMIX’s
team was replaced by a new one [4] whose mission was specified as to
“redefine the objectives of the association, focusing on the preservation,
promotion, and dissemination of the intellectual legacy of Iannis Xenakis’s
work.” Indeed, after the death of Iannis Xenakis, the founder of Les Ateliers
UPIC/CCMIX, it seemed more appropriate for the new team to rename the
association the Centre Iannis Xenakis (CIX), which was unanimously decided
at an Extraordinary General Meeting on June 3, 2009. The French Ministry
of Culture had closed Xenakis’s original research lab, the CEMAMu (Centre
d’Etudes de Mathématique et Automatique Musicales), where the UPIC was
first developed, soon after the composer’s death in 2001.[5]
Since December 2010, after a brief interlude at the then Centre
culturel de rencontre La Tourette, the Université de Rouen hosts the
CIX: under the intellectual auspices of the research lab GRHis (Groupe
de Recherche d’Histoire), the CIX archives are now on the shelves of the
University Library (SCD de Lettres et Sciences Humaines), and its historic
studio and office are set up in spaces provided by the Research Pole of the
Maison de l’Université (student center).
THE ARCHIVES OF CENTRE IANNIS XENAKIS

CYRILLE DELHAYE

Considering the incredible vitality of this historic center for music
composition for nearly forty years (over 130 composers—and still counting—
have worked in connection with the association),[6] it is logical that the
documentary resources of our archives are exceptionally rich, occupying
over forty linear meters of shelving. In addition to historic holdings, our
collection is constantly growing thanks to generous bequests made mainly,
but not exclusively, by former Xenakis collaborators,[7] who share our
deep concern to make such documentation readily accessible for future
research by scholars and musicians.
After establishing a pre-inventory[8] (beginning in 2012: protecting our
collections following library preservation norms), the CIX, under the aegis

220

of the GRHis, obtained support from the French Ministry of Culture under
a national digitization program, as well as funding from the GRR Culture et
Société en Haute-Normandie (Major Research Network of Upper Normandy)
to begin digitizing and cataloguing our holdings. We also continue to
receive support, albeit modest, from the Drac-Normandie (Ministry of
Culture’s regional office of cultural affairs). Thanks to our agreement and
well-functioning cooperation with the University Library, brief or extended
consultations of our archives by doctoral students occur regularly.[9]

CENTRE IANNIS
XENAKIS:
MILESTONES
AND
CHALLENGES

THE PAPER ARCHIVES

Around one-third of our core collection, about eleven linear meters of
shelving containing ca. 60,000 pages, are paper archives: correspondence,
course notes, research notes, hardware and software documentation,
press clippings, program notes, etc. FIG. 1
SHEET MUSIC AND PRINTED MATERIAL

The CIX has approximately 450 scores, most of which are unpublished.
The current state of research suggests we can assume that many of them
originated from calls for candidates for courses in music composition
previously organized by the center. Some of them, however, especially
the graphic scores and scores of composers in residence, were written
specifically at the center.
Printed (published or unpublished) documents often focus on the
center’s research activities or on the UPIC system. In addition, hard copies
of academic theses and dissertations (MAs, PhDs) are also included in this
category. FIG. 2
MULTIMEDIA MATERIAL

Multimedia materials (3500 items) account for over half of our archives.
Although this collection is heterogeneous, audio documents constitute the
majority. Not counting vinyl records, published cassettes, and commercial
compact discs (which represented the center’s music library), other
resources (such as DATs, tapes, and engraved CDs) are mainly unpublished
documents. This is a unique collection of recordings that includes concerts,
sound banks used by electroacoustic composers, as well as completed
published or unpublished works.
Iconographic sources are also significant: photographs, for example,
often reveal a documentary attractiveness, such as portraits of composers
in action. More recent photographic bequests, such as that of Bruno
Rastoin (exclusive and rare material concerning Xenakis’s polytope Diatope
(1978) both in Paris and in Bonn in addition to various UPIC workshops)
or that of Henning Lohner (including several unique portraits of Xenakis in

FIG. 1 CIX paper archives in the Université de Rouen library, 2019 © Cyrille Delhaye
and CIX Archives
FIG. 2 CIX score archives in the Université de Rouen library, 2019 © Cyrille Delhaye

and CIX Archives

223

CYRILLE DELHAYE

action, both publicly and privately) constitute real treasure troves.
Although video sources are not numerous, they are nevertheless
very relevant: they include documentaries around the UPIC for internal or
promotional use, some by Xenakis himself, or unprecedented films of concerts.
Finally, the archives also contain many old media. This is an ongoing
process of figuring out how to extract and save in a sustainable manner the
data on these old floppy disks, Syquest cartridges, QIC cartridges, or other,
even older data cartridges. FIG. 3
DIGITIZATION OF ARCHIVES FOR PRESERVATION

We continue to digitize CIX’s collections according to the funding available
for this purpose. At the time of writing, most of the multimedia items have
been digitized (except for some old still-unreadable media), but much of
our paper holdings remain to be done. Because of their fragility, our 534
burned compact discs and eighty ¼ inch magnetic tapes were digitized
first. Oversized papers (some scores, posters, UPIC tracing pages) have
been completely and professionally digitized. All of our DATs, as well as
photographs from Rastoin’s bequest, have also been preserved. Several
more recent bequests have arrived at least partially digitized. Finally,
the CIX actively remains on the look-out for little or previously unknown
sources and collaborates with new private or institutional partners in
rendering them available for research purposes under Creative Commons.
VALORIZATION ACTIVITIES: DIGITIZED ARCHIVES ONLINE

FIG. 3 Panoply of CIX archives in the Université de Rouen library, 2019 © Cyrille Delhaye
and CIX Archives

In addition to the permanent conservation of documents, the French
national digitization program with which we began this process requires
the dissemination of our archives via our website. For this purpose,
another partnership was created with the Portail de la Musique
Contemporaine (Gateway to Contemporary Music) to promote data and
metadata from our digital collections.[10] Such online resources further
facilitate public access to the works created and archived at CIX, as well
as the creative processes associated with them. All such data is available
under conditions protecting the intellectual property of their authors and/
or assignees, according to the agreements negotiated by the Gateway’s
collective rights management agreement (compressed image formats,
streaming extracts in compressed format for audio and video).
After much debate, the CIX chose the digital library platform Omeka
for its website. It is free software under the free General Public License (GPL),
developed for the Roy Roszenweig Center for History and New Media.[11]
This platform is part of the digital humanities movement and is used by the
U.S. Library of Congress and by the Europeana portal, among many others.
It is noteworthy that since February 2018, CIX’s Omeka entity is hosted by

224

the TGIR Huma-Num of the CNRS,[12] and is fully integrated in Isidore, the
federated search engine for humanities data in France,[13] which offers
sustained scholarly exposure of our collections.
The Omeka platform allows for digital editorialization of archives, the
creation of virtual exhibitions, and the possibility of adding comments or
even curation by registered users. In 2012, the CIX curated a travelling
exhibition that is available in French and English. It traces the history
of the UPIC, mainly from documents in our archives: correspondence,
concert posters, photographs, video testimonies highlighting the
experiences of composers, and the many educational workshops
conducted with children or blind people.[14] In May 2015, a web
editorialization of this exhibition was created to extend the experience
and establish a link with CIX’s catalogue of digital collections: visitors
are invited to discover new archives that are highlighted, as well as to
continue their research with the help of the online catalogue.[15]
CENTRE IANNIS XENAKIS’S ACTIVITIES

In addition to activities concerning our archives, the CIX is also active
on the campus of the Université de Rouen, organizing many lectures
and concerts there, including our regular participation in the Université
de toutes les cultures (UTLC), a lecture series designed to address the
general public on very specific subjects.[16] We also collaborate closely
with the nearby Ecole national d’architecture—Normandie, having jointly
hosted several international forums and colloquia, for example, Xenakis’s
Polytopes: Music and Architecture, and have coproduced a collective book
subsequent to another joint symposium, Xenakis et les Arts.[17] In 2015
and 2016, with the ENSA-Normandie and also the European University
of Cyprus’s music department and the architecture department of the
University of Cyprus, we co-organized a major international conference
on the Continuum in Music and Architecture.[18] Furthermore, like our
predecessors Les Ateliers UPIC and the CCMIX, we are regularly invited
to hold UPIC workshops for children, in schools of fine arts, and for the
general public in France and abroad.
Several of our individual members are quite active, regularly
participating in international conferences on various subjects related to
Xenakian and/or archival topics.
In 2016, we were invited by the coordinating partner, Onassis
Stegi, to participate in the Interfaces project, cofunded by the Creative
Europe program of the European Union as an associate partner.[19] The
project’s main focus is to develop “new models and practices for audience
development in contemporary music in Europe.” It was through this
project that, on the one hand, we collaborated closely with the European

CENTRE IANNIS
XENAKIS:
MILESTONES
AND
CHALLENGES

225

CYRILLE DELHAYE

University of Cyprus to develop the software application UPISketch for
mobile devices,[20] and on the other hand, enjoyed coordinating with
the ZKM | Center for Art and Media Karlsruhe both the “UPIC: Graphic
Interfaces for Notation” conference,[21] as well as this publication.
PROJECT FOR A JOINT DIGITAL ARCHIVE LIBRARY
OF KSYME AND CIX

Since February 2015, subsequent to the events organized to celebrate
KSYME’s 35th anniversary, the contemporary music research center
which was founded in 1979 by Iannis Xenakis, Giannis G. Papaioannou,
and Stephanos Vassileiadis in Athens,[22] our two institutions plan to
create a joint library of digitized archives focusing on the UPIC. KSYME’s
recent move to the Athens Conservatoire should now expedite this
process.[23]
In order to create a joint library of digitized archives with the KSYME,
it is possible to set up an open archive warehouse via Omeka (based
on the OAI-PMH protocol). The CIX has already used this protocol to
disseminate our archives to the other research centers and gateways
mentioned above. This is a long-term project but a very exciting one.
KSYME has begun digitizing some of its archives and has started
uploading them to their own Omeka website: https://ksyme.omeka.net/.
COMPOSING ON THE UPIC BETWEEN PARIS AND ATHENS:
DIMITRIS KAMAROTOS

This joint digital archive of the CIX and KSYME has already proved to be
fundamental in shedding light on the trajectories of composers who have
composed using the UPIC across Europe. The first research project, for
example, has brought to light two particularly significant cases: that of the
Greek composer Dimitris Kamarotos and that of the Hungarian composer
Ivan Patachich.
While preparing a keynote I was due to give at the conference
“Échanges musicaux entre la France et la Grèce à l’aube du xxie siècle,
1980–2010 (Musical exchanges between France and Greece at the dawn
of the 21st century, 1980–2010)” at the Sorbonne in 2018,[24] I had
the opportunity to correspond, by email, rather extensively with Dimitris
Kamarotos (*1954),[25] which brought to light the unique experiences of
this composer who very early applied himself to using the UPIC both from a
pedagogical and a purely compositional point of view.[26] He discovered the
UPIC at the CEMAMu in Paris in 1981 after meeting Iannis Xenakis in his
courses at the Université de Paris I.
In 1987, Kamarotos composed Epiphineia for UPIC, clarinet, piano,
and double bass. This piece also uses a computer program (Gen 2/1) that

226

generates polyphonic musical structures based on chaos theory. He shared
with Xenakis the neologism he originally coined for this UPIC piece: EpiFinie (the prefix epi-, meaning “on” in Greek plus the suffix -finie, “finite” in
French) which to Kamarotos indicated a space with finite properties. Xenakis
suggested to him the definitive title Epiphineia in reference to the Catholic
religious holiday of the Epiphany as well as its connotation of revelation.
Kamarotos’s piece was premiered during a collective concert that featured
various new works by Greek composers who had worked on the UPIC at
KSYME. Further, Dimitris Kamarotos recounted, for example, having played
an alternative version of Mycènes Alpha in the presence of Xenakis at that
concert. The concert also featured a piece by Haris Xanthoudakis (*1950)
created in 1983–84 at the CEMAMu in Paris: L, comme Buñuel ou La Forêt
des symboles. The latter went to Paris with Kamarotos to discover the UPIC
at the beginning of the 1980s. Finally, a piece by Vasilis Riziotis (1945–
2016) closed the concert: At a Dream’s Constellation for piano/celesta and
UPIC, composed the same year during an UPIC workshop at the GoetheInstitut in Athens. Fully recorded, this concert gave rise to the first disc of
pieces for UPIC in Greece published and produced by the KSYME.[27]
COMPOSING ON THE UPIC IN PARIS AND IN ATHENS:
THE EXAMPLE OF THE HUNGARIAN COMPOSER IVAN PATACHICH

Already, the work jointly carried out at CIX and KSYME has made it possible,
for example, to single out the work of Ivan Patachich, who worked in both
our centers—CIX (at the time Les Ateliers UPIC) and KSYME—and composed
works overlapping his experience with the UPIC in Athens with one in France.
Ivan Patachich (1922–1993) was a Hungarian composer and pioneer
of electroacoustic music in Hungary.[28] His works have won numerous
international awards; he travelled extensively and composed at Columbia
University, New York (1969), in Stockholm (1974), Bourges (1980), Athens
(1987), and Paris (1988).
According to Costas Mantzoros (composer, researcher, and longtime
collaborator of KSYME), Ivan Patachich began to produce the piece
Musique dessinée[29] at KSYME in Athens in July 1987, and then edited it in
Budapest at Hungarian Radio.[30] More precisely, according to musicologist
John G. Papaioannou, Ivan Patachich met the composer Takis Velianitis[31]
(*1963) at the KSYME in the summer of 1987,[32] where he was working as
a UPIC instructor and collaborated with Patachich on Musique dessinée.
In the CIX archives, we discovered that a few months later, in 1988,
Ivan Patachich composed a second work on the UPIC: Chanson nocturne du
poisson at Les Ateliers UPIC. While searching for this reference, we noticed
that there are actually copies of both of Patachich’s two works for the UPIC
in CIX’s archives.

CENTRE IANNIS
XENAKIS:
MILESTONES
AND
CHALLENGES

227

CYRILLE DELHAYE

CONCLUSION

The singular approach of the research and pedagogy of composition and
research that was conducted originally at the CEMAMu, and later at Les
Ateliers UPIC, then at CCMIX, and finally at CIX has attracted composers
from around the world wanting to know—and for many, to try—another
way of composing. The archives they have left (and others continue to
donate to our collection) often exemplify the stratification of their creative
processes, generating a unique and valuable documentation. The
challenge now is to maintain and ensure the importance of this knowledge
by sharing it with the greatest number of parties, fulfilling our mission
of open dissemination of Xenakis’s legacies. To achieve this, digitizing
documents, cataloging and formatting metadata that meet international
standards for interoperability are clearly the on-going stages of this project.
In addition, recent work by Rodolphe Bourotte around the UPIC and
UPISketch workshops have shown that this tool for musical composition by
drawing still inspires many composers, beginners or not[33]. It is therefore
CIX’s goal to preserve this technical heritage (the UPIC) and enhance the
development of its software versions.
Finally, the CIX will continue, both alone and with selected partners,
to promote the intellectual heritage of Iannis Xenakis’s influence through
conferences, lectures, and publications, such as this one.

FOOTNOTES
1.
See Després, this volume.
2.

See Pape, this volume.

3.

Internal report by Fernand Vandenbogaerde, Inspecteur Général à la Direction
Générale de la Création Artistique du Ministère de la Culture, December 6, 2006
(CIX Archives, uncatalogued).

4.

Founding members of the new team included: Françoise Xenakis (Honorary
President), Paul Méfano (President), Jean Louis Villeval (Vice-President), Sharon
Kanach (Vice-President), Bruno Rastoin (Treasurer), and Marie-Emmanuèle Verrier
(Secretary). A full list of current members and officers can be found here:
http://www.centre-iannis-xenakis.org/membres

5.

See Genevois, this volume.

6.

For a full, on-going list of composers see:
http://www.centre-iannis-xenakis.org/upic_compositeurs?lang=en

CENTRE IANNIS
XENAKIS:
MILESTONES
AND
CHALLENGES

228

229

CYRILLE DELHAYE

7.

Some such former collaborators are logically represented in this volume as well:
Després, Kanach, Lohner, and Médigue, although several others have also made
generous bequests of precious original documents.

8.

See our general inventory:
http://www.centre-iannis-xenakis.org/inventaire_archives?lang=en

9.

For instance, another contributor to this volume, Victoria Simon, was in residence
in Rouen for several weeks in early 2016 while a PhD student at McGill University,
Montreal, Canada.

10.

http://www.musiquecontemporaine.fr/fr/search?so=da&archiveIds=55

11.

https://omeka.org/

12.

Huma-Num (TGIR) - très grande infrastructure de recherche) : Digi(tal)Huma(nities)
very large research infrastructure https://www.huma-num.fr/ of the CNRS
(National Center for Scientific Research).

13.

https://isidore.science/collection/10670/2.ofsr4v

14.

http://www.centre-iannis-xenakis.org/cix_expositions?lang=en

15.

At present, only a French version of the virtual exhibition is available:
http://www.centre-iannis-xenakis.org/exhibits/show/expo-upic

16.

http://culture.univ-rouen.fr/conferences-grand-public-395031.kjsp (At the bottom
of the page, there are links to videos of each conference, according to year.)

17.

Multi-author publication: Xenakis et les arts: miscellanées, ed. Pierre Albert
Castanet and Sharon Kanach, (Rouen: Éditions Point de vues, 2014).

18.

http://www.centre-iannis-xenakis.org/continuum_home

19.

http://www.interfacesnetwork.eu/article.php?pid=1-the-project

20.

See Bourotte, this volume. See also:
http://www.centre-iannis-xenakis.org/upisketch.
Also, the link to the very first UPISketch workshops:
https://www.boccf.org/Templates/Pages/Event.aspx?id=4756

21.

http://www.interfacesnetwork.eu/post.php?pid=217-upic-graphic-interfaces-fornotation-conference

22.

https://cmrc35years.wordpress.com/

23.

See Tsioukra, this volume.

24.

http://relmus.org/?page_id=20

25.

http://dimitriskamarotos.com/

26.

Numerous emails were exchanged between the author and Kamarotos in the
period April 19 – May 6, 2018

27.

POLYAGOGY, LP with four compositions by Xenakis, Xanthoudakis, Riziotis,
and Kamarotos, Music-Box-records 1987 X33SMB13018.

30.

28.

Among other achievements, Patachich founded the ExAStud Studio
(Expermentum Auditorii Studii) in Budapest in 1971.

Costas Mantzoros, “Re: Ivan Patachich”, email addressed to the author,
January 30, 2018.

31.

https://velianitis1.wixsite.com/velianitis/biography

32.

John G. Papaioannou, 20th Century Greek Avant-garde Music: A Cross Section
(liner notes (Athens: Eteba, 1998), 137–38.

33.

See Bourotte, this volume.

29.

Ivan Patachich, Musique dessinée, Archives du Centre Iannis Xenakis,
Université de Rouen, CIX 754, cote 87. To hear an excerpt from this work:
http://www.centre-iannis-xenakis.org/items/show/171

ESTABLISHING A

XENAKIS CENTER

IN GREECE:

THE UPIC
KATERINA TSIOUKRA

AT KSYME-CMRC

235

KATERINA TSIOUKRA

ESTABLISHING A
XENAKIS CENTER IN
GREECE: THE UPIC
AT KSYME-CMRC
(CONTEMPORARY
MUSIC RESEARCH
CENTER)

KATERINA TSIOUKRA

After the collapse of the seven-year military junta in Greece and the
restoration of the Republic, Iannis Xenakis was finally allowed to return
to the country in 1974, after 27 years of political exile. At that time, the
Hellenic Association of Contemporary Music (HACM) played a leading role
in officially representing Greek modernists and introducing the Greek
audience to both national and international contemporary repertoires
through monumental concerts and festivals, such as the five Hellenic
Weeks of Contemporary Music (1966, 1967, 1968, 1971, 1976); the
Xenakis Week in 1975; and later, the World Music Days in 1979. A key
figure and significant for promoting modernism in music was the dilettante
musicologist, professional architect, and city planner John G. Papaioannou.
Papaioannou personified nearly all activities relating to contemporary
music in the country since the late 1950s in lessons and public lectures.
He was also actively involved in founding several organizations that
sought to promote modern music, such as the Goethe Institute’s Studio
für Neue Musik (Studio for New Music) (1962), the Greek branch of the
International Society of Contemporary Music (1964), and HACM (1965),
all located in Athens where Papaioannou held important positions.
Papaioannou had gained the trust of most of the foreign institutes in
Athens (USIS, Hellenic-American Union, Goethe Institut, Instituto Italiano di
Cultura) and collaborated with them artistically and financially to promote
modern music in Greece.[1]
Beginning in the mid-1950s, Xenakis frequently corresponded with
Papaioannou and they soon developed a relative familiarity that can
be detected in their letters.[2] Papaioannou contributed to introducing
the exiled Xenakis to the Greek audience on numerous occasions. He
presented his works along with those of other modernists in a concert

236

held by the then newly founded Hellenic-American Union in 1959.[3]
Papaioannou was also the person who was willing to overlook certain
formalities regarding the submission of Amorsima-Morsima to the Music
Competition 1962, in which both Xenakis and Anestis Logothetis were
formally introduced to a wider Greek audience after winning the first
Manos Handjidakis prize ex aequo.[4] In addition, he included Xenakis
in the New Greek School of composers—a characterization of his own
coining—and regularly promoted Xenakis in his publications on the
development of modern Greek music and composers.[5] Papaioannou was
the link between Xenakis and the existing foundations of contemporary
music in Greece; the man behind their establishment, operation, and
artistic planning who was fully aware of how to promote a noteworthy
composer to the Greek audience.[6] After the country’s regime change
in 1974 and during Konstantinos Karamanlis’s conservative and
“Europeanisational” administration, HACM received unprecedented
support and financial aid from the Greek government thanks to the efforts
of Papaioannou. Xenakis also benefitted from the Greek government’s
artistic encouragement through the week-long festivities dedicated to him
in 1975 that were organized by HACM.[7]
Xenakis’s plan to establish a center for contemporary music in Greece,
similar to the French Centre d’Etudes de Mathématique et Automatique
Musicales (CEMAMu), can be traced back to this period when his Greek
passport was restored to him, and the government began welcoming him.
In fact, creating this new center was for Xenakis “the first thing he asked
to do” in Athens.[8] At that time, “[his] joy was great and [he] was ready to
contribute to the new [sic] reconstruction of the culture of [his] country,”
which had recently experienced the collapse of the military junta.[9]
A strong reason for establishing the new Contemporary Music Research
Center (KSYME-CMRC)—hereinafter KSYME, its acronym in Greek—was
to domicile Xenakis’s latest invention in Greece, as soon as the UPIC
became available. John G. Papaioannou and the composer, popular music
pedagogue, and choir director Stephanos Vassiliadis were introduced to
UPIC’s artistic and educational potential during the World Music Days in
Bonn in 1977, when its first public demonstration took place. It was then
and there that it was decided to have a UPIC in Greece, fulfilling Xenakis’s
dream of founding an institution in Athens.[10] In 1978, KSYME’s statutes
were signed by twenty-five founding members and the center was officially
founded in 1979.[11] Its temporary management committee included
John G. Papaioannou, Stephanos Vassiliadis, and Alkistis Soulogianni;
the first Board of Directors included Iannis Xenakis (as president), John
G. Papaioannou, Manolis Protonoratios, Stamatis Chrisolouris, and
Stephanos Vassiliadis, who served as KSYME’s director.[12]

ESTABLISHING A
XENAKIS CENTER
IN GREECE:
THE UPIC AT
KSYME-CMRC
(CONTEMPORARY
MUSIC RESEARCH
CENTER)

237

KATERINA TSIOUKRA

Xenakis’s vision about establishing a center in Greece that followed
the same objectives as the CEMAMu is revealed in KSYME’s first
promotional material, although the relationship between the two centers
is not explicit in their respective statutes. CEMAMu’s brief “goal” was
summarized as “the study, the teaching, and the practice of the sciences
and the techniques applied to audiovisual artistic creation, and this by
means of its choice and in particular the use of electronic devices.”[13]
John G. Papaioannou’s and Stephanos Vassiliadis’s contribution to the
wording of KSYME’s statutes is reflected in the following paragraph of the
center’s goals:[14]
Promoting research for the broadening of sonic possibilities, capable
of being used in contemporary music composition.
B Research on acoustics and the psychophysiology of hearing.
C Development of intertwined methods for the simultaneous study of
music, mathematics and other sciences or arts.
D Education, through consistent teaching of the aforementioned
disciplines, suitable personnel, with an emphasis on youth and
allotment of scholarships.
E Exploration and development of pedagogical methods for music,
which will be applicable in the future in other similar centers in
Greece, without age, gender or racial restrictions.
F Informing and cooperating with educational institutions (elementary,
middle and higher education, general or specific, technical or artistic).
G Promoting music creativity based on the aforementioned research
methods.
H Promoting music analysis and research of sonic structures of folk
music of various civilizations and especially Greek folk music
(Byzantine, traditional, etc.) and the sounds of the Greek environment.
I Development of Greek and international contacts through workshops,
conferences and other social events, centered around the
aforementioned Center’s activities.
J Development of public events—lectures, listening sessions,
discussions etc., in Greece and abroad, where the results of the
Center’s activities will be presented.
K Publications based on the aforementioned research results.

A

KSYME’s goals were formulated in an analytical way, primarily
promoting Xenakis’s views. Secondarily, however, references to awarding
scholarships, research on various civilizations, lectures, workshops,
public events, listening sessions, and publications are highly relevant
to Papaioannou’s own activities in music. Further, music pedagogy,

238

educational cooperation, and musical “Greekness” are largely related to
Vassiliadis’s views.[15] It is worth mentioning that KSYME’s inclusivity was
expressly formulated in its statutes. Despite an analytical approach, there
was no reference to electronic media or devices or even the UPIC, even
though it triggered the center’s establishment and, a few years later, its
activation and full operation.
Although the center was officially founded in 1979, its operation was
significantly delayed due to the lack of financial resources, which would
have permitted the immediate purchase and delivery of a UPIC, as well as
KSYME’s simultaneous commencement. It took almost seven years (1979–
1985) to amass a substantial amount of money, primarily through state
funding and donations, following the example of the state-funded CEMAMu.
Until its activation, KSYME’s main grants specifically came from the
Ministry of Coordination (Scientific Research and Technology service) and
the Ministry of Culture and Science.[16] KSYME’s first attempt to purchase
a UPIC was in 1984 when its price began to drop. It was the center’s first
investment, which was completed in March 1985. Until KSYME’s official
opening, its technician, Andreas Staphylopatis, had the opportunity to
“thoroughly test” the UPIC in Paris.[17] In the summer of 1985 the UPIC
arrived in Greece.
Although in KSYME’s promotional material the Greek UPIC was said
to have been presented in the “Xenakis Seminar” held in the Centre
Acanthes in 1985, Staphylopatis specified that only parts of it were
used, complementary to the two French UPICs brought to Delphi for the
seminar.[18] The Centre Acanthes, participating in the European Year
of Music, hosted “one of Europe’s major events in contemporary music
in 1985,” a seven-week seminar in Aix-en-Provence, in Salzburg (in the
New Mozarteum), and in Delphi, Greece (in Delphi’s European Center).
In Delphi, the first demonstration of the UPIC in Greece took place, even
though it was not exactly the one KSYME had received that summer.
Nevertheless, Xenakis’s status contributed once again to bringing Greece
into the spotlight during the European Year of Music, this time thanks to
the promotion of this invention to dozens of European musicians in three
different cultural destinations on the continent.[19]
However, a proper celebration of the arrival of Xenakis’s much
anticipated innovation in 1985 could not take place during the same
period, even though the UPIC had already been received. KSYME was
facing another problematic and pressing issue since its foundation: finding
premises for its headquarters. Even though infrastructure was not the
primary issue KSYME had to solve compared to its financial problems,
the lack of a suitable place for its artistic and educational goals definitely
contributed to delaying its opening. The search for such a location started

ESTABLISHING A
XENAKIS CENTER
IN GREECE:
THE UPIC AT
KSYME-CMRC
(CONTEMPORARY
MUSIC RESEARCH
CENTER)

239

KATERINA TSIOUKRA

immediately after KSYME’s foundation, but due to its financial status and
other misfortunes, it did not immediately bear fruit. The older HACM’s and
the newly founded KSYME’s headquarters, both having Papaioannou’s
organizational signature, were intended to be housed together. Major
plans for a Cultural Center in Athens appeared among the first solutions.
Without a doubt HACM and KSYME were both considered part of the
city’s planned Cultural Center. They were also intended to be a part of
a future Music Academy House. Xenakis’s reputation expedited the
proceedings and it was planned that the two music institutions—KSYME
and HACM—would be temporarily accommodated in the basement of the
Athens Conservatoire’s new building, then under construction (also part
of the Athens Cultural Center), until they could find a permanent home.
[20] Xenakis, as the president and founder of KSYME, truly supported the
plans to accommodate this Greek center in the future Athenian Cultural
Center. In fact, Xenakis wrote to the president of the Hellenic Republic,
Konstantinos Karamanlis, that “[he] was ready to contribute with [his] own
power to the country’s cultural reconstruction […] by relocating [his] artistic
and educational activities”; providing that KSYME would be a part of the
Cultural Center, “[it would have been] an opportunity for the beginning of
[his own] relocation to Greece.”[21] However, the Athens Conservatoire’s
new building had not been completed yet, and it remains to this day an
incomplete “monument” of contemporary Greek architecture.[22] Thus,
KSYME continued to exist as a center without a physical presence for five
more years.
Then, in 1985, after clearing customs, the UPIC was installed in
Vassiliadis’s famous personal studio in the Holargos suburb until it was
transformed “temporarily” to accommodate all of KSYME’s operations.
[23] The center’s opening ceremony took place on April 23 1986. Xenakis
was present at the ceremony along with the Board of Directors. Not only
did he demonstrate his own “Polyagogy,” he also promoted KSYME’s
general goals, underlining the center’s close relationship to the CEMAMu.
Technicians from both centers were also present to support the opening of
Xenakis’s Greek center, Carmello Cappiello from the CEMAMu and Andreas
Staphylopatis from KSYME.[24] Much publicity was given to KSYME’s
opening ceremony and Xenakis’s visit to Athens, and the general public’s
introduction to the UPIC really caught the press’s attention. In an interview
Xenakis gave at the time, he presented the UPIC as a means of changing
the traditional way of composing music into a “more approachable
[procedure] that [was] interesting and not only for specialists [...] even for
students of elementary school and kindergarten.”[25] Further, KSYME’s
opening ceremony was held almost a year after Xenakis’s proposal for
the Polytope of Athens had been rejected by the Ministry of Culture.[26]

240

However, Xenakis’s response to a related question in the same interview
reflects a new beginning for him in Athens and a genuine interest in
his Greek center at that time. He said, “I am intent on what I started,
provided that it can be realized. [...] This year I came back because the
Contemporary Music Research Center [KSYME] has interested me for
several years now. We delayed [its opening] due to the lack of financial
means and a location. I believe very much in this center. Besides, it is not
something new; in France, the CEMAMu is operational since 1972.”[27]
Nearly a decade later, Xenakis continued to promote the UPIC in
Greece as a compositional and educational tool, even though he had
stopped creating works with it at that time. Xenakis was interviewed by the
famous Greek poet and writer, Titos Patrikios, for a documentary portrait
of him by Dimitris Anagnostopoulos, and it is one of the very few times that
Xenakis spoke in Greek about the story of the UPIC:
This inclination of mine to draw, not to write notes that are
bothersome, dates back to the 1950s when I was sketching out
music—albeit with great accuracy—and I was able to convert those
drawings into performable notes. The idea was more general than
notes. Notes are a descendant of a neumatic tradition, because
music, apart from the ancient one which was somewhat alphabetical,
later became neumatic. The hand rose and the pitch of the voice
rose; it lowered, and the sound lowered, or the neume was like
oligon [sic] in Byzantine music that indicated the same pitch. This
was abandoned at the end of the ninth century in the West, while
in Byzantium, it continued and still exists. Drawing, meaning the
sketching of music, has deep roots and it is much more natural for a
human to see a shape and describe whether the pitch rises or falls.
This is how we learnt.[28]
A large number of people (children, teenagers, and adults) came into
contact with the UPIC at KSYME in Holargos, not only through KSYME’s
educational programs but also as visitors. Although KSYME’s promotional
material refers to an extremely large number of students, the center’s
diaries in which its full activities were recorded do not specify any number
of works. However, KSYME’s creation, its philosophy and goals, Xenakis’s
influence and presence, and the center’s artistic activity all contributed
to educate a generation of young composers in Greece, at a time when
electronic music had not been introduced in higher education. During
KSYME’s first and fruitful years, many of them created works using
the UPIC. In addition, UPIC’s presence at KSYME’s studios remained
an inspiration, even after it stopped functioning. The electroacoustic

ESTABLISHING A
XENAKIS CENTER
IN GREECE:
THE UPIC AT
KSYME-CMRC
(CONTEMPORARY
MUSIC RESEARCH
CENTER)

241

KATERINA TSIOUKRA

composer Katerina Tzedaki mentions that “UPIC’s presence influenced in
a certain way any compositional procedure in that space [KSYME’s studio],
not only by changing its acoustics, but as an idea, as a reassurance of the
potentiality of approaching music in infinite time scales.”[29]
This year KSYME celebrates its fortieth anniversary since its
foundation. Interestingly enough, it has found its “permanent” home in
the Athens Conservatoire building, along with its precious archives and
equipment. In addition, since mid-2018, KSYME’s and the ChourmouziosPapaioannou Foundation’s Unified Archives are being organized as a whole
by the Center of Research and Documentation of the Athens Conservatoire,
under the direction of KSYME’s former colleague and Xenakis pupil, Haris
Xanthoudakis. The Greek UPIC, even though it is not in use any more, has
its own place for public display in the Athens Conservatoire as a part of
KSYME’s history. This article is the first effort to tackle KSYME’s historical
and artistic impact through research on the center’s archival material,
currently being catalogued. The entire research procedure led to the need
for creating a catalogue of the works that featured KSYME’s UPIC, which
can be visited online at the center’s official website.[30] This first attempt to
collect all the works related to KSYME’s UPIC remains a work in progress
and demonstrates the tool’s footprint on Greek electroacoustic music, and
also on a significant part of KSYME’s artistic and educational contribution
to the county’s recent music history

FOOTNOTES
1.
Ioannis Tsagkarakis, The Politics of Culture: Historical Moments in Greek

Musical Modernism (PhD diss.), vol. 1 (London: Royal Holloway, University of
London, 2013), 147–148; Katerina Tsioukra, “The Concert Series of USIS and
the Hellenic American Union in Athens during 1952–1959,” in 1st Conference
for Post-graduate Students and Young Researchers (Corfu: Ionian University,
Department of Music Studies, [publication of proceedings in progress]).

2.

Twenty-two handwritten letters from Iannis Xenakis to John G. Papaioannou
have been discovered at KSYME (CMRC)-ChouPaF Unified Archives. The
first one was sent on 25.2.1956. ChouPaF stands for the Chourmouzios Papaioannou Foundation (Emile Chourmouzios was the husband of the famous
pianist Marika Chourmouziou-Papaioannou, therefore the brother-in-law of
John G. Papaioannou). The ChouPaF archives comprise the archives of Emile
Chourmouzios, Marika Chourmouziou—Papaioannou, John G. Papaioannou, and
Nikos Skalkottas. KSYME and the ChouPaF have the same board of directors
and currently share their headquarters at the Athens Conservatoire. In addition
to its own “audiovisual”, “administrative”, “activity records”, KSYME’s archives
also contain the archives of the Hellenic Association of Contemporary Music
(HACM) and the Greek Studio for Electronic Music. The two sets of archival
holdings have recently been unified.

242

3.

Katerina Tsioukra, “The Concert Series of USIS and the Hellenic American
Union in Athens during 1952–1959,” op. cit.

4.

Even though the call of the 1962 Music Competition was for unperformed/
unpublished works—until December 16, 1962 - Amorsima - Morsima, a work
that has not been published and is not included in Xenakis’s current catalogue
of works, had already been performed on May 7 and May 24, 1962 according
to a handwritten analysis that Xenakis provided to the two jury teams. This
fact was overlooked by John G. Papaioannou who was a member of both, the
person responsible for all organizational issues and the one who corresponded
with Xenakis giving him information about the competition. For a more detailed
analysis on this issue see Katerina Tsioukra, “1962 Music Competition: Manos
Handjidakis’s Prizes” (MA thesis) (Corfu: Ionian University, Department of Music
Studies, 2018), 72–76, 85.

5.

6.
7.

8.

9.

ESTABLISHING A
XENAKIS CENTER
IN GREECE:
THE UPIC AT
KSYME-CMRC
(CONTEMPORARY
MUSIC RESEARCH
CENTER)

243

KATERINA TSIOUKRA

14.

“Founding act and constitution” (September 20, 1978) pp. 1–2, in KSYME
(CMRC)-ChouPaF Unified Archives. [author’s translation].

15.

Στέφανος Βασιλειάδης: Βιογραφικό σημείωμα (Stephanos Vassiliadis: Curriculum
vitae), http://composers.musicportal.gr/?lang=el&c=vasiliadis

16.

KSYME’s Balance Sheets from 1981 to 1985. KSYME (CMRC)-ChouPaF Archives.

17.

KSYME’s promotional material “Brief History of K.SY.M.E”, K.SY.M.E [ca. 1990],
p. 6, in KSYME (CMRC)-ChouPaF Unified Archives.

18.

Ibid; Kostas Stratoudakis, “Polyagogy and the Contemporary Hellenic Electronic
Music, 1st Part,” in Ichos & Hi-Fi, 164 (1986), 38.

19.

Henning Lohner, “The UPIC System: A User’s Report,” in Computer Music Journal,
10, (1986), 42.

20.

“Pavlos Hatzithomas: Athens, September 10, 1980 […]” 391/1/10/5, p.2, in the
Historical Archive of the Konstantinos G. Karamanlis Foundation.

21.

“Iannis Xenakis […] Κύριον Κωνσταντίνο Καραμανλή: Πρόεδρον της Ελληνικής
Δημοκρατίας [Mr Konstantinos Karamanlis: President of the Hellenic Republic]
[24.6.1980]” in KSYME (CMRC)-ChouPaF Unified Archives.

22.

ελc Team, Νεότερο Μνημείο χαρακτηρίστηκε το Ωδείο Αθηνών (13.10.2017)
https://www.elculture.gr/blog/article/νεώτερο-μνημείο-ωδείο-αθηνών/

23.

Ioannis Tsagkarakis, The Politics of Culture: Historical Moments in Greek
Musical Modernism (PhD diss.), vol. 1 (London: Royal Holloway, University of
London, 2013), 194, 241.

Vassiliadis’s personal studio was just a “temporary” solution, but ended up being
the permanent home of KSYME until very recently.

24.

As Stephanos Vassiliadis stated in an interview, after KSYME had commenced
operations: Kostas Stratoudakis, “Polyagogy and Contemporary Hellenic
Electronic Music, 1st Part,” in Ichos & Hi-Fi, 164 (1986), 36.

“Contemporary Music Research Center (KSYME), POLYAGOGY: A New Path for
the Creative Approach to Music.” Program notes for the opening ceremony on
23.4.1986, in KSYME (CMRC)-ChouPaF Unified Archives.

25.

Elena Chouzouri, “Giannis Xenakis: Art Is the Liberating Power of the World,” in
ENA (May 1986), 134 [author’s translation].

26.

Ioannis Tsagkarakis, The Politics of Culture: Historical Moments in Greek Musical
Modernism (PhD diss.), vol. 1 (London: Royal Holloway University of London,
2013), 237–239.

27.

Elena Chouzouri, “Giannis Xenakis: Art is the Liberating Power of the World” in
ENA (May 1986), 133 [author’s translation].

28.

In mentioning the “oligon,” Xenakis was in fact referring to the “ison” symbol
in Byzantine music. According to the Xenakis scholar Nikos Ioakeim, Dimitris
Anagnostopoulos’s documentary on Iannis Xenakis was produced in 1995 and
was broadcast by National Television. Some years later the documentary was also
broadcast by the Hellenic Parliament TV channel with the addition of several other
clips on Xenakis. After contacting the personnel of both channels, neither version
of the documentary has yet been located, neither in their archives nor even in
their catalogues. For the purpose of this chapter, the author has located the
second version of this documentary online.
https://www.youtube.com/watch?v=ezU4vR50m2Y&feature=youtu.be [excerpt
can be found at 44:33– 47:00]

29.

Personal communication with Katerina Tzedaki on March 29, 2019.

30.

UPIC, https://www.ksyme.org/upic.html

Nicolas Slonimsky’s and Brigitte Schiffer’s papers on presenting and promoting
Greece’s modernism in music were highly influenced by Papaioannou.
Especially in Schiffer’s case; she had developed a friendship with Papaioannou
and had strongly supported his activities regarding contemporary music in
Greece, such as the Hellenic Weeks of Contemporary Music and Xenakis’s
Week. See Nicolas Slonimsky, “New Music in Greece,” in The Musical Quarterly
51, (1965), 232–233; Brigitte Schiffer, “Neue griechische Musik,” Orbis
Musicae 1, (1972), 196–197; Brigitte Schiffer, “Xenakis Week, Melos (July,
1975),” 18, in Ioannis Tsagkarakis, The Politics of Culture: Historical Moments
in Greek Musical Modernism (PhD diss.), vol. 1 (London: Royal Holloway,
University of London, 2013), 201.
Papaioannou orchestrated the promotion of the life and works of Nikos
Skalkottas, after the Greek composer’s early death.

From a copy of a handwritten letter by Xenakis that was apparently sent to
Konstantinos Karamanlis. Even though the original letter has not yet been
located in the Konstantinos Karamanlis Foundation’s archives, nor in any
other correspondence between them, it nevertheless demonstrates the views
of the composer particularly regarding the cultural reconstruction of Greece.
“Iannis Xenakis […] Κύριον Κωνσταντίνο Καραμανλή: Πρόεδρον της Ελληνικής
Δημοκρατίας [Mr Konstantinos Karamanlis: President of the Hellenic Republic]
[24.6.1980]” in KSYME (CMRC)-ChouPaF Unified Archives.

10.

“Press Release: KSYME’s opening, Wednesday April 23, 1986, 12.00 noon:
History,” p. 1, in KSYME (CMRC)-ChouPaF Unified Archives.

11.

“Founding act and constitution” (September 20, 1978) in KSYME (CMRC)ChouPaF Unified Archives.

12.

“Press Release: KSYME’s opening, Wednesday April 23, 1986, 12.00 noon:
History,” p. 2, in KSYME (CMRC)-ChouPaF Unified Archives.

13.

“Centre d’etudes de mathematique et automatique musicales: Statuts”
(1972). [Xenakis, Iannis. Auteur], “CENTRE D’ETUDES DE MATHEMATIQUE ET
AUTOMATIQUE MUSICALES. STATUTS,” Centre Iannis Xenakis,
http://www.centre-iannis-xenakis.org/items/show/728 [translation by author].

KSYME:
THE UPIC IN
GREECE—TEN YEARS

OF LIVING AND
CREATING WITH

THE UPIC AT
DIMITRIS KAMAROTOS

KSYME

249

DIMITRIS KAMAROTOS

KSYME: THE UPIC IN
GREECE—TEN YEARS
OF LIVING AND
CREATING WITH THE
UPIC AT KSYME
1978 AND AFTER

DIMITRIS KAMAROTOS

I first saw the UPIC unit installed at KSYME[1] a few weeks before the
official opening of the center. That was in early spring 1986. FIG. 1 It was
just a few months after I had returned to Greece after studying music in
Paris for eight years. During those years of university, with instrument and
composition studies, I had the opportunity to attend concerts of Xenakis’s
music and most of his lectures at the Université de Paris I.
It was much earlier, in September 1978, that I became very
interested in his music, writings, and ideas. I participated as a volunteer
in the setting up of his Mycenae Polytope. In southern Greece, on a hill
close to ancient Mycenae, a huge sound system was installed to playback
electronic music tapes, with microphones for acoustic instruments played
by amazing soloists and voices, as well as lighting effects using huge antiaircraft searchlights. During the interpretation of the piece, herds of sheep
and goats with bells were moving across the neighboring hills and naturally
mixing their sounds with percussion, solo voice, choirs, and electronic
sound. The electronic composition was created at the CEMAMu with a first
version of Polyagogia, a prototype, the first generation of the UPIC. All of
these elements were parts of a music composition with colossal sound
and spatial dimensions. Although I was participating by doing small things
for the production, I had the opportunity to see and listen to Xenakis, the
musicians, and the organizing team. Being close to the creative team, in
combination with the event itself, made this experience one of the most
influential and inspiring in that period of my life.
During those days, close to Xenakis and to the project, were two
important figures who I met and worked with later, after my return from
France and when I began working at KSYME with the UPIC. Xenakis
himself refers to them in the credits of the Mycenae Polytope program
as follows: “But nothing would have happened without the tireless
interest and the long-range effort of my friends John G. Papaioannou
and Stefanos Vassiliadis, who coordinated everything within and outside

251

DIMITRIS KAMAROTOS

Greece with such devotion and love.”[2] Immediately after this experience
with Xenakis’s Polytope, having just finished my studies in Greece, I was
preparing to continue my music studies in Paris. My ideas about what
music actually was were broadening every day, and already I had planned
to study a combination of subjects: music composition, musicology, and
computer science. At that time (end of the 1970s), computer music was
not yet a distinct area of study neither in Greece nor in France. In the
years to come, in parallel with my studies in France, my inspirational
relation with Xenakis’s music was mainly centered on his ideas and less
on his music. I was studying with Daniel Charles and my ear was leaning
more towards John Cage and less to the abyssal—as they sounded to
me then—clusters that Xenakis was creating in orchestral and solo
instrumental works. Nevertheless, some situations and events turned my
attention back to his music again.
First and incidentally, my composition teacher, Émile Damais, did
not consider Xenakis a “real” composer, but rather an “illusionist” in
music. That had the exact opposite effect on me: it revived my interest in
Xenakis’s music! On the other hand, a new age of frenetic developments
in computer music was happening, especially concerning industrial
production and design of hardware and software. So, when I heard from
Xenakis himself about the new UPIC system, I was captivated by the idea
of an “all-comprising” audio processing unit. It promised a unified field
between sound generation and music composition, a concept that was
directly emanating from his ideas.[3]
EXPERIENCE WITH THE UPIC IN FRANCE AND IMPLEMENTATION
OF THE UPIC SYSTEM IN GREECE
FIRST YEAR: PERSONAL IMPRESSIONS AND RESPONSIBILITIES

Once in France, I contacted the CEMAMu, visited it, reserved time there,
and was finally able to work with the system. Unfortunately, these first
contacts were inconclusive. The time I had with the UPIC system was
limited (around 30 min per session); moreover, the machine itself was
notoriously slow. As a result, there was no time really to set a goal and
achieve some progress. Not only a whole composition was impossible,
but even a moderately complex sound structure or experimenting with
an elaborate sound wave were beyond reach. I was used to working in
university studios with ample time and numerous recording possibilities,
something that did not exist at CEMAMu.
PASSAGE FROM IRCAM
FIG. 1 The UPIC installed in the KSYME studio, May 1986 © Dimitris Karageorgos

By the end of my studies in Paris (1984–85) I had been given the
opportunity to work at CEMAMu’s “rival” IRCAM with the 4X machine.

252

Marc Battier and Horacio Vaggione, two composers I had met and
worked with at the Faculty of Paris VIII, helped and supported me in this
venture. I was invited, as a young composer, to create a new piece. I
had a short introduction on how to handle, boot, and reset the system,
and was given a personal external hard drive to store my work, and I
even had the possibility to write small parts of code in order to program
some new functions. Τo control the 4X, I used a highly practical and
innovative hardware interface called Pacom. I was offered many nights
a week for two months: I was alone with the machine from 10 pm till the
following morning (if I so desired). This, plus countless espressos from the
automatic coffee machine, was something equivalent to heaven for me at
the time! As a result, I was able to create a new piece that was premiered
at IRCAM’s venue, Espace de Projection. That ended up being something
much more comprehensive, regarding a system and its musical abilities,
than the limited experience I had had with the UPIC.

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

253

DIMITRIS KAMAROTOS

system to Greece, and equip a full creative sound studio around it had
been under discussion for some time (since the Mycenae Polytope), and
major efforts had been underway over the previous five years to make it
happen.[4]
MEETING THE PEOPLE

During the following month, I had the opportunity to meet and start
working with some of the principal collaborators of the years to come. In
particular, Haris Xanthoudakis, the other Greek composer who had studied
in France and had just arrived back in Greece. He, too, had experience
with the UPIC at CEMAMu. I also met Andreas Stafylopatis (professor at
the National Technical University of Athens computer science department).
He was collaborating closely with CEMAMu and KSYME at this time, and
carried full responsibility for the technical installation of the unit in Greece.
Thus, he assured the technical link connecting the two institutions. FIG. 2

REDISCOVERING THE UPIC IN ATHENS

FIRST PHASE OF KSYME

Although inconclusive, the first sessions with the UPIC had nevertheless
been promising, and unexpectedly continued the following year when I
was back in Athens. The announcement about the opening of the KSYME,
and the installation of a UPIC unit, was lauded in every newspaper and
newscast for days.
In parallel, there was a lot of discussion about the system’s
possibilities, the pertinence of electronic and computer music, costs, and
so on. Then, Xenakis himself arrived in Athens for the official opening.
Shortly prior to this, KSYME launched a rather modest call for composers.
This call came from the two influential people mentioned above: John
G. Papaioannou and Stefanos Vassiliadis. Stefanos was the general
manager and artistic director of the Centre. He planned to get acquainted
with and eventually to bring all the Greek composers he could to the
Centre, especially the ones oriented on and educated in electroacoustic,
electronic, mixed, and computer music. Hence, in March 1986, I was
at KSYME with my résumé and my music: some tapes of instrumental
pieces, analog electronic compositions, scores for small ensembles,
and the piece I had composed and produced at IRCAM. The few hours
of experience I had had with the UPIC at the CEMAMu seemed to be an
important factor, because the one in the Athens studio was an exact copy
of it (hardware and software).
From my discussion with Vassiliadis I acquired some new information
concerning the relationship between KSYME and Xenakis and the
personnel already at KSYME. Also, I was briefed on some technical issues
about the unit. I learned that the idea to create the Centre, bring the UPIC

After the official inauguration on April 23 1986, we began to hold regular
and informal meetings in the Center to organize upcoming activities.
Following the recommendations of Vassiliadis, some first responsibilities
were delegated. It seemed very important to develop a platform to get
active groups of composers and musicians interested in learning, working,
and creating with KSYME’s new UPIC system. Xanthoudakis and I were
responsible for formulating a call and drawing up a first syllabus for
composers interested in working with the system. More specifically, Haris
focused on mixed composition (acoustic instruments and the UPIC), and I
on more computer-based and structural compositional matters. For these
first courses, I was interested in including some basic ideas from Xenakis’s
book Formalized Music, and also in not just giving practical instructions, but
also adding some technical notions on the UPIC’s unique design: a system
that permitted unified compositional thinking from micro-form, (such as
designing a sound wave), to macro-form—a music creation system capable
of producing both sound textures and musical forms. A tool permitting
the transformation of a mathematical abstraction into musical form[5], a
system that, as I discovered much later, potentially enabled the user to
transgress sound material[6], a basic concept that could end up breaking
some rules incorporated and formally prescribed in Western composition
over a number of centuries. This potential of transgression, I now believe,
was always present in the core of Xenakis’s music.
During the first months, I developed a closer collaboration with
Andreas Stafylopatis. This was partly due to the fact that I had some
knowledge and practice in computer programming, and in particular for

255

DIMITRIS KAMAROTOS

sound generation and processing. Another important reason was that I
had become extremely interested in discovering more about the UPIC and
its possibilities. Hence, I spent most of my time at the Centre.
By September 1986, Stafylopatis had completed the first user
manual of the KSYME UPIC in Greek. It was a detailed 20-page document,
covering:
1. Startup and Shutdown processes
2. Functional description and Operations
3. Saving and Loading

FIG. 2 Andreas Stafylopatis and Iannis Xenakis, April 1986

© Andreas Stafylopatis Archive

This manual, although well structured and adapted to cover the system’s
particularities, was still considerably complex for traditionally trained
(non-technically oriented) composers. Over the years, working with three
generations of composers in the KSYME studio, this manual was of little
use to most of them.
One reason why many surprising technical difficulties for the users
remained after their first contact with the system was due to the influence
of how the system was promoted: as an intuitive, non-technically inclined
system encouraging creativity. People were promised they would be
able to make music, or at least complex, interesting sound structures
without any knowledge of computers, or even music. This was what the
media proclaimed when the UPIC was first announced at KSYME. Further,
this was derived from Xenakis’s own comments on the system, after a
filter of over-simplification was applied to his words by journalists. Being
responsible for the courses with composers, and later for the special
program that introduced primary and secondary school pupils to the
system, I retained this same line of presentation when working with the
system. Consequently, I presented the main functionalities of the system
as a music-making machine open to free, impulsive, and associative
experimentation, at least to very young future composers. For adult
musicians and composers, I emphasized and encouraged them to use
modelling: get an idea to comply or to try to formalize an existing one
through mathematical, graphical, trigonometrical, physical, or musical
implements. This approach opened new horizons for some of them who
had previously only had traditional, classical-oriented musical training.
For the first six months or so, we experienced several malfunctions
with booting, saving, and the handling of data. Soon afterwards, though,
some of these problems became rarer, after numerous subsystem and
main program updates resulting from our collaboration with CEMAMu’s
engineers.

256

THE CREATIVE STUDIO AROUND THE UPIC SYSTEM

In the first days of the UPIC at KSYME, a sound studio was equipped and set
up to add functionality to the UPIC. This studio was not a formal recording
studio, but it nevertheless offered a lot of potential for creative work.
The location, however, was not ideal; it was an apartment that
belonged to the director of the center, Stefanos Vassiliadis. KSYME
occupied the ground floor of a multi-storey apartment building in a densely
populated Athens suburb. It was insufficiently insulated, yet convenient
for the flow of a large number of people at any time of the day as it had a
separate entrance and none of the adjacent apartments were inhabited.
This sound studio was, in a way, a second-generation music lab after
the one that existed in another basement in the center of Athens during
the 1970s, the ΕΣΣΥΜ, the Hellenic Association for Contemporary Music,
whose studio was built around a prominent EMS vSynthi-100 unit. This older
studio had some of the equipment which the UPIC—KSYME studio inherited:
Revox tape recorders, hardware audio filters, patch-bay, oscillometer, and
two EMS VCS3 analog modular synthesizers. Additionally, there were some
newly purchased tape recorders, studio monitors and mixers, a number
of microphones, headsets, and all kinds of cables. During the next year,
as soon as they appeared on the professional market, CD and DAT digital
recorders were purchased.
It is important to note something concerning the creative profile of
this laboratory: although the main unit was the UPIC, there were a lot of
combinatory capabilities using different techniques. That gave the studio
a profile closer to a university music faculty studio than to a dedicated
one-unit laboratory. This resulted from decisions regarding the equipment
made by the artistic manager Stefanos Vassiliadis. It also had to do with
my personal inclinations as an active member of this team. This kind of
open-minded view on music creation through different media, systems,
instruments, and styles was something I preferred and aimed for. These
technical characteristics of the initial UPIC—KSYME lab seemed to me to
be close to Xenakis’s idea of an open creative system. The multifunctional
environment of the studio was shaped around the same principles, but
in a modular way, equally using new digital and older analog equipment.
This mind set of a “no-simplicity, no-clarity, no-minimalistic” approach to
compositional tools, in opposition to an intense search for clarity in form
and the resulting composition, was something that captured the attention
of many young composers I was working with during the first years of the
UPIC—KSYME lab. Over the next ten years, it also shaped the proposals
and the completion of educational and research programs by KSYME. In
parallel, dedicated activities concerning creation and education exclusively
with the UPIC coexisted.

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

257

DIMITRIS KAMAROTOS

THE FIRST SET OF ACTIVITIES

The first educational and creative programs took shape during the next six
months of 1986:
1. Call for young composers to attend UPIC workshops with the option to
reserve time later for music creation;
2. Personalized communication with older composers who had
already worked with mixed and electronic media (such as tape and
instruments or analog electronics). Inform them about the existence
of and the options concerning the UPIC and the opportunity to work
with it. Invitations to foreign composers for residencies at KSYME to
work with the UPIC;
3. Call for musicians to contact the center in order to establish a
music ensemble specialized in mixed compositions with the UPIC
(instruments and tape);
4. General call and personal communication with scientific collaborators
for the creation of groups focusing on research proposals and
consortiums;
5. Collecting and making available all documentation and support for
the system’s technical functions. Investigating technical improvements
of the UPIC and the supporting studio.
In the following months, some of the goals began to develop and became
the center's main activities.
COMPOSERS’ WORKSHOPS

A call for young composers was issued at the official opening and was
renewed via the media from time to time over the summer. Many music
students and about ten young composers expressed interest and started
attending the workshops as of May 1986.
In these workshops there was a short introductory technical course
with Andreas Stafylopatis and then courses on theory and practice. The
prescribed time was about 12 hours per week, but in practice this expanded
into much longer because some students asked for and had extra personal
time with the system. Not all of them were equally motivated, so giving some
of them personal assistance seemed to be more efficient, either individually
or in small groups of two or three. Their technical ability with the system
advanced gradually, and the young music students and composers became
more confident with the UPIC. Personal studio time during this period was
mainly granted at night.[7] In parallel, I was achieving a more profound
appreciation of the system’s potential. These courses continued over the
years in the lab, but also in external workshops when the unit was travelling.

258

One important element in these educational and creative activities
was the system’s processing time. Even for a relatively experienced user,
that is, without creating anything that would uselessly slow down the
machine, the time required for computation was by today’s standards
unbearable. In practical terms, depending on the complexity of waveforms
and the density of lines in the macro-form (arcs on timeline), it could take
from half an hour to several hours to create and listen to a few minutes
of recordable sound. It was not unusual for inexperienced users to make
a wrong choice of parameters. In such cases, the waiting time could end
up producing something unexpected or simply unusable. The slowness of
this version of the system never changed throughout the years. From the
very beginning we were all hoping for a faster system; what we used to call
an “accelerated version.” In the summer of 1987, I had the opportunity to
discuss this matter directly with Xenakis. This disadvantage of the UPIC at
KSYME was never eliminated nor improved, although the next generation
UPIC[8] was remarkably faster and capable of some parallel functions
during sound calculation. For this same reason, some practices were
suggested during the workshops and a few others were invented by
the composers themselves who worked with this system. In particular,
two choices were proposed to the composers in order to best use the
available time:
– Use of loops. Whenever the sound did not change for some time, a
properly edited loop of prerecorded material was preferable to extra
processing time.
– Use of handmade sketches of the macroform, if possible, on a 1:1
scale. This gave the possibility of thinking and discussing the form
and its possible result before entering the processing mode. FIG. 3
While calculating sound, if some given parameters were wrong (out
of domain), there was a big risk of the system defaulting into an endless
calculation loop. Undoubtedly, these considerations influenced the
creative results.
The first workshop ended on September 6, 1986 with a first
presentation of resulting compositions. Haris Xanthoudakis and I then
started collaborating on the syllabus and management of the next
courses.
During the second workshop of the first year, courses were also
given by Andreas Stafylopatis, the composers Vangelis Katsoulis, Minas
Alexiadis, and Costas Moschos, the acoustic engineer Gottfried Schubert;
and the director of KSYME, Stefanos Vassiliadis.
From such activity and creative workshops, some young composers
created their first electroacoustic or purely electronic music pieces,
notably: Akis Daoutis, Nikos Poulis, Takis Velianitis, and Spyros Faros.

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

FIG. 3 Pre-sketched material for the author’s Intermediary Space, UPIC composition
1986 © Dimitris Kamarotos Archive

261

DIMITRIS KAMAROTOS

Just before them, three first works by an older generation of composers
were completed by Haris Xanthoudakis, Vassilis Riziotis, and me. These
first creative results were presented in concerts over the following months.
In October 1986, while a second series of courses on the UPIC was
underway, three commissions for new compositions using the UPIC were
granted to V. Riziotis, for tape and piano, H. Xanthoudakis for tape, and me,
for tape, clarinet, double bass, and piano.
These new creations were presented in April 1987 at the Goethe
Institute of Athens, recorded and released on LP.[9] FIG. 4
COLLABORATING WITH EXPERIENCED COMPOSERS

We contacted well-known Greek composers who were interested in or
already using electronic sound in their compositions. Of these, three
were particularly involved: Michalis Adamis, Nikos Mamangakis, and
Nikiforos Rotas. I contacted them personally and assisted them with
various activities around the UPIC system, the KSYME lab, and computer
music in general.
Especially Michalis Adamis and Nikiforos Rotas continued to be
interested and used new compositional, computer-based tools, even after
the functional period of the KSYME—UPIC system ended. I continued to
visit them in their personal studios and followed their involvement with
new technologies during the 1990s. They experimented with the first
UPIC-generated sounds, and later continued with the NeXT system of
KSYME and Mac computers (more on that below).
We must not forget a fourth important Greek composer who was
interested in and creative with the UPIC: Stefanos Vassiliadis, who, besides
being a very productive analog electronic music composer and personal
friend of Xenakis, also inspired and supervised most of KSYME’s activities.
In 1987, two foreign composers were invited for a residency at
KSYME to compose using the UPIC: Iván Patachich (Hungary) in June 1987,
and Thortseinn Hauksson (Iceland) in November 1987.
From November 11–20, 1987, a special workshop and concerts were
organized with Daniel Kienzy, French saxophone soloist and composer.
He experimented with students and composers at the KSYME lab and
demonstrated possibilities of his instrumentally produced textures
combined with the sound of the UPIC.
FORMATION OF A MUSIC ENSEMBLE

FIG. 4 The POLYAGOGY LP with four compositions, by Xenakis, Xanthoudakis, Riziotis,
and Kamarotos, 1987, Music-Box-records X33SMB13018 © Dimitris Kamarotos Archive

Many professional performers were invited for sessions and participated
in recordings and concerts. I was particularly interested in creating a
small, resident, contemporary music ensemble that would be available for
mixed compositions with electronic parts made with the UPIC system and

262

acoustic instruments. Any real-time processing of instrumental sounds
was impossible at that time because of the design of the system and its
computational capabilities.
But even without real-time capability, during the first years of the UPIC
at KSYME, a research project with a music ensemble was created, with
the acronym title: “ΠΡΟΣ.”[10] For four years, many musicians joined this
group and some of them participated in most of the concerts and studio
research sessions.[11]
SCIENTIFIC COLLABORATION: RESEARCH PROJECTS

From the first months after the opening of the center, many members of
the scientific academic community became interested. They were involved
in formal research projects and activities.[12]
THE RESEARCH PROJECT “HXE”

During the years 1986–1994, research projects were conceived,
proposed, and realized at KSYME. Most of them were related to the UPIC
system in collaboration with other research partners. A significant project
was proposed to and endorsed by the Ministry of Education in 1989,
called HXE. (acronym in Greek for Sound Map of Greece). Its intent was
to research tools for automated comparison of sound patterns using a
sound data base composed from rural soundscapes around the country.
A research consortium was created with KSYME, NTUA, and ERT.[13]
Xenakis was particularly interested in this project; formally, he was a
scientific advisor of the program and wrote a letter to congratulate the
National Secretary for Research and Technology, Perikles Theoharis, for
endorsing the project and to affirm his own support for the goals of the
research.
In this research project, Elias Koukoutsis was the scientific
coordinator for the NTUA and I represented KSYME. The project fulfilled
different tasks and deliverables over three years. A first large database
with sounds from non-urban sites was created, based on numerous
recordings from all over the country. The first tools of automated sorting
were based on a codification of each sample’s name. In a second phase,
sorting was based on digital information on the header of every sample
file; in a third phase, an attempt was made to directly compare patterns
of extracted data from every sample. In its final phase, the plan was
to integrate the results with the new real-time version of the UPIC. This
did not happen because KSYME never acquired the new version of the
system. Instead, a new application was designed and delivered, in a
Windows environment as a GUI for the handling of the map related to the
database of sounds.[14]

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

263

DIMITRIS KAMAROTOS

TECHNICAL SUPPORT, DOCUMENTATION

KSYME’s UPIC was documented and maintained functional for about ten
years by Andreas Stafylopatis. During that operational period few people
could perform the basic commands to reboot and restore the system in
the event of complications. In parallel, great efforts were made to remain
informed, prepared, and to search for funding to upgrade our UPIC to the
new real-time version.
THE EDUCATIONAL PROGRAM FOR YOUNG STUDENTS:
A VALUABLE EXPERIENCE WITH SOUND AND MUSIC USING
KSYME’S UPIC

The concept of the program was a practical experiment based on Xenakis’s
ideas about universality and humanistic use of research on sound. In
December 1986, with Xenakis in Athens, a new program of the UPIC—
KSYME lab was announced in collaboration with the Ministry of Education.
This activity consisted of opening the KSYME studio to groups of young
people so that they could come in contact with the expressive capabilities
of sound and experiment with the UPIC. At the press conference, Xenakis
remarked: “This opportunity for young people to come to the center to
learn about and play with sounds is as valuable an experience as visiting
the Acropolis or the National Museum.”[15] The program was co-organized
with the National Secretariat for the Young Generation. I undertook the
coordination and a large part of the teaching. The UPIC—KSYME lab was
available for one year, three times per week, to groups of young people.
There were two different age groups: 10 to 15 years old and 15 to 25. In
practice, due to demand, it was extended for a second year, and the vast
majority of the groups were from 10 to 16 years old, mainly school classes.
That created a major problem because the activity had been arranged for
groups of maximum 10 people. After the second month, we had to divide
the larger groups into two or three sessions. A total of about 4500 young
people in this age group came to the UPIC—KSYME lab over these two
years. The program we devised consisted of a short introduction showing,
through examples, how sound can be a flexible expressive medium. Then,
a second part consisted of a demo with functions and structures of the
UPIC. The third and most important part was to form small work groups,
define an achievable goal, and create a sound structure with the system.
The duration of each course was 3–4 hours. I hired two or three assistants
from the group of young composers already working in the lab, mainly to
help me with the third part of these sessions that involved many groups
working in parallel. My experiences of this sensitive and demanding
job were multiple and rich: I often was surprised by the genuineness of
these young creators’ imaginations. Their ideas about sound were, in

265

DIMITRIS KAMAROTOS

many cases, unanticipated and their collaboration in groups (from 2 to 5
people), both impulsive and rewarding. One frequent thing the youngest
did was to make a simple sketch of a familiar machine (a car, an airplane)
or something imaginary (a robot, a rocket). Since I was giving them this
possibility under the arc design function, a different sound texture was
produced each time. As a next step, they were given the possibility to
prepare a simple page with one horizontal line we called “horizon” and
some short lines we called “birds.” Then, with pre-chosen waveforms, we
obtained some seconds of sound (30–40 sec), which often motivated them
to experiment in other directions. A common observation was that after four
hours of working, we were just starting to find good communication and
interesting interaction. Unfortunately, the program provided only a single
session per group. Once again, the system’s inability to produce sound
with shorter computational processing time was a serious disadvantage.
However, the benefits of getting the children to think, discuss, use a
computer interface, all together, cannot be underestimated. FIG.5
THE UPIC-LAB USED BY A NEW GENERATION OF GREEK
COMPOSERS—IMPRESSIONS AS MANAGER OF THE PROGRAM

FIG. 5 Young pupils with the author, working with the UPIC, 1987 © KSYME (CMRC) ―
ChouPaF Unified Archives[16]

The first call for young composers interested in working with the UPIC was
particularly appealing because no fee was charged for this. That created
some extra work—reading all the applications and in many cases, some
extra interviews—before making the final selection. In all cases, there
were more candidates than available places on the courses. During
the first months, this was extremely demanding because of the small
number of people working at the center. There was a much larger group
that supported the center in many and necessary ways (administration,
public relations and relations with the ministry, relations with educational
institutions) but the day-to-day operations relied on just four or five people.
Soon, however, this changed. Within six months, a much larger group was
taking on and exchanging functions of different responsibilities.
We had administrative meetings whenever possible, certainly more
than once a week. At these meetings, Stefanos Vassiliadis was always
present, helping to keep everything running. The only meetings without
him were some technical sessions with Andreas Stafylopatis and Achileas
Aggelidis.[17] Another important person who followed the first steps of the
newborn UPIC studio and became increasingly involved, participating in
concerts and research projects after 1990, was the Byzantine chanter and
musicologist Lycourgos Angelopoulos.[18]
In terms of selecting young musicians (composers and students of
composition), we took great care to create homogeneous groups, with
regard to their level in music theory and acoustics, their experience as

266

composers, and their ways of approaching compositional subjects. This
was not always successful; nevertheless, such differences created very
interesting dynamics within groups. The overall concept was to create
small groups working on:
– General knowledge—quite basic—of sound and acoustics.
– Reference to compositional techniques and principles that could be
valid for both electronic and instrumental sound.
– General description—schematic—of the UPIC system, with emphasis
on Xenakis’s concept behind it.
– Practical instructions to get them prepared to work with the UPIC.
– Also, practical instructions on how to work with analog audio signals
in the studio.
This last point, although it might not seem so, was absolutely
essential. In fact, every successful use of the UPIC system, producing
anything from a simple waveform to a complete sound structure of several
minutes, needed to be properly recorded. There was no capacity to store
sound within the system, just values of parameters on huge floppy disks.
FIG. 6 The only way to get the material was to pass through patch bay,
filters, effects, and studio mixer to end up with good quality sound on
stereo tape. This, for most of the users, was not an obvious procedure.
More significantly, after two years, the composition and
electroacoustic music class was established at the Athenaeum
Conservatory of Music, FIGS. 7, 8 Although the Conservatory was not
formally related to the UPIC—KSYME studio, it had great importance for
us. We were the same people teaching at both institutions (with a different
syllabus). Besides compositional matters, the courses of this new class
covered studio techniques, sound processing, editing, and recording. Many
of the students were already working with UPIC and others came to KSYME
during the following years to work with UPIC. In this way, the average
technical knowledge of studio sound reached a higher level and working in
the UPIC KSYME lab was more easily directed into music creation.
The last and most decisive part of the workshops with young
composers in the UPIC KSYME lab was the personal creation of a complete
composition. We worked together mainly at night, assisting composers
one by one to create their first piece with the system. This is how the first
group of composers finished their works, which began to appear over the
following six months. There were many ways of presenting the works of
this informal group, a group that over the following five years involved 30
to 40 young composers and musicians as well as 10 to 15 composers of
older generations. These presentations and concerts took place at some of
the main venues in Athens for contemporary and electronic music (such
as The Pallas venue, Goethe Institute, French Institute, Greek-American

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

FIG. 6 Double density, double sided, 8-inch floppy disk used by the UPIC ©
Dimitris Kamarotos Archive
FIG. 7 Opening of the electroacoustic composition class in the Athenaeum Conservatory,
Nov. 1987, with: H. Xanthoudakis, G. Papaioannou, S. Vassiliadis, D. Kamarotos and I.
Xenakis © KSYME (CMRC) ― ChouPaF Unified Archives
FIG. 8 The analog studio of the electroacoustic composition class in the Athenaeum
Conservatory, 1988. The studio was equipped by KSYME and functioned with courses
and studios for composers working with the UPIC. © KSYME (CMRC) ― ChouPaF
Unified Archives

269

DIMITRIS KAMAROTOS

Union, and later, the Megaron Athens Music Hall), but also in more
informal concert spaces. Many of these events combined speech (text,
poetry), video creation, and visual arts (modern sculpture and design) with
electronic tape music. Two of these spaces staged around 30 different
events with works composed on the UPIC between 1989 and 1991[19].
FIG. 9 Another of these concerts took place in the ancient planetarium of
Athens during the first Athens Conference on Psychoacoustics.
Over the following years, these educational activities became much
more organized and were frequently offered as part of specific programs.
Two of these programs or courses were adapted and financed by the
Ministry of Education:
1. Emmeleia Course (1988–1992)
For 45 young musicians and composers. The course aimed to enrich
and intensify the study of writing music with new digital tools and
of studio techniques as a part of a creative compositional process,
music production, and music education. In this course, learning and
working with the UPIC was a basic requirement.
2. The Chroai Course (1990–1992)
For 45 young musicians and sound engineers, devoted to the
digitization of sound archives, old scores, Byzantine traditional music
writing, and digital techniques for comparative processing.

FIG. 9 Before an electronic music concert in the Eymaros gallery, 1990, with

composers T. Velianitis, D. Kamarotos and D. Karageorgos © KSYME (CMRC) ―
ChouPaF Unified Archives

Lycourgos Angelopoulos directed the Byzantine music part of this
program. The UPIC was used in a very specific way in this educational
program: to imitate and reproduce, with simple synthesized sound, the
extremely elaborate microtonal movements of Byzantine vocal traditions.
This kind of vocal expression is called melisma. We elaborated a protocol
to analyze these small recorded vocal parts and then imitate their
movements with the UPIC. Then, these patterns were saved as models in a
special database. The Chroai course was funded entirely by the Ministry of
Culture, not only the teaching, but also the equipment, field research, and
even some monetary compensation for the student collaborators.
As mentioned above, after 1990 the use of computational tools with
better performance was urgently needed. In parallel with the research
projects and collaboration of KSYME with universities in the USA, a NeXT
system was acquired.[20] After this, all projected research and educational
activities were adapted to this environment. Nevertheless, composers
continued working with the UPIC system at KSYME until 1995/1996; they
mainly produced small parts or samples created with the system and
integrated these into more complex compositions.

270

SOME TECHNICAL ISSUES AND PARTICULARITIES OF THE
SYSTEM, POSSIBLE OPTIONS TO DEVELOP THE SYSTEM AND
COLLABORATION WITH TECHNICAL STAFF AND PARTICIPATION
AS THE UPIC SYSTEM MANAGER

There were some special technical characteristics of the system that
a user interested in producing sound had to take into consideration.
In particular, saving work while working was a very important part of
the process. Although this was formally possible, it was practically
unattainable. The external floppy disks (8-inch double sided, double
density) were rather difficult to find. Only one company in Athens was
importing these floppy disks which were used by the aviation computers
of Olympic Airways. They were quite expensive and their capacity, although
large for the time, was not sufficient to save considerable parts of a work.
One would need 2–3 disks to save just one minute of sound. Few people
used these disks, and when they did it was to save parameter values—
code, design of waveforms, and partitions—rather than sound. (By way of
comparison, 5 or 6 years earlier, when I was working with IRCAM’s 4X, I
had been given a huge hard disk (diameter: ca. 50 cm) that was capable of
storing most of my work in sound per session (up to ten minutes of 44 kHz
stereo sound).
Besides this difficulty of saving work, there was another important
functional problem when working with the UPIC, which had to do with
the capacity of the main memory storage. The capacity of the machine’s
internal disk was 35 Mb. Depending on the complexity of waveforms
and the design of music structures, this corresponded to something like
10 min of sound or much less if very complex. Because of this, unused
material could never be left on the internal disk when working with the
UPIC because “<E$PACE ………….>” was likely to appear on the TeleVideo
monitor. FIG. 10 This meant that the last few hours or so spent waiting were
all for nothing, because the machine would crash and need rebooting, so
everything was lost. The use of this internal disk as intermediate storage
during processing was part of the code. Changing the capacity of the
internal disk would only have solved the problem if parts of the software
were rewritten as well.
All unexperienced composers, young and old, needed assistance. In
order to avoid receiving very late-night distress calls at home, I Scotchtaped a photo from the first Alien movie to the inside panel of the system,
the one that had to be opened to check if it was actually still in processing
mode. I added a paraphrased line from the movie, which said (in Greek):
“Deep in the night, at KSYME, no one can hear your screams!” I was
amazed to see that this relic is still there, inside the door of the central
processor. FIG. 11

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

FIG. 10 The text monitor of the system, the TeleVideo screen © Dimitris Kamarotos Archive
FIG. 11 The inside panel of the main system door reveals a 30-year-old joke
© Dimitris Kamarotos Archive

273

DIMITRIS KAMAROTOS

To summarize:
The system came to Athens after several years of tireless efforts
by a small group of people in Greece, mainly John G. Papaioannou and
Stefanos Vassiliadis, but also with the support of Greek administrators,
namely Melina Mercouri, as acting Minister of Cultural Affairs when the
system was bought, and Thanos Mikroutsikos as Minister during the next
years of the UPIC at KSYME, as well as, continuously throughout all those
years, Alkistis Soulogianni, Director of the Department of Letters at the
Greek Ministry of Culture. It was natural, from Xenakis’s optimistic view of
things, to deduce that this would continue, and in some way, KSYME would
become another center for the research, development, and creative use of
the system, collaborating with the CEMAMu. However, this was not the case,
mainly because the natural reaction of the Greek cultural administration
at the time was procrastination. The great efforts and funding that made
it possible to start this endeavor with the UPIC in Greece did not continue.
Also, changes in the administrative personnel, local and national politics,
therefore of financial priorities, amongst others, explain this. Xenakis
discussed this with me during the Patra’s International Festival.
The system that arrived in Greece was considered by Xenakis himself
and his team as no more than a functional, working version of the system,
which was always intended to be advanced and improved.
In retrospect, we now know that although discussed, the “new—
accelerated—UPIC” was not yet deliverable in 1987. It was officially
announced and technically described as being functional at the Glasgow
ICMC 1990.[21] From a financial point of view, KSYME could not at that
time purchase this new machine. The major part of the center's finances
was dedicated to the two main courses mentioned previously: Emmeleia
(1988–1992) and Chroai (1990–1992). These projects used the UPIC, but
did not devote any resources to its development; that was considered the
responsibility of CEMAMu.
THE UPIC SYSTEM OUTSIDE THE KSYME STUDIO.
(THREE CASES: FRENCH INSTITUTE OF ATHENS,
PATRA’S FESTIVAL,CONFERENCE OF DELPHI)

Additional archive material belonging to Kamarotos's contribution is available online.
© KSYME (CMRC) ― ChouPaF Unified Archives and Dimitris Kamarotos Archive

The Athens UPIC system was composed of several modules, interconnected
in order to have the system fully functional:
– The master console, used to give commands for basic functions, like
reset, reboot, shutdown, system restore;
– The graphics display monitor and control keyboard, with the
functionality of graphic representation of parameters, waveforms,
envelopes, and the possibility to control and directly debug the
graphic processing core;

274

– main internal hard disk (35 Mb); the graphic tablet: a graphic input
interface working with an electromagnetic stylus, with a set of
commands set as stylus-activated buttons on the right;
– an electromagnetic stylus, connected by cable to the stylus
converter;
– the stylus converter—Summagraphics control unit;
– main CPU/Intel 512K RAM, with double processor 16 bit A/D and
D/A converters;
– a unit for an external, exchangeable 8-inch floppy disk;
– a black ink monochrome printer;
– a cubical rack containing the main CPU cards, the graphic processor,
the D/A and A/D converters, and the main HD unit, equipped with
cooling fans.
In order to listen to, record, and edit the synthesized sound a
peripheral sound installation was needed. This peripheral system
consisted of a sound mixer, amplifiers, studio monitors, stereo tape deck
recorder (more than one, in order to perform sound-on-sound processing),
a multi-track analog recorder and, not required but in high demand,
good quality effect units (spring or plate reverb and delay). The system
was not complete and functional unless connected with a multitude of
connecting cables of different sizes and specifications. Once the system
was connected, a careful boot-up procedure needed to be performed. This
was critical because the system was prone to unstable connections, and
poor connections could result in software malfunction. In practice this
meant that every time we relocated the system, we needed to spend time
connecting, reconnecting, and testing with the boot sequence until the
system ran properly. When packed up, the volume and weight of the system
needed a small truck or a large van to transport it safely. Thus, moving and
relocating the UPIC was complicated, costly, and carried a risk of damaging
equipment that would be difficult to replace.
As far as I recall, the system was moved to:
– IFA (French Institute of Athens), 1986
– Patra’s International Summer Festival, 1987
– Athens Computer Technology Fair, 1989
– Thessaloniki, Echorama - Fair, 1990
– Some (2–3) of the destinations for the Chroai project, 1991
– Delphi Computer Music Conference and Concerts, 1992

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

275

DIMITRIS KAMAROTOS

Athens; a penthouse in the center of the city below Lycabettus Hill with
a very open and impressive view over Athens. The premises were later
transformed into the library of the same institution. The UPIC event was coorganized by the Greek Ministry of Culture, the French Institute, and KSYME.
A fully functional sound facility, furnished and supported by KSYME,
accompanied the UPIC system. The whole setup gave the impression of
a very high-tech home sound installation rather than a computer music
studio. However, it was totally adequate to create electronic music and
to demonstrate the system. I was responsible for coordinating the part
regarding the UPIC system.
Xenakis was invited for one week. I remember him in the nearby
Lycabettus Hill Hotel (today St. George Lycabettus hotel). I also remember
him specifically asking for this hotel because of the view over Athens and
the absence of traffic noise.
The project included a Xenakis concert in the Pallas concert venue of
Athens: his Medea was performed as well as Psappha. Sylvio Gualda came
to Athens for this occasion. The other part of the project was the ongoing
Institut Français d’Athènes activities. We gave daily demonstrations of the
UPIC and held a 10-day workshop with a small newly selected group. We
also programmed the premieres of the “Music Sketches,” simple and short
music compositions by those attending the workshop. Finally, we opted for
a collective work combining all the individual compositions, which I edited
at the end of the workshop. The tapes from this workshop are still in my
personal archives. We also organized a concert at the end of the workshop,
a presentation of the first works made with the UPIC at KSYME, the
collective work mentioned above, and Xenakis’s Mycènes Alpha.
During these days, the composer François-Bernard Mâche, a close
friend of Xenakis, came to Athens for the performance of his work Phenix,
in the same concert as Xenakis’s Psappha and Medea. I met with Mâche
at Kolonaki square in Athens for a coffee and we had a discussion (in
both French and Greek) about what I was mainly interested in at the time:
creative and pedagogic uses of the UPIC. I can’t recall all the details, but I
do remember—because it was a kind of mild shock for me—that although
he believed very much in the principles that led to the design and the
first development of the system, he also thought that its best qualities
would only be attainable in the next versions, with improved computational
performance.

THE FRENCH INSTITUTE OF ATHENS 1986

PATRA’S INTERNATIONAL FESTIVAL 1987

The first relocation of the system was in November 1986. This was the
first year that the UPIC—KSYME studio existed. It was transported and
installed on the top floor of the main building of the French Institute of

The KSYME UPIC system was also presented during summer 1987 at the
International Festival in Patra (in southern Greece). The system was moved
to Patra for about 15 days.

276

The festival, presided by Thanos Mikroutsikos, a composer himself,
included an international conference on the innovative (for 1987) subject
of Music and Micro-computers. It also hosted dedicated activities as well
as concerts on the subject. Mikroutsikos invited Xenakis as a guest of
honor and president of the conference. He also invited KSYME and the the
UPIC to give demonstrations and a workshop, and we produced a series of
open-air contemporary and computer music concerts.
Xenakis’s music was performed in the open-air concerts. Also, some
of the first complete works made in the UPIC—KSYME lab were once again
performed. The Xenakis Ensemble and many other invited musicians
participated.[22] The activities (workshop and demonstrations) around The
UPIC took place from July 20–30, 1987. Here, the unit was installed in
a bigger, noisier, and less appropriate space. Also, there were too many
people participating; therefore, a creative process for the participants was
unachievable. Nevertheless, this was another good opportunity for a large
number of people to learn, see, and “touch” this machine.
Collectively, at KSYME, we were interested in the future development
of the studio through collaboration with more composers, musicians, and
researchers. During the festival, we had the opportunity to meet with
people interested in the field. Some of the future collaborations I had with
Patra’s University and the ITY[23] were initiated during those days.
The open-air concerts were remarkably interesting because it was
the first time we had designed and built such an installation (open-air for
mixed and electronic music). We had a dedicated space on the top of the
Castle of Patra, a small hill on the edge of the city. The acoustics were very
interesting because of a rather silent environment and a huge stone wall
(remains of a medieval castle) reverberating and gently diffusing electronic
and amplified instrumental sounds.
To respond to the requirements of these concerts the festival had
bought a Steinway grand piano some months prior. The instrument was
there, on the top of this hill, and it probably still belongs to the municipality
of this city. I remember that we assisted in the design and construction of
a special cover that would protect the instrument from high temperatures
and dust.
Pieces previously composed with KSYME’s UPIC and a number of new
works by the invited composers, not made with the UPIC, were performed
at these concerts. Those present and who performed their works were:
David L. Wessel (U.C. Berkeley), Clarence Barlow (U.C. Santa Barbara),
Barry Truax, Wilfried Jentzsch, Nikos Panagopoulos, Kostas Moschos,
Vangelis Katsoulis, Christos Hatzis, and Juan Blanco. Further, represented
by their works but not present: Françoise Barrière and Anestis Logothetis.
The first pieces with UPIC by the Greek composers presented the previous

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

277

DIMITRIS KAMAROTOS

year in the IFA were also performed (Xanthoudakis, Riziotis, Daoutis,
Velianitis, and the author). At these concerts, the mixed pieces (for
UPIC-created electronics and instruments) were performed by KSYME’s
instrumental ensemble PROS.
The above-mentioned composers who came to Patra also
participated in the conference and gave workshops.
AN UNEXPECTED DISCUSSION WITH XENAKIS IN THE CAR

Since Xenakis was there for the conference and we had a UPIC workshop
and concerts, I was very close to him on a daily basis, along with a lot of
other people. One evening, two days before the end of the festival, we
were all invited by the festival director Thanos Mikroutsikos to dine in a
Greek tavern by the sea in the town of Rio, about half an hour’s drive from
the festival.
While we were still at the conference venue, I had exchanged few
words with Xenakis on the subject of everyday use of the UPIC at KSYME.
So, when we travelled together in my little Japanese car to the dinner,
it seemed natural to me to continue our discussion. I had, on several
occasions, exchanged some thoughts or questions with him on subjects
related to his ideas or, more concretely, on compositional methods used
in his works. That was in public places during my university years and
later, about a year prior, during the official inauguration of the UPIC lab
in Athens. I knew that he was a kind of “lonely thinker,” and avoided
spending time on conventional social conversations. He would prefer, in
my view, to stay silent and think about what was critical, avoiding any
useless exchange of words. Therefore, I was prepared to have, perhaps,
a silent journey with him. Yet on the contrary, he was eager to continue
the conversation and interested in the use of the system in Athens even
more. He wanted to know what the people working with the system
considered important for its advancement. Obviously, I told him about
the real-time (accelerated) system, and the expectations for something
much quicker for all functions and even capable of some parallel tasks.
He responded as though these were obvious, but minor details of a future
update. He told me about many potential enhancements of the machine
as a compositional tool. He even referred to it as a thinking aid for the
composer, in Greek (“απελευθερωση της σκέψης του συνθέτη.”[24]) He also
spoke about the use of color in the interface. I was surprised, because
color was already part of the existing interfaces of commercial systems at
the time and I would have never thought of it as a crucial upgrade for the
UPIC. From his very concise remarks, I understood that for him, color was
a way to handle more parameters in the simplified interface of the UPIC.
He expressed this as: “giving multi-dimensional control of sound.”

278

In the meantime, I had managed to get lost on the little dark roads
between Patra and Rio, and since GPS didn’t exist, I was a bit anxious.
But, unintentionally, it gave us more time for our discussion. I tried
to keep him interested and learn his opinion about the work we had
accomplished by getting young composers to work with the UPIC, and
the music that he had had the opportunity of listening to in concerts
the previous days. He made it very clear that although this is a natural
continuation of the center, he was hoping, or shall I say, seriously thinking,
about something else. He told me about it during the last ten minutes of
our journey. Doing my best to recall this after so many years, he expected
KSYME to follow and support the CEMAMu by purchasing the new
version, and even by using KSYME’s relationships with universities and
its research funds to expand the development and industrial production
of the UPIC in Greece. This may sound irrelevant now, but it didn’t sound
strange to me and it wasn’t at that time. He knew we had started to
collaborate with NTUA, and I had personally asked him to participate as
a scientific advisor to a research proposal (HXE “Sound Map of Greece”)
mentioned above.
After this, we arrived at the tavern near the sea, and with a lot
of people from the conference and festival around a long table, our
conversation couldn’t continue. My next opportunity to have this kind of
personal discussion with him came five years later at the International
Conference on Computer Music in Delphi.
Related to this concern and desire of Xenakis to continue the
development of the system and keep KSYME updated with the newest
version of the UPIC are the following letters. Through these, I can
remember the evolution of this subject:
First, a letter was addressed by Stefanos Vassiliadis to Xenakis and
the CEMAMu in November 1986 regarding this upgrade and confirming
the need for it. FIG. 35
In 1988, a little over a year later, another letter was addressed to
the CEMAMu by KSYME, mentioning it should be read by Xenakis. The
letter first gives a general description of KSYME’s activities with the UPIC
system during the first two years, and then again expresses the need for the
new version of the system, and the request to find a way to lower its cost. I
don’t know whether there was any response to this letter.
There is a third letter I know of (from Andreas Stafylopatis’s personal
archive) about the same issue, addressed by Stafylopatis to the director of
KSYME, Stefanos Vassiliadis. In it, there is reference to the second letter, of
June 15, 1988 and a description of the system upgrades from 1985 to 1994.
It confirms that although there was a very good relationship between KSYME
and the CEMAMu studios, and that the KSYME—UPIC system had been in full

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

279

DIMITRIS KAMAROTOS

use for years, only wishes about acquiring the new version were exchanged. I
can confirm that I had exactly the same understanding about this subject.
THE DELPHI CONFERENCE 1992

The last, as I recall, transport and relocation of the KSYME UPIC unit was for
the Delphi Computer Music Conference from July 1–6, 1992. This conference
and festival was organized by KSYME in collaboration with the European
Cultural Centre of Delphi and the Ministry of Culture.
The UPIC system and sound equipment belonging to KSYME was
transported to Delphi one week before the event, together with all the rented
equipment. In the context of this international event on computers and music,
a large number of parallel activities were sponsored in different locations:
– The main conference room, a venue with a capacity for simultaneous
translation into three languages.
– An auditorium for indoor concerts.
– Four small studios, as demonstration rooms, where some teams had
installed their own software and hardware. That was the case with the
CEMAMu (along with Les Ateliers UPIC) with the new Windows-based
UPIC.
– A large basement room transformed into a quadraphonic computer
music studio. There, the IRCAM team installed the hardware for the
new real-time version of their software (under Opcode, at the time).
– An outdoor concert location, in the garden of the nearby historical
Sikelianos Villa,
– A large open area, on the edge of this mountainous location, chosen
and equipped with sound equipment, for the big computer music
concert that ended the conference and the festival.
Just one day before the official opening, I arrived in Delphi having driven
from Athens, together with Stefanos Vassiliadis and Iannis Xenakis. As
we arrived, a meeting was arranged with the Minister of Culture, Madame
Anna Psarouda-Benaki, who was already present. This meeting was quite
unofficial. We were all sitting around a low square table in the lobby of the
conference center with a breathtaking view over the Itea valley and, far
away on the horizon, the sea. Stefanos Vassiliadis gave an introduction
about the importance of the conference that was to take place and the
presence of so many remarkable composers, researchers, and academic
teams. He was also obviously aiming to initiate a discussion about further
and more substantial financing of KSYME and particularly, with the
presence of Xenakis at the table, about acquiring the new UPIC. When
Xenakis spoke I was surprised because, in contrast to what I was used
to hearing from him on such occasions in previous years, he vigorously
supported a much more general argument. He insisted that what was

280

needed and achievable in Greece was massive support of education and
research. Furthermore, that the potential for breakthrough research in music
was already present and should not be neglected. I don’t recall the minister
reacting directly to Xenakis’s argument.
In addition to Xenakis, Paul Lansky, Roger Reynolds, Tristan Murail (who
was about to leave for Columbia University), Jean- Baptiste Barrière, Brad
Garton, Perry Cook, Fred Malouf, Stanislaw Krupowicz, Chris Chafe, Cort
Lippe, Simon Emmerson, and François-Bernard Mâche were also invited
and present at this conference. Additionally, many Greek composers who
had worked at KSYME in previous years were there. Compositions by Titi
Adam, Giannis Manolessos, Panos Doukas, Dionisis Tsaglas, Giorgos Filippis,
Katerina Tzedaki, Alexandros Kalogeras, Athanasios Zervas, Nikos Perakis,
and the author, were performed. A great number of international soloists
came to participate in the concerts.
For a better understanding of the situation, it is useful to know that
during the previous two years, many international exchanges, collaborations,
and joint research projects were initiated. An important component in this
international research cooperation with KSYME was the NeXT computer
system. This system, Steve Job’s creation after he left Apple, was considered
to be the most advantageous and compact environment for the future
of computer music. In Greece, KSYME put together a team, headed by
Professor Thanassis Rikakis, which organized and promoted the use of
this system as well as international exchanges with a view to installing and
developing such a system at KSYME. Since I was part of this group from
the beginning, I have a comprehensive overview of how this new technology
compared with the existing UPIC and what effect it had on the activities
related to it.
By 1992, a new studio based on a NeXT computer system was already
working at KSYME. It was installed on the top floor of the building. The UPIC
remained in the ground floor studio, still functional but rarely used. Many
activities revolving around the NeXT studio were similar to those undertaken
during the first years of the UPIC. These activities were initiated locally by
a small team with Rikakis and me, but were also actively supported by
Professors Perry Cook (Stanford University) and Brad Garton (Columbia
University). These two composers, researchers, and friends came to KSYME
several times in order to help us acquire the hardware, build the software
environment, and structure the studio. After they left, I assumed a similar
role of system supervisor that I had in the beginning of KSYME with the
UPIC. However, there was a big difference: this was a UNIX-based system
with a hierarchical structure, and we could already exchange many things
with our supporting partners in the USA on a daily basis, via the Internet.
This was a major difference to the previous situation with the UPIC. Already,

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

281

DIMITRIS KAMAROTOS

with this team, we had shared some joint research (published papers and
international conference preparations like the one in Delphi.[25] ) Later, these
international collaborations resulted in the organization of the ICMC 1997 in
Thessaloniki and the program on psychoacoustics at the Aristotle University
of Thessaloniki.
In Delphi, in the summer 1992, this new potential within KSYME
was already palpable. It contributed to the successful organization of
this significant international event on computer music. During this event,
although Xenakis was a prominent guest and a founder of the KSYME, with
the Center’s UPIC system still in its first version, it was not as appreciated
and promoted by the organizers as it would have been a few years earlier.
At this conference and festival many computer music laboratories were
present with their recent achievements, in terms of music and software:
Columbia, Princeton, CCRMA-Stanford, and UCSD universities, plus IRCAM
and Les Ateliers UPIC. Thus, the new version of the UPIC was present and
demonstrated by the team that developed it. Gerard Pape, then director of
Les Ateliers UPIC, was also present.
During the days of this conference, a new (not yet commercial) version
of IRCAM’s Max/FTS (“Faster Than Sound”), a version of Max ported to the
IRCAM Signal Processing Workstation (ISPW) for the NeXT was brought
and installed with its full functionality on KSYME’s NeXT environment.
Cort Lippe was responsible for this; he brought with him the triple DSP
IRCAM card and installed it on our system. This was located in a large
room in the basement of the Delphi Centre. I remember myself, together
with some composers (mostly students from the first UPIC workshops),
working furiously all night with it. We were certainly amazed by the userfriendly interface, but also, for someone with experience of the UPIC, by
the impressive speeds of this real-time system. This version impressively
performed real-time algorithmic processing of instrumental sound and voice,
which was already a main feature of this environment from 1989, yet this
represented an important advancement. Experiencing this, Xenakis’s view
about a minimalistic interface aiming at conceptual formalization in music
no longer seemed to be our only holy grail. Promising, real-time algorithmic
compositional tools were already in our hands.
Although, as mentioned, the old UPIC was also present, more as a unit
of reference than as an efficient music system, there was, nevertheless, a
lot of thinking and discussions about it and a possible future for it. Most
importantly, Xenakis was there with his ideas and his music. During the
conferences a lot of important issues were discussed in organized panels.
A very remarkable one was with Xenakis, Reynolds, Lansky, and Mâche
discussing computer music, with Thanassis Rikakis as moderator. I will get
back to this, below.

282

THE DELPHI CONVERSATION WITH XENAKIS

During this conference I had another important private conversation with
Xenakis. This moment remains very vivid in my memory. After a paper
I had presented,[26] I initiated a discussion with him on its subject. He
seemed interested and made some very important remarks about it. But
the conversation naturally shifted to the subject of the UPIC, which I saw
as declining, at least as a practical and usable system at KSYME. I made a
comment alluding to a comparison with other compositional and creative
sound tools showcased at the conference. I presented to him a case for
providing the system with a sampling function, an opinion shared with
many of the KSYME UPIC users. He responded with the same reasoning he
had aired the previous day in a discussion about introducing expressivity in
his music:
I don’t need to try with computers to imitate a sound that exists
already. You don’t need that. What is interesting is to explore other
paths or ways or sounds or even evolutions of sounds that have never
been done or realized, and that is the interesting point.
Those were his words during that panel discussion, and they were
almost identical to his response when I brought up the issue of sampling
for the UPIC,[27] a function that was not possible with KSYME’s UPIC.
By this he insisted on the fact that he considered sampling an
alternative (and maybe faster?) way to create new waveforms and textures
but not to imitate acoustic instruments.[28] Xenakis was then seventy years
old. We had a celebration for his 70th birthday in Athens with concerts and
exchange of letters, some months previously. At this afternoon discussion
in Delphi, he seemed to me to be as sharp and perceptive as some twelve
years earlier, when I heard his lectures in Paris. It was obvious that he had
a similar global view as then, regarding computer music technology, the
potential of academic teams in the USA, and their dynamic presence at
this conference. But in our conversation at Delphi, he was less practical
and more visionary and idealistic, at least that is how I perceived it. He
told me more about what a tool such as the UPIC could mean for the
human mind, for a “researcher universalis”. He kept speaking about art
(and not specifically music) as a field where human potentiality can be
liberated. For this we would need a “special tool” (the UPIC?) to bring art
closer to a much greater number of people. He gave me the surprising
impression that this was not necessarily connected with musicians or
composers. Perhaps he meant that a composer should be more of a
researcher of philosophy than of sounds, first and foremost judging for
himself.[29] Following his own spontaneous associations, he returned to

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

283

DIMITRIS KAMAROTOS

his personal perspective before, or in parallel, with the technical reality
of the UPIC. He spoke to me about a machine that would be able to verge
towards mathematic developments although the user need not be a
mathematician, and to urban creation without needing to be an architect.
Such a machine would be able to handle ποίησις, the Greek word he used,
which means poetry in modern Greek but, creation in ancient Greek. And,
of course, he meant it in this latter sense. This was the second apocalyptic
moment I had with Xenakis in my life (apocalyptic in the original Greek
meaning of the word, in this case, something like: oracular, revealing). The
first one was at the Mycenae Polytope.
In this Delphi discussion, it was maybe a reflection of thirty seconds,
or one minute long, within his speech. I was so marked and unsettled by
this, that, right afterwards, I made a note of his argument. A note I still have,
and that is why I can recall it. It was surely just an attempt to jot down my
general impression, to keep a note of what, exactly, I thought he meant.
That same night, we had a final big concert at the specially prepared
open space, under the stars of that July night, looking over the valley from
the ancient site of Delphi. Everyone participating in the conference had
prepared something special for that night. The technical sound setup
consisted of just four towers of loudspeakers encircling the large area,
but we had the impression of something much more complex. Over the
years, whenever I see someone who was present that night, we recall the
moment together with great emotion, and confirm that this was a unique
and amazing experience.
The Delphi International Conference informally marked the end of
the UPIC’s productive life at KSYME. The unit remained functional for
about tree to four more years, but it was used less and less by composers.
Thus, it was not showcased as an efficient system at the next important
international event organized by KSYME: The International Computer
Music Conference 1997 (ICMC 1997 in Thessaloniki).
Personally, I continued to design and produce small sound structures
with it, up until 1996. At a rough estimate, I spent between five and ten
hours per week on the UPIC, or about 450 hours per year for the first four
years. Over the following four years, this diminished and became less and
less, mainly to get some special textures and forms and then integrate them
into completely different sound generative environments, like C-Sound or PD.
A directly related question is: Should the original UPIC be considered
a system for the production of synthesized sound or rather as a
generative[30] music machine? Technically, the system could be used as
a sound synthesis machine (like Music V in the previous years). However,
the continuity between the creation of a waveform and musical form is
the main principle that is promoted by this tool. I believe that separating

284

these two would be like thinking that a “‘normal” use of a digital calculator
is to make divisions and multiplication, while the remaining operations
would be completed with pen and paper. Despite what seems to be its
obvious intention, the system we had at KSYME could not incorporate
the generative process compositional algorithms, unless of course they
were divided into fragmented mathematical functions and then fed into
the machine. Such an ability became standard and a main advantage of
other productive music environments at the time. Xenakis was interested
in this and he already attempted and presented such features in his
orchestral works from the 1950‘s,[31] but he was severely constrained by
the technology available to him at the time.[32]
Seeing all the capabilities of the system together, I was convinced
that it was not meant for such fractional functionality, like merely creating
a texture or making a rough sketch of a composition in arc-mode with
macro-functions (marked: “parasimansis”[33] in the Greek version of
the system). FIG. 39 However, one was free to do this. Perhaps the UPIC
could be useful in the context of a researcher’s studium, as a tool for
contemplation, unlocking new paths to seek and find solutions. And
indeed, this is a very interesting model for compositional thinking.[34]

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

285

DIMITRIS KAMAROTOS

6.

Christopher Haworth, “Giving Voice to the Inaudible: Perception and Nonperception in Iannis Xenakis’s Late Electroacoustic Music,” in Proceedings of
the International Symposium “Xenakis. The Electroacoustic Music,” ed. Makis
Solomos (Université Paris 8, May 2012), accessible online:
http://www.cdmc.asso.fr/sites/default/files/texte/pdf/rencontres/intervention6_
xenakis_electroacoustique.pdf
By transgression, the unity of timescales model illuminates a hierarchy of
different rules and discourse types which act upon and structure musical space in
advance.”

7.

An exhaustive list of UPIC—KSYME composers is currently being crowd-sourced
and verified here: https://www.KSYME.org/upic.html

8.

The “real-time” UPIC was developed at the CEMAMu, but never installed at
KSYME.

9.

On this LP, my composition Epiphineia was wrongly transferred to the master
from a recording made by National Greek Radio with only the microphones for the
instruments: therefore, the UPIC sound is practically absent. The full master of this
piece and a copy of it exists in the KSYME (CMRC)—ChouPaF Unified Archives.

10.

“PROS” in Greek, meaning “TOWARDS.”

11.

These musicians included: Vassilis Papavassiliou, double bass; Minas Alexiadis
composer, pianist; Dimitris Mangriotis, cello; Daniel Cholette, piano; Thodoros
Kotepanos, piano; Vicki Vassiliadi, flute; and Andreas Symvoulopoulos, piano,
keyboards.

12.

Some of the researchers who collaborated on KSYME’s projects 1986–1994:
Prof. Emmanuel Protonotarios (member of the board of KSYME), NTUA (National
Technical University of Athens); Prof. Andreas Stafylopatis (technical advisor,
responsible for the UPIC), NTUA; Prof. Brad Garton, Columbia University; Prof.
Perry Cook, CCRMA Stanford University; Prof. Thanassis Rikakis, CMC Columbia
University; Prof. Sergios Theodoridis, Signal Processing, Athens University; Prof.
John Kontos, Athens University; Prof. Elias Koukoutsis, NTUA; Prof. Konstantinos
Papaodyssefs; NTUA.

13.

ERT: Greek National Radio and Television Network.

14.

This research project is filed at the National Secretariat for Research and
Technology as “HXE” n# EK8932.

15.

Mesimvrini newspaper: “A ‘music University’ for children proposed by Iannis
Xenakis,” December 6, 1986.

16.

KSYME (CMRC) ChouPaF Unified Archives: ChouPaF stands for the Foundation
of Emilios Chourmouzios—Marika Papaioannou (Emile Chourmouzios was the
husband of the famous pianist Marika Papaioannou, therefore the brother-in-law
of John G. Papaioannou). The ChouPaF archives comprise the archives of Emile
Chormouzios, Marika Chourmouziou-Papaioannou, John G. Papaioannou, and
also Nikos Skalkottas. KSYME and the ChouPaF have the same board of directors
and currently share their headquarters at the Athens Conservatoire. In addition to
its own “audiovisual”, “administrative”, “activity records”, KSYME’s archives also
contain the archives of the Hellenic Association of Contemporary Music (HACM)
and the Greek Studio for Electronic Music. The archives have recently been
unified, see also Tsioukra, this volume.

17.

Achileas Aggelidis was a very experienced sound technician and electronic
engineer who also supported the previous ΕΣΣΥΜ lab.

18.

Later, as of 2005, Lycourgos Angelopoulos was president of KSYME.

FOOTNOTES
1.
KSYME—CMRC, Contemporary Music Research Center of Athens.
2.

Mycenae Polytope Program, 1978 published by the Hellenic Association for
Contemporary Music and the National Tourist Organisation of Greece.

3.

Iannis Xenakis, Formalized Music. Thought and Mathematics in Composition
[1971], trans. Sharon Kanach, revised edition (Stuyvesant, NY: Pendragon Press,
1992), 200: “I believe that music today could surpass itself by research into the
outside-time category, which has been atrophied and dominated by the temporal
category.” and, “It has a considerable advantage: its mechanization—hence tests
and models of all sorts can be fed into computers, which will effect great progress
in the musical sciences.”

4.

For more details about the founding of KSYME, see Tsioukra, this volume.

5.

Simon Emmerson, Music, Electronic Media, and Culture (Farnham: Ashgate
Publishing, 2000), 203: “We hear the results of deterministic yet chaotic
processes all around us: from control systems in buildings to computer noises,
to the resulting ‘noise’ of the World Wide Web. These are steadily becoming
their own ‘indicative fields’. An algorithmic process of generation may then—
unexpectedly, without necessarily the intention of the composer—relate to a
‘sounding model’ in some process in the real world. In a profound sense, this was
predicted by Iannis Xenakis, whose works move to and fro across what appears
to be a divide between those having a clear sonic metaphor in the real world (the
‘mass sounds’ of Pithoprakta, the arborescences of Cendrées) to those apparently
embedded firmly in mathematical abstraction (the ST series or Nomos Alpha).”

286

19.

Athens contemporary art spaces Ileana Tounta and Evmaros.

20.

A NeXT computer station, provided with NeXT STEP software by NeXT, Inc. In this
same environment, the World Wide Web was invented by Tim Berners-Lee, and
NeXT’s OPENSTEP system was later the basis for Apple’s MacOS.

21.

See: https://www.jstor.org/stable/833053?seq=1#page_scan_tab_contents

22.

Performance to M.E for tape and dancer by Vassilis Riziotis; Mi Monan Opsi for tape
and oboe by Haris Xanthoudakis; Intermediary Space for tape by the author. Many
invited musicians also participated, including the Xenakis Ensemble from Holland.
Xenakis’s works performed: Akanthos, Ikhoor, Psappha, Jalons, and Thallein. This
concert took place in the ancient Roman Odeon of Patra on July 21, 1987.

23.

Computer Technology Institute of Patra’s University.

24.

Translated from the Greek: “liberating composer’s thoughts.”

25.

An example of this collaboration: Perry Cook of Stanford CCRMA, Taxiarchis
Diamantopoulos, Giorgos Philippis, and the author, KSYME, “IGDIS (Instrument for
Greek Diction and Singing): A Modern Greek Text to Speech/Singing Program for
the SPASM/Singer Instrument/A Greek language text reading program had been
constructed which generates control files for the SPASM/Singer physical model of
the human singing voice”, Proceedings of the 1993 International Computer Music
Conference, September 10–15, Tokyo, Japan.

26.

D. Kamarotos, “@music’ a new model for the understanding of music functionality
on human evolutionary behaviour”, Proceedings of the International Computer
Music Conference and Festival, Delphi, 1992.

27.

Xenakis, Reynolds, Lansky and Mâche discussing computer music, with Thanassis
Rikakis as moderator. This discussion was recorded and transcribed by Karen
Reynolds. It is available online:
http://karenreynolds.com/xenakis.html?fbclid=IwAR0DYDeYH-UFckYNGhjv1WL8_
Xaj3YW7SXpEeEYnsoRMCVqN8E4dhmgQUiE
Here is another relevant excerpt from the same discussion: Xenakis: “About
musical phrasing and things like that, they have to be part of the mathematics.
If you heard phrasings, I didn’t do anything at all, which means that it is, as
Meyer-Eppler distinguished fifty years or so before, the tiny things that you are
conscious of after a while. This is the interest of probability functions, because
although you do not control them point by point, they have an average evolution,
a very tiny one, which goes into this domain: the liveness of the sound. I thank
you that you have heard it, because that’s an important feature of it. It’s not
produced by any kind of pianissimo or something like that, the evolution of pitch
and so on. It’s directly taken from the result of the probability functions with the
parameters that I told you about.”

28.

And indeed, a sampling function was included in the UPIC real-time version, and
was widely used by most composers working on that system.

29.

Xenakis confirmed this elsewhere as well. See, for example: “(I)t seems that a
new type of musician is necessary, an ‘artist-conceptor’ of new abstract and
free forms, tending towards complexities, and then toward generalizations on
several levels of sound organization. […] The ‘artist-conceptor’ will have to be
knowledgeable and inventive in such varied domains as mathematics, logics,
physics, chemistry, biology, genetics, paleontology (for the evolution of forms),
the humanities, and history; in short, a sort of universality, but one based upon,
guided by and oriented toward forms and architectures. […] (i)t is apparent that
the artist, and consequently art, must be simultaneously rational (inferential),
technical (experimental) and talented (revelatory); three indispensable and

KSYME:
THE UPIC IN
GREECE—
TEN YEARS OF
LIVING AND
CREATING WITH
THE UPIC AT
KSYME

287

DIMITRIS KAMAROTOS

coordinated modes which shun fatal errors, given the dimensions of these
projects and the great risk of error.” Iannis Xenakis,. Arts/Sciences: Alloys:
The Thesis Defense of Iannis Xenakis before Olivier Messiaen, Michel Ragon,
Olivier Revault d’Allonnes, Michel Serres, and Bernard Teyssedre, trans. Sharon
Kanach. (Stuyvesant, NY: Pendragon Press, 1985) 3–5.
30.

Generative, in this case as having the function of originating or producing music.

31.

Metastasis (1954), Pithoprakta (1955–56).

32.

Tim Rutherford-Johnson, Music after the Fall: Modern Composition and Culture
since 1989, (Berkeley, CA: University of California Press, 2017), 344.

33.

parsimansis refers to the writing of Greek Orthodox ecclesiastic music after the
reform of 1814. It is a code for graphic description of vocal sound movement with
details of the micro-movements and texture. ‘

34.

Frédérick Duhautpas, Renaud Meric, and Makis Solomos, “Expressiveness
and Meaning in the Electroacoustic Music of Iannis Xenakis. The Case of
La Légende d’Eer”, in Electroacoustic Music Studies Network Conference
-Meaning and Meaningfulness in Electroacoustic Music (Sweden, 2012), 10,
hal-0076989500769895, from the abstract: “Xenakis has sought to escape the
language model in favor of a conception of music as an “energetic” and “spatial”
phenomenon.” (1), From the Conclusion: “Xenakis’ (sic) approach as a new form
of naturalism in music. It does not seek to represent or paint images of nature
or communicate messages. Rather, Xenakis seeks to immerse the listener in the
underlying undetermined processes found in nature. Composer F.-B. Mâche made
the following comment about this type of approach: ‘In the twentieth century, one
large characteristic of music is not to realize the humanist ideal of communication
between men, but to rediscover the function the universe once had: the sacred;
that is an interrogation about the universe and not just the psychological and
the social dimension.’ Mâche, François-Bernard, Entre l’observatoire et l’atelier,
(Paris, France: Kimé, 1989), 41.

PROBABILITIES,

DRAWING, AND

SOUND
SYNTHESIS:
THE MISSING
RODOLPHE BOUROTTE

LINK

293

RODOLPHE BOUROTTE

PROBABILITIES,
DRAWING, AND SOUND
SYNTHESIS: THE
MISSING LINK
INTRODUCTION

RODOLPHE BOUROTTE

This chapter is a collection of reflections by the author about Xenakis’s
UPIC and its possible evolutions. In this sense, it owes much to the
creation of the UPISketch application. Today, in 2019, there is already
some literature about UPISketch’s present state and its origins;[1] Here
I shall focus on the future development of UPISketch, and more broadly
speaking, on imaginable software iterations.
Considering the UPIC as a reference point, we start from a solid
basis, with clear features: to sum up, we have a page (like a score, but
in the continuous domain) on which we draw arcs that represent the
pitch of synthesized sounds against time. But drawing can also be
used for determining the envelopes of these arcs, or the waveforms
themselves.
So, what kind of thoughts did the idea of a software program
designed, literally, for drawing sound inspire in us? This is what I shall
develop below, with an emphasis on the questions raised, which are
very diverse. Naturally, the following topics must be addressed: pitch,
time, dimensions, continuousness/discreteness, lattices (or sieves), and
finally probabilities, as a proposition for a feature that did not exist in
the original UPIC.
There are several ways of producing music. Roughly, there are
three main types: composition, improvisation, and generation of
interactive systems. All these are possible whether the hardware utilized
is instrumental, or electroacoustic, or mixed. This chapter is primarily
interested in composition and the way it links imagination to a result;
therefore, the word “notation” will be used in its anticipated sense, in a
way that allows us to prepare something we have in mind. Here notation
will not be discussed as a way of translating an image into sound, as
long as this image has not been intended for a musical meaning in
the first place. Such a case could be considered more as a “sounding
notation,” like in sonification, for example: as musical as the result may
sound, the material that produced this result did so incidentally (or by
laws inherent to nature), but not because of a conscious decision by

294

a human being.[2] As one subject dealt with in this volume is graphic
notation, it seems appropriate to develop a bit the meaning of this word
“notation.” Citing Wikipedia:
In linguistics and semiotics, a notation is a system of graphics
or symbols, characters and abbreviated expressions, used (for example)
in artistic and scientific disciplines to represent technical facts and
quantities by convention. Therefore, a notation is a collection of
related symbols that are each given an arbitrary meaning, created to
facilitate structured communication within a domain knowledge or field
of study.[3]
For the purposes of this text, the notion of notation will be
narrowed down to an unambiguous, nonsymbolic technique, but without
belittling other ways of considering it.[4] Finally, the possibility of using
graphic notation for describing probabilistic events will be explored.
According to this hypothesis, the unambiguity of notation mentioned
above refers to a precise definition of the amount of deviation at a given
time for a given value, thus not to any exact value but rather drawn at
random.
THE CONCERN ABOUT PITCH IN MUSIC CREATION

Pitch, according to the Oxford English Dictionary, is defined as “the
quality of a sound governed by the rate of vibrations producing it; the
degree of highness or lowness of a tone.”[5] The “highness” of a tone,
however, is already a disputable concept:
The conception of high and low as applied to sound seems to
have come to the Greeks but slowly; and when they were obliged for
teaching purposes to give names to the strings of their lyre, they called
the lowest string of the tetrachord Hypate, which means “highest,” for
in instruments of the harp shape, such as the trigon, this string was the
“highest” when placed upright, or, as we should say, the longest.[6]
For music creation, we will stick to a slightly modified definition
by replacing the word “tone” with “sound.” Then, it is general enough
to cover all the usages of pitch in music, because psychoacoustics
has shown us that the relationships between a perceived note and the
sound spectrum are rather complex. In this respect, pitch can be either
a precise note in the classical Western meaning, or an overall tendency
of the sound spectrum, as can be related in some cases to the spectral
centroid.[7] Meanwhile, in the twentieth century, several approaches
have shown less interest in pitch as a harmonic function and as a
physical entity to compose with (electroacoustic music being one
prominent domain for this kind of approach), it seems rather difficult to
conceive music without having in mind at least an overall pitch contour.

PROBABILITIES,
DRAWING,
AND SOUND
SYNTHESIS:
THE MISSING
LINK

295

RODOLPHE BOUROTTE

Indeed there appears to be a wide consensus about the fact that
pitch is of primary importance in composition. It is important to point
out that pitch, like any physical quantity, needs time to be perceived.
THE CONCERN ABOUT TIME IN MUSIC CREATION

Music is time-based. Time is the container of our musical output.
Again, there have been different creative approaches in the musical
domain. Generative music questions how we conceive a piece: we
work on setting up a process, and it is this process that will take the
role of unfolding the details of the art piece in time. People, including
Mozart, have composed systems for generative music, and have created
algorithms for composing music. Even Iannis Xenakis’s concept of
“outside time”, a method he developed to work beyond the limitations of
the linear time concept, can give us a glimpse of the idea of something
that is able to define music without being instantiated. We can define
a set of rules and decide that this is enough for describing the desired
musical result. For instance, we can imagine an infinite number of
versions of Xenakis’s pieces Herma (1961) and Nomos Alpha (1965),
as suggested in a publication by the Musical Representations Team
at IRCAM.[8] But what can be said about the final product, if not that it
uses time? The distinction lies in the composition process. It’s amusing
to think that the question of authority might be related to that of time
instantiation—but the question of attributing or not the authority of a
piece when it is still in its conceptual state, and not yet realized in time,
is far beyond the scope of this chapter. However, instantiation in time
is to be a key aspect for the present discussion, since the goal is to
integrate probabilities in a compositional process. However, as long as
the description of these probabilities is not processed into real events,
the physical experience of hearing an instantiated result is not possible.
THE PHYSICAL REPRESENTATION

The following statements by Heinrich Hertz reveal a fundamental feature
of the scientific method: the inner formation of images representing
phenomena occurring in the outside world, allowing us to infer laws and
anticipate how things are presumed to happen. By extension, his words
are also a fairly good introduction to the reasons for creating graphical
representations of the physical world:
The most direct, and in a sense the most important, problem which
our conscious knowledge of nature should enable us to solve is the
anticipation of future events, so that we may arrange our present
affairs in accordance with such anticipation. As a basis for the

296

solution of this problem we always make use of our knowledge
of events which have already occurred, obtained by chance
observation or by prearranged experiment. In endeavouring thus
to draw inferences as to the future from the past, we always adopt
the following process. We form for ourselves images or symbols
of external objects; and the form which we give them is such that
the necessary consequents of the images in thought are always
the images of the necessary consequents in nature of the things
pictured. In order that this requirement may be satisfied, there must
be a certain conformity between nature and our thought. Experience
teaches us that the requirement can be satisfied, and hence that
such a conformity does in fact exist. When from our accumulated
previous experience we have once succeeded in deducing images
of the desired nature, we can then in a short time develop by means
of them, as by means of models, the consequences which in the
external world only arise in a comparatively long time, or as the result
of our own interposition.
We are thus enabled to be in advance of the facts, and to decide
as to present affairs in accordance with the insight so obtained. The
images which we here speak of are our conceptions of things. With
the things themselves they are in conformity in one important respect,
namely, in satisfying the above-mentioned requirement.[9]
When Xenakis constructed a timeline comparing the historical
evolution of music and mathematics, he showed a great interest in the
“Invention of the bi-dimensional representation of pitches versus time
by the use of staves and points (Guido d’Arezzo), three centuries before
the coordinates by Oresme”[10] His point was possibly to emphasize
the close interlinkage of knowledge in the arts and sciences throughout
history. By citing Oresme (ca. 1350), Xenakis may not have known
about this graph FIG. 1, part of a manuscript discovered by Sigmund
Günther in 1877 which supposedly dates back to the tenth century. The
mathematician and historian Howard Gray Funkhouser (1898–1984)
says about it:
“The graph given here in facsimile is of significance in the history of
graphic methods in that it appears to be the oldest extant example of an
attempt to represent changeable values graphically which in appearance
closely resembles modern practice. The distinguishing feature is the use
of a grid as a background for the drawing of the curves.”[11] FIG. 2
What is more it seems incredible that the scientific breakthroughs
suggested by the examples above did not come into common use until
the nineteenth century![12]

PROBABILITIES,
DRAWING,
AND SOUND
SYNTHESIS:
THE MISSING
LINK

FIG. 1 Nicholas Oresme (1323–1382), Tractatus de figuratione potentiarum
et mensurarum, Venice, Italy, 1505. In Tractatus de latitudinibus
formarum, edited by Biagio Pelacani da Parma © Wikimedia Commons
FIG. 2 Unknown author, ca. 1000. In Howard Gray, Funkhouser. “A Note on a Tenth
Century Graph.” Osiris 1: 261 © The University of Chicago, 1936

298

The choices Xenakis made in his timeline chart are naturally open to
discussion, but we adhere to his graphical orientation: if graphics were not
so important, Xenakis could have willingly cited the one of the first known
notations for music, in the form of alphabetical signs, which happens to be
of Greek origin.
Music notation is the representation of several physical values
evolving over time. Since the nineteenth century, experimental physics has
made much use of graphs and plots—visual representations to visualize
experiments or observations.
Interestingly, the notation of music is a reversed process compared
to scientific graphs: instead of representing observed values, music
notation describes, like a timed map, the physical state we seek to
observe (with our ears) in our environment at successive moments.
There is indisputable magic in the act of making plans. Music
creation has much in common with any architectural or building process:
as humans, we are delighted when taking control over matter. We like to
link our imagination to the real world. In the case of music, it is somehow
much easier to create a modified space around us: molecules of air
being lighter than bricks, they allow us to deploy our imagination in an
immense domain of possibilities. Also, the physical metaphor created by
acoustic movement cannot be ignored. The emotional effects from loudly
projected sounds are great, because they are instinctively linked to a
supposedly large physical cause.
In short, in the domain of electroacoustic music, a system that would
aid representing physical values related to music and translate them
directly into audible sound would be very valuable. This was the purpose
of the UPIC system, and with UPISketch and its future iterations, it is also
ours.

PROBABILITIES,
DRAWING,
AND SOUND
SYNTHESIS:
THE MISSING
LINK

299

RODOLPHE BOUROTTE

for example, as Bradford Skow suggests: “Intuitively speaking, to say that
time is one-dimensional is to say that we can represent time as a line,
and that all events that occur in time can be assigned a position on that
line.”[13]
Back to notation: for most of its history until now, notation has been
deployed on two-dimensional physical media. In fact, a 2D medium can
help us represent 3D values without much of a problem, sacrificing a little
precision, however, for the third dimension: FIGS. 3, 4
We can even push to four dimensions. That is the case with a map,
with its contour lines suggesting the third dimension and its colors that
can be assimilated to the fourth dimension. Then, what could we do with
a 3D physical medium? Not much more, since for a fourth dimension we
would need a plastic material, at once transparent and capable of bearing
information for each coordinate of a 2D slice of it. FIG. 5 is an example of
a possible “score,” in a non-transparent dough, so that the overall view
doesn’t provide access to the fourth dimension data that may be stored in
the individual slices.
Of course, with the advent of Virtual Reality, nothing can stop us from
imagining a notation system in 3D. Let us say the maximum quantity of
dimensions that can be visualized will probably be four: three dimensions
in virtual space, and one of color. Many attempts have been made to
represent more-than-three dimensional spaces—the light cone in special
relativity theory and the hypercube are good examples of these—but we
can’t really see them as straightforward. However, a musical process,
such as has been profoundly explored by Julio Estrada with his concepts
of “macrotimbre” and “multiparametric composition,”[14] can easily require
a description of at least six different values for each instant. So, we seem
to be a little stuck, and we are not sure that going 3D offers any great
advantage.

A MATTER OF DIMENSIONS

On the various occasions we had to present the concepts behind the UPIC
and speculations about its future, there was often feedback like “What
about 3D?” I will address this question here.
First, our current state of knowledge assumes that the universe can
be properly described with the notion of space-time: three dimensions
of space and one dimension of time. The difference between time and
space is a rather interesting question, still challenging for physicists and
philosophers. However, something appears to be universally agreed:
time is a line. Again, the strategy about time in this chapter is different
from some uses in aesthetics where time is indeterministic. Here, time
is considered in the spirit of anticipation of what we want to see/hear
happen at a desired time. This—time as a line—seems to be a good basis,

THE DIALECTICS OF CONTINUOUS VERSUS DISCRETE

Again, this is an old debate, but we humans have still not resolved
this issue. There are even arguments as to whether, in the case of a
component of space-time being discrete, it should be time or space,
or both. Measured data is no exception to this uncertainty. When
representing data, we often face the question whether the original quality
of this data was discrete or continuous. The function of the real variable x,
f(x) = 2 * x may look continuous, but does this reflect physical reality? Also,
in computer music we are used to manipulating samples, measured from
real values, each being 22.6 µs in the case of the CD format. And from a
different perspective, pitch analysis as performed by the ear does reflect
a very special characteristic of acoustic reality: the fact that harmonic

301

RODOLPHE BOUROTTE

spectrums are composed of frequencies showing an integer ratio between
them. This gives way to a natural tendency to “discretize” our perceived
universe: the generally decreasing energy of harmonic partials, from the
fundamental to higher frequencies, suggests that we use sets of discrete
frequencies for making music (so-called musical scales used traditionally
in any culture of the world). What about dividing the pitch continuum by
discrete steps? We did so. An advantage of this (generally static) division is
that it provides a finite number of items that can be manipulated by means
of addition or of other kinds of operations. This is what led to the glorious
music of Bach. Once the process is theorized, there are no limits to further
manipulations: several authors, including Xenakis with his sieve theory,[15]
or Wyschnegradsky with ultrachromatism,[16] did think about dividing the
pitch continuum differently than following any tradition. Reflections about
scales, including thirds tones or quarter tones have existed since a long
time ago, notably with the Greeks around the fourth century BCE:
“The diatonic scale, which is obtained by tuning pure fourths and fifths
by ear [...] was altered to the soft diatonic of Polymnastus; in this scale the
lichanos of each tetrachord was flattened by a quarter of a tone: producing
the intervals (ascending) semitone, 3/4 tone, 1–1/4 tone.”[17]
WITH OR WITHOUT LATTICES

FIGS. 3, 4 Rodolphe Bourotte, Some 3D Graphs in Levels of Gray, 2019
© Rodolphe Bourotte

Dealing with discrete values means creating lattices. As suggested in
the previous paragraph, lattices have this kind of numeric property,
appropriate for arithmetic calculus. So, choosing a lattice for one property
of a sound has important aesthetic implications. This means that for a
certain amount of time, one of the properties of the sound will only have
a finite amount of possibilities. We can therefore be tempted to imagine
lattices that change over the duration of a musical piece. This has of
course been done by several composers, but in general, by discrete
steps: for a period of time we constrain pitches (for example) to lattice A,
then for another time period to lattice B. What if we made a continuous
transformation from lattice A to lattice B? It would be more consistent
with the idea of dynamic morphology, as coined by Trevor Wishart in his
book On Sonic Art.[18]
First, we may want to implement a version in which there is the same
number of elements in A and in B. We will not address the cases when
the distribution (the way they are spatially distributed) of A and B are very
different. FIGS. 6, 7
Intuitively, we see that for the transition to be perceived, we need a
minimum density of events between the two. There would be some kind
of equation defining an approximate minimum density f, like f > alpha *
m/T, where f is the number of events per second, alpha some factor to

303

RODOLPHE BOUROTTE

refine, m the maximum derivate among the various values changing over
the time T. The question begins also to raise some paradoxical thoughts:
there will be a point where the evolving sieve could be assimilated to an
instantiated curve per se. It will be when the time density of considered
events to be triggered will merge into a perceived continuum.
Finally, more philosophically (or even tricky): perhaps one component
(#1) of a sieve could be considered a track, containing all the possible
values for every given time within a piece. The composer would decide
afterwards when events should happen on this and other tracks. Let
us keep in mind that the decision of creating timed events is of the
same nature as a discretization, that is, the discretization of time. It is
extremely rare to consider time as continuous in music, especially at the
meso level.[19] Indeed, “sound objects” are individual entities, hence
discrete.
There is also a link to probabilities: probabilities mean “drawing a lot”
(which is a discrete event). In computer music, if we think of probabilities,
it is often on the micro level (for instance, at the sampling rate), as a way
to produce a result that sounds continuous on the macro level (the sound
we hear).
PROBABILITIES AND DRAWING

FIG. 5 Rodolphe Bourotte, A Hypothetical Score a la plancha, 2018, modelling dough
and acrylic paint © Rodolphe Bourotte
FIG. 6 Rodolphe Bourotte, Sketch of Evolving Sieves: Interpolation between Sieves, 2019
© Rodolphe Bourotte
FIG. 7 Rodolphe Bourotte, Sketch of Evolving Sieves: Ambiguity in the perception of
individual “sieve voices”, 2019. Slow trig rate is circled on the left. © Rodolphe Bourotte

Drawing would be a very efficient way of describing probabilities. There is
not, to our knowledge, any intention formulated by Xenakis to use drawing
instead of formulas for describing probabilities of events. This is surprising,
because it would lead to a unification of both worlds in a simple fashion. A
drawing by Xenakis for his piece Achorripsis[20] reflects such a position, by
dividing time into segments of fifteen seconds, and filling the matrix with
values of the number of events from 0 to 5:
The same approach has been observed in Xenakis’s GENDY pieces
(1991–1994): for the eleven sequences of Gendy3, as shown by Peter
Hoffmann,[21] each corresponds to a different “sound synthesis parameter
set” applied to “a GENDYN sequence entity.”
Our proposition is that instead of using probabilities in their rigorous
mathematical description, which may certainly seem closer to natural
models, one can decide on artificial, arbitrary probability distributions,
conceiving scores by providing for each voice at every point in time a value
and an amount of deviation from this value. This would be described
properly either by a 2D graph with gray levels, or by a 3D graph, as
described in Figures 3 and 4. Then, at a given slice of time (accessible at
any scale), the probability distribution would look like visualized in FIG. 8.
The plot represents the probability for the pitch that will be triggered at the
time of the slice.[22]

305

RODOLPHE BOUROTTE

CONCLUSION

UPISketch’s raison d’être is its UPICian heritage, but its creation was
also motivated from the outset by possible new developments. The most
important feature is notational: we want to use drawing as a way of
describing/organizing sound events. The goal of this chapter is to give an
overview of the ideas that link probabilities, sound synthesis and drawing,
and to show how this process implies multidisciplinary thinking, including
how we understand the world we live in.

FOOTNOTES
1.
Rodolphe Bourotte and Sharon Kanach, “UPISketch: The UPIC Idea and Its

Current Applications for Music Pedagogy,” in Organised Sound 24/3 (Cambridge:
University Press, 2019), 252–260, doi: 10.1017/S1355771819000323.

FIG. 8 Rodolphe Bourotte, A Single Slice of Time, 2019 © Rodolphe Bourotte

2.

Sonification is the process of translating a physical value into an audible
sequence. It can be applied to anything, for example, stock market prices, see
David Worrall, “Using Sound to Identify Correlations in Market Data,” in Auditory
Display, Lecture Notes in Computer Science Series, ed. Sølvi Ystad, Mitsuko
Aramaki, Richard Kronland-Martinet, and Kristoffer Jensen, (Berlin: Springer,
2010), 202–18.

3.

Wikipedia Contributors (2018), Wikipedia entry on Notation,
https://en.wikipedia.org/wiki/Notation

4.

For a reference book about graphic notation in music, see Theresa Sauer,
Notations 21 (New York: Mark Batty, 2009).

5.

Pitch, Definition of pitch in English by Oxford English Dictionaries,
https://www.lexico.com/en/definition/pitch

6.

Charles Francis Abdy Williams, The Story of Notation (London: Walter Scott
Publishing Co. Ltd.; New York, C. Scribner’s Sons, 1903) 12,
https://archive.org/details/storynotation00willgoog/page/n9

7.

For a detailed description of various audio features, see Geoffroy Peeters, “A Large
Set of Audio Features for Sound Description (Similarity and Classification) in the
CUIDADO Project,” IRCAM internal report, 2004, p. 13,
http://recherche.ircam.fr/equipes/analyse-synthese/peeters/ARTICLES/
Peeters_2003_cuidadoaudiofeatures.pdf

8.

Moreno Andreatta, Gérard Assayag, Carlos Agon, and Stephan Schaub, “Formal
Aspects of Iannis Xenakis’ ‘Symbolic Music’: A Computer-Aided Exploration of
Compositional Processes,” in Journal of New Music Research, 33:2 (2004),
145–59. https://doi.org/10.1080/0929821042000310621

9.

Heinrich Rudolph Hertz, trans. D. E Jones and John Thomas Walley, The Principles
of Mechanics Presented in a New Form (London: Macmillan, 1899).
https://archive.org/details/principlesofmech00hertuoft/page/xxviii

10.

Iannis Xenakis and Benoît Gibson, Kéleütha: écrits (Paris: L’Arche, 1994), 34–35,
author’s translation.

11.

Howard Gray, Funkhouser, “A Note on a Tenth Century Graph,” in Osiris 1 (January
1936), 260.

PROBABILITIES,
DRAWING,
AND SOUND
SYNTHESIS:
THE MISSING
LINK

306

12.

Historians seem to agree on the fact that one of the most important contributions
to data graphics is by William Playfair (1759–1823): “William Playfair is the
principal inventor of statistical graphs. […] Playfair’s graphs were elaborate and
well constructed: they appeared regularly in several publications over a period
of more than 30 years and they introduced a surprising variety of devices and
techniques that are in use to this day. He invented three of the four basic forms:
the statistical line graph, the bar chart, and the pie chart.” in, The Encyclopedia of
Social Measurement, ed. Kimberly Kempf-Leonard (Amsterdam: Elsevier, 2005).

13.

Bradford Skow, “What Makes Time Different from Space?” Nous 41, 2 (2007),
227–52. https://doi.org/10.1111/j.1468–0068.2007.00645.x

14.

Julio Estrada, “JULIO ESTRADA: THÉORIE DE LA COMPOSITION (II).”
https://www.academia.edu/8456158/JULIO_ESTRADA_TH%C3%89ORIE_DE_LA_
COMPOSITION_II_

15.

Iannis Xenakis, Formalized Music: Thought and Mathematics in Composition
(Hillsdale, NY: Pendragon Press, 2001), Chapter 11.

16.

Ivan Wyschnegradsky, La loi de la pansonorité, ed. Pascale Criton and Franck
Jedrzejewski (Geneva: Éditions Contrechamps, 2017).

17.

Charles Francis Abdy Williams, The Story of Notation (London: Walter Scott
Publishing Co. Ltd.; New York, C. Scribner’s Sons, 1903), 21.
http://archive.org/details/storynotation00willgoog

18.

Trevor Wishart, On Sonic Art, New and revised edition, ed. Simon Emmerson,
Contemporary Music Studies Series, Book 12 (Amsterdam: Harwood Academic,
1996).

19.

“Meso” is an important and useful term, often used in Curtis Roads’s seminal
book Microsound: “The mesostructural level groups sound objects into a quasihierarchy of phrase structures of durations measured in seconds,” in Curtis
Roads, Microsound (Cambridge, MA: MIT Press, 2004), 14.

20.

For this particular drawing please see Iannis Xenakis, Composer, Architect,
Visionary (The Drawing Center, 2010), 57.
https://issuu.com/drawingcenter/docs/drawingpapers88_xenakis

21.

Peter Hoffmann, Music Out of Nothing? A Rigorous Approach to Algorithmic
Composition by Iannis Xenakis, published by Technische Universität Berlin,
Fakultät I: Geisteswissenschaften, 2009.
http://opus.kobv.de/tuberlin/volltexte/2009/2410/

22.

This video shows the operational principles behind drawing probabilities.
http://rodolphebourotte.info/GraphicNotation/PGSSDraft.mp4

COMPOSERS
EXPERIENCING
THE UPIC

JULIO ESTRADA
RICHARD BARRETT
FRANÇOIS-BERNARD MÂCHE
TAKEHITO SHIMAZU
BRIGITTE CONDORCET
(ROBINDORÉ)

THE LISTENING

JULIO ESTRADA

HAND

315

JULIO ESTRADA

THE LISTENING HAND
This text is closely related to my activities in research on musical-creation—
not necessarily composition—and on the continuum, as well as my
experience teaching at CEMAMu between 1980 and 1998, where from
2000 to 2001 I was invited as director to lead research aimed at creating
a new model for the UPIC system.[1]
Starting from a simple principle—graphic rendering of musical
material—Xenakis’s UPIC demonstrates a pedagogy for music that is
open to a broader public, whether musicians or not. It is the user who
obtains all results without being guided by academic aesthetics or by new
technologies. The UPIC is a kind of musical creation table where each
user must explore on their own what suits his or her imagination and
thought. Direct access to musical creation without previous knowledge of a
musical language—but sound processing through drawing, or pedagogical
approaches generated by the system—are aspects to be maintained in
future developments of the UPIC system.
UPIC VERSIONS

JULIO ESTRADA

In 2000, the music department of the French Ministry of Culture invited
me to direct the CEMAMu, where I worked with Gérard Marino and Vincent
Fontalirant, computer scientists whose ongoing task was to complete a UPIC
PC version. After the CEMAMu's Scientific Committee accepted my approach
to develop a “21st century UPIC PC soft,” I formally proposed to integrate
theoretical proposals from Xenakis and also to incorporate my own research
on the continuum, which in turn aspired to open other musical horizons.
Neither CEMAMu’s Scientific Committee nor its Board of Directors had the
musical authority or the scientific commitment necessary to defend such a
new project, which forced me to resign in June 2001. The Ministry of Culture
decided in September of the same year to close the center.
The main ideas of my approach to develop the system were to
reintegrate functions of the various UPIC versions produced since 1977 that
had disappeared in subsequent iterations. It was also imperative to integrate
Xenakian stochastic timbres, or the expansion from functions of the micro type
to functions of the macro type. The idea of building a new UPIC system came
from my research in musical creation since 1980. I introduced Xenakis to
some of those theoretical approaches[2] at a conference in Zurich[3]:
1. rhythm-sound continuum
2. music creation by three-dimensional drawing
3. conversion of graphic renderings to music notation
4. continuum-discontinuum fusion

316

I shall go into more detail about these four proposals:
RHYTHM-SOUND CONTINUUM

The notion of continuum naturally leads to the observation of the physical
unit rhythm-sound,[4] where rhythmic frequencies are fundamental to
sound frequencies. Electroacoustic tools enable one to observe that
frequency, amplitude, and harmonic content data of any waveform
preserve their structures in the ambitus of low frequencies. This gives an
objective and homogeneous identification of the respective components of
sound and rhythm:
A frequency
– rhythm: duration
– sound: pitch
B amplitude
– rhythm: attack
– sound: dynamics
C rhythm: micro-durations[5]
– sound: color
All six of these components constitute a rich object whose
material, as audible as reality itself, highlights rhythmic and sound
data; their diversity requires unifying them as a macrotimbre. The
physical nature of the rhythmic-sound macrotimbre leads in turn to
the notion of chronoacoustics,[6] which integrates modern Einsteinian
thought concerning the spatiotemporal fusion of matter, in contrast to
traditional acoustics.
In 1980, I proposed to Xenakis to expand the range of the UPIC
to rhythm as part of the musical frequency continuum. This idea was
refused because of Xenakis’s assumption that the UPIC system allowed
generation of rhythms with envelopes. I was struck by the 1983 version
of the UPIC whose drawing table was twice as large as the first one; this
would enable increasing its original ambitus to rhythm. Later, the 1990s
version opened towards low frequencies, reaching durations longer than
one minute. Although this proved that the CEMAMu had modified its
initial vision, no new works resulted from these enhancements.
I insisted on my initial approach in 1981, when I experimented with
the superposition of several frequencies close in pitch at Stanford
University’s CCRMA (Center for Computer Research in Music and
Acoustics), obtaining a tight nucleus of fundamentals whose harmonics
were perceived as rhythms, rhythms-sounds, and sounds. Afterwards,
I developed a method of drawing rhythm-sound continuums in the field of
written acoustic music with eolo’oolin for 6 percussions, 1983.[7]

THE LISTENING
HAND

317

JULIO ESTRADA

I confirmed these results with UPIC’s own methods with the project yuu’upic
(1993),[8] using low frequencies as generators of new musical material.
Working on eolo’oolin and on the yuu’upic project required drawing
rhythm, a convenient method for a design-based system. The attempt to
transcribe rhythm through drawing cannot avoid the relationship between
time and duration: any line representing a duration is obliged to remain
fixed, to be discontinuous, until the duration has been achieved. FIG. 1
MUSIC CREATION BY THREE-DIMENSIONAL DRAWING

With the UPIC, time becomes the x coordinate while the y coordinate
represents the energy level of the pitch frequencies, envelopes, or waveforms
FIG. 2 By fixing time as a parameter, a drawing is obliged to follow the course
of time or be partially cancelled. In the trajectory on the left the initial point i
and the final point f evolve without contradictions, whereas the trajectory on
the right must end before concluding its counter clockwise motion.
Both curves in Figure 2 also illustrate the contradictory design of
rotations of curved trajectories. For instance, the attempt to draw a circle
with only one trajectory requires drawing a second trajectory to complete
the figure, a counter-intuitive solution that characterizes the music creation
by the drawing. Such contradictions encourage us to extend our graphical
rendering method to trajectories with three or more dimensions; more
difficult to draw but richer and helpful, because in such cases, the trajectory
may refer to an evolution where time is not necessarily one of the main
coordinates. A graphical clock of time’s evolution is sufficient to trace the
trajectory and frees up the coordinates from this task. For simultaneous
representation in a given collective trajectory of other rhythm or sound
components, all will be synchronized by the speed of time flow. This could
allow for a visual reading clear enough to become an equivalence of the
musical information it contains: self-sufficiency similar to a graphic pre-score.
The advantage of multiple trajectories integrating time evolution is their ability
to design information-rich macrotimbres. The time-counter (clock) is identified
by constant units of duration—lines with points at the center cutting the path
of the work. FIG. 3 The coordinates: x-range of the vowels; y-range of pitches; zvibrato, in fractions of a second. Three new coordinates of the trajectory, not
specified in Figure 3, are, for example: u, thickness of the line, evolution of
the amplitude; v, lines inserted in the rough face with diagonals, pressure in
voice emission; w, lines in the smooth face, density of vocal granulation.
The design of the 21st Century UPIC would simultaneously represent
all the data inside the body of an entire trajectory; the unfolding of present
time would become its frontal face, like a mouth. The inclusion of multiple
trajectories may use arbitrary correlations or relative equivalences between
rhythmic-sound frequencies and visual elements; that is, low frequency

FIG. 1 Chronographic representation of rhythm and sound, 2010. Horizontally, the
drawing of the durations advances by thresholds up to the rhythmsound limit (1/16''), or
the line tends to curve as it approaches the vertical axis. Drawing by the author in 2010,
digital version by Christian Morales, in further musical digital drawings referred to as
Ch.M., in 2019. © Julio Estrada and Ch.M.
FIG. 2 Curved temporal trajectories, 2000 © Julio Estrada and Ch.M.

FIG. 3 Trajectory for a voice: 3-dimensional space with a 3-dimensional trajectory, 1994
© Julio Estrada and Ch.M.

320

THE LISTENING
HAND

duration (visual rhythmic pulsation), attack intensity of the duration (initial
light), rhythmic harmonic content (granulation of light material), sound
frequency (colors), sound amplitude (light intensity), waveform harmonic
content (closed geometric shapes), pressure in the emission (molecular
focus), texture (image filters), etc.
CONVERSION OF GRAPHICAL RENDERINGS TO MUSIC NOTATION

The opening and closing sections of Xenakis’s Metastasis demonstrate
the case of writing produced by an exchange between graphical data and
musical data. In the method of rendering musical data through drawing,
musical writing is not a transcription since this would imply a change from
one type of writing to another. Instead, the notion of conversion becomes
more representative of the passage from graphical data to the code
of music writing, and in turn leads us to the notion of a resulting score,
established only after the graphical form.
Among their resources current technologies integrate new methods
of music notation; however, writing music generated from graphics
requires considering musical values in terms of chronoacoustic physics. A
way to get closer to this task could start by analyzing what is comprised
in a waveform in order to convert its physical data into musical code
equivalents. Converting durations into written values can be simplified by
the reference to arbitrary units (i.e., 3, 5, 7, 11), whereas the amplitude
can use a referential range of dynamics (from 0 db at 3p to 3f). FIG. 4
As we can see on the right FIG. 5, the conversion of the six data
extracted from the waveform allows for their macrotimbre to be identified:
(a) general duration, quarter-note = metronomic velocity of 60 strokes
per minute; (b) pitch, 1/64”; (c) accent, loudest dynamic, <3f; (d) overall
intensity, dynamic mean of the waveform, f; (e) vibrato[9] or micro-duration;
(f) timbre, harmonics identified in relation to the grid. At the bottom, on the
left: a sequence of small pulsations of the rhythmic data; on the right: a
fleeting succession of the order of appearance of harmonics.
The interest in converting the drawings I made in 1980 for eua’on[10]—
Náhuatl (Aztec): eua, fly away; on, distant—my only work made on the
UPIC—into instrumental music led me to produce a set of complementary
drawings for the creation of a large orchestral score, in 1995, eua’on’ome—
Náhuatl: ome, two. Its orchestral macrotimbre was based on research
designed to be applied to strings, wood, metals, and percussion,
oriented to create a homogeneous writing whose goal was to erase their
differences by sharing similar articulations of pitch, dynamics, color,
attack pulse, micro-duration, and pressure in the emission. The orchestral
mass individualizes nearly fifty voices made up of the addition of eight
simultaneous macrotimbres.[11]

FIG. 4 Waveform and rhythmic value grid, 1994 © Julio Estrada and Ch.M.
FIG. 5 Conversion of the data extracted from the waveform above in Figure 4 into
musical notation, 2018. At the bottom, two synthetic forms of micro-temporal evolution
© Julio Estrada and Ch.M.

323

EUA'ON'OME Julio Estrada, e.16b, for orchestra, 1995, premiered and recorded with

Baden-Baden Orchestra, Südwestfunk, conducted by Olaf Henzold in Donaueschingen,
Germany, October 20, 1995. In Xenakis, UPIC, Continuum, Electroacoustic and
Instrumental Works from CCMIX Paris, Mode 98/99, 2 CDs, Éditions Salabert, excerpt
from 7'45'' to 10'44'' © juliusedimus

JULIO ESTRADA

The interest in a new UPIC version or other systems that allow
conversion of data from complex trajectories into a score is based on the
need for a fast calculation tool in order to develop modern musical writing
for voice and instruments. Nevertheless, although codification obstructs
the processes of analogical representation of the musical imagination, in
the case of score conversions, it offers the advantage of analyzing both
the writing-to-matter relationship and the audible results.
At the University of Mexico, we developed the eua’oolin system—
Náhuatl: oolin, movement—a modest but effective tool for recording
three-dimensional trajectories in real time for their conversion into sound
results and musical notation.[12] Sound is converted using a commercial
synthesizer controlled by software that allows a maximum conversion
of eighths of a tone, close to the continuum. Unfortunately, timbres are
limited to instrumental colors of the modest synthesizer we used for
sound generation. Rhythmic writing divides the second into five equal
parts. Using a small wand with a ball on its tip, the user draws free
trajectories in a cube with dimensions between 40 and 80 cm per side.
Two synchronized cameras record the small ball, one placed on the x-y
plane and the other on the x-z plane; each stroboscopic pulse lengths
1/10th of a second. FIGS. 6, 7
Listening by hand implies combining the ear and sight in a synesthetic
perception, the basis of a new method of musical representation of
physical matter. The generalization of the graphic method to represent all
the possible components of the macrotimbre eliminates the old academic
division that musical conceptions only pass through the ear. Therefore, the
frank integration of the audiovisual field into musical thought offers the
mind a clearer perception of the temporal transformations of matter, their
movement—a fundamental aspect in music.
The creative process behind ishini’ioni (Purépecha): ishini, always,
ioni, time—for string quartet (1984–1990), originated from the conception
of the eua’oolin system, which led me to develop transformations of
movement through topological variations that control pitch, intensity,
color, and rhythmic bow articulation. FIG. 8
The ability to create an image—and consequently imagine—everything
that moves through the drawing leads to the observation of the action
itself, its intrinsic energy as a physical value attributable to any drawing.
This energy, whether physical or even abstract, represents information as
important as that of the specific component assigned to a macrotimbre.
For musical thought, drawing becomes a dynamic alternative that extends
the methods of assigning macrotimbric data. For example, a vector with
the same amount of energy as another—at the level of the ambitus of
each component—can always express itself with an equivalent value

FIGS. 6,7 Two synchronic sequences of a 3-dimensional trajectory, 1990, both photos
made with stroboscopic pulse lengths of 1/10th of a second light, length about 3
seconds. 3D trajectory by Julio Estrada 1990 © Julio and Benito Estrada [13]
FIG. 8 Julio Estrada, Topological variations, 1986, fragment of a passage of ishini’ioni.

One of the series of four trajectories, one each per string instrument, containing five
components, is converted into the cello score: from top to bottom, string color, bow
speed, pitch (two voices), vibrato speed, and dynamics. Ink and color pencil drawing by
the author on graphic velum paper, 72 × 48 cm. © Julio Estrada Archives

ISHINI'IONI Julio Estrada, e.19, 1990, for string quartet. In Julio Estrada. Chamber
Music for Strings, Arditti String Quartet, Arditti Quartet Edition 27, Auvidis Montaigne,
MO 782056, CD, digital recording by Radio France, Paris, France, excerpt from 6'30'' to
8'03'' © juliusedimus

326

THE LISTENING
HAND

through another component. The ear will move from a forward listening
directed towards a single data to a listening that will rather perceive the
way information moves. A visual example helps us to grasp this idea
better: a simple trajectory originally applied to a vocal or instrumental color
starts from the vowel o and passes continuously to the vowel a, a little
lighter than the first. The energy of the same trajectory can be attributed
to, amongst others, datapitch, dynamics, color of the bow on the string,
the articulation of the bow-pulse, voice’s respiration, brass’s breath—or
spatialization. FIG. 9
CONTINUUM-DISCONTINUUM FUSION

Science observes physical states of matter in various forms, the most
commonly known being gas, liquid (of continuous order), and solid (of
discontinuous order). What we come to know through science or our beliefs
becomes at the same time referential knowledge for the processes of
representing fantasies that maintain certain relationships with reality. This
is particularly striking in the arts, which, in conscious or unconscious ways,
use this knowledge in the manifestation of creations which, transmitted
perceptually, often carry their fantasies in forms close to matter.
In contrast to the continuity of music inspired by fluids, the universe
of scales approaches solids, information expressed in the form of fixed
pitches and intervals. Traditional methods associated with scales seem
to be influenced by the inherent fixity of their data by forcing rhythmic
durations to nail themselves to the pitches of melodic writing, for
counterpoint to be conceived as the mechanics controlling the point-tocounterpoint ratio, for harmony to maintain itself in an ever-synchronous
verticality, and for musical micro- and macroforms to remain crystallized as
a memory that predicts the course of time.
Towards the beginning of the twentieth century, a constant search for
new scales led creators and researchers to focus on experimenting with a
diversity of new scales produced by the division of the tone (Carrillo, Hába,
Wyschnegradsky), of the “octave” or frequency replication interval (fri)
(Novaro), and later in scales produced by harmonics that can be reduced
to the ambitus of the fri (Partch), scales outside the fri, inspired by nonEuropean music (Xenakis), or a continuum of scales, in or out of the fri
(Estrada).
In order to be able to project the spatiotemporal relationships of the
new scales easily, we need to approach them through research outside
their specificity by integrating them into a kind of discontinuum-continuum,
meaning a space outside hierarchies and with lower resolutions than
those of our perception of continuities. By moving away from systems one
can look at the elementary distances between their intervals to allow their

FIG. 9 “oa” trajectory and its attribution to several alternatives among the components of

a macrotimbre having comparable degrees of energy, 1994 © Julio Estrada and Ch.M.

328

combinatorial structure to be derived easily from their interval classes. If
we work with scales as a continuum matter, we will be able to get closer to
their singularities. Thus, the possibility of traversing the space of any scale
with intervallic transitions of minimum distances, d1—step by step—
makes it possible to obtain all the combinatorics through their interval
classes. From there, the expectation of projecting their sequential and
vertical relationships becomes both logical and necessary. The origin
of the interval class theory and its integration in a melodic-harmonic
sole texture have been developed in Canto naciente (1975–78), 8
brass, choral section, juliusedimus [4’04’’ to 7’02’’ of the complete
performance]. CANTO NACIENTE
The combinatorial potential of intervals of the scales makes it
possible to reduce all their possible aggregations of intervals to a
minimum.[14] For example, an aggregation or identity of the intervals
comprising 1 semitone, 1 tone, and 1 major sixth (1–2–9) will generate
a series of 6 permutations intertwined with each other by small
transformations of the order d1 (1–2–9, 2–1–9, 2–9–1, 9–2–1, 9–1–2,
1–9–2). This series of cyclical permutations constitutes a permutahedra,
a mathematical structure that allows all possible permutations of interval
identities to be continuously generated. FIG. 10
I proposed combining the UPIC with MuSIIC-Windows software,
designed to obtain the combinatorial potential of pitch ranges or
durations ranging from 3 to 53 divisions of the frequency replication
interval (fri),[15] which can be used to explore different types of
conversion resolutions in new musical scores.[16]
The 21st Century UPIC project envisaged the integration of the
vast continuum of scales contained in the MuSIIC software, so that the
mathematical organization of the discontinuous and continuum universes
could intertwine and give rise to a fusion open to new creative and
theoretical exploration.
A window remains concerning the continuous transformation
of timbre: in the field of acoustics, I propose, together with Víctor
Adán, using the methods of combinatorial interval potential theory to
reduce complex structures such as waveforms to a series of intervals
representing either the micro-temporal evolution of their frequency or of
their amplitude. This requires the frequency and amplitude level structure
of the waveforms to be made discrete in advance at frequency and
amplitude intervals. Aiming for a continuous variation of color as a central
goal, this approach proposes the ultra-fast generation of continuous
transitions between sequences of intervals whose content can follow
various series of permutations within a waveform identity constituted by
two simultaneous identities: one of frequency and the other of amplitude.

THE LISTENING
HAND

CANTO NACIENTE Julio Estrada, e.8, 1975-78, for brass and choral section, premiered
and recorded with UCSD Brass ensemble, conducted by Tom Lee at Intercon 82, Festival
of Pan-American Contemporary Music, Center for Music Experiment, Music Department,
University of California San Diego, La Jolla, California, USA, April 17, 1982, excerpt from
1'18'' to 2'59'' © juliusedimus

331

JULIO ESTRADA

These continuous color changes would be the product of constant
permutation of the two groups of intervals and their independent
transitions to other frequency and amplitude identities belonging to their
starting scales or to adjacent scales at d1 distance. The previous step
was taken to a modest level by the MuSIIC-Win software, which made
it possible to create fairly simple waveforms characterized by small
numbers of frequency and amplitude intervals.[17]
A SPACE OF EXPLORATION-CREATION

Creative exploration of the continuum occurs outside of didactic
memorization: exploring this territory becomes an unheard-of training
experience that encourages auditory research. The nature of the
continuum allows us to see the widespread equality of information where
no signal indicates the existence of a single reference point other than the
limits of its own space. Creating music—in opposition to composing—in
this continuum becomes significant through one’s intentionality facing
a homogeneous space that leads one to discover answers alone.
Learning through such nudity is like witnessing a construction, step
by step. Finding or losing oneself inside such a fluid space relies on
evaluating through sight and listening how to understand the perceptive,
rational, and artistic experience of grasping the value of what is
created. Discovering freedom of action through matter itself places
one in pedagogical exile that is close to a painter’s intuition; therefore,
attainment depends solely on one’s own gift.
This great discontinuum-continuum, comprising long durations to
micro-durations, links the spatiotemporal domain of music, marking a
reference point that integrates scientific notions with musical theories
using physics as a basis. Naive acoustics that serve the dogmas of
musical languages do not manage to detach themselves from academic
atavisms; on the contrary, accepting musical material as it is—plus the
tools of mathematical organization—lead us to assume that scientific
knowledge may be shared by the imagination, and thus gives way to its
scope. The new perspective of this discontinuum-continuum, coupled
with the basic references offered to the imagination by the physical
states of reality, enable one to consider that the metaphysical
substance of such fantasies can generate creative metaphors capable
of transforming the musical art from its roots.
FIG. 10 Permutahedra of an identity of the type [a b c d], 1994, 4 different intervals
producing 24 permutations, ordered in the figure from A to G and from a to g.
Geometrical structure by Julio Estrada in 1994, digital version by Ch.M. in 2019
© Julio Estrada and Ch.M.

THE LISTENING
HAND

332

FOOTNOTES
1.
Parts of this text are taken from a working report to CEMAMu: “The UPIC of Iannis

Xenakis: Its Future Development,” a synthesis of which was published as: “Neues
Kompositionswerkzeug. Das UPIC-System und seine zukünftige Entwicklung,”
translated into German by Gisela Gronemeyer, MusikTexte, Zeitschrift für Neue
Musik 89 (2001), 58–59. Some other passages derive from my recent book,
Realidad e Imaginación Continuas. Filosofía, Teoría y Métodos de Creación en el
Continuo (Continuous Reality and Imagination. Philosophy, Theory and Methods of
Creation in the Continuum), UNAM, México, in press.

2.

J. Estrada, “Théorie de la composition: discontinuum-continuum,” PhD
dissertation, Université de Strasbourg Sciences Humaines, 1994.
https://unam.academia.edu/julioestrada/Thesis-Chapters

3.

J. Estrada, “Computer-assisted Music Composition: Software on the Combinatorial
Potential of Scale Intervals and the eua’oolin System,” concert series of computer
music and symposium, Musikschule Konservatorium Zürich, Switzerland,
December 11, 1988.

4.

An idea proposed by Henry Cowell in New Musical Resources
(See www.ubu.com/historical/cowell/Cowell-Henry_New-%20Musical-Resources.pdf)
and reprised by Stockhausen in “how time passes...” based on his experience with
electronic music, see
https://www.artesonoro.net/artesonoroglobal/HOW%20TIME%20PASSES%20BY.PDF

5.

This phenomenon can be observed with a bass drum: after a single, strong
percussive attack, a series of micro-durations resulting from the attack is
produced during the evolution of its sounding.

6.

J. Estrada, “Théorie de la composition,” fn. 17, 497.

7.

See an excerpt here: https://www.youtube.com/watch?v=K-4lwHieYI0

8.

The title refers to the series of yuunohui (Zapotec: yuu, clay; nohui, humid).

9.

Apart from Xenakis’s “beats,” vibrato being the artificial equivalent of microduration in terms of traditional writing.

10.

https://www.youtube.com/watch?v=9LUNXqcVUOg

11.

See Robindoré, this volume, Figure 4, for an excerpt of the UPIC score of eua’on.

12.

J. Estrada, and M. Peña, eua’oolin project, Instituto de Investigaciones Estéticas e
Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas, Universidad
Nacional Autónoma de México, UNAM, 1989–1995.

13.

J. Estrada, “eua’oolin: desarrollo de equipo musical por trayectorias temporales
multiparamétricas y su transformación algebraica,” Memoria, Tercera Conferencia
Internacional: Las Computadoras en Instituciones de Educación, México,
Cómputo Académico, UNAM, UNISYS (1987), 118–121.

14.

J. Estrada, “Théorie de la composition,“ 1994, 139–235.

15.

Teoría d1, MúSIIC-Win, Música, Sistema Interactivo de Investigación Creación,
Julio Estrada, theory; Max Díaz and Víctor Adán, software, México: Escuela
Nacional de Música, Laboratorio de Creación Musical, UNAM, México, 2006.

16.

In terms of notation, MuSIIC-Win uses new signs for scales whose intervals are
multiples of the prime numbers 2, 3, and 5, while the rest of the scales must be
expressed in fractions.

17.

Julio Estrada and Víctor Adán, “Transformación continua de la forma de onda por
medio de la permutación de sus intervalos de tiempo,” International Society of
Musical Acoustics, Escuela Nacional de Música, UNAM, México, 2002.

DISQUIET Richard Barrett, 2018, 26'54'', 8-channel, stereoversion © Richard Barrett

MEMORIES OF THE

UPIC:
RICHARD BARRETT

1989–2019

339

RICHARD BARRETT

MEMORIES OF THE
UPIC: 1989­–2019
The products of the intelligence are so complex that it is impossible
to purify them in order to submit them totally to mathematical
laws. Industrialization is a forced purification. But you can always
recognize what has been made industrially and what has been
made by hand. Industrial means are clean, functional, poor. The
hand adds inner richness and charm.[1]

RICHARD BARRETT

This present text is based on a combination of my typewritten report
to the UPIC, submitted in February 1989 (and recently unearthed and
scanned by Sharon Kanach, to whom many thanks), and a lecture I gave
on working with the UPIC at the Institute of Sonology in The Hague in
November 2007, together with additional remarks added in March 2019.
In 1987 I took part in a two-week UPIC course under the auspices of
the Huddersfield Contemporary Music Festival in England. Subsequently,
I worked at Les Ateliers the UPIC on a tape composition using the
system from January 3–9, 1989, and shortly afterwards (January 14–27)
completed this piece, entitled The Unthinkable, while at the same time
teaching and demonstrating the UPIC system to students, schoolchildren,
and members of the public at the Barbican Centre in London. It was my
first attempt to compose a piece of electronic music.[2]
At that time, Les Ateliers UPIC was established in a number
of temporary shacks in the middle of a building site near the Paris
Périphérique which would subsequently become the new home of the
Paris Conservatoire. I had travelled to Paris on a tiny grant from the Arts
Council of Great Britain with my friend and colleague Ian Willcock, who
was also realizing a UPIC piece at the time. We shared a studio, one
working at the UPIC board while the other sketched and calculated
materials, in the same hut where the Swiss composer Klaus Huber was
working extremely loudly on a composition of his own, and the “studios,”
of course, had no soundproofing, either from the building works outside
or from Huber’s UPIC activities next door. Ian and I eventually decided to
work mostly at night, although the bedroom we were also sharing was in a
hotel that seemed to rent its rooms out by the hour, so there was always
plenty of noise of a different kind going on there during the daytime. I
finally finished editing my piece, back in London, at 7 o’clock on the
morning of its first public performance.

341

THE UNTHINKABLE Richard Barrett, 1989, 6'28'' © Richard Barrett

RICHARD BARRETT

Since there were no outputs for digital audio from the UPIC system
at that time, making a composition involved recording its sections from
the UPIC onto an analogue tape recorder and then physically splicing
them together, unless the whole piece were made from a single “page.”
A page could contain up to 1024 arcs, each of any degree of linear
complexity, and, in the version I used, it was also possible for one arc
to perform frequency modulation on another instead of being routed to
the outputs. It was also possible to use sampled waveforms for the arcs,
but only single waveforms: some of the sounds in the piece I composed
there were made by using an entire struck gong sample as a single
waveform. (These can be heard as high-pitched tinkling sounds, at 0’51’’
for example.) Playback was initiated by touching the board with the pen
at the time-point one wishes to start from (usually at the left-hand edge),
but the pen could also be used to “scrub” to left and right across the
board. Bernard Parmegiani’s composition Exercisme IV, composed with
the UPIC in 1986, clearly sounds as if the composer were recording a
“performance” using this scrubbing function, and then editing the result
as if it were the kind of “concrete” material he more often worked with.
The result is something which sounds clearly like Parmegiani in terms of
its phrasing and timing, even if its sonic material is very uncharacteristic.
As Richard Toop points out in his liner note to La Légende d’Eer,[3]
at a time when Boulez at IRCAM was overseeing the development of
systems whose operation could only be understood by professional
computer technicians rather than by musicians, Xenakis was busy
developing a system which could be understood and used as easily
by children as by composers, if not more so: in my brief experience
teaching with the UPIC I found that children were a lot freer with their
imaginations when let loose on the machine than were most adults,
realizing immediately, for example, that an arc shaped like the flight of a
bee would indeed sound like the bee, while a picture of a house wouldn’t
sound like anything in particular. Xenakis’s own UPIC pages for his
composition Mycènes Alpha (1978) are reminiscent sometimes of ancient
ruins, sometimes of trees or microorganisms (often looking simpler than
they sound, on account of using complex envelopes which can’t be seen
but which impact strongly on the sound textures), and of course one can
readily see the connection between their forms and the ruled surfaces
of Metastasis (1953–1954) or the glissando clouds of Pithoprakta
(1955–1956). My own pages looked rather more like the aftermaths of
a series of explosions in broom cupboards, that is to say quite inelegant
in graphical terms. I was never intending that they should be looked at,
although during composition I would often lay out the thermal printouts
of the pages in different orders on the floor to try and get an idea of how

MEMORIES
OF THE UPIC:
1989 –2019

342

some particular concatenation would sound, and indeed after some time
they faded from brown to yellow and finally to white, so that the sound is
ultimately all that remains.
The Unthinkable in its original form existed as a 15ips stereo
analogue tape, which was copied to a Betamax PCM digital tape and
eventually to AIFF format. It was composed as 23 UPIC pages in sequence
(not mixed or overlapped), using the maximum ambitus setting (LA-2 to
RE#9). Each page represents a distinct musical unit—thus the inevitable
division into pages of the music was made a primary feature of the
composition—22 of the pages have durations according to a Gaussian
distribution centered on a mean of 15’’ (the range is 10.3’’ to 20.6’’) while
one, the penultimate page in the sequence, lasts 1’11.4’’. The pages
follow one another without intervening gaps; some contain, or end with,
short silences, many of which were reduced somewhat in the final version
(editing on a digital audio workstation (DAW), which of course was not
possible in 1989) so that the original duration of 6’48’’ was reduced to
6’25’’. This durational scheme is the only remnant of an initially complex
and rigorous precompositional plan, which was abandoned aspect by
aspect, as it became clear that, given the strictly limited working time
(which in London had to fit around student sessions), an essentially
empirical, improvisatory mode of operation was the only one likely to
generate useful results—although even then, several embryonic lines of
enquiry would have to be abandoned because of not guaranteeing usable
products within the time constraints.
One or two of the more interesting sounds (to my ear) in the final
composition arose mysteriously and unintentionally (for example, the
accelerating sounds that begin at 5’19’’, which don’t correspond to
anything on the page and must be some unpredictable artifact of the
frequency modulation). There was no time to analyze and investigate
further their composition and provenance, and so no possibility of
reproducing and/or transforming them; immediately after my working
period with the UPIC I hoped to have the opportunity to return to some of
these phenomena so as to be able to expand the repertoire of coherently
usable possibilities on the UPIC, although in the event this never took
place. In my 1989 report I wrote:
Of course, it is absolutely necessary, when working with any musical
medium, to be able to realize, in notation or otherwise, sounds
which one has previously envisaged—it may be interesting, but is not
usually musically fruitful, to grope blindly for miraculous accidents,
and one corollary of the speed of operation of UPIC is that it could
discourage the reflective and analytical aspects of composition in

343

RICHARD BARRETT

favor of aimless and unclear thinking. Or that, at least, is the way I see
it, which probably means I have not managed to avoid such pitfalls
myself. In any case, the result was that the range of sound materials
in The Unthinkable is a limited one—limited to those materials I had
been able to master rather than be enslaved by—which may be no
great disadvantage in itself, except that I feel these limitations to have
arisen largely as a result of exigencies not immediately related to the
experience of composition (whatever that is).
Thirty years later this statement seems like a somewhat desperate
apology for having had to admit “too much” spontaneity into the
composition process, from a composer who at the time was committed
to a much more rigidly systematic working method. These days I would
say something more like “part of one’s self-training as a composer is to
develop the ability to attract ‘miraculous accidents’ to oneself, and, just
as importantly, to recognize them when they occur,” and that one of the
primary purposes of systematic composition procedures is indeed to
enable a rapidity and spontaneity in one’s exploration of their potential, to
take care of the “reflective and analytical aspects,” so as to liberate the
imagination to improvise and to be intensely present at each moment. In
1989 my activities as an improvising musician were taking place, so to
speak, in private—Paul Obermayer and I had started working together as
FURT about three years earlier, giving a couple of public performances
in 1987 and then “retiring” until 1991 to explore and develop our work
together through a long series of recordings.[4] In retrospect it is clear to
me that the UPIC experience was an essential catalyst in the process by
which I passed through a necessary phase of radical systematization of
my compositional means, and began to approach the integration of an
equally radical spontaneity into those means.[5] Being forced, against my
better judgement, to compose spontaneously and empirically is a theme
that runs throughout my notes from 1989. I wish I (or anyone else) could
have told my younger self to let go of his preconceptions and free his
imagination, that this wouldn’t lead to compromise and (the wrong kind of)
incoherence.
Much of The Unthinkable emerged from investigations into the
frequency modulation function of the UPIC. It seemed less interesting and
more time-consuming to examine frequency modulation (FM) from the
point of view of precisely calculated relationships between arcs sonores
and arcs modulants (the latter always being assigned to channel 0 so
that they wouldn’t be heard in themselves), as well as less idiomatic to
the graphic input of the UPIC. More general topological/morphological
relationships were sought, including the following:

344

General registral relationships: especially where the modulating and/
or modulated arc has a complex forme d’onde whose timbre changes
unpredictably and discontinuously above a certain (sometimes
quite low) frequency, a “fault” of the UPIC which could be turned to
compositional advantage.
B Arcs sonores higher than, lower than, or crossing over arcs modulants:
this relationship gives rise to two distinct “families” of sonorities, with
an intervening discontinuity.
C Rate of pitch change (gradient of glissando) and the rate of change of
this rate, and the general morphology of the arcs (linear, curving, with
or without singularities, etc.): nearly all arcs were drawn point par point,
even where supposedly smooth curves occur, so as to exclude as far as
possible any impression of “painterliness” and to concentrate instead
on creating forms reminiscent, for example, of exponential or chaotic
functions.
D Relative intensity between carrier and modulating arc, obviously giving
a range between almost pure timbre and almost pure noise, and
facilitating continuous (or otherwise) transformations between the two.
E Envelope relationships: some increasing and some decreasing in
intensity, or with several peaks of intensity and so on;— a sound could
thus be given a simple or complex timbral evolution (experiments with
mixing and crossfading unmodulated timbres having proved to be
laborious and only intermittently and unpredictably successful).
F The relative complexity of waveforms: Drawing a waveform by hand
with a precise idea of the timbre it will produce, is almost impossible.
Waveforms which look very different on the graphics tablet end
up sounding like similar examples of a generalized somewhat thin
and reedy sound. What I ended up doing was making a “family” of
progressive stages of (graphic) distortion of an initial sine wave (which
can be heard at the end of the piece, from 6'23'' onwards, on a single
pitch, in reverse order, ending with the sine tone), and all the arcs in
my piece were derived from that family, except those derived from
percussive ondes musicales (tabla, gong, and, eventually, drawn
waveforms reproducing their characteristics) to give “pulsed” sounds,
the pulses individually having a much higher frequency, of course.
These pulsed sounds were also used unmodulated at various points.
G Single arcs modulants of complex morphology, acting upon whole
structures of arcs sonores.

A

In these ways, sounds of generally high but controllable complexity
were generated, many contradicting the tendency of the UPIC to favor the
production of pitched sounds, even if containing glissandi, untempered

MEMORIES
OF THE UPIC:
1989 –2019

345

RICHARD BARRETT

intervals and clusters, etc. The composition could eventually be seen as
having taken place in several stages:
Undirected, then directed, experimentation, mostly in areas not directly
relevant to the end product but more concerned with achieving a
necessary fluency with the system and an initial overview of its
potentialities.
B Having discovered (somewhat later than envisaged) some sound
material, not only usable in itself but also sufficiently pregnant with
possibilities for more extensive elaboration to be contemplated, the
primary structures of the music could be composed in skeletal form,
without as yet finalizing the order of the pages. I used a number of
large pieces of tracing paper overlaid on the tablet, each of which
contained a number of basic graphic sound objects. These then
appear in different kinds of superimposition on many of the 23
pages that the piece consists of, giving rise sometimes to almost
exact recurrences of sound forms and at other times to more oblique
reminiscences.
C after a period of listening to this primary structure, roughly recorded
in a chosen order on cassette, it was articulated, “orchestrated,”
contradicted, annihilated, etc., by superimposing related or unrelated
sonorities as transients, colorations, copulae, alternatives, and so on.

A

The latter two stages involved more listening than drawing,
especially C, frequently to the point of (and beyond) fatigue and disgust
with the materials. Such a working method contrasted strongly with my
usual compositional methods (for notated music) at that time, which
were far more “considered,” both in the sense of being more reflective
and in that of using statistical strategies to build up superimpositions of
interlinked musical processes, with no perceived need to tinker with the
results. In 1989 I suggested that any future work I undertook with the
UPIC should attempt to move the compositional emphasis back towards
processes, rather than the gestures that The Unthinkable consists of,
which depended, as I wrote at the time, on “the ‘irrationale’ of the ear
making decisions and connections without recourse to a ‘coherent’ or
‘constructed’ overview”, such as a system of structural proportions, and/
or one of pitch relationships, pervading the different temporal layers
of a composition. I made a comparison with free improvisation, which I
was already involved in at that time, though with the difference, that the
effect—and, in particular, the precise timing—of hearing all the pages
in sequence had to be abstractly imagined rather than experienced
as a whole before the tapes were spliced together. (Indeed, I made all

346

the splices in a single session, without listening to them until the piece
was complete.) I wrote at the time that “a slight retiming of one or two
events, and some rebalancing of adjacent ones” would be desirable, and
that was the extent of my later interventions into the composition. On
the other hand, the intuitive way in which it was conceived and composed
has actually characterized most of the electronic compositions I’ve made
since then, not dissimilarly (and for not dissimilar reasons, I think) to the
difference in approach Xenakis would apply to instrumental and electronic
work. I was pleasantly struck to discover the similarities in sound between
The Unthinkable and my most recent electronic composition, disquiet (2019),
which should be quite apparent on listening to them one after the other,
even though the newer piece is four times as long, generally involves much
less rapid sonic transformations, and was made by completely different
methods; namely, a software version of the ARP 2600 synthesizer.[6]
My work with electronic music subsequent to The Unthinkable tended
strongly towards using transformations of recorded (sampled) sounds
rather than synthesizing them ex nihilo, although my interest in synthesis
eventually revived after it became possible, using more flexible digital
resources, to achieve the same degree of sonic intricacy that the UPIC
was designed to generate. It’s only quite recently that The Unthinkable
has come to seem to me less like an experimental sidetrack in my musical
output, and more like a pointer whose direction was further explored only
after more than twenty years, with a decisive move towards synthesized
sounds in life-form (2012) for cello and electronics.
Although the sounding arcs could be assigned to one of only two
audio outputs, it was still possible to incorporate somewhat primitive
spatial features. A minority of sounds emanate from only one channel,
several events move across the stereo spectrum by the superimposition
of collinear arcs with different envelopes for the two channels, while most
sounds were “doubled” by placing almost-collinear arcs with identical
envelopes in both channels. The degree of collinearity varies, so that the
precise pitches from the two channels (during an event) may converge
and diverge, thus manipulating the spatial complexity of the stereo
image as well as the timbral profile of the conglomerate sound. Since
the arc modulant for a given “bundle” of almost-collinear arcs is always
the same one, a certain amount of the sound information is inevitably
shared between the channels, depending on the variables related to FM
mentioned above, so that the conglomerate sounds acquire a changing
extension in space rather than mobile positions.
I did make what I thought were some rather interesting discoveries
which ended up being crucial to the composition, and were quite
idiomatic to the UPIC system. One was to use extremely rapid glissandi,

MEMORIES
OF THE UPIC:
1989 –2019

DISQUIET Richard Barrett, 2018, 26'54'', 8-channel, stereoversion © Richard Barrett

348

covering several octaves in a fraction of a second, either as audible
arcs or as modulators, and another was the fact that some fascinating
artifacts could be discovered by examining tiny sections of a complex
texture and playing them back at extremely slow playback rates. A third
was to take advantage of the fact that the resolution of the tablet enabled
an arbitrary degree of rhythmical complexity to be realized. And a fourth
was that one could make the rather characterless sound of the machine
much more gritty by concentrating on the lower end of its pitch range,
which is why, if you saw my pages, you would find much going on at the
bottom of the page and very little elsewhere. Also, I made quite extensive
use of the possibility of selecting a number of arcs and then copying,
resizing, shifting, or rotating them.
In my 1989 report, I made a few suggestions for improvements that
might be made to the UPIC system:
A reflection function could be added. This would seem more musically
productive than the present rotation function. If reflection in a centrally
placed vertical axis were also available to envelopes and ondes
musicales it would greatly aid the system’s flexibility in various areas,
including (with envelopes) spatial composition, of which more below,
and (with ondes) the generation of new timbral resources.
B Where events are transferred between pages by the réduction function,
the numbering of arcs sonores in the transferred event is changed to
follow the numbers already present on the destination page, but their
arcs modulants, if any, retain their original numbers. It is essential that
this limitation is corrected, since it would very simply save a great deal
of time-consuming reassignment, and thus facilitate more extensive
use of the two functions in combination.
C The ambitus of a page (also during entendre) should be constantly
visible on one or other readout screen, since at present it is easy to
forget, and impossible to check the particular ambitus within which
one is working (unless one risks changing it!). In my own work this
problem was minimized by the use of a constant ambitus, but it does
seem inconsistent that when in the calculer mode one is able to
specify the horizontal extent (duration) of the page while retaining
the graphic display, but not its vertical extent. Given that the time
constraints placed on composers (and students) is not likely to change,
any alteration in the system which can thus save needless waiting (for
example, for the computer to redraw the page) would be a great help. It
would also aid the inputting of accurate information to have a constant
readout of the coordinates of the pen’s position on the board.
D When inputting envelopes, the vertical scale should be linear in

A

MEMORIES
OF THE UPIC:
1989 –2019

349

RICHARD BARRETT

perceived intensity rather than in decibels, or there should be some
means of converting between the two. This feature would not only
increase accuracy, but also render the envelope functions more
accessible to younger operators. Otherwise the intensity scale on the
right of the board should be explicitly calibrated in decibels (dB), since
at the moment it is impossible to gauge the intensity in dB of an arc
before having drawn it.
E The choisir function should be accessible by drawing nonrectangular
areas on the board (dessiner continu or point par point). Also, it
should be possible to choose more than one parameter at a time (e.g.,
a specified forme d’onde and channel).
F There should be a direct digital output to facilitate recording onto digital
tape without an intervening analogue stage, thus (if a digital editor
were available) disposing of the need to cut and splice tape. I do not
mention this out of a blind worship of everything digital, but because
it seems incongruous to have to engage in the anachronistic process
of tape-editing at the end of having worked with a highly sophisticated
computer system. It also seems (at the risk of sounding oversensitive)
that insufficient attention has been paid in general to sound quality,
which is a shame in view of the obvious advantages of working with a
system like this.
G More output channels should be available to facilitate spatial
composition, surely one of the potential strengths of any music
composed on tape, and/or the addition of a function to allow sounds
to move smoothly between channels, perhaps by choosing an area
analogously to choisir and assigning to it a scheme of channel
transference, or by specifying an origin channel and a destination
channel for each arc in a similar way to that in which its (single) output
channel is presently specified.
H The lower frequency range of the board could be extended as far as,
say, 0.5 Hz (or even further), which would greatly extend the possibility
of FM-related sounds (using the arc modulant as a “low-frequency
oscillator”) to increase the UPIC timbral potential, as well as rendering it
possible to use ondes musicales in a similar (but more flexible) way to
the sampling functions on other systems. But perhaps this would then
no longer be the UPIC...
I’m not sure whether any of these features ever found their way into
the system. As previously mentioned, this was my first attempt at electronic
composition, and, since then, most of my increasing activity in electronic music
has been in the opposite direction from fixed media compositions like The
Unthinkable, developing instead a specifically and fluently instrumentalistic

MEMORIES
OF THE UPIC:
1989 –2019

350

approach to the medium, especially in the context of partly or completely
improvised music. In another sense, though, this development fulfils Xenakis’s
insistence on the crucial importance of the hand, an “instrument of the mind”
which “stands between randomness and calculation.”[7]

FOOTNOTES
1.
Iannis Xenakis, “Xenakis on Xenakis,” interview with Roberta Brown and

John Rahn, Perspectives of New Music 25, 1 (1987), 23.

2.

https://soundcloud.com/r-barrett/the-unthinkable-1989

3.

Richard Toop, liner notes for CD of La légende d’Eer (Disques Montaigne), 1995.

4.

Richard Barrett and Paul Obermayer, “Statement for Nic Collins,” (2000),
https://furtlogic.com/node/7

5.

Richard Barrett, Music of Possibility (Chipping Norton: Vision Edition), 2019,
passim.

6.

This was the ARP2600 V3 software produced by Arturia:
https://www.arturia.com/products/analog-classics/arp2600-v/
A stereo version of disquiet (which was composed for 8-channel playback) may be
heard and downloaded here:
https://soundcloud.com/r-barrett/disquiet-2018-electronic-music-originally-in-8channels

7.

Xenakis, op. cit.

THE

UPIC
UPSIDE
FRANÇOIS-BERNARD MÂCHE

DOWN

357

FRANÇOIS-BERNARD MÂCHE

THE UPIC
UPSIDE DOWN

FRANÇOIS-BERNARD MÂCHE

As the original form of the UPIC is now more a memory than a still-available
device, and since I may have been its first user, after Xenakis, I will begin
by evoking some historic landmarks which characterized the origins of the
UPIC system, and justify the way I intended to make use of it. I used the
UPIC not only as a graphic synthesizer transforming drawings into sounds,
but also the other way around; that is, transforming sounds into workable
drawings, and I will explain my reasons for making such a choice.
Xenakis had abandoned Pierre Schaeffer’s Groupe de recherches
Musicales in 1962. He was disappointed by Schaeffer’s hostility towards
Bohor (1962), a piece Xenakis dedicated to him. He was also hurt by
Pierre Boulez’s criticism of Eonta the following year, 1963. Xenakis began
teaching that same year in the USA at Tanglewood, and then a couple of
years later at Indiana University, Bloomington. But neither Schaeffer nor
Boulez, nor Xenakis’s American employers were willing to seriously support
his project of a center devoted to music synthesis by digital means. His use
of mathematics and references to physics had to remain purely intellectual
until he founded the EMAMu (Équipe de Mathématique et d’Automatique
musicales), in 1966, with the support of high-level computer scientists,
and philosophers like Dufrenne, Francès, Revault d’Allonnes and LeviStrauss,[1] The EMAMu, first hosted in the École pratique des Hautes
Études, was connected to the nuclear physics laboratory of the Collège
de France in 1969 thanks to the physicist Louis Leprince-Ringuet. Also
in 1969, Xenakis was requested by then President Georges Pompidou
to collaborate with Pierre Boulez on the creation of a new institution to
be called IRCAM (Institut de Recherche et de Coordination Acoustique/
Musique), devoted to science allied to music, and they both publicly
presented the project. But soon Boulez, being more skilful than Xenakis at
dealing with politicians, ousted Xenakis and remained solely responsible
for IRCAM.
In 1972 the EMAMu became the CEMAMu, which at last was
equipped with a digital-to-analog converter built by the Centre National
d’études des télécommunications. The system was a digital drawing table,
the same size as the desk on which Xenakis had been elaborating his
scores as well as his architectural projects. Here one drew on tracing paper
with a special pen, both electric and graphic. The scale of the millimetric
surface could be selected, so that the vertical axis could correspond to
any interval, and the horizontal axis to any duration. Practically no limits

THE UPIC
UPSIDE DOWN

358

were fixed to the amount of simultaneous time and pitch units, called
arcs, since one single so-called page could comprise up to 2024 arcs.
Each page had access to 128 envelopes in one bank, and they could be
combined. Similarly, 128 waveforms were stored in another bank. The
normal ambitus of a page was 6 octaves, but it could also be fixed to up to
10 octaves, including infrasounds and ultrasounds, or be limited to a very
small interval. One could choose either discrete pitch steps or continuous
lines. Such a page could be used to elaborate one sound, one sequence,
or the whole composition. FIG. 1
The same year, 1972, I had composed Korwar, for harpsichord and
tape. The tape organized sounds taken from speech (in Xhosa), frogs, birds,
boars, whales, and rain. I also published a paper entitled “La musique est
une fonction biologique” (“Music is a biological function”). The main themes
of this paper were:
– There is no purely acoustic difference between noise and music, or
between natural sound and human-made music. What matters is
the encounter between thought and sounds, which depends mainly
on context.
– The musical atom is neither a note nor any quantum, but a quale,
a difference similar to the one that exists between phonetics and
phonology.
– Music is not basically a message, but a biological function, which
is not limited exclusively to the human species, and which probably
has its roots in playing.
– Cage is wrong in rejecting any voluntary action on the sounds.
Nature only acquires meaning when responding to humankind’s
respectful action.
The same year, 1972, I shared with Xenakis a monographic issue of
the review l’Arc, where I had published an article entitled “Xenakis and
Nature.” We were close friends, but we had different orientations. Xenakis
appreciated nature as much as I appreciated rationality, but with different
outcomes. I was both willing to support the UPIC and curious to explore
its possibilities, someday, in spite of harboring a basic distrust about any
systematic approach, such as serialism. My own experience of musique
concrète since 1958 had taught me that there is often something more
interesting and richer in acoustic, natural sounds, than in synthesized
structures that a priori follow some fixed system.
In 1977, two years before the commercial release of the first digital
sampler, the Fairlight CMI, I started exploring the UPIC; that is, its first
version. At that time, it was far away from real-time computing, and long

FIG. 1 Schematic diagram of the UPIC’s setup from an internal document of Les Ateliers
UPIC: L’UPIC du CEMAMu © CIX Archives
FIG. 2 Page 12.12.77 (tracing paper 5 octaves, 1 semitone = 1cm), 1977

© François-Bernard Mâche

360

waits were needed before one could discover the sounds that corresponded
to the drawings on a page. I particularly realized that remarkable drawings
did not guarantee remarkable sounds, or even simply meaningful results,
and that they often conveyed misleading illusions. FIG. 2
In 1978 Xenakis composed Mycènes alpha, the first piece entirely
composed on the UPIC, which was premièred on the August 2, 1978 at
Mycenae in Greece, where the composer was at last authorized to return,
30 years after his death sentence in absentia. We can see in it a fascinating
visual analogy to da Vinci’s analytical drawing of vortices. FIGS. 3, 4
In 1979 I heard about the first digital sampler. Unfortunately, it
was extremely expensive and therefore first reserved for entertainment
music. The same or the next year, Publison commercialized its DHM89B2
and KB2000, later nicknamed “the French Infernal Machine 90”, (an
English name, probably to appear more serious and reliable…), and
met with immediate success. FIGS. 5, 7 I talked about it to Xenakis, who
taught me that the UPIC had an analytical feature which might yield some
comparable results.
Among other possibilities, the DHM offered a harmonizer, an envelope
generator, an evolutive vibrato, a delay, a reverb, etc. The keyboard allowed
separate treatment of pitch and duration; for example, automatically
keeping the duration of a sample when transposing its pitch. I used that in
the finale of Aulodie in 1982, where a soloist synchronizes in unison with
the complex rhythms of two recorded tracks.
A few other historic details explain my expectations about the UPIC. In
March 1980, Xenakis was the supervisor of my doctoral dissertation: “The
Idea of Model in Today’s Music.” Four months later I received a commission
to write music to accompany an exhibition near Avignon, whose theme was
“Water,” and I composed four “Phonographies de l’eau,” a term I had coined
17 years earlier to refer to art that parallels music just as photography
parallels painting. Walter Ruttmann’s Wochenende (Weekend) from 1930,
a talking movie without pictures, was probably the first example of such an
art. Already in 1980 the UPIC could function as a crude sampler, respecting
the pitch of a sound signal, but allowing some rhythmic invention. One
of my Phonographies, entitled Proteus (1980), used this possibility.
Unfortunately, I was the only composer interested in such a function, which
subsequently disappeared from the newer versions of the UPIC; otherwise it
could easily have developed a full sampling capacity.
At that time Jean-Claude Eloy composed ETUDE IV: Points-LignesPaysage (1978–80) on the UPIC, and I composed Hyperion (1981) entirely
on the same system. At Xenakis’s request I was teaching a course entitled
“Music composition in the biosphere” at Paris 1 University. In tune with
my practice of natural models, I used the ability of the UPIC to extract

THE UPIC
UPSIDE DOWN

FIG. 3 Iannis Xenakis, Mycènes Alpha, 1978, UPIC score page © 1978 Editions
Salabert—Paris, France, reproduced by kind permission of Hal Leonard Europe S.r.l.—Italy
FIG. 4 Excerpt from Leonardo da Vinci’s notebooks © Wikimedia Commons
FIG. 5 DHM89B2 harmonizer, 1978, scan of the packaging. This was the first sampler in
the history of music. © Publison

FIG. 6 François-Bernard Mâche, Aulodie, 1983, finale (pages 16 and 17)
© François-Bernard Mâche
FIG. 7 Three Octave Keyboard KB 2000, 1980, scan of the packaging. © Publison

AULODIE François-Bernard Mâche, 1983, for soprano saxophone, from Aulodie: Ruth

Velten, CD Genuine GEN 16424, Éditions Durand, 1983, excerpt from 7'21'' to 7'53''

AMPHIBIAN François-Bernard Mâche, with rhythm excerpt (39”) from Proteus, 1980,
undated and unpublished, excerpt from 4'32'' to 5'09'' © François-Bernard Mâche

HYPÉRION François-Bernard Mâche, 1981, unpublished, from Hypérion, CD Jade

015/12 19 34, excerpt from 0' to 1'58'' © François-Bernard Mâche

FIG. 8 Very simple spectrum of the marsh warbler (acrocephalus palustris), sonogram ©
François-Bernard Mâche

FIG. 10 Complex envelope of the white-faced storm petrel (pelagodroma marina),
sonogram © François-Bernard Mâche

FIG. 9 Complex envelope of the white-faced storm petrel (pelagodroma marina),

FIG. 11 Complex envelope of the white-faced storm petrel (pelagodroma marina),
sonogram © François-Bernard Mâche

sonogram © François-Bernard Mâche

two features from different sounds: dynamic envelopes and spectrum
waveforms. Most of my models were different animals, plus a few nonEuropean instruments like the Ethiopian bagana. For the second time I
used technology which enabled me to analyze natural models with greater
accuracy than pure listening. I had done something similar in 1964, using a
Kay electric spectrograph for speech analysis in Le son d’une voix, a piece
stemming from a phonetic model, which Michael Gielen conducted at the
Royan Festival, and that, in fact, anticipated the spectral school by some
ten years. FIGS. 8, 9, 10, 11
While experiencing some morphing, that is, combining dynamic
envelopes and waveforms coming from different analyses, I noticed that
using complex envelopes with simple waveforms was much more efficient
than the other way round (complex waveforms with simple envelopes). The
nature of synthetic timbre did not so much depend on the common view
of steady spectrum contents, but chiefly on the multiple small dynamic
movements of the envelope. At the same time, Jean-Claude Risset was
scientifically developing his analysis of sounds and could describe the
same phenomenon with great accuracy, leading henceforth to more subtle
synthesis of acoustic instruments. The beginning sequence of Hypérion is
made with the simplest sine waveform associated with complex envelopes,
and with a background using slow continuous glissandi. This work was
premièred at Lille on November 4, 1980 (partial), and in Paris on June 19,
1981 (complete). FIG. 12
Three months after Hypérion, in 1981, I tried quite a different
experience in Nocturne, a piece for piano and tape. FIG. 14 The electronic
tape was made on the UPIC as a complex canon of melodic contours. A
basic outline of some 20 arcs was varied at different durations, registers,
ambitus, intervals, and waveforms, initiating complex canonic counterpoints
between the soloist and the tape, and between different layers on the tape
itself. The intervals of the contour could change in many ways, although
without ever changing their direction.
The idea of such a particular canon had some affinities on the one
hand with Xenakis’s arborescences, as he developed in Synaphai (1969),
for example, and on the other hand with Mandelbrot’s fractals, which at
that time had been fashionable among artists for ten years or so.
After 1983 I used the UPIC more rarely, in spite of the new
possibilities of listening to the results of drawings in real time, which, in fact
transformed it into a kind of live instrument fit for the stage. The reason is
that samplers were finally becoming affordable, and I thought they could
cumulate the benefits of handling any kind of sounds, any scales, with
all the flexibility of musical instruments, all while offering the liberty to
overcome their limits and routines. Hence, from 1983 on, I rather used

FIG. 12 François-Bernard Mâche, Hypérion, 1981, page T1 © François-Bernard Mâche
FIG. 13 François-Bernard Mâche, Hypérion, 1981, page 1b (waveforms from exotic
instruments) © François-Bernard Mâche

FIG. 14 François-Bernard Mâche, Hypérion, 1981, notation of evolving unisons
© François-Bernard Mâche
FIG. 15 François-Bernard Mâche, Nocturne, 1981, page 6 © François-Bernard Mâche

NOCTURNE François-Bernard Mâche, 1981, for piano, from Nocturne: Andrew Infanti, CD
Musiques sournoises, 2001, Éditions Durand, excerpt from 5'51'' to 6'42''

372

the “French Infernal Machine” which I already mentioned above. And as
soon as the Mirage could be purchased, I managed to buy one. That was
in 1985, which was also the year when Les Ateliers UPIC were founded.
I presided over it for several years, and, in France as well as abroad we
hosted a great number of training sessions, concerts, residencies for
foreign composers, and various educational activities.
Two years prior to this, I had been elected Professor of Musicology
and Director of the Music Department at the Université de Strasbourg.
There, I managed to raise the funds to buy a UPIC system, and in 1987
I organized a center and targeted curriculum called Primus, in order
to train Tonmeister (sound engineers) capable of reading a score, of
possibly writing one themselves, and of managing recording and postrecording sessions, something that did not exist in France at that time.
The students also learned to work with the UPIC system. We had it along
with a Fairlight VT5 Voicetracker (acquired in January 1986) to transform
sounds into midi data. Personally, I owned a Commodore computer (as
of May 1986) and soon got a sampler better than the Mirage, namely an
Akai S900, which I used for my pieces Aliunde (1987), Tempora (1988),
and Kengir (1991). Among the samples I used, many were borrowed from
the UPIC.
Tempora was written for three samplers, each one with a Midi
keyboard, and they played animal sounds as well as synthetic or acoustic
samples, all working as imaginary instruments. I believed that whole
orchestras made of, or including, samplers would soon be available
and grant electronic sounds the same possibility of expression that the
traditional acoustic instruments had kept. The UPIC itself had already
acquired the flexibility of a real-time music instrument. The commonplace
of endless crossfades between audio fluxes would no longer be the main
way of developing an electronic work. What a deception when I was soon
to realize that such a beautiful dream was hopeless! Everything in the
electronic business, and specifically in the digital acoustic domain, was
ruled by the sole obsession with profit, and with innovation at all costs
being the motto (be it smoke, mirrors, or real); this made programmed
obsolescence a rule. For many electronic compositions, the only hope
for a long survival would be henceforth inevitably brought back to
unchanging recordings, since porting to new sampling platforms is hardly
possible, and anyhow, even when successful, doomed again to shorter
and shorter life expectancy. Most of the time, digital archives will die
before their authors. With regards to the UPIC, its current survival in the
Université de Rouen, under the form of “UPIX” (for Windows in 2001, and
more recently for other platforms like UPISketch for mobile devices), is so
far one of the few notable exceptions.

THE UPIC
UPSIDE DOWN

373

FRANÇOIS-BERNARD MÂCHE

My last commitment for a composition entirely made with the UPIC
was in 1987, when I started composing Tithon. In 1980, on a Greek island,
I had the opportunity to make a close recording of an interesting insect,
probably a “wart biter” (decticus verrucivorus), which had ventured into my
house. Contrary to the monotony of many insects, the song of this one was
rhythmically varied and even contained a hidden melody. I decided to adopt
it as a model. Below, I indicate extracts of its song and of the treatments
I applied to them, thanks to the UPIC and some other devices, in the
composition Tithon (1980):[2]
1. Extract from the original recording (46'')
2. Other extract, at a slower pace: minus 1 octave (13'')
3. Same kind of rhythmician insect (wart biter = decticus verrucivorus) 19''
4. Sound of the hidden melody (30'') FIG. 16
5. Same melody minus 3 octaves. (45'')
6. A midi file from the same melody (through Melodyne), (just for fun,
for in the end I did not use the melody at all…) (45'')
Tithon is not a program music, even if the title refers to a beautiful
Greek legend, which I cannot help telling. Dawn is in love with Tithonos,
a beautiful Trojan prince, brother of Priam, and nephew of Ganymedes.
He is also in love with her since the day when she abducted him one
morning while he was leading his flock. At that time princes could also
be shepherds. Sometime later they had two children, and Dawn started
feeling worried about their future. Her husband Tithonos, being a nephew
of Ganymedes, had access to Olympus. She decided to beg Zeus to grant
Tithonos immortality. Zeus is usually very thrifty with such favors, but he
accepted, taking into account the extended, distinguished service of Dawn.
The only problem was that she forgot to also require eternal youth for her
lover. Day after day Tithonos deteriorated, until he shriveled and shrunk to
such an extent that he became a poor grey thing hanging on some sprigs,
hereinafter referred to as a “cicada.” But he was still in love with Dawn and
greeted her loud and clear every morning.
Indeed, Tithon is not a program music, but nearly every sound
originated in insect recordings, and the piece is imbued with different
moods, typically blooming in summer, like insects’ songs.
In guise of a conclusion, I would like to move from an historic
recapitulation to a tentative reflection about the future of what the UPIC
and the like represent. In spite of their many drawbacks, there are so many
benefits in computer music and bioinformatics that I think they will not
be abandoned. With data processing, the composer can conceive as a
whole the laws of assembly and the sound identity of what is assembled.

375

FIG. 16 François-Bernard Mâche, Tithon, 1980, hidden melody emphasized with the
software AudioSculpt by IRCAM © François-Bernard Mâche and AudioSculpt
FIG. 17 François-Bernard Mâche, Tithon, 1980, page 13. Each of the seven colors
represents a particular waveform for the chosen contour. © François-Bernard Mâche

FRANÇOIS-BERNARD MÂCHE

Instead of dealing with all the limited possibilities and constraints which
a music instrument offers, it seems that there are no limits other than
those of his/her own competences and imagination. A computer can be
commanded to produce such or such sequence of preset sound events
according to laws which will have been formalized in a program, and
this program, for example, can itself present all the complexity and the
training ability of a neural network. Instead of subjecting writing music
to the auditive anticipation of the result of a future performance, one
can launch algorithms whose final sound realization is no longer entirely
foreseeable. This approach, to this day, having allured more than one
follower of musical data processing, presents the double character of
a total rationalization—because everything, including indetermination,
must be specified in a program—and paradoxically, an adventure
where what is produced by the computer has the multifariousness
and sometimes mysterious character of one second, factitious, nature.
Instead of composing a work, some aim at composing a program
suitable for generating an infinity of achievements. One thus explores
the algorithms (which one believes to author), arousing an external
universe of a strangeness that is sometimes threatening. This approach
ends up returning the composer, assuming s/he is not absorbed in the
illusion of absolute power), to his/her most traditional, and least rational,
responsibilities: personal taste, intuition, experimentation, the aptitude
to feel in advance the emotions s/he will organize in the duration, all
capacities without which no choice is legitimate nor even possible among
the machine’s sometimes innumerable proposals. The formalization of
such selection criteria would be possible in its turn only if the knowledge
of the human brain were complete, a still remote utopia. Thus, the
way followed for one half-century by musical data processing has not
been without reminding us of certain aspects of what the revolution of
writing music had produced near the end of the fourteenth century. In a
somewhat comparable way, some six centuries later, the computer has
contributed to prolonging the experimental spirit which had dominated
the 1950s and 1960s of the last century, by proposing novel facilities. It
is, however, necessary to be disillusioned a little when certain provisional
appraisals are made. The computer certainly enables incredible time
savers. But a short handling error can also sometimes cause the
instantaneous loss of several days of work. The complexity of certain
software sometimes involves anomalies that the best data processing
specialists struggle to identify, even with the help of their best repair
software.
Furthermore, paradoxically, sound synthesis transformed the
production of amazing sonorities into a kind of standardized category.

376

Those, as a result, lost so much of their attraction that they could be
used as a negative argument in favor of some reactionary aesthetic
choices. Whereas it is easy to simulate an organ or a vibraphone almost
to perfection, synthetic string instruments, however, often appear
caricatural. And in any case, the results always come out of loudspeakers,
with the constraints and characteristics inherent in these transmitters.
Data processing seems more dedicated to providing prostheses to
acoustic instruments than to replacing them, and it is C.A.D. (computeraided design) which is undoubtedly one of the best possible uses of
computers, wisely retrogressed from the role of demiurge to that of
secretary. They can help outline and write scores, without the listener
even suspecting their intervention. Even on this level, commercial
availability of innumerable software programs for harmonization,
orchestration, arrangement, and composition, can unfortunately support,
along with some dose of amateurism, a certain idleness of mind. By
spreading an illusion of creativity which tolerates sleepy imagination
and careless listening, it often causes sound floods where the best
is drowned amongst the worst. Matching the irresponsibility of the
listener, transformed into a passive and inattentive consumer, looms
the irresponsibility of composers fascinated by the complex proliferation
of sounds of which they control neither the birth nor the evolution. In
other cases, on the contrary, their irresponsibility consists in getting a
completely formalized control of a production process, without worrying
much about the thought, or the absence of thought, which will result for
those who are being addressed.
The composer, as a data processing specialist, is ultimately always
constrained to admit that music is completely formalizable and only at
the cost of a—sometimes—dangerous reduction. The principal challenge
that data processing confronts, by facilitating certain tasks, is to have to
reflect about the difficulties inherent in a given work, even about its
very finality. Ultimately, music, like any art, rests on desire, much more
fundamentally than intelligence. Data processing gives the opportunity
to check what the ancient Greeks already knew: Eros, born much
earlier than Zeus and Athena, nevertheless always remains young. Data
processing, be it with the UPIC or any other tool, should remind artists
that they should be philosophers rather than technocrats.
Personally, I have always tried to combine my interest in powerful
computer resources with a vision broader than technology or language.
The latter maintain the musician (creative and listener) in the circle of
social relationships and social emotions, while music also has a more
mysterious function of harmony with nature, not only with feelings, but
also with the consciousness of the limits and the natural requirements,

THE UPIC
UPSIDE DOWN

377

FRANÇOIS-BERNARD MÂCHE

to harmonize with invention in order to avoid the divorce between
humankind and nature. Music can contribute to sparing us certain
disadvantages of hybridization with “artificial intelligences.”

FOOTNOTES
1.
Founding members of the EMAMu were the mathematicians Marc Barbut,

François Genuys, and Georges-Théodule Guilbaud; the philosophers Mikel
Dufrenne and Olivier Revault d’Allonnes; the psychologists Paul Fraisse and
Robert Francès; and the anthropologist Claude Lévi-Strauss.

2.

Hear: http://www.centre-iannis-xenakis.org/fbm_tithon_examples

THE UPIC FOR A

JAPANESE
TAKEHITO SHIMAZU

COMPOSER

383

TAKEHITO SHIMAZU

THE UPIC FOR A
JAPANESE COMPOSER
As a non-European composer, my encounters with the unique and
characteristic computer music system UPIC, which began nearly thirty
years ago, generated unexpected results and opened new avenues for
my composition which I shall develop below. These same processes
may still yield some hints for composers of the younger generations,
regardless of their various compositional, experiential, ethnic, or cultural
backgrounds.
In my case, this then new system—but still valid today—generated
some ideas:
– Understanding its hierarchical structure, such technology is
often found now in nearly all IT music-related equipment and
applications. But discovering it as a young composer, I learned
to compose scores not only using the UPIC’s surface (or drawing
table) but to comprehend the more complex thinking behind
creating scores or notes.
– How to obtain “originality” in my work (composition) using a system
that has specific limitations and/or strong characteristics inherent
in the original system? I found some solutions by pursuing the
extreme limits or margins of the system, and also by engaging
with some ideas from my cultural background: in the first example
cited below, I used only very simple lines and integrated ideas
and thoughts from Japanese traditional works, Haiku poems, Noh
theater, etc.
These results gave me unique possibilities to compose new work,
not only for my compositions using computer technology but also for my
instrumental music.
FIRST ENCOUNTER WITH THE UPIC

TAKEHITO SHIMAZU

My first encounter with the UPIC dates back to when I attended an
UPIC workshop in July 1990, held at Les Ateliers UPIC studio, then in
Massy, just south of Paris. However, before that, the UPIC was already
well known in Japan. The most significant opportunity for the UPIC and
Japanese composers at an earlier time was surely the concerts and
presentations in Yokohama and Tokyo (at Tokyo’s Eurospace of and at
the Kunitachi Music College) in 1984.[1] Unfortunately, I couldn’t take
part in those events, but often heard reflections about them from some
participating composers, such as Yori-Aki Matsudaira.

384

During the one-week workshop in 1990, I produced my first piece
for the UPIC, titled Monodie IV. The short period of the workshop was, of
course, not long enough to explore all the creative interests it provoked,
but I could not resist my strong interest as a composer to make a properly
formed composition. Under such conditions, Alain Després, then director of
Les Ateliers UPIC, kindly reserved two hours every day for me for four days
on one of the UPIC setups (out of two available, as I recall), even though
there were more than ten participants. This private time on the machine,
in addition to the tutorials offered, enabled me to complete this work.

THE UPIC
FOR A
JAPANESE
COMPOSER

MONODIE

My first question when confronting the machine was how I could express
my individuality, because the UPIC system seemed to be the result of an
idea by the great composer, Iannis Xenakis, who had built this system first
and foremost for himself. And I was afraid that drawing lines or figures on
the graphic table could and would produce music that would be very (too)
similar to that of the creator of the system. Or, ultimately, one might make
just a very ordinary and uncharacteristic piece, like a woodcut. Then, I
recalled an experiment that Yori-Aki Matsudaira (1931–), one of Japan’s
leading composers to this day, had told me about when he attended one
of the UPIC workshops in Japan in 1984. He had drawn some lines at the
very corners or extreme edges of the graphic table, intending to see how
they would sound. What he told me gave me some hints about how to go
about my first attempts and I began to draw just one line. Around that
time, I had composed a few pieces with the same title, Monodie, meaning
“musical form like a single melody.” Adopting a similar musical model, I
tried some possibilities in this direction. And this time, I used the same
title but added only a new number “IV.”
As my main material, I chose a single sound sample, namely, a
singing voice produced by a singer, which I had recorded for another piece
just before. But this time I used only one cycle (Hz.) of the sound. Using the
FFT (Fast Fourier Transform) function, or Fourier synthesis, included in the
UPIC system, I obtained some new sounds, very similar to the voice of the
singer. Likely inspired by Yori-Aki Matsudaira’s idea, I began to draw on the
very low range of the sound. FIG. 1
As one can see, in the score there is almost only one line or rather
only one flux. For this piece I adopted other ideas based on traditional
Japanese music, such as You-Kyoku (music for Noh theater), and Gidayu
(music for Bunraku, traditional Japanese puppet theater).
This was one of the ways I considered that I could put original
characteristics in my composition for the UPIC. Using traditional
Japanese ideas has been a very important process in my composition

FIG. 1 Alain Després and the author, at Les Ateliers UPIC, Massy, France, 1990 ©
Takehito Shimazu
FIG. 2 Takehito Shimazu, Score of Monodie IV, 1990 © Takehito Shimazu

387

TAKEHITO SHIMAZU

from very early on; that is, I had been composing for traditional Japanese
instruments or for traditional Japanese dance. I was composing these
kinds of compositions not only because of real demands or commissions,
but because such types of music (and sounds) were part of my daily
surroundings, having grown up in a Buddhist temple. After that and to this
day, I have pursued compositional ways of combining traditional material
using scientific methods, including even electronic or computer music.
Specifically, in this piece, a melody derived from a You-Kyoku, called
Shakkyo (Stone bridge) is gradually formed and finally, the melody is
transformed into the style of Gidayu, with very drastic pitch changes,
intentionally using distortional noise and developing it into heterophonic
sounds. Thus, with such a precise concept, I was able to finish this piece
in a few days. However, I had reservations about sounds coming only from
speakers, and I had previously combined some of my compositions for tape
with live instrument(s). So, I made a new piece for a percussionist and tape
(UPIC-generated), titled Monodie IVa. FIG. 3
ILLUSION

MONODIE IV Takehito Shimazu, 1992, 12'52'', for UPIC tape, excerpt from 6'45'' to 7'15''
© Takehito Shimazu

As a result of this first piece for the UPIC, a couple of years later, in 1993,
I was asked by Les Ateliers UPIC to compose a new work for the UPIC. By
that time, I recall, the studio had moved from Massy to Alfortville, also right
outside Paris. I went to France to work on this, expecting that the most
characteristic changes to the UPIC as I had known it would be the new
version’s possibilities as a real-time system. So, I attempted to compose
a new piece for live performance with the UPIC, and indeed, I did play
the piece on the UPIC, live, at the workshop after completing the piece.
However, after giving it some more thought, I added a sangen, or shamisen,
a three-stringed Japanese instrument, to compensate the lack of visual
effect and reality. At that precise moment, Kazuko Takada (1951–2007),
the excellent Japanese sangen player, was also attending this new project
initiated by Les Ateliers UPIC. Three Japanese composers—Joji Yuasa
(*1929), Yuji Takahashi (*1938), and I—had all been invited to compose
new pieces for the new version of the UPIC and, as well and if possible, to
conceive of new possibilities between traditional Japanese instruments
and the UPIC. Thus, I was able finish a new piece called Illusion with the
rare combination of a sangen player and UPIC.
In Illusion I conjure the image of a traveler, specifically, Matsuo Basho,
the most famous poet and greatest master of Haiku, who had made a
journey around the Tohoku region, in northeastern Japan. Fukushima,
where I lived at that time and indeed still live, is located at the entrance to
the region. The following is the program note of the piece I prepared for its
world première:

FIG. 3 Takehito Shimazu, Monodie IVa, 1990, score for percussionist and UPIC
© Takehito Shimazu
FIG. 4 Monodie IVa setup © Takehito Shimazu

MONODOIE IV A Takehito Shimazu, 1992, 17', for tape (UPIC) and percussion, recorded
at the Festival of Asian Composers League, Sendai, Japan, June 7, 1992 at the Sendai
International Center with Shin-ichi Ueno, percussion (SPX1000 is a reverberator by
Yamaha), replayed with percussionist Michael Pugliese at the Portrait de Iannis Xenakis
concert, Radio France, Paris, France, November 30, 1992, excerpt from 10'28'' to
10'58'' © Takehito Shimazu

390

Here is a very famous Haiku, the shortest style of the Japanese
traditional poem created during the Edo period, which was made by Basho,
a Haiku master and reputedly his last piece:[2]

THE UPIC
FOR A
JAPANESE
COMPOSER

(in Japanese)
Tabi ni Yande
Yume wa Are-no wo
Kake Meguru
I have found an English translation of this Haiku:
On a journey, ailing—
My dreams roam about
Over a withered moor
During my compositional process, the imagery of this Haiku provided
me with some suggestions for this new piece. Namely, I employed the
numerical combinations 5 and 7, which are the rhythms of the Haiku
(in Japanese), as well as the prime numbers I often use in other works,
namely, 2 and 3, as the components of 5. The activity of composing is, in
my opinion, very similar to a journey. In fact, I composed my Illusion at Les
Ateliers UPIC near Paris, very far from my home.
Using the new version of the UPIC system, I made the tape part
of this piece. Although I incorporated some imaginary sampled sounds
of nature, such as rain, wind, river flow, and others in the Haiku that I
imagined, the most important sound was from the sampled sounds of the
shamisen.
The instrumental part for the shamisen or sangen (meaning three
strings) also consisted of combinations of the prime numbers for the
durations, pitches, and other details.
It is possible to play this piece with a sangen player and either with
a UPIC system in real time or on tape. I also created another version with
tape only (or UPIC). To enhance the live sound, a digital reverberator (such
as the Yamaha SPX1000) controlled by a computer (programmed by the
composer) is useful.
As a composer, I strive ideally to work with humans and machines or
humanity and science; in other words, the combination of a “warm system”
and a “cold system.” To achieve this, I use many kinds of interesting
numerical combinations, and this belongs, in my opinion, to a cold system,
like the use of computer. On the other hand, I give the instrumentalist
many opportunities to select ways of playing freely, sometimes with
minimal limitations but at other times with strict ones. This, I consider, is

FIG. 5 Takehito Shimazu, Score of llusion in Desolated Fields, 1994, p.1 © Takehito Shimazu
FIG. 6 CCMIX CD cover, 1998 © CIX Archives

392

a kind of warm system. For effective interaction, I adopted psychological
operations within the time span of this piece. FIG. 5
I interpreted the word “dreams” in the poem as a kind of “illusion;”
hence, the title of this piece.[3]
CONTINUUM (CONTINUATION)

I feel very fortunate and honored that this piece was included in the CD set,
CCMIX Paris: Xenakis, UPIC, Continuum (mode 98/99, 2001). FIG. 6
During the same period as this project, I participated as one of the
core members in the preparatory committee for the International Computer
Music Conference (ICMC), which was to be held in Tokyo 1993 and, finally,
I was made Director of the music committee. I organized the international
jury, programmed more than twenty concerts, and so on. This ICMC was
the first international event for computer music ever held in Asia.
Some of the staff of Les Ateliers UPIC also participated in this event
and I was very pleased to prepare a special space and concerts for the
UPIC during the conference. Later, I continued to be interested in the UPIC,
not only in Japan but in France as well. And I have often been invited to
the studio. In the meantime, Gerard Pape had become director, and he
also helped me and made great efforts for me to produce new work. And
Sharon Kanach gave me the opportunity to pursue my research and work
more in the studio, which had then relocated to Romainville, also just
outside of Paris, as a composer-in-residence for one month, even though
the studio was about to temporarily relocate to La Tourette Convent near
Lyon. That was in February 2008. I was very lucky because each time
Les Ateliers UPIC broke new ground, I also found new dimensions of
composition.
During almost the same period, I also studied and researched various
techniques in computer music at IRCAM and at INA-GRM in Paris. And I
believe I made good use of these experiences in many compositions and in
other activities as a composer. But I certainly obtained the most (and most
musically satisfying) results from the UPIC.

FOOTNOTES
1.
See Després, this volume.
2.

MATSUO BASHO, by Makoto Ueda, Kodansha International Ltd., Tokyo, 1982.

3.

See also program booklet Illusion, world premiere at Studio 104—Salle Livier
Messiaen, Radio France, December 2, 1994.

THE UPIC
FOR A
JAPANESE
COMPOSER

BEYOND THE

CONTINUUM:
THE UNDISCOVERED

TERRAINS
BRIGITTE CONDORCET
(ROBINDORÉ)

OF THE UPIC

399

BRIGITTE CONDORCET (ROBINDORÉ)

BEYOND THE
CONTINUUM:
THE UNDISCOVERED
TERRAINS OF THE UPIC
THE UNIVERSALITY OF THE LINE

Iannis Xenakis stated, “It is the multiplicity of experiences that constitutes
the truth of a work of art,”[1] and these words apply so well to his own
graphical synthesis system, the UPIC—a work of art in its own right. The
UPIC produced a multiplicity of musics, all from the personal experience of
quite a range of composers—from Xenakis himself to Jean-Claude Risset,
Julio Estrada, Curtis Roads, Daniel Teruggi, Gerard Pape, Takehito Shimazu,
Nicola Cisternino, and the author[2] to name just a few.[3] The immediate
truth that the UPIC revealed was the universality of a human’s relationship
to drawing, of the soul to the hand; an unobstructed path from inner
impulsion to lines and curves containing the energy of creation. As Anne
Hindry[4] has expressed:
In the beginning was the line. The curved and continuous one, which
traced, for the first man, the threshold of his universe and the one,
closer and more drawn, which delimited, on the ground, the contours
of his shadow [...] thus distinguishing the formless in an attempt to
order chaos, to bring the world into perspective [...] It was indeed
the first line, this hint of a dash that emerged from the vital impulse
consisting in drawing out of oneself the recording of one’s passage,
the sign of one’s existence. Since then [...] and until the modern,
then post-modern era, the mirror-line, the autographic stroke, has
continued, in all its states [...] Bearer of the artist’s most intimate
imprints [...].
THE ARCHITECTURAL ROOTS OF THE UPIC

BRIGITTE CONDORCET
(ROBINDORÉ)

Iannis Xenakis’s creative experience as an architect and the application
of graphics to instrumental compositional processes in some of his early
major orchestral works were clearly precursors of the actual conception of
the UPIC system.[5] In fact, through architecture, and also by introducing
mathematical theories of probability to the use of pitch, and later to
electronic sound generation (as in the GENDYN program developed at the
CEMAMu),[6] Xenakis found an individual, pioneering path of liberation

400

from the prevailing musical dogma of serialism in the 1950s. This path
lifted him into a vaster arena of musical architecture. Xenakis considered
serialism’s formal structure to be weak, due to its emphasis on the note/
phrase level of composition.[7] His vision or “auralization,” (as it were) of
musical form encompassed sonic structures and currents similar to those
found in the natural world, which are unconsciously familiar to the human
psyche.[8] Although his methods of architecture and what he later termed
“stochastic music”[9] were complex, if not abstruse, paradoxically, this
approach brought an unprecedented acoustic and physical experience to
music. One could say his is a music of archetypes.
The well-known example of Xenakis’s composition Metastasis
(1954–55) is the first in which his use of architectural-like graphics,
later translated into instrumental trajectories, can be observed. Xenakis
comments: “In the Philips Pavilion I realized the basic ideas of Metastasis:
[...] I was interested in the question of whether it is possible to get from
one point to another without breaking the continuity. In Metastasis, this
problem led to glissandos, while in the Pavilion it resulted in hyperbolic
parabola shapes.”[10]
The first image FIG. 1 shows a preliminary sketch of Metastasis,
delineating continuous pitch transformation paths (glissandi) for individual
string parts. (The second image FIG. 2 displays the corresponding section
of the final instrumental score, as a reference.) Figure 1 is shown here
because it prefigures the first graphical score which Xenakis produced
on the original UPIC system for his work Mycènes Alpha (1978). A further
illustration of the continuum field in UPIC graphics is shown in the
third image FIG. 3, an extract (“page”) of an early UPIC work, eua’on, by
composer Julio Estrada. It is an ideal example of the energy of the creative
impulse passing through a drawing, representing continuous frequency
curves on the macro-compositional level.[11]
Metastasis was thus a significant part of the inception of an idea
which would take more than twenty years to develop into an interactive,
computerized compositional system. The first UPIC was operational in
1977.[12] In tracing back its roots to the nature-generating structures
of stochastics and the translation of architectural drawings into music,
one can understand why the system has been associated with a certain
universality.[13] It presented a user-friendly interface, well-adapted to
pedagogy, yet at the same time it could challenge the professional
composer with complex considerations, from macroform to the micro-level
of sound generation. The UPIC automatically set up a continuum between
the almost sculptural plasticity of sonic events, due to their strong visual
component, and the definition of music as organized sound in time.[14]

BEYOND THE
CONTINUUM:
THE
UNDISCOVERED
TERRAINS
OF THE UPIC

FIG. 1 Iannis Xenakis, Metastasis, graphic sketch delineating string glissandi

© Iannis Xenakis Family

FIG. 2 Iannis Xenakis, Metastasis B, 1953–1954, first page, final score

© Boosey & Hawkes

403

BRIGITTE CONDORCET (ROBINDORÉ)

THE UPIC: A SONIC MODULE OF NEW
COMPOSITIONAL PARADIGMS

FIG. 3 Julio Estrada, eua’on, 1980, fragment of a UPIC score drawing © Julio Estrada

The UPIC has been the subject of numerous articles and theses since its
inception, and particularly since the real-time version of the 1990s.[15] Much
as a lunar module explores the terrain of the moon, the UPIC was a type of
sonic module for exploring a large range of electroacoustic compositional
paradigms and techniques, its starting point being the frequential continuum.
It provided a comprehensive graphical user interface for representing all
compositional levels in interaction—a unique framework for the coexistence
of macroform, mesostructures, and microsonics. The interface offered a
bridge between the classical compositional model of score drawing and the
abstract models of electroacoustic composition, such as the use of objets
sonores in musique concrète or programming code for sound generation.
The macroform in the UPIC was called a “page,” which could represent an
entire composition or a portion of one continued on subsequent pages.
Each page consisted of mesostructures or events of “arcs” (line/curve
segments) drawn in a frequency versus time axis, which served as a type
of central nervous system, with each arc linked to multiple microsonic
defining elements (including waveform, envelope, and amplitude). Each
page could contain up to 4000 arcs, played back at speeds between 1/10th
of a second to over an hour, with no change in pitch or sound quality, only
the rate of events in time. This time stretching feature, in both expansion
and contraction of a page (with the additional option of acceleration and
deceleration), opened a space for work in the continuum/discontinuum
temporal domain.
It is difficult in today’s environment of imaging computer programs for
architecture, music, film, and visual art to realize what a radical concept
the UPIC represented in the 1970s. The immediacy of a graphical interface
that translated drawing into sound was novel in computer music, whose
composers at the time were largely thwarted by programming. Access to
the continuous frequency space also stood in contrast to the era’s growing
popularity of note-based keyboard synthesizers, used mainly in pop, rock,
and disco music. The UPIC thus spearheaded a truly divergent path into new
paradigms of electroacoustic composition, in and beyond the continuum,
thereby securing a unique place in the history of computer music. Later, the
frequential continuum concept was vastly expanded in the development
of timbral, dynamic, and rhythmic continua in acoustic composition by
composer Julio Estrada, largely inspired by his work on the UPIC.[16]
Due to a timbral stereotype of the UPIC (a somewhat harsh,
unnuanced tone), few people realize that it provided a significant range of
synthesis methods and tools, making it a very sophisticated compositional
system. This would indicate that the stereotype resulted from its use rather
than from any inherent limitation. Perhaps, though, it could be argued

404

that one of the “drawbacks” of the system was the ease of drawing, which
tended to oversimplify the compositional process and lull composers
into the illusion of accomplishment without the rigor of sonic exploration
that a classic electroacoustic composition would demand. I say this
from personal observation and experience as former head of Musical
Production at the CCMIX. One of the further challenges to composers
was the limited length of residencies, primarily due to institutional
and personal financial considerations, as the UPIC at the time was not
available to the public outside of the studio.
Mention may also be made of the typical experience of composers
facing the UPIC process of drawing as part of electroacoustic composition.
The relationship between a few lines drawn on a page and the resultant
raw sound was almost always unexpected and even unsettling at first
use. Composers were confronted with a new paradigm, which often led
to frustration, or to accepting underachievement. This “wall” of newness
tested composers’ ingenuity to find their own voice and creative imprint
under demanding compositional and time constraints. To those who did,
these constraints could become the source of an original path of creation.
The ability to grapple with and overcome a challenge, thereby surpassing
oneself—and ideally bringing a new element of one’s identity into
manifestation—is a universal theme. This recalls the extraordinary thought
of Arthur Koestler: “Einstein’s space is no closer to reality than Van Gogh’s
sky. The glory of science is not in a truth more absolute than the truth of
Bach or Tolstoy, but in the act of creation itself.”[17]
UPIC’S FERTILE TERRAIN OF SYNTHESIS METHODS AND
FREQUENCY EXPLORATION

The implemented and inferred UPIC synthesis methods included:
Additive synthesis. At its origins, additive synthesis was developed by
the superposition of sine waves in harmonic relationship to one another,
in a theoretical attempt to recreate any sound from nature (the Fourier
theorem). The more complex the sound, the more sine waves of different
frequencies and amplitudes were required. Although perhaps successful
to physicists and acousticians, compositionally it had its limits. The UPIC
offered an expanded form, achieved by multiple simultaneous arcs whose
relationships were rarely harmonic, and to which one could assign nonsinusoidal waveforms. This led to very rich sound aggregates.
Subtractive synthesis was not a specifically implemented synthesis
technique in the UPIC, however, it could be simulated. Classically achieved
by applying a filter to alter or remove the partials of a sound (a portion of
its timbral elements), in the UPIC this could be achieved by either removing
superimposed arcs, by graphically redrawing one or more waveforms,

BEYOND THE
CONTINUUM:
THE
UNDISCOVERED
TERRAINS
OF THE UPIC

405

BRIGITTE CONDORCET (ROBINDORÉ)

or by using an envelope to modify its amplitude—all three techniques
contributing to simulating filtering.
Graphical synthesis in the UPIC was achieved by hand drawing
waveforms. This category was unique to the system—that is, the ability to
access the visual representation of a waveform and to either draw it from
scratch, or modify it by hand. Xenakis very often touted this feature of
creatio ex nihilo.[18]
Resynthesis or resampling in the UPIC consisted of extracting a
waveform from a monophonic sample, which then became a synthetic
waveform that could be assigned to an arc or arcs on a page. The 1990s
UPIC sported a more effective hardware controller and processor[19] with
improved sampling functions, allowing for the extraction of a larger sonic
portion of a recorded sound than only a single waveform. This offered
access to a previously inaccessible domain of synthesis that bordered
on musique concrète. This is one of the main features that enabled the
UPIC to depart from the harsh sonic stereotype mentioned above. It also
presents its own unique category of continuum: between a sampled sound
and its potential journey into synthetic derivatives.
Frequency modulation (FM) synthesis involves altering or modulating
the frequency of one waveform (the “carrier”) with another waveform (the
“modulator”), whose amplitude and frequential harmonic or inharmonic
relationship to the carrier will contribute more or less to the complexity of
the resultant sound. This implemented UPIC feature was greatly enhanced
when the frequency range of the 1990s UPIC was extended to infrasonics,
starting at 0.01 Hz. This expanded range, coupled with the possibility of
utilizing resynthesized (resampled) sounds as modulators and carriers
offered a truly unlimited space of sonic exploration.
Amplitude modulation (AM) synthesis is classically achieved when
a carrier wave’s amplitude is altered by a modulator (although there are
other features of AM not pertinent to this discussion). In the UPIC, it was
not an implemented function, such as FM, although it could be simulated
by envelopes applied to individual arcs.
Synthesis by aliasing. Caveat emptor: This is a radical and creative
category of synthesis, and certainly not based on any implemented
feature. In fact, contrariwise, aliasing is considered an undesirable
by-product of digital sound reproduction. For example, if a system
has a sample rate of 44,100 Hz (cycles per second), which is equal to
roughly twice the audible range of the human ear (around 20,000 Hz
depending on individual auditory capacity), then any complex waveform
whose partials exceed 22.05 kHz (1/2 the sample rate, also called
the Nyquist frequency) would, by the “wall” or limits delineated by the
system, see the higher partials folded back into the audible frequency

406

range, as by a mirror effect, in the same ratio in which they exceeded
the “wall.” Aliasing generally renders the signal blurred or distorted, and
most systems implement anti-aliasing filters to eliminate this by-product.
Because the UPIC could so easily produce the superposition of complex
waveforms, aliasing was a very common feature of the resultant sound,
although generally not understood and rarely, if ever, consciously used
for its unpredictable sound effect or in any way controlled or calculated.
One can see by this so-called “synthesis method,” that regardless of
its countercurrent use of audio system limitations, the UPIC has the
potential to usher the composer into truly uncharted compositional terrain,
one which Xenakis himself occasionally exploited, though not with any
scientific rigor.[20]
Granular synthesis was one of the most immediate and simple
methods of synthesis on the UPIC, though again as a vast extension
of the original conception (using sinusoidal waveforms with Gaussian
envelopes). The UPIC arcs could be drawn to be tiny “grains” or dots in
agglomerations of hundreds, if not thousands, on a page in all types of
formations, durations, and frequency ranges, as well as assigned very
complex waveforms. As grains coalesced and accumulated, they would
create larger articulated sonic events or masses, often very close to the
structures of Nature, a now characteristic feature of granular synthesis.[21]
Finally, mention should be made of a unique and underused feature
in the UPIC called the Frequency Table, which was implemented in its
real-time versions.[22] Frequency was determined by the position of the
arc(s) on the vertical axis of the page, a feature carried through from
the original version. However, with the Frequency Table, a composer
could choose to operate within up to four different simultaneous tables
or grids that could be superimposed on each page. These grids were
invisible to the eye, however, and accessed by assigning one of four
tables to whatever arc was being drawn, the same way as one would
assign the waveform or envelope to it. An arc could thus be “placed”
within different frequency spaces determined by the composer, with as
large a range as 0.01–22,050 Hz. (For those with classical training, it
was possible to display Hz values in Notes + Octave designations with
positive or negative cent values (a half-step or semitone being equal
to 100 cents). In note values, with middle C at 261.54 Hz, this range
covered from F - 14–23 cents to F + 9–25 cents.) One could argue that
arcs assigned a frequency below 20 Hz would be inaudible to the human
ear. However, highly complex (resampled) waveforms could contain more
information than a single, simple frequency cycle, thus rendering them
audible in the infrasonic range.
Interestingly, the Frequency Table further introduced a concept

BEYOND THE
CONTINUUM:
THE
UNDISCOVERED
TERRAINS
OF THE UPIC

FIG. 5 The author having tea with Iannis Xenakis at his apartment in Paris during their
interview for Computer Music Journal, 1995 © Curtis Roads

408

that was potentially as impactful as the continuum: the tempered
discontinuum. With a function called “discrete/non-discrete,” the user
could define how the frequency space was to be moved through. If nondiscrete, then a diagonal arc would sound like a glissando, the classical
use of the continuum with the UPIC. However, if “discrete” were chosen,
the user could create equal temperaments between 1–99 divisions
per octave. The same diagonal arc would then sound like discrete
steps in a defined temperament. For those who wished to utilize nontempered scales, the arcs would have to be drawn individually within a
non-discrete frequency table. These features were almost never used,
although they contained very intriguing possibilities of exploration into
tempered scales beyond 12-tones, for those who wished to compose
with determined pitches.
REAL-TIME PERFORMANCE AND POST-SYNTHESIS
PROCESSING

Due to the greatly improved, somewhat revolutionary, hard and software
developed by the CEMAMu team (Raczinski, Marino, Serra, and others),
the second and third versions of the UPIC were powerful enough to
perform many operations in real time. Although the UPIC was conceived
to be a studio compositional system, the first use of these real-time
capacities was by Xenakis himself when he chose to use the UPIC as
a live performance system for his work Taurhiphanie (1987), (for UPIC,
light effects and amplified bulls and horses) in the amphitheater at Arles,
France. According to hardware engineer Jean-Michel Raczinski, who
was part of the production team in Arles, the fact that Xenakis pushed
the limits of the system to achieve a performance-level status, was an
unforgettable and exhilarating experience, if not slightly harrowing at
the early stages of the system’s new capacities.[20] Perhaps the UPIC
was not commonly used as a live performance tool also because there
were so few units available (two or three at the CCMIX) and they were
designated for composer residencies and courses. The UPICs at the
CEMAMu were used primarily for research.
The UPIC feature of parametrical independence allowed graphical
curves defining one parameter to be applied to another. For example,
an envelope could share the same visual description as a waveform yet
retain its own time-varying amplitude function. In real-time use, these
parameters could be swapped or redrawn almost instantaneously,
extending the concept of synthesis to a type of sonic metamorphosis
in real time—a continuum in its own right. This said, most composers
used the UPIC to generate sound material which they would later submit
to transformation processes in a studio, such as echo, reverberation,

BEYOND THE
CONTINUUM:
THE
UNDISCOVERED
TERRAINS
OF THE UPIC

409

BRIGITTE CONDORCET (ROBINDORÉ)

convolution, filtering, spectral processing, spatialization, and multitracking.
EVER ON A SIDEREAL PATH

And I love listening to the stars at night.
It is like the sound of 500 million tiny bells.
~ Le Petit Prince, Saint-Exupéry[23]
In my opinion, the UPIC has not uttered its last word. Indeed,
some form of the UPIC concept has now been developed by a variety
of programmers into various stand-alone apps, including IanniX, HighC,
and UPISketch. However, the final version of the UPIC developed at the
CEMAMu still contains significant potential that could be explored by longer
residencies for composers and researchers alike, should the systems
be refurbished and again made available. I, for one, stand at my own
compositional threshold, pondering a reacquaintance with this benchmark
system in the history of electroacoustics. May the sonic sidereal wanderings
of many a composer be once again manifested through the UPIC, pursuing
a Xenakian journey into the continuum and beyond.

FOOTNOTES
1.

Iannis Xenakis, “Changer l’homme,” L’Arc 51 (1972), 31.

2.

Iannis Xenakis, et al. 2001. CCMIX Paris/Xenakis/UPIC/Continuum:
Electroacoustic and Instrumental Works by Xenakis, Risset, Estrada, Roads, Pape,
Robindoré, Cisternino, Teruggi, Shimazu (New York: Mode Records), (CD set mode
1998/99).

3.

A full list of composers who have used the UPIC can be found here:
http://www.centre-iannis-xenakis.org/upic_compositeurs?lang=en

4.

Anne Hindry, “Du trait à la ligne,” in Le magazine du Centre National d'Art et de
Culture Georges Pompidou 86 (1995), 12. Translated from the French by the
author.

5.

Brigitte Robindoré, “The Impact of Electro-acoustics on Acoustic Composition and
Thought: The Continuum and Noise,” MA thesis, Université de Paris VIII, 1997.

6.

Marie-Hélène Serra, “Stochastic Composition and Stochastic Timbre: GENDY3 by
Iannis Xenakis,” in Perspectives of New Music 31, (1993), 236–57.

7.

Iannis Xenakis, “La crise de la musique sérielle,” in Kéleütha, ed. Alain Galliari
(Paris: L'Arche, 1994), 39–43.

8.

Brigitte Robindoré, “Eskhaté Ereuna: Extending the Limits of Musical Thought.
Comments on and by Iannis Xenakis,” in Computer Music Journal 20 (1996),
11–16.

410

9.

Iannis Xenakis, Formalized Music, revised edition (Stuyvesant, NY: Pendragon
Press, 1992), Chapters I, II, III, and V.

10.

Iannis Xenakis, Music and Architecture: Architectural Projects, Texts, and
Realizations, ed. Sharon Kanach (Hillsdale, NY: Pendragon Press, 2008), 99.

11.

Julio Estrada. 1980. Eua’on for UPIC. Score print-out provided by the composer.

12.

See Médigue, this volume.

13.

Peter Nelson, “The UPIC System as an Instrument of Learning,” in Organized
Sound 2 (1997), 35–42.

14.

Edgard Varèse and Chou Wen-Chung, “The Liberation of Sound,” in Perspectives
of New Music 5 (1966), 11–19.

15.

See, for example, Henning Lohner, “The UPIC System: A User’s Report,” in,
Computer Music Journal 10 (1986), 42–49; Gérard Marino, Jean-Michel Raczinski,
and Marie-Hélène Serra, “The New UPIC System,” ed. S. Arnold and G. Hair, in
Proceedings of the 1990 International Computer Music Conference (1990),
249–252; Gérard Marino, Marie-Hélène Serra, and Jean-Michel Raczinski, “The
UPIC System: Origins and Innovations,” in Perspectives of New Music 31 (1993),
258–69; Brigitte Robindoré, The UPIC User’s Guide and Tutorial (Paris: Centre
d’Etudes de Mathématique et Automatique Musicales, 1993, 1995); Gerard Pape,
“Sculpter le son par le graphisme de l’UPIC,” unpublished manuscript (1997).

16.

See, for example, Julio Estrada,“Le continuum en musique: structure et ouvertures
en composition, ses dérivations esthétiques,” in Aesthetik und Komposition, ed.
Ulrich Mosch and Borio Gianmario, Darmstadter Beitrage zur Neue Musik (Mainz:
Schott), 1994; Julio Estrada, “Freiheit und Bewegung: Transkriptionsmethoden in
einem Kontinuum von Rhythmus und Klang,” in MusikTexte: Zeitschrift fur Neue
Musik 55 (1994), 57–62; Julio Estrada, “Problems posed by the Transcription of
a Chrono-graphical Representation into a Multiparametric Continuum of Rhythm
and Sound,” in Report of the Musicology Congress Musik als Text, Freiburg,
Albert-Ludwigs Universität (1994); Julio Estrada, “Théorie de la Composition:
discontinuum-continuum,” PhD dissertation, University of Strasbourg, 1994; Julio
Estrada, “eua’on’ome,” Donaueschingen: Donaueschinger Musiktage Program
Notes (1995); Brigitte Robindoré, “The Impact of Electro-acoustics on Acoustic
Composition and Thought: The Continuum and Noise,” MA thesis, Université de
Paris VIII, 1997.

17.

Arthur Koestler, The Act of Creation (London: Hutchinson, 1964).

18.

Brigitte Robindoré, “Conversations with Jean-Michel Raczinski,” unpublished
manuscript (Paris, 2019).

19.

See two related articles: Jean-Michel Raczinski and Gérard Marino, “A Realtime Synthesis Unit,” in Proceedings of the 1988 International Computer
Music Conference (1988); Jean-Michel Raczinski and Gérard Marino, Real-time
Unit Specifications (Paris: Centre d’Etudes de Mathématique et Automatique
Musicales, 1991).

20.

Brigitte Robindoré, “Conversations with Jean-Michel Raczinski,” unpublished
manuscript (Paris, 2019).

21.

Curtis Roads, Microsound (Cambridge, MA: MIT Press, 2002).

22.

Brigitte Robindoré, The UPIC User’s Guide and Tutorial (Paris: Centre d’Etudes de
Mathématique et Automatique Musicales, 1993, 1995).

23.

Antoine de Saint-Exupéry, Le Petit Prince, (Paris: Gallimard, 1945), 95; translated
from the French by the author.

BEYOND THE
CONTINUUM:
THE
UNDISCOVERED
TERRAINS
OF THE UPIC

XENAKIS
AND
THE UPIC

RONALD SQUIBBS
PIERRE COUPRIE
HENNING LOHNER

MYCÈNES ALPHA:

A LISTENER’S
RONALD SQUIBBS

GUIDE

419

RONALD SQUIBBS

MYCÈNES ALPHA:
A LISTENER’S GUIDE
INTRODUCTION

Mycènes Alpha is unique in that it is the only electroacoustic work for
which the Greek composer Iannis Xenakis provided a graphic score that
is integral to the conception and presentation of the work. It is strongly
suggested that the reader listen to the work several times, preferably
in conjunction with viewing the graphic score, in order to form some
preliminary impressions and questions of his or her own prior to reading
the interpretation that is offered in this essay.[1]
HISTORICAL AND TECHNICAL BACKGROUND

RONALD SQUIBBS

Mycènes Alpha was composed in 1978 at Xenakis’s studio for
electroacoustic research and composition, the CEMAMu (Centre d’Etudes de
Mathématiques et Automatiques Musicales), for a multimedia performance
piece, the Polytope de Mycènes, which was presented that same year at
Mycenae, Greece. As part of the Polytope de Mycènes, Mycènes Alpha
was presented in the form of seven sound interpolations.[2] The work
was subsequently released as a continuous musical structure suitable
for concert performance or private listening. It is this version that is the
subject of the present analysis.
Mycènes Alpha was composed on the first version of the UPIC (Unité
Polyagogique Informatique de CEMAMu), which is an electroacoustic
instrument that allows the user to design virtually all levels of a musical
structure by hand. Its graphic interface receives input for timbre
(waveforms and envelopes), for the pitch and duration of individual sounds
(arcs), and for the configuration of arcs into sections of music (pages). The
graphic score of Mycènes Alpha shows the arcs and pages only. As in a
short score, where details of instrumentation and dynamics have been
omitted, the graphic score provides only information regarding the pitch
and relative duration of the sounds. With respect to the work’s timbres,
James Harley has written: “The timbres tend to be noisy, but also static.
Variation is achieved through the layering of the notes and the dynamic
envelopes.”[3] Dynamic flow is also achieved by means of the shapes
formed by the clusters of arcs and by the curvature of some of the arcs,
which create glissando-like effects. Despite the compositional possibilities
that it opened up, the UPIC challenged Xenakis to work creatively within
some relatively severe technical constraints, at least initially.[4] His
success in doing so accounts for the work’s peculiar charm.

420

THE STRUCTURE OF MYCÈNES ALPHA:
GENERAL CHARACTERISTICS OF THE SECTIONS
TABLE 1 shows a list of the sections in Mycènes Alpha, each of which is

numbered in the first column. Each section number is followed in the
second column by that section’s start time.[5] The durations shown in
the third column of the table correspond to the differences between
the start times that are shown in the second column. The labels in the
fourth column refer to the morphological characteristics of the sections.
Repetitions of the labels along with the use of the prime symbol (‘)
indicate varied repetitions of morphological types, each of which will be
described in more detail below. This analytical interpretation makes use
of six morphological types. Five of these types reappear in varied form
once each, and one of them—type D—appears in two varied repetitions.
The fifth column shows that there is some variation in the use of pitch
register among the sections, with eight of them making use of nearly all of
the available registral space.[6] The sixth column indicates the orientation
of the majority of the arcs within each section. The use of curved arcs is
restricted to four out of the thirteen sections, one of which (Section 11)
contains a mixture of horizontal and curved arcs. Even in those sections
where only horizontal arcs are used, the perception of individual pitches
is relatively rare because the arcs are typically clustered densely together
within the registral space.
PART I: MORPHOLOGICAL CHARACTERISTICS

Mycènes Alpha divides into two parts, the first containing Sections 1–6
and the second containing Sections 7–13. The observations given in
this section will focus only on the characteristics of Sections 1–6, which
constitute a single, relatively closed structural unit.
Section 1 (labeled Morphological Type A in Table 1) consists of four
bands of clustered horizontal arcs, distributed over the whole of the pitch
register. There are discernable areas of open space between the bands.
Even though individual arcs within the bands are mostly horizontal, the
bands change shape as the section progresses, thus creating a sense of
motion rather than the impression of a single, sustained chord.
Section 4 (labeled Morphological Type A’ in Table 1) presents a
variant of the contour of Section 1. This section, which begins at 1’53”,
consists of three bands of horizontal arcs distributed over nearly the whole
of the pitch register.

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

RONALD SQUIBBS

421

SECTION

START
TIME

DURATION
(SECONDS)

MORPHOLOGICAL
TYPE

REGISTER(S)

ARC DIRECTION

1

00"

17

A

all

horizontal

2

17"

38

B

med. high

curved

3

55"

58

C

low

horizontal

4

1'53"

5

A'

all

horizontal

5

1'58"

55

B'

all

curved

6

2'53"

60

C'

low, then all

horizontal

7

3'53"

24

D

low, med.

horizontal

8

4'17"

59

E

all

curved

9

5'16"

60

E'

all

horizontal

10

6'16"

60

D'

all

horizontal

11

7'16"

59

F

all

mixed

12

8'15"

20

F'

all

horizontal

8'35"

61

D"

low, med.

horizontal

9'36"

Total Time

13

TABLE 1 General Characteristics of Sections in Mycènes Alpha

Section 2 (beginning at 17”, labeled Morphological Type B in Table
1) begins with a narrow band of curved arcs in the middle upper register,
in the vicinity of A4. The band gradually expands to occupy more of
the registral space, resulting in a bush-like structure that is a type of
arborescence (branching structure), a general morphological category that
appeared in several of Xenakis’s works from the 1970s onward.[7]
Section 5 (beginning at 1’58”, labeled Morphological Type B’ in Table 1)
presents a variation on the contour of Section 2. It begins with a single
arc at approximately A3 (one octave lower than in Section 2) from which a
second arc soon branches off. Additional branchings result in a complex
configuration that extends over most of the pitch register before returning
to the area around A3 near its end. The two sections are linked not only by
their general morphology, but also because each begins audibly around
pitch class A, albeit an octave apart.
Section 3 (beginning at 55”, labeled Morphological Type C in Table 1)
is confined entirely to the lowest register, with its arcs all occurring
approximately within the range from C1 to D#1. At some places within
this section, pitches one octave lower and one octave higher than those
indicated on the graphic score become clearly audible. (This is likely due
to the waveform used to generate the sounds.) The amplitude decreases
markedly near the conclusion of the section, approaching silence at the

422

very end. This attenuation of the amplitude suggests a relative degree of
formal closure at this point. The effect of closure is musically appropriate
here, since the following section (section 4) initiates a sequence of varied
repetitions of Sections 1–3 that occupies the remainder of Part I.
The resemblance between Section 6 (beginning at 2’53”, labeled
Morphological Type C’ in Table 1) and Section 3 is exact until about 10
seconds before the end, when a cluster of sustained sounds begins to
accumulate, moving from the lowest register (C1) up to about C4. This
cluster recalls the texture of Section 1, and thus provides, by means of
structural rounding, a fitting conclusion to Part I.[8]
In summary, the morphology of the sections in Part I forms the simple
and well-defined pattern: A B C A’ B’ C’.

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

423

RONALD SQUIBBS

which corresponds to the (approximately) 1:1 ratio between duration of
section 3 and the sum of the durations of Sections 1 and 2.

FIG. 2 Relations among durations in Sections 4–6 of Mycènes Alpha

PART I: TEMPORAL STRUCTURE

The temporal structure of Mycènes Alpha is based on a primary unit of one
minute, which was the limit of duration for a page of music composed with
the original version of the UPIC. Among the first three sections, Section 3
is the only one to approach this limit, having a duration of 58 seconds. The
preceding two sections increase progressively in length, with the sum of
the durations of Sections 1 (17 seconds) and 2 (38 seconds) nearly equal
to the duration of Section 3. The relations among the durations of these
sections approximate simple ratios involving the integers 1, 2, and 3, as
shown in FIG. 1.

FIG. 3 illustrates the relations among groups of sections in Part I. At
this level of structure, the differences between the relations within the
groups (as shown in FIGS. 1,2) are subsumed into a relative degree of
equilibrium. This is because the combined duration of Sections 4–6 is
approximately equal to the combined duration of Sections 1–3, each
group making up approximately half of the entire duration of Part I.
The 2:1 ratio between the duration of Part I and that of Sections 1–3
and 4–6, respectively, is a reflection on a higher structural level of the
approximately 2:1 ratio between Sections 2 and 1 at the beginning of
Part I (see Figure 1).

FIG. 1 Relations among durations in Sections 1–3 of Mycènes Alpha

FIG. 3 Relations among groups of Sections in Part I of Mycènes Alpha

The relations among the durations of Sections 4–6 are more
straightforward. Section 4 has a duration of 5 seconds (1:12 of 60) and
Section 5 follows with the complementary duration of 55 seconds (11:12
of 60). Section 6, in turn, follows with a duration of 60 seconds, which is
exactly equivalent to the sum of the durations of Sections 4 and 5. FIG. 2
illustrates these relations. The only ratio that is the same in Figure 2 as it is
in Figure 1 is the 1:1 between Section 6 and the sum of Sections 4 and 5,

At this level of structure, the differences between the relations within
the groups (as shown in Figure 1 and 2) are subsumed into a relative
degree of equilibrium.
PART II: MORPHOLOGICAL CHARACTERISTICS

The six sections in Part I divide evenly into two groups of three sections
each. Part II is slightly more complex, but the varied repetitions of

424

morphological types produce a succession of sections whose musical logic
is almost as straightforward as that in Part I.
Section 7 (beginning at 3’53”, labeled Morphological Type D in
Table 1) consists of a succession of clusters of horizontal arcs that are
confined to the lower register. This section—which is repeated in temporal
augmentation in Section 13 (beginning at 8’35”, labeled Morphological
Type D” in Table 1)—is the only morphological type that includes periods
of silence. These silences, in fact, divide the section into twelve short
segments that are followed by a longer, concluding thirteenth segment.
The number of segments in Section 7 (and also in Section 13) may or may
not be intended to be a reflection of the number of sections within the
work as a whole, but the numerical correspondence is striking nonetheless.
The density of the clusters makes the frequencies of the individual arcs
all but impossible to distinguish except in the thirteenth segment, which
features sustained individual arcs in its middle and at its end. The
pitches of these arcs are approximately A1 and E2, two pitches whose
fundamental frequencies are in the ratio 3:2. As will be demonstrated later,
this ratio plays an important role on several levels of the work’s temporal
structure.
The morphology of Section 8 (beginning at 4’17”, labeled Morphological
Type E in Table 1) suggests the form of a fantastic, mythological creature.
From a sonic perspective, it is significant that this section is composed
almost entirely of curved arcs, giving it an unusual degree of fluidity. Over
the course of its unfolding it occupies all of the available registral space.
Toward the end of the section a narrow band of arcs descends to a point in
pitch space in the vicinity of D4 before branching off in opposite directions,
ultimately opening into a fourteen-note cluster that spreads out over a space
of about two-and-a-half to three octaves.
Section 9 (beginning at 5’16”, labeled Morphological Type E’ in
Table 1), though not as fantastic in appearance as Section 8, has some
morphological features in common with it. It has clusters and open spaces
in about the same areas as Section 8 but it consists entirely of horizontal
arcs until the very end, when an ascending glissando is superimposed over
the still-active horizontal arcs in order to connect the end of Section 9 to
the beginning of Section 10.
Section 10 (beginning at 6’16”, labeled Morphological Type D’ in
Table 1) consists of clusters of horizontal arcs like Section 7, but each of
the clusters is connected to the preceding and following one by means of
narrow bands of arcs. In retrospect, the final segment of Section 7 may
be regarded as a compound segment whose two clusters are connected
together with a narrow band of arcs, in effect providing a precedent for the
connected clusters of Section 10. While all of the clusters in Section 7 are

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

425

RONALD SQUIBBS

built up from pitches in the lowest register, the majority of those in Section
10 are placed within the upper register, with only a few of them reaching
lower into the registral space. In a general sense, the morphology of
Section 10 appears to be a free inversion of the morphology of Section 7.
Section 11 (beginning at 7’16”, labeled Morphological Type F in Table 1)
contains another fantastic-appearing image. This section is remarkable
in that it contains a relatively balanced mixture of horizontal and curved
arcs. A briefer variant of the general morphology of Section 11 appears in
Section 12 (beginning at 8’15”, labeled Morphological Type F’ in Table 1),
which consists entirely of horizontal arcs. While Section 11 extends over
the entire register, Section 12 is more compact and ends on a single pitch,
at approximately C#3.
As mentioned previously, Section 13 (beginning at 8’35”) is a
temporally augmented repetition of Section 7. It thus provides a degree
of closure by referring back to material from the beginning of Part II. The
closure it provides is even more marked than that provided by the return
of clustered arcs at the end of Section 6 in Part I, in two respects: (1)
it repeats an entire section, not merely a texture associated with that
section; and (2) its longer duration provides a structural “ritardando” that
helps to dissipate the energy of the music in preparation for the work’s
approaching conclusion.
To summarize, Part II consists of two sequences of three sections,
each of which is initiated by a version of morphological type D, followed by
the introduction of a new morphological type and a variant of it. The second
sequence is rounded out by a final variant of D material. The sequence of
morphological types in Part II may thus be symbolized as D E E’ D’ F F’ D”.
PART II: TEMPORAL STRUCTURE

The temporal structure of Part II is simpler than that of Part I, but it has
some complexities of its own. Its first subdivision, consisting of Sections
7–9, contains two approximately one-minute sections (8 and 9) and one
section (7) that is 2:5 of a minute in duration. Its second subdivision,
consisting of Sections 10–13, contains three approximately one-minute
sections (10, 11, and 13) and one section (12) whose duration is 1:3
of a minute. Analysis of the relations among the sections within these
subdivisions is straightforward, but the use of different subunits of one
minute in each section complicates the analysis of relations between the
subdivisions as well as between the subdivisions and Part II as a whole.
FIG. 4 shows the relations among the sections in the first subdivision
of Part II. The duration of Section 7 is 24 seconds, which is 2:5 of one
minute. The relation of the duration of Section 8 (59 seconds) to Section
7 is approximately 5:2, as shown in the figure. The relation of the duration

426

of Section 9 (60 seconds) to the combined duration of the previous two
sections (83 seconds) is approximately 5:7. The decimal approximation of
5:7 is .72, which is slightly larger than the decimal approximation of the
simpler ratio 2:3 (.67). Because of the relatively close approximation of
2:3 to 5:7, the simpler of the two ratios has been substituted for the more
complex one in Figure 4.

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

427

RONALD SQUIBBS

FIG. 5 Relations among durations in Sections 10–3 of Mycènes Alpha

The relations between Part II and its subdivisions may also be
expressed in ratios that have been seen previously. The ratio of 5:2 in
FIG. 6, between Part II as a whole and Sections 7–9, is the same as that
between Sections 8 and 7 in Figure 5. The ratio of 3:2, between Sections
10–13 and 7–9 in Figure 6, is the inverse of the 2:3 that appears in both
Figures 4 and 5 and recalls the 3:2 between Sections 3 and 2 in Figure 1.
FIG. 4 Relations among durations in Sections 7–9 of Mycènes Alpha

Sections 10–13 present a different challenge to the representation of
the relations among its sections. In order to diagram the relations among
the sections in a way that may be compared easily with the previous
diagrams, it is necessary to pair two of the sections together in order
to present the sections as three entities rather than four. Since the
sequence of morphological types in Sections 7–9 is D E E’, it makes the
most sense to preserve the idea of separating the first D-type section
(10) from the first section of a different type (11, type F) and to separate
this section, in turn, from its varied repetition (Section 12). Section 12,
at 20 seconds, is the briefest of the sections in this subdivision. Since
Sections 11 and 13 are of approximately equal duration, Section 12
could be paired with either of them while still preserving a relative sense
of durational balance among the three entities in the diagram. Pairing it
with Section 13, however, has the advantage of more firmly integrating
the final, rounding section into the main body of the second subdivision
of Part II. For these reasons, the diagram in FIG. 5 shows the relations
among Sections 10, 11, and 12–13.
A comparison of Figures 4 and 5 reveals some similarities in the
internal organization of the subdivisions of Part II. The relation between
Section 9 and the combination of Sections 7 and 8, expressed as the
ratio 2:3 in Figure 4, recurs as the relation between Sections 12–13
and the combination of Sections 10 and 11 in Figure 5. The 1:1 ratio,
expressing the relation between Sections 9 and 8 in Figure 4, recurs
between Sections 11 and 10 in Figure 5.

FIG. 6 Relations among groups of Sections in Part II of Mycènes Alpha

TEMPORAL STRUCTURE: GLOBAL PERSPECTIVES

Until now the discussion of temporal structure has been limited to
relations within the two parts of Mycènes Alpha. In this final section on
temporal structure, some aspects of the work’s overall temporal structure
will be explored. Each new perspective that is introduced will be referred
to one or more of the networks of temporal structures that has been
introduced previously. The resulting correspondences between levels of
the temporal structure of Mycènes Alpha suggest possible strategies for
listening in which different aspects of the work may be kept in mind on
successive hearings, thus allowing the listener to experience multiple
dimensions of the work’s overall structural design.
FIG. 7 shows the relations between the whole of Mycènes Alpha and
each of its parts, and between the parts themselves. Remarkably, these
relations are identical to those within Part II itself, as shown in Figure 6.
The identity of the structures at these two levels reveals a depth to the

428

work’s temporal structure that may or may not have been intentional
on the composer’s part. As Xenakis said in an interview with Bálint
András Varga: “Musicologists may analyze scores and come up with their
conclusions—and they may be perfectly right—but their findings need not
indicate anything conscious on my part.”[9] In this case, it is reasonable to
conjecture that the correspondence between these levels of the temporal
structure may have resulted from the use of systems of proportions such
as those proposed here. Alternatively, it may have grown intuitively out of
a feeling for proportional balance between whole and parts that would
have developed from decades of experience in generating musical and
architectural structures.

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

429

RONALD SQUIBBS

FIG. 8 Grouping of Sections according to use of registral space

FIG. 9 Grouping of Sections according to arc orientation
FIG. 7 Relations of Whole and Parts in Mycènes Alpha

There is also a sense of formal balance that is articulated by the
distribution of registers and arc orientations among the sections of
Mycènes Alpha. Eight out of the thirteen sections make use of relatively
unrestricted registral space, while five sections are more restricted in their
use of register (see TABLE 1). The division of the 13 sections into 5 + 8
according to use of register is a division according to integers from the
Fibonacci series. When the durations of the sections in this division are
taken into account, the total duration of each group of sections results
in a by-now-familiar pattern of ratios. This is illustrated in FIG. 8. A similar
pattern occurs when arc orientations are used as a means for dividing the
sections into groups and the durations of these groups are compared to
the duration of the whole work. This is illustrated in FIG. 9.

Finally, there is a global division of the work according to the golden
section, whose decimal approximation to three places is 0.618. As was
mentioned during the discussion of morphological types in Part I, an
ascending cluster begins to accumulate at about 10 seconds or so before
the conclusion of Section 6. Within the context of the work’s overall form,
this point—which is within the vicinity of 3’40” into the work—occurs at
its negative golden section, i.e., 1 – 0.618 = 0.382. It thus divides the
work into a smaller portion followed by a larger portion, with the division
occurring according to the golden section.
CONCLUSION

Mycènes Alpha is an adventurous foray into the previously uncharted
territory of wholly graphic electroacoustic composition. Its use of varied
repetition, together with its economical use of proportional structures —
nested at different structural levels and observable from different
structural perspectives—reveals it to be a very disciplined and highly
structured foray as well. Whether or not the composer arrived at the
structural features described above through conscious effort, intuition, or
some mysterious combination of the two, the structure of this and many
other works by Xenakis reveals a persistent concern with the value of
time, including the listener’s time. Time in Xenakis’s music is not a space

430

in which the composer seeks to explore as if aimlessly. Rather, it is a
crucible for the focusing of energy, a place in which to offer the listener
a concentration and intensity of experience that is difficult to find in the
work of many other composers.

FOOTNOTES
1.
For recordings, see Electro Acoustic Music: Classics. Neuma Records CD 450–74

(1990) and CCMIX Paris. Mode Records CD 98/99 (2001). The graphic score has
been published in Iannis Xenakis, “Mycenae Alpha 1978,” in Perspectives of New
Music 25, no. 1/2 (1987), 12–15; in the booklet accompanying Electro Acoustic
Music: Classics; and in Sharon Kanach, “The Polytope de Mycènes 1978,” in Iannis
Xenakis, Music and Architecture, ed. Sharon Kanach (Hillsdale, NY: Pendragon
Press, 2008), 232–38, here 236–38. A scrolling video of the graphic score with
audio is available at http://www.centre-iannis-xenakis.org/items/show/668.

2.

Xenakis, Music and Architecture, 241–43.

3.

James Harley, “The Electroacoustic Music of Iannis Xenakis,” in Computer Music
Journal 26, no. 1 (2002), 33–57, here 51.

4.

For technical descriptions of later versions of the UPIC, see Henning Lohner, “The
UPIC System: A User’s Report,” in Computer Music Journal 10, no. 4 (1986),
42–49; Iannis Xenakis, “Appendix III: The New UPIC System,” in Iannis Xenakis,
Formalized Music, ed. Sharon Kanach (Stuyvesant, NY: Pendragon Press, 1992),
329–34; Gérard Marino et al., “The UPIC System: Origins and Innovations”, in
Perspectives of New Music 31, no. 1 (1993), 258–69 and Sharon Kanach,
“Appendix A: The UPIC System,” in Xenakis, Music and Architecture, 280–85.

5.

The start time for Section 1 corresponds to the onset of the work’s first sounds,
following any leading silence that may have been edited into a given recording.
On Electro Acoustic Music: Classics the duration of the leading silence is 0.5''; on
CCMIX Paris it is 4''; and at http://www.centre-iannis-xenakis.org/items/show/668
it is 13''. All of the published graphic scores give the timing for the beginning
of Section 2 as 55'': this should be changed to 17'', which may be verified via
playback software or by using a sound editor (such as Audacity). The 55'' mark
belongs at the beginning of Section 3.

6.

The graphic score shows that the registral space in Mycènes Alpha extends over
five octaves, from C1 to C6, in which A3 corresponds to 440 Hz.

7.

For general introductions to the arborescence as a morphological category in
Xenakis’s music, see Bálint András Varga, Conversations with Iannis Xenakis
(London: Faber and Faber, 1996), 88–91; James Harley, Xenakis: His Life in
Music (New York: Routledge, 2004), 71–88; Nouritza Matossian, Xenakis, rev. ed
(Lefkosia: Moufflon, 2005), 278–86; and Benoît Gibson, The Instrumental Music
of Iannis Xenakis: Theory, Practice, Self-Borrowing (Hillsdale, NY: Pendragon Press,
2011), 138–50.

8.

The sense that this gesture signals the recall of material heard previously may
have led James Harley to regard it as a separate section, even though the graphic
score does not indicate a section break at this point. He divides Mycènes Alpha
into fourteen sections rather than the thirteen that are identified here. See Harley,
“The Electroacoustic Music of Iannis Xenakis,” 51 and Harley, Xenakis: His Life in
Music, 115.

9.

Bálint Andràs Varga, Conversations with Iannis Xenakis, 2003, 204.

MYCÈNES
ALPHA:
A LISTENER’S
GUIDE

ANALYTICAL APPROACHES

TO TAURHIPHANIE

AND VOYAGE

ABSOLU
DES UNARI VERS

ANDROMÈDE BY
PIERRE COUPRIE

IANNIS XENAKIS

437

PIERRE COUPRIE

ANALYTICAL
APPROACHES TO
TAURHIPHANIE AND
VOYAGE ABSOLU
DES UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS
INTRODUCTION

Iannis Xenakis’s electroacoustic work represents only a small percentage
of his musical production. However, as Makis Solomos points out, these
fourteen works represent real milestones, “masterpieces of absolute
originality and innovation”[1] in the history of electroacoustic music.
But, beyond this often-emphasized originality, Iannis Xenakis seems
also to have provided a true model for music research. By transposing
the methods of scientific research into the field of artistic creation, he
created a new discipline that combines the logic of mathematics, the
empiricism of computer sciences, and the creativity of arts.
It is standard practice to classify the composer’s electroacoustic
production into three time periods:[2]
1. Works from the 1950s and 1960s representing the production
carried out by or under the influence of the Groupe de Recherches
Musicales (GRM).
2. The “climax of the early 1970s” with the realization of Polytopes
between 1967 and 1978.
3. The works of the late 1980s composed with the UPIC.[3]

PIERRE COUPRIE

The analytical research of this chapter concerns this last period
and focuses on two emblematic works, rarely presented and analyzed:
Taurhiphanie (1987) and the Voyage absolu des Unari vers Andromède
(1989). It is difficult to find sources,[4] and there is a very important
difference between concert versions and those released on CD, but the
technical context of their production or the surprising strangeness of their
sound and musical rendering make it an exciting field of research for the
musicologist. I will show that these characteristics are obviously strongly

438

linked to the UPIC, the instrument on which Xenakis worked both as a
designer and as a user for the composition of these works.
Analyzing an electroacoustic work presents several difficulties, such
as the lack of visual support (score, transcription, or other), the study
of the complexity of materials, and the predominance of nonrepetitive,
evolutive forms. To solve these difficulties, I will use acoustic analysis and
visualization techniques already proven in my previous publications.[5]
After introducing some background information on the UPIC and the few
sources that exist on the creation of these two works, I will develop the
essential points for understanding the analytical method, and then I will
present the first results of the comparative study.[6]
CONTEXTS THE UPIC SYSTEM

For a detailed presentation of the UPIC, I invite the reader to consult three
seminal papers: the article by Gérard Marino, Marie-Hélène Serra, and
Jean-Michel Raczinski which focuses on a description of the functional
aspects of the instrument;[7] the introduction to drawing techniques and
their sound rendering by Iannis Xenakis;[8] and the article by Rodolphe
Bourotte and Cyrille Delhaye with a perspective on the UPIC and its uses
in education and with other technologies.[9] In the history of computer
music, which usually begins with the MUSIC software, the first version of
which was released in 1957,[10] or the development of digital instruments
from the 1970s, the UPIC appears to be one of the most important tools.
Indeed, although its use remained rather confidential, limited to a certain
number of studios, its concept, based on converting a drawing into a
synthesis sound,[11] has inspired many developers. The pedagogic[12] and
artistic potential of image conversion into sound makes this instrument so
powerful.[13]
The first versions of the UPIC[14] were not in real time,[15] which made it
a composition tool for studio use. The first real-time version of 1987 allowed
some form of interaction and could therefore be used live, in concert. The
UPIC appears to be a very innovative instrument, combining composition
functions, a graphical user interface that was easy to use by composers or
even children, and a live performance capability using a gestural interface.[16]
These characteristics prefigured current music creation software. By
comparison, the other two main tools developed in the 1970s and
1980s in Paris, namely, the 4X[17] at IRCAM and SYTER[18] at GRM, were
essentially sound transformation tools which could be used as well for
mixed works that combined acoustic instruments with electronic sounds.
These few technical details about the instrument itself are also
related to sound rendering. The UPIC differed from other technologies
of the time. As James Harley[19] and Makis Solomos point out in their

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

439

PIERRE COUPRIE

discussion of Pour la Paix,[20] the sounds produced by the UPIC may
seem harsh because the composer does not try to smooth out the result.
This remark obviously echoes other works by Xenakis, such as Bohor,
composed in 1962.
CREATION OF THE WORKS

I have chosen to analyze Taurhiphanie and Voyage absolu des Unari vers
Andromède by Xenakis for several reasons. The first is that they were
composed two years apart, in 1987 and 1989. Being electroacoustic
works, they were both composed on the UPIC system. Another reason
is that they share the same process of creation and publication: the
recordings released on CD are very different from their performance in
concert. Finally, there are very few sources that allow us to understand
the composition process used by the composer. Taurhiphanie and the
Voyage absolu des Unari vers Andromède, therefore, appear to be ideal
for comparative analysis. However, this chapter is not a reference analysis,
but rather proposes a few guidelines to understand the aesthetic issues
that these two works represent.
Taurhiphanie was premiered on July 13, 1987, at the Arles arena
during the Radio France Festival in Montpellier. The performance
combined electronic music and a peaceful demonstration of bulls
and horses from the Camargue region. The concert also included
a performance of Les Pléïades (1978) and Psapha (1975) by Les
Percussions de Strasbourg and the Ensemble Pléïades conducted by Silvio
Gualda.
The set FIG. 1 consisted of a circular raised stage in the middle of
the arena on which the UPIC was installed and around which the animals
circled. The work included fixed and improvised parts from sixty fragments
manipulated in real time by playback with variation of sequences and by
effects such as freezing[21] or reverse. In the original concept, the bulls
were to be equipped with high frequency (HF) microphones to capture
their breathing; the UPIC would then also have been used to manipulate
these sounds in real time. It turned out that the lack of rehearsal time and
the movement of animals, which was difficult to control because of the
intensity of the sounds diffused, led Xenakis to use prerecorded live sound
playback.[22] The performance did not have the expected success.
In 1988, Iannis Xenakis produced a stereophonic version for four
loudspeakers containing only the fixed parts. The work was released on
CD in 1994.
As James Harley points out,[23] Taurhiphanie differs from Mycènes
Alpha, also composed on the UPIC, in the continuity of its transformations
and its formal construction.

PIERRE COUPRIE

441

The sources used for the analysis include a score and audio recordings
as shown in the table below.[24]

TYPE

FIG. 1 Iannis Xenakis, Taurhiphanie, 1987, during the performance at the Arles arena
© Iannis Xenakis Family

SOURCE

DURATION

INFORMATION

26 Photos

IXF

Taken before and during the concert

Text

IXF

Publisher’s tape notice

Drawing

CIX

Tape structure with start of improvisation

Printed matter

CIX

Audio

CD

10'53''

CD edition[25] – stereophonic

Digitized audio tape BNF

3'41''

Inscribed: “mounted bulls sequence
tape” (in English) – monophonic – June
28, 1987
This may be the tape used during
the concert to replace the real-time
recording of the bulls.

Digitized audio tape BNF

6'45''

With a mention of “Right track. Non-final
version. Ready for editing with amorces
and mixing” (in French) – monophonic –
July 13, 1988
Contains three sequences that are also
on the CD version.

Digitized audio tape BNF

8'08''

With a mention of “Left track. Non-final
version. Ready for editing with amorces
and mixing” (in French) – monophonic –
July 13, 1988
Contains three sequences that are also
on the CD version.

Page 30 of the score (unreadable)

The Voyage absolu des Unari vers Andromède was premiered
on April 1 1989 at the Kamejama Honyokuji Temple as part of the
International Kite Exhibition organized by the Goethe-Institut in Osaka,
Japan. It was premiered in France a few months later during the
Festival d’Avignon in the main courtyard of the Palais des Papes in a
program that also included Rebonds A and B, Idmen A and B, as well
as improvisations by Michel Portal and Bernard Lubat. The title, Voyage
absolu des Unari vers Andromède, refers to traditional Japanese unari
kite bows, simple one-string aeolian instruments which produce a sound
arch vibrating in the wind that resembles the chirping of insects.
As with Taurhiphanie, the sources used for the analysis include a
score and audio recordings as shown in the following table.
Unlike Taurhiphanie, the UPIC “score” of Voyage absolu was an
invaluable help in understanding some aspects of Xenakis’s creative
process.

PIERRE COUPRIE

443

TYPE

SOURCE

Score (15 pages)

IXF

DURATION

INFORMATION

Audio

CD

15'29''

CD edition[27] – stereophonic

Digitized audio tape BNF

12'49''

With a mention of “A version” (in French)
– stereophonic

Digitized audio tape BNF

12'39''

With a mention of “Demo examples”
(in French) – stereophonic Contains
examples from the UPIC and a long
extract from Taurhiphanie

A notice FIG. 2 and 12 pages of the
drawing realized on the UPIC (pages: 61,
62, 30, 35, 36, 34, 33, 33, 38, 9, 31,
32, 66[26])

THE ANALYSIS METHOD

FIG. 2 Iannis Xenakis,Voyage absolu des Unari vers Andromède, score, 1989

© Iannis Xenakis Family

Both works are perfectly adapted to the methods of analysis that I
usually use on acousmatic music.[28] These are works on magnetic tape
and whose sources contain only fragmentary parts of the UPIC score.
It was therefore necessary to use other types of graphic supports for
this study. As the works are very close in time to each other, and also
in terms of the tools used and the compositional approach used for CD
publishing (sources of the creation are recomposed in the studio), a
comparative analysis is completely justified and makes it possible to show
how Xenakis made different compositional and aesthetic choices from
fairly similar material.
As I mentioned briefly in the introduction, analyzing a fixed work is
quite difficult. I have already presented and analyzed in detail the problem
of the lack of visual support in several of my publications.[5] For the
analysis of the two works in this article, I used spectral representation
and audio descriptor extraction techniques to create visualizations that
decomposed the sound textures into musical gestures and, in the case
of the Voyage absolu des Unari vers Andromède, contextualized the
fragments of the score.
The techniques of audio descriptor extraction from the audio signal
used here have already been described in detail in an analysis of an
extract from Son Vitesse-Lumière[29] by François Bayle.[30] To summarize:
a set of audio descriptors[31] are extracted, either directly from the signal
or through spectral analysis achieved with a fast Fourier transform (FFT)
algorithm.[32] A representation (visualization) is then made to allow the
data to be read.[33]
The visualization part is essential because it is the source of the
interpretation that the musicologist will use to make the analysis. I used four
visualization techniques that are particularly efficient for musical analysis:

444

1. The simple graph (morphology identification) or the superposition of
curves (correlation identification between values);
2. The flow graph or Brightness, Standard Deviation graph (BStD)[34]
(see FIG. 3.1), allowing to visualize an estimation of the evolution
of the timbre through 3 descriptors. This graph is particularly
efficient for the analysis of electroacoustic music by facilitating the
interpretation of correlations between descriptors;
3. The linear or logarithmic sonogram;
4. The self-similarity matrix (see FIG. 3.2) representing the similarity
between values[35] (identification of musical structure or form). FIG. 3

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

As shown in Figure 3.2, the self-similarity matrix is realized in three steps:
1. The creation of the table[36] and the distance computation. The
values to be calculated appear on the x-axis and y-axis of the table.
2. The mapping of numerical value results into grayscales (mapping)
making the table easier to interpret.
3. In this article, I use color matrices, so the third step is to apply a false
color filter.[37]
These representation techniques are classified into three categories:
1. What I call macroscopies[38] allowing visualization of the entire work
while keeping a view of the complexity of the short structures;
2. Correlation analysis at several hierarchy levels in order to identify the
links between the variation of several descriptors;
3. Analysis of internal or external morphologies, both localized or around
a focal point.
This representation method has the advantage of allowing analysis
without selecting an observation level first. In addition, it also offers the
possibility of studying both sound and musical phenomena located on
one or more dimensions or that have rather fuzzy borders and are strongly
dependent on perception. In this sense, even if I rely heavily on techniques
of signal analysis from acoustics or visualizations from the hard sciences,
the object observed is not a laboratory sample like an isolated fragment,
but the work itself. These researches are naturally in a systemic or
complexity[39] study direction, which seems to me to be the only way to
study this type of musical work.
COMPARATIVE ANALYSIS

The presentation of these first analytical results is organized in three
parts: forms and segmentations, gestures, and the poles of continuous–
discontinuous. However, they do not correspond to the stages of the
analysis and could just as easily have been presented in a different order.

FIGS. 3.1, 3.2 Techniques for producing a flow graph (1) and a self-similarity matrix (2),

2019 © Pierre Couprie

446

FORMS AND SEGMENTATIONS
FIG. 4 represents a self-similarity matrix computed on the zero crossing
rate (ZCR) of the Taurhiphanie’s waveforms. This representation provides
a good estimation of the whole form of the work. Vertical band reading
can be used to segment the shape into three large parts or eight more
detailed parts. In addition, the central part offers a strong contrast
with the other parts of the work by being similar to itself (colors close
to yellow and red), but not to what comes before or after (purple color
indicating a low similarity).
This representation also provides two other important formal clues.
The first concerns the duration of the parts. Xenakis seems to have
organized the material into fairly long ranges with constant evolution and
only a few breaks. The second clue concerns the transitions between each
of the parts, which seem quite distinct, thus separating them into welldefined blocks.

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

FIGS. 5, 6 illustrate the most salient transformation processes and
transitions:
1. Transition between two parts including silence.
2. Transition by very short crossfade.
3. Accentuation by amplitude modification or spectrum densification.
4. Long morphological gesture.
5. Coloration by modification of the spectral centroid.
6. Destructuring a material by altering a dimension such as amplitude or
spectrum.
7. Tightening of the spectrum.

These two representations are created from three audio descriptors[40]
in a single graph. Correlations between several elements of the curve—for
example, y and width—and significant changes—for example in figures 4 and
6—highlight salient elements of the spectrum evolution. On all the graphs,
there is no real break and this evolution appears to be rather continuous.
Also, the two forms do not have repetitions; each part allows to cross a step
in a continuous evolution of the sound material, a morphological form.[41]
James Harley proposes a two-part form segmentation of the Voyage
absolu des Unari vers Andromède.[42] FIG. 7 shows this segmentation
as well as the one derived from a two-level listening analysis. These
segmentations are compared here with two complementary self-similarity
matrices calculated on the FFT and on three audio descriptors root mean
square (RMS) amplitude, spectral centroid, and spectral variance. These
figures highlight strong similarities between the two works in terms of form
construction:

FIG. 4 Self-similarity matrix of Iannis Xenakis's Taurhiphanie, 1994, computed
on the ZCR descriptor in software iAnalyse, 2019, screenshot © Pierre Couprie
FIG. 5 Four examples of transformation processes from a BStD representation of Iannis
Xenakis's Taurhiphanie, 1994, produced with software iAnalyse, 2019, screenshot ©
Pierre Couprie

449

PIERRE COUPRIE

– An overall division into two parts (indicated by a wide line and an
arrow), the second part can itself be subdivided into two other
parts.
– The presence of a long part (A in Taurhiphanie and C in Voyage
absolu…) built on a continuous evolution of the sound material.
– The presence of short parts (C in Taurhiphanie) and B, D in Voyage
absolu…) whose duration contrasts strongly with the other parts.
These two works, therefore, appear to be linked in terms of structure while
at the same time being the result of very different compositional strategies.
However, the form alone is not sufficient for comparative analysis. I will
now show how the morphogeneses or gestures[43] used by Xenakis also
play a very important role in the transitions and in the characterization of
the subparts.
GESTURES: FROM THE UPIC TO SOUND REALIZATION

FIG. 6 Three examples of transformation or transition processes from a BStD
representation of Iannis Xenakis's Voyage absolu des Unari vers Andromède,
1987, produced with software iAnalyse, 2019, screenshot © Pierre Couprie
FIG. 7 The form and comparison between FFT and the audio descriptors as selfsimilarity
matrices, produced with software iAnalyse, 2019, screenshot © Pierre Couprie

As mentioned above, I had access to the score of the Voyage absolu des
Unari vers Andromède. This consists of twelve drawings on the UPIC.
[44] Considering the numeration of the pages divided between 9 and
60, it is likely that it is only a fragment of the complete score. In addition,
pages 32 and 60 are identical and there appear to be only two original
drawings (page 32 and 34), the others being variations of page 32. The
second original drawing (page 34) did not result in any variations. Figure
8 provides a hypothesis on the realization of these variations. We can see
that Iannis Xenakis worked mainly from variations by rotation[45] and by
assembling the same multiplied form (as in pages 9, 30, 38 and in the
ones that follow). Finally, few drawings are directly visible and perceptible
in the spectrum computed from the CD version. FIG. 9 shows the spectrum
(top) and a schema (bottom) containing the locations of the actual
drawings.[46] I have named A and B the two forms that appear clearly
on the spectrum as probably having their origin in a UPIC drawing, but
they are not present in the score. Similarly, the fragment 9b comes from
page 9, but there is a montage of two additional iterations compared to
the original form. The only appearance of page 34 (noted 34b) at 12:03
is, for its part, greatly modified by the effects of multiplication and time
stretching.
What is observable in this work is unfortunately not observable in
Taurhiphanie. Indeed, if the score exists, it has not yet been digitized,
and the fragility of the originals have not yet allowed me to work on
the identification in the CD version of the shapes drawn on the UPIC.
Nevertheless, some of the shapes visible on the spectrum probably come
from materials drawn on the UPIC, their appearance being very similar

450

to those used in the Voyage absolu des Unari vers Andromède. While
listening to the digitized tapes at the Bibliothèque Nationale de France
(BNF), I realized that the waveforms used in the UPIC probably all come
from recordings of bulls’ roars. In addition, the very short morphologies
in glissandi, such a as at 2'22'', 5'34'', between 6'55'' and 7'58'', or at
the end of 8'35'' are very similar to some of the roars present on the
sound recording tape available at the BNF.
The CD production of these pieces, therefore, appears as a
composition in its own right, based on materials partly made on the UPIC.
Both of the two pieces can be decomposed to analyze how Iannis Xenakis
managed the transitions between materials and the progressive changes
in textures.

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

CONTINUOUS AND DISCONTINUOUS:
TRANSFORMATIONS AND TRANSITIONS

In my analysis, I highlighted the composition of the two works as an
assembling of several sequences, some of which use materials from
drawings on the UPIC. However, during the listening, the editing aspect
does not really appear and an impression of moments would be more
accurate. Each of them has its own written logic and all these moments
follow one another without any real break. This first form of continuity
is particularly visible on the complete logarithmic spectrum of each
piece. FIG. 10
In Taurhiphanie, except for the central break between 3:48 and
5:28,[47] the spectrum shows continuity on two types of materials:
1. 0'00''–3'45'': A material with a very rich spectrum.
2. 5'15''–End: A rather harmonic set of sounds.
In the Voyage Absolu des Unari vers Andromède, the logarithmic
spectrum highlights the crossfade transitions chained between three
types of sound materials:
1. 0'00''–3'00'': material with a rather clear spectrum.
2. 3'00''–8'00'': A very rich and dense sound material.
3. 8'00''–End: A set of sounds whose spectral sites are quite narrow.
In the second work, the crossfade transitions between the three
types of materials are very evident. These transitions between the
main parts also operate at a finer level. Listening to and viewing the
sonograms reveals that both works were composed as a montage of
several sections on several levels. If Iannis Xenakis uses the crossfade
between the large parts, he varies the transitions of shorter sound
materials (see FIG. 11):

FIG. 8 Hypothesis of the genesis of the score pages from two original shapes (framed) of
Iannis Xenakis's Voyage absolu des Unari vers Andromède, 1987 © Pierre Couprie

FIG. 9 Time location of the score pages of Iannis Xenakis's Voyage absolu des Unari vers
Andromède, 1987, produced with software iAnalyse, 2019, screenshot. A, B, are missing
gestures in the score and 9b and 34b are variations of pages 9 and 34. © Pierre Couprie
FIG. 10 Logarithmic spectrums of Iannis Xenakis's Taurhiphanie, 1994 (top) and Voyage

absolu des Unari vers Andromède, 1987 (bottom), produced with software iAnalyse,
2019, screenshot © Pierre Couprie

FIG. 11 Examples of transitions by crossfading or by a silence in Iannis Xenakis's
Taurhiphanie, 1994, produced with software iAnalyse, 2019, screenshot © Pierre Couprie
FIG. 12 Comparison of Iannis Xenakis's Taurhiphanie, 1994 (top) and Voyage absolu

des Unari vers Andromède's, 1987 (bottom) waveform and deviation between the
RMS amplitudes of the two channels in red, produced with software iAnalyse, 2019,
screenshot © Pierre Couprie

454

1. Via a very short silence (1.2 seconds at most) present only in
Taurhiphanie.
2. By using a very short crossfade.
3. By using long crossfades or progressive transformations of the
material. FIG. 11

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

455

PIERRE COUPRIE

FOOTNOTES
1.
Makis Solomos, “Introduction,” in Iannis Xenakis, la musique électroacoustique,

ed. Makis Solomos (Paris: L’Harmattan, 2015), 5.

2.

Boris Hofmann, “The Electroacoustic Works by Xenakis and Their Instrumental
Contemporaries,” in Iannis Xenakis, la musique électroacoustique, ed. Makis
Solomos (Paris: L’Harmattan, 2015), 19–28.

3.

UPIC: Unité Polyagogique Informatique du CEMAMu. The UPIC is a digital
instrument that allows users to compose by drawing on a graphic tablet. Iannis
Xenakis composed four works on UPIC: Mycènes Alpha (1978), Pour la Paix
(1981), and the two works analyzed in this chapter.

4.

I would like to thank Mâkhi Xenakis, Sharon Kanach, Cyrille Delhaye (GRHis), and
Pascal Cordereix (BNF, Bibliothèque Nationale de France) for all the help they gave
me in consulting parts of the sources.

5.

Pierre Couprie, L’analyse musicale et la représentation analytique de la
musique acousmatique: Outils, méthodes, technologies, Habilitation Thesis
(Paris: unpublished manuscript, 2015); Pierre Couprie, “Prolégomènes à la
représentation analytique des musiques électroacoustiques,” in Circuit 25,
no. 1 (2015), 39–54; Pierre Couprie, “Analyse de la musique mixte: Logiciels,
procédures, workflows,” in Analyse de la musique mixte, ed. Alain Bonardi, Bruno
Bossis, Pierre Couprie, and Vincent Tiffon (Paris: Delatour, 2017), 61–79; Pierre
Couprie “Nouvelles approches audionumériques pour l’analyse musicale.” in
Musicologies nouvelles 5 (2018), 120–132.

Taurhiphanie, Iannis Xenakis, examples of transitions by crossfading
These transitions, both in large parts and shorter structures, create great
continuity in the evolution of form. However, both works also have forms of
discontinuities that are revealed in the balance between the two channels.
Iannis Xenakis systematized a strong stereophonic oscillation of the
material. FIG. 12 shows the waveforms and a deviation curve of the RMS
amplitude[48] in red.
It can be noticed that the frequency of oscillation is very different
in the two works. Even if the one at the top (Taurhiphanie) has a greater
range of deviation, this oscillation is almost continuous; only Voyage
Absolu des Unari vers Andromède has some moments of relative stability
(around 1'00'', 9'30'' and 14'00'').
Continuity and discontinuity are therefore to be found at several
timescales and are complementary to each other. Thus, the de-correlation of
the channels allows the composer to obtain a less monolithic material. It is
easy to imagine what Iannis Xenakis wanted when he suggested playing these
stereophonic versions over four loudspeakers by crossing the channels.

6.

Representations, whether of the signal, its analysis, its decomposition into
descriptors or graphs and transcriptions, have been made on the iAnalyse 5 software
developed for musical analysis assistance (http://ianalyse.pierrecouprie.fr).

7.

Gérard Marino, Marie-Hélène Serra, and Jean-Michel Raczinski, “The UPIC System:
Origins and Innovations,” in Perspectives of New Music 31, no. 1 (1993), 258–69.

CONCLUSION

8.

Iannis Xenakis, “Determinacy and Indeterminacy,” in Organised Sound 1, no. 3
(1996), 143–155, here 150–52.

9.

Rodolphe Bourotte and Cyrille Delhaye, “Learn to Think for Yourself: Impelled by
UPIC to Open New Ways of Composing,” in Organised Sound 18, no. 2 (2013),
134–45.

10.

The MUSIC software was developed by Max Mathews from 1957 at the Bell
Telephone Laboratories on an IBM 704. It is referred to as MUSIC I.

11.

This idea had already been partially put into practice by Larry Rosler and Max
Mathews who had developed a graphic system in 1966 to draw the frequency
and amplitude of synthesized sounds (see Jean-Claude Risset, “Recollections
and Reflections on Organised Sound,” in Organised Sound 20, no. 1 (2015),
15–22, here 18.).

12.

Αnastasia Georgaki, “Sound Pedagogy Through Polyagogy: Initiation to Xenakis’
World in Primary School Through the HighC Interactive Whiteboard,” in Iannis
Xenakis, la musique électroacoustique, ed. Makis Solomos (Paris: L’Harmattan,
2015), 241–54; Malika Combres, “La musique contemporaine à l’école,” in
Transposition, no. 2 (2012), 23–31,
http://journals.openedition.org/transposition/462

13.

Maria Harley, “Musique, espace et spatialisation. Entretien de Iannis Xenakis avec
Maria Harley,” in Circuit 5, no. 2 (1994), 9–20, here 12.

14.

The first version of the UPIC was completed in 1977.

In this short paper, I have attempted a first approach at comparative
analysis of these two emblematic works of electroacoustic production by
Iannis Xenakis. As I have been able to demonstrate, the use of analytical
methods based on acoustic representation or visualization of information
extracted from the signal has allowed me to study the construction of the
works in more detail, and also to propose some hypotheses about the
creative process. The exploration of new sources will probably be able to
complete these analyses.
If Iannis Xenakis has provided a model for the interaction between
mathematics, computer science, and artistic creation, he has also offered
us a model for what are known as digital humanities, just as Jean-Claude
Risset did. Research on such works cannot be conducted without the
interaction between several scientific disciplines and a constant back and
forth between research and creation. Through his works, Iannis Xenakis
has shown us a very rich path for music research by combining in the
same discipline issues that may seem very different, but which contribute
to the same goal; the renewal of artistic forms.

456

15.

In other words, the time required to calculate and generate sound is far greater
than the few milliseconds that give the illusion of real time used in live music.

16.

Marlon Schumacher and Marcelo M. Wanderley, “Integrating Gesture Data in
Computer-aided Composition: A Framework for Representation, Processing, and
Mapping,” in Journal of New Music Research 46, no. 1 (2017), 87–01, here
88–89.

17.

The 4X processor is the result of development carried out by Giuseppe Di Giugno
and IRCAM researchers. It was finalized in 1981 and marketed in 1984.

18.

The SYTER system (Système Temps Réel) was developed at the Groupe de
Recherches Musicales by Jean-François Allouis in 1978.

19.

James Harley, “The Electroacoustic Music of Iannis Xenakis,” in Computer Music
Journal 26, no. 1 (2002), 33–57, here 53.

20.

Makis Solomos, “L’équilibre fragile de Pour la Paix,” in Iannis Xenakis, la musique
électroacoustique, ed. Makis Solomos (Paris: L’Harmattan, 2015), 127–57.

21.

Freezing consists in stopping the advance of the playback head without stopping
the sound. The reading is then performed by the playback of a multitude of sound
grains located around the position of the playback head.

22.

James Harley, “The Electroacoustic Music of Iannis Xenakis,” in Computer Music
Journal 26, no. 1 (2002), 33–57, here 52–53.

23.

Ibid., 53.

24.

Only audio recordings were used for musical analysis. The abbreviations in the
source column stand for: IXF: Iannis Xenakis Family; GRHis: History research
laboratory (France, Rouen); CD: CD Edition; BNF: Bibliothèque Nationale de
France.

25.

Iannis Xenakis, Aïs – Gendy3 – Taurhiphanie – Thalleïn (Neuma Records, 1994).

26.

The order is the same as that of the PDF document of the sources.

27.

Iannis Xenakis, Musique électroacoustique (Fractal Records, 2001).

28.

Acousmatic music is generally associated with composers from France or abroad
related to the GRM. Even when it refers to music composed in a studio on a
medium and diffused entirely on loudspeakers in concert, it is difficult to describe
some of Xenakis’s works as “acousmatic music.” The filiation would rather be
from computer music.

29.

Pierre Couprie, “Voyage dans Grandeur nature,” in Son Vitesse-Lumière, ed.
François Bayle (Paris: Magisson, 2016), 47–57.

30.

On this point, the three works present a certain similarity in terms of form, even
though the composition techniques are very different. They share the idea of a
continuous sound flow articulated by strong morphologies or musical gestures.

31.

The descriptors used are mostly low level: RMS amplitude, zero-crossing rate
(ZCR), spectral centroid, spectral variance, spectral deviation, inharmonicity.

32.

Unless otherwise specified, the FFT computation parameters for extracting audio
descriptors are: Window size = 2018, Window type = hanning, Window step = 25 %.

33.

The visualization is obtained by converting the list of numerical values into a
diagram or by converting the numerical values into color values (mapping).

34.

Mikhail Malt and Emmanuel Jourdan, “Le BStD: une représentation graphique de
la brillance et de l’écart type spectral, comme possible représentation de l’évolution
du timbre sonore,” in L’analyse musicale aujourd’hui, ed. Xavier Hascher, Mondher
Ayari, and Jean-Michel Bardez (Paris: Delatour, 2015), 111–28.

ANALYTICAL
APPROACHES TO
TAURHIPHANIE
AND VOYAGE
ABSOLU DES
UNARI VERS
ANDROMÈDE BY
IANNIS XENAKIS

457

PIERRE COUPRIE

35.

It therefore does not represent the values themselves, but their distance.

36.

I utilize here the term used in computer science (table); in mathematics we use
the term matrix. A matrix is called self-similarity when the computation is based
on only one set of values.

37.

This step is not trivial, as it compensates for the graphic aberrations caused by
grayscale visualization. The coloring generally used is a gradient close to the light
spectrum.

38.

In reference to Joël de Rosnay’s macroscope, see Joël de Rosnay, The
Macroscope: A New World Scientific System (New York: Harper & Row, 1979).

39.

On these questions, I refer to Abraham Moles, Les sciences de l’imprécis (Paris:
Seuil, 1990); Edgar Morin, On Complexity (New York: Hampton Press, 2008).

40.

The graph represents: y = spectral centroid, width = spectral variance, color = ZCR.

41.

John Young, “Forming Form,” in Expanding the Horizon of Electroacoustic
Music Analysis, ed. Simon Emmerson and Leigh Landy. (Cambridge: Cambridge
University Press, 2016), 58–79, here 61.

42.

James Harley, “The Electroacoustic Music of Iannis Xenakis,” in Computer Music
Journal 26, no. 1 (2002), 33–57, here 54.

43.

Philippe Lalitte points out the impact of the gesture on the perception of form; see
Philippe Lalitte, “Conditions de possibilités d’une rhétorique formelle perçue,” in
Intellectica 48–49 (2008), 103–14, here 104.

44.

There are thirteen drawings, but pages 32 and 60 are the same.

45.

The rotations shown in Figure 8 are approximate.

46.

It is, of course, possible that there may be others, masked by transformations.

47.

As transitions are made by crossfades, the times shown here and in the following
lists are approximate.

48.

The deviation between the two RMS amplitude graphs shows the balance of the
levels: 1 (bottom) = predominance of the right channel, 0 (middle) = balance
between the two channels, +1 (top) = predominance of the left channel.

IANNIS XENAKIS,

ROBOTS,
AND THE
UPIC—
HENNING LOHNER

“THE GREATEST
ROBOT SHOW THE
WORLD NEVER SAW”

463

HENNING LOHNER

IANNIS XENAKIS,
ROBOTS, AND
THE UPIC—
“THE GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”
PROJECT HISTORY, PART 1: “WHY ME?”

HENNING LOHNER

Xenakis was the composer-in-residence at Centre Acanthes in 1985,
a six-week course that focused entirely on his work; it was held as
part of the European Year of Music. I was lucky to be there. At my
first private meeting with the composer he asked me why I wanted to
write music; I said: “I want to change the world.” He responded: “Have
you ever been depressed?” My life changed forever. Xenakis became
my mentor and surrogate father—he would remain so until the end of
his life. I soon began publishing about Xenakis’s work in German and
American journals, and was eager to share my enthusiasm of this great
composer’s work wherever I could. I had become a regular guest at his
studio in Rue Victor Massé. Often, I would arrive from Germany with
the night train and go to the studio around six in the morning; the key
would be under the doormat. Usually, I would spend a day at a time
“rummaging” through the Master’s notes and archive until he came
round to discuss my findings. He would then proceed to give me the
most exclusive, meaningful training a composer and thinker could ever
imagine.
In early 1989 I was hoping to organize a Xenakis festival in Munich
in conjunction with the city’s annual international opera festival. Didier
Deschamps, then the director of the Institut Français in Munich,
and Sabine Kienow from Frankfurt, a major force in the German
communications world, were driving the network that sent me back to
Paris to ask Xenakis whether he would accept an opera commission
from the City of Munich. Xenakis was not a fan of opera, yet a stage of
magnitude was mandatory for the project contained in a slim folder he
consequently put into my hands: the Robot Ballet.

FIG. 2 Photocopy of page 1 of Xenakis’s original manuscript for the Robot Ballet, 1982.
FIG. 1 Xenakis and the UPIC, 1985 © Henning Lohner and CIX Archives

Reproduced from facsimile at CIX Archive, fonds Lohner. Originals can be consulted at
the Iannis Xenakis Family Archive. © Iannis Xenakis Family

466

THE PROJECT

Here is what the ballet was intended to be, in Xenakis’s own words:
Title: Introduction to the Rights of Humans and of Automatons
[A Ballet of Emancipated Robots]

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

SUBJECT:

Since prehistoric times man has been creating his own environment:
equally spawning things and beings that seem to guarantee humanity’s
greatest freedom of action, thought, well-being, and leisure, along with
ever-growing disaster.
Today, humankind is already occupying the entire planetary space for
its own goals; tomorrow it will be conquering the galaxies.
At the same time, man is creating increasingly complex and
sophisticated automatons, believing in the human machine itself. We can
begin by entrusting simple functionalities of industrial and agricultural
work to these machines, and by tomorrow we will move all the way to
biological automatons recommitted with the capabilities of judgment,
expediency, feelings, decision-making, and finally, self-regeneration.
This progress is inevitable: Humanity will create a parallel humanity
and possibly an entire autonomous universe. On this path, the major
concerns of freedom, obligation, and creativity will have to settle their
accounts with those of their new creatures, as powerful and intelligent as
their makers, if not more so.
Human Rights today are really nothing but the anticipation process
for the ethical and moral battery of questions that future generations will
have to deal with. FIG. 2
FLOW OF THE SHOW (“BIRD’S EYE VIEW”):

The Robots’ movements (i.e. evolutions) create a type of abstract
ballet which, from time to time, seems surprisingly realistic. This fluid
transition between movements is conceived as a strong contrast in
tension that will give the audience the irresistible desire to see and hear
more for the entire duration of the show.
The Robots represent Hercules fighting Antaeus, who, in order to
regain his strength, has to touch the Earth beneath him, but in the end
succumbs to Hercules.
The Robots’ movements will be of very diverse natures: fights, duels,
submission, pushing and shoving, even the exchange of feelings between
the Robots, such as affection and love, are representable. The show will
be an image of humanity in the sense that all gestures are indicative of a
society in miniature. We are creating an ode to the glory of human beings,
to justice and peace, moved by the Act of Creation, given by Nature itself.

FIG. 3 Photocopy of Xenakis’ autograph: text and vocal examples for the Robot Ballet,
1982. Reproduced from facsimile at CIX Archive, fonds Lohner. Originals can be
consulted at the Iannis Xenakis Family Archive. © Iannis Xenakis Family

468

Music and lights on and/or around the Robots will highlight the Act
of Creation.
Essential texts will be projected throughout the staging area via a
multi-vision video-wall, supporting the above-mentioned subjects, from
the physical, atomic and astrophysical sciences; philosophy, religions,
human rights, animal rights, living beings, races, etc. will be projected by
a system of slides on clearly visible screens.
PROJECT FEATURES (ORGANIZATION):

Nine SMART 6.50 R (or similar) robots are to be dispersed irregularly
within the audience’s space.
The event will last about 30 minutes. It should be repeated several
times a day with ample time between performances to let the audience
enter and leave.
The performance space should, if possible, be a public space, in
other words: not within the factory hall where the machines usually work.
However, the space needs to have a flooring that can carry the weight of
the robots.
Sound will be dispersed through a system of speakers that are
distributed within the entire space between the robots and the audience.
This will allow for the sonic effect of “flying sound.”
Music will be pre-recorded on multi-channel tape; add to this three
UPIC graphic music computer units; some robots will freely improvise on
these.
Lighting, just like the motion of the robots and the music itself,
and indeed the entire event, will be completely automated. Installation,
disassembly, and transportation will be of such ease that the show can
travel easily from location to location for about a full year.
The venues can be anywhere as long as they have flooring that
structurally can carry the robots and the space should be sheltered (a
hangar, abandoned factory, etc.)
Apart from the fact that the robots necessarily have to be mounted
to the floor, they can perform all possible motions thanks to their three
wrist axes; the specific motion capabilities of these joints will of course
be considered in the composition. All motion will be composed by myself
in programming language in the same way I develop and compose a
musical score.
The automated control programming for the show will be carried out
by myself along with CEMAMu[1] engineers under my supervision. The
music will be composed entirely by me, in principle at CEMAMu.
For reasons of economy it is conceivable to utilize robots that are not
currently in use so long as they can perform computerized manoeuvres.

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

469

HENNING LOHNER

KINETIC PROCEDURES:

I will define the precise figures or “routines” the robots will “dance”
when the time comes; these will be animated by special settings based
on the varying angles and propulsion speeds of the Robots’ capabilities
(see FIGS. 4, 5). These settings are established specifically by functional
and deterministic mathematical methods, along with stochastic laws
of distribution (in particular during the Robots’ wrestling and disorderly
sessions). Mathematical distribution models such as Bernouli, Poisson,
and Cauchy will be used with or without elastic barriers. Ideally, I would
also like to include cellular automaton routines and, if possible, fractals.
The entire show will be composed in the sense that the mathematical
models underlying the musical composition will equally be applied to the
motion of the Robots and the overall staging of the show.
TEXT EXAMPLES FOR THE VOCAL PARTS:

– “Today, we automatons, created by man, liberate man from his
own slavery; his human rights are expanded”.
– “Tomorrow, we automatons will rebirth man himself as stronger,
more beautiful, and more capable than he has ever been before”.
– “The day after tomorrow, we automatons will be equal to man
himself, and as he is now equal to us, we will be equal to him”.
– “All will be at peace in harmony: no conquest, no defeat; no
directions anymore. Life and Death, to be or to be born: all has
become indifferent”.
– “We are truly Gods”. “This is the Universe’s Game”.
CORE ASPECTS OF THE PROJECT

(Text written by Xenakis in collaboration with Sistema Dinamo,
revised by Xenakis, Radu Stan, and Henning Lohner).[2]
The complete musical work includes a fully automated, scenic
composition. The protagonists on stage are nine Robots, possibly aided by
other machines.
This work is a homage to science and to the power of progress
inherent to humanity.
As our 20th century closes, this work will reflect on the actual role
the most progressive technologies have on our civilization. Imagine a
scenario of living together with these automatons that are continuously
becoming more intelligent. Both formally and in terms of the content of
our show we will be investigating questions of ethical and moral problems
in anticipation of the “new social rapport” we will undoubtedly have as we
look into the 21st century.

471

HENNING LOHNER

This work merges creativity with the technological knowledge of
current industry standards into a completely new formula. The artist
will create new ideas, and industry has the opportunity to show their
most progressive products to a broader audience, outside of the
manufacturing hall.
As such, this work is in complete synchronicity with Xenakis’s
creative continuity—who has made it his life’s work as an artist to engage
with the progress of technology and its effects.
Therefore, we can summarize these positive truths:
The particular emotional power of the performance.
The complete novelty of structural and visible representation of
events and their application in society and in the media.
C Stimulation and reflection resulting from ethical and philosophical
aspects of the show.
D Use of industrial machines and products as protagonists in a new,
contemporary work by one of the most important composers of the
20th century.
E Flexibility and ease-of-use of the project’s components, along with
(relatively) low maintenance, will allow for relative ease of installation
and disassembly logistics of the performances themselves and
between their venues.
F International intelligibility of the characters via a universal language,
regardless of heritage or social order; the audience need not have
any elite nor particular affiliation or prejudice.

A

B

We believe that these remarks are indicative of successfully
integrating the product-oriented interests of industry and the creative
expression of a scenically composed, artistically and socially valid
performance symbolizing the notion of progress for humanity.
PROJECT HISTORY, PART 2: “WHY?”

FIG. 4 Example of robotic motion: Eric the Robot shaking hands and displaying on
its chest the logo of R.U.R. (Rossum's Universal Robots), play by Karel Čapek, 1921
FIG. 5 Example of robotic motion: Marvin Minsky with his Tentacle Arm, ca. 1963,
screenshot © AI History, movie, 2010, posted on CSAIL YouTube public channel by
MITCSAIL

Prior to my involvement, the goal was to give the world premiere of the
Ballet of Emancipated Robots during the bicentennial celebrations of the
French Revolution in 1989, specifically at the Mission du Bicentenaire de
la Révolution Française et de la Déclaration des Droites de l’Homme et
du Citoyen (Bicentenary Commemoration of the French Revolution and
the Declaration of Human Rights and Citizens) at Le Grande Arche de La
Défense in Paris.[3]
This event and venue made perfect sense with regard to the intent,
form, content, and appearance of the Robot Ballet. But first: Why would
anyone attempt a ballet for robots? Although the cultural history of the

472

twentieth century since Expressionism is full of ideas about robots,
nothing involving a real robot had ever been done before. Surely there
must have been good reasons why no one had succeeded at it, although
a few had tried. “It’s actually quite easy to make something new. You just
have to pay attention to what exists, and then do something different”—
this was a mantra I would hear from Xenakis on occasion. It sounded
convincing. However, making real robots dance proved much more difficult.
In attempting this ballet, the opportunities were perhaps its
challenges:

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

The drama and the composer’s personal history.
The robot itself.
C The invention of two significant musical interfaces.
D The staging and logistics of the show itself.

A

B

HUMAN VS. MACHINE

“The idea of the automaton, for example, exists since the beginning of
time, because man wants to resemble God. FIG. 12 This idea, actually, has
been formulated by the musician in using certain compositional structures,
such as the fugue, long before any theories about robots came around.”[4]
An unassuming and short quote, this nevertheless clearly describes the
interlacing of Xenakis’s philosophical position with practical questions of
creating; indeed, creation is a constant flow of birth and rebirth.
For Xenakis, who, as a resistance fighter in his early 20s, caught a
bomb that blew off nearly half of his face, surviving on a mere thread of
life, I have no doubt that creation equaled survival and rebirth—in his case,
with a glass eye and half his face either missing or filled with shrapnel. In
my view it is not a coincidence that the only truly substantive research
object in his archives on this project was a book on medical ethics and
human rights.[5]
Xenakis’s ballet exposé, in particular his “text examples,” suggest
a profound understanding of Maslow’s hierarchy of needs. The effects
of excessive, progressive automation are cited as one of the dominant
threats to basic human needs[6] such as food and water, work and
education, mental stability, and so forth; indeed, Xenakis’s entire output
deals with the Human Condition.
It is a strange and fortuitous coincidence that the year 1921, in which
Xenakis was either born or conceived,[7] also marks the birth of the term
“robot” and its predominantly negative connotation as a threat to humanity,
as portrayed in the theater play R.U.R. (Rossum’s Universal Robots) by
Karel Čapek.[8] FIG. 4 The theme of the piece is surprisingly similar to the
dramatic outline Xenakis gives for his ballet.

FIG. 6 Photocopy of Xenakis' autograph, scale and reach of the Robot Arm 1, 1982.
Reproduced from facsimile at CIX Archive, fonds Lohner. Originals can be consulted at
the Iannis Xenakis Family Archive. © Iannis Xenakis Family

474

While the concept of autonomous “artificial life” finds its antecedents
in the earliest surviving scriptures, the first appearance of the actual term
“robot” occurred in this play by Čapek: derived from the Czech word robota,
which translates as “compulsory labor.”

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

THE ROBOT PROTAGONIST

The Unimate was the first digitally programmable robot; invented by George
Devol, it was patented in 1954.[9] Basically, this was the first real robot.
That same year Xenakis began his composing career with his first major
orchestral work, Metastasis, premiered at Donaueschingen in 1955, and
changing the course of music forever. From then on, in a curious paradox
of parallel developments, the progress of robotization and Xenakis’s
personal development as a composer marched consistently side-by-side.
In the early 1960s SRI International introduced Shakey, the first
mobile and perceptive robot. Marvin Minsky developed his tentacle
arm FIG. 5 and the notion of “artificial intelligence” (AI). In 1975, while
Xenakis was deeply engaged with designing his first UPIC, ABB of Sweden
introduced the spot-welding robot, ASEA IRB 6 FIG. 8, the world’s first
completely microprocessor-controlled robot.
The Comau Smart 6.50 R FIG. 10, which Xenakis intended to use,
was practically the twin of the ASEA IRB 6, but with six fully computercontrollable axes and ratios. Being a spot-welding machine on an
automotive assembly belt meant it could perform very precise actions
within an area of a few millimeters. Although it looked Herculean, the
machine was not “clumsy.”
The appearance of this robot alone symbolizes notions of human
progress: it looks like, and acts as an extension of a human arm. FIG. 9
As such, this robot fits an iconography that Xenakis was very familiar with.
The machine’s ambitus is surprisingly similar in range not only to a human
in motion, but also to the concept of the Modulor.[10]
Equally important, the robot’s computerized control center drove
a maximum of 1800 execution steps (“evolutions”) with a 64k RAM
maximum storage. This is nothing compared to today’s computer memory
capacities, but it was significant in 1988: 1800 evolutions allowed for
fluid, uninterrupted programming of motion for at least 30 minutes, thus
guaranteeing the practical performability of the show. Furthermore,
external interfacing was possible, which was mandatory for Xenakis in
order to synchronize all the events of the show.
The Smart and the ASEA robots were significant precisely because
they gave the impression of being able to perform a greater amount of
automatic programming steps than a human programmer would be able to
enter into the command control at the same time, allowing for a completely
automated showing of the performance without human supervision.

FIG. 7 Xenakis' autograph, scale and reach of the Robot Arm 2, 1982. Reproduced from
facsimile at CIX Archive, fonds Lohner. Originals can be consulted at the Iannis Xenakis
Family Archive. © Iannis Xenakis Family
FIG. 8 Juan Toquica, definition of a coordinate system for the ASEA Robot (left), ca.
1974. Retrofitting of Asea IRB6-S2 industrial robot using numeric control technologies
based on LINUXCNC and MACH3-MATLAB. 10.1109/ROBIO.2017.8324737 (right), 2017
© Alberto Alvares, Juan Toquica, Eduardo Lima II, and Marcelo Bomfim

FIG. 9 Raymond Duchamp-Villon, Le Cheval majeur (The Large Horse), 1914
© Philippe Migeat, Centre Pompidou, MNAM-CCI/Dist. RMN-GP, public domain

FIG. 11 Linda Bucklin, Robot (right) vs. android (left), 2013. Courtesy of Shutterstock

FIG. 10 The Comau Smart robot, Torino, Italy, February 2014, advertising brochure
© Comau Smart PAL

FIG. 12 Michelangelo, detail of the Sistine Chapel ceiling, 1536–1541, Rome, Italy
© public domain

© Linda Bucklin

478

In other words, the looks and functionality of the machine gave
hope: the hope that a machine could actually do more than a human, and
optimism, breaking with their past, beginning a new life of their own.
THE UPIC AND ROBOTS

A robot is literally the visible externalization (the “front end”) of the internal
mathematical models (the “back end”) inside the computers that drive the
robot to “behave on its own”: computational science that, by its nature, can
spawn endless variants of mathematical automatons. For Xenakis, robots
could become a direct “anthropomorphic”[11] gestalt of their computational
digital “intestines”; these mathematical intestines being of the same
substance as Xenakis’s musical and kinetic compositions.
Xenakis’s fascination with this particular type of robot lies in humanity’s
desire to actually have thinking machines versus the ability to have
thinking machines. The Smart 6.50 R or the ASEA had enough ergonomic
capabilities to create the optical illusion of acting human for the audience,
and this was intended and planned by its inventors.
Xenakis’s attraction to robotics was an extension of his research into,
and his invention of, musical interfacing. Both robots and the UPIC could
be related as programmable music data input interfaces, while at the same
time actually being performers of the sounds they create. In creating music,
Xenakis was of course aware that certain human-made mathematical
models could generate and automatically produce their own quasi
independent iterations, mathematical automatons.
To announce that some robots will improvise on the UPIC graphic table
was a remarkable idea for that time: it meant that Xenakis was expecting to
display the robots’ “hand to brain” ergonomic capabilities in a very detailed
and exacting way; the effect being that the preconceived notion of robots
looking “clumsy” in their movements would be counteracted by very finely
tuned actions, immediately visible to the audience.[12]
PROJECT HISTORY, PART 3, “WHY NOT?”

The project had originally been outlined for the FIAT Foundation.[13] After
Xenakis was awarded the Fiat Foundation’s sponsored prize in November
1987,[14] specifically attributed to Les Ateliers UPIC,[15] Xenakis went to
FIAT’s automobile factory in February 1988 to view the robots and discuss
the strategy for their theatrical implementation. In order to do this, Xenakis
collaborated with Sistema Dinamo, the cultural branch of the COMAU
company.[16]
However, time ran out to meet the production deadlines of the
Bicentennial. Twelve months was just not long enough to compose,
program, finance, and produce the staging of an event of this magnitude.

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

479

HENNING LOHNER

By the time I joined the project, Xenakis had looked at several
other options for the robots, as there were three or four very similar
models around. In the meantime he had also visited Renault in France.
I had contacted Mercedes Benz and BMW in Germany. I had Letters of
Commitment to stage the ballet at the Almeida Festival in London, the
Frankfurt Feste, the Festival de Lille, the Gulbenkian Foundation in Lisbon,
Strasbourg Musica, the State Opera of Hamburg, and the Villa Medici.
Ultimately, the Robot Ballet failed for three reasons: (a) it was ahead
of its time in terms of ease of use; (b) the total cost of the project (the
equivalent of over € 1.5 million today, excluding the cost of the robots)
was prohibitive; and (c) the automotive industry’s sponsorship focus
was not aligned with our project. In a letter to me, the director of cultural
projects at Mercedes Benz symptomatically wrote: “We believe this project
to be basically worthy of our sponsorship. However, to be efficient with
our sponsorship program we have concentrated our interests in longterm directives. A single project such as yours thus does not fit into our
sponsorship guidelines.”[17] All in all, we spent a total of three years trying
to get this project going. By the end of 1991, sadly, we abandoned it.
CONCLUSION

Robots are not androids. FIG. 11 Androids are made to replicate humans
so that one cannot see a difference, whereas robots were meant to act
like humans, but were always seen as clearly different. The rise of android
science fiction culture in the media and in science was particularly
appreciated by Xenakis.[18] Xenakis chose robots and not androids
precisely because they look different than us. Although androids could
perform the same tasks, they would confuse the observer.
Xenakis was acutely aware of the moment in history when we, as a
civilization, were still “living the dream”; holding on to the analog world, but
already able to see into the future of what a digital age was promising. At
that precise moment, Xenakis attempted to display—and play—with ethical
questions that were based on recognizable patterns of experience: the
hand (arm) of the robot replacing the hand of the human.
“Finally, a kind of aesthetic, rational, and intuitively fluid of imagination
seems to circulate between light, sound, technology, theories, almost
without a break in continuity.”[19]
In view of Xenakis’s quasi universal model of composition (each
individual composition being directly related to each other, like a
mosaic[20]), his Robot Ballet provides circumstantial evidence that the
composer-inventor used his gift of computing to enable the UPIC to be at
the center of a very specific chain reaction between music and its common
mathematical basis in composing for lights, spatial hearing, and space

480

itself, through institutional, scientific experimentation at CEMAMu, through
which the UPIC came into being. Here, finally, in his Robot Ballet, the UPIC
would be and become much more than a graphic interface for a music
computer. Here, the UPIC itself becomes the centerpiece of a theatrical
world drama in which the robot’s mechanical hand replaces the human
hand, producing new music on a machine “handed” to them by the original
composer, so as to give birth to a new music that would subsequently be
perpetuated by the robots themselves.

IANNIS
XENAKIS,
ROBOTS, AND
THE UPIC—
“THE
GREATEST
ROBOT SHOW
THE WORLD
NEVER SAW”

481

HENNING LOHNER

11.

It’s an interesting paradox that in his text on robots, Xenakis included
anthropomorphic semblance although he was generally opposed to such notions
in his art. I believe this was actively accepted by Xenakis in this instance to prove
his more general point of the “ethical rivalry” between humans and robots (“An art
like music, in itself, without anthropomorphic or realistic reference. [...] [t]his is the
meaning of polytopian adventures. This is the quest for a pan-musical expression.”
Iannis Xenakis, “Polytopes,” in Festival d’Automne à Paris 1972–1982, eds. JeanPierre Léonardini, Marie Collin, and Joséphine Markovits (Paris: Messidor/Temps
Actuels, 1982), 2018 [translated by H.L.].

12.

“What interests me is that I am free to choose, my score allows me multiple paths,
I can improvise on elaborate structures, and of course mix the elements at my
convenience.” Iannis Xenakis quoted in Le Matin, June 19, 1987, “Le compositeur
à Arles: Xenakis dans l’arène” (propos recueillis par Brigitte Massin). [translated
by H.L.].

13.

“Fondation de France—Institut de France: Les Sphères du Mécénat 1987,” n.d.,
n.p. Source: CIX Archives, Fonds Després (uncatalogued).

14.
FOOTNOTES
1.
The Research Center for Musical Computing and Acoustics in Paris, founded and

See: “Le Match des Enterprises: Giovanni Agnelli,” in Paris Match, November 13,
(1987), 154.

15.

Xenakis’s original of this exposé is held in the Xenakis Archives, Dossier OM 28/5
and 32/1–8. My translation was made from the copy in my personal archives.

Email exchange between the author and Alain Després (28.05.2019) confirmed
that the grant was actually utilized by Les Ateliers UPIC for North American and
Mexico tour of the UPIC.

16.

Source: CIX Archives, Fonds Lohner, uncatalogued.

3.

Xenakis Archives, Dossier OM 32/6.

17.

4.

Iannis Xenakis, “Condition du musicien”; originally published in France Forum, no.
223–224, Oct. – Dec., 1985, reprinted in Iannis Xenakis, 1994. Kéleütha: écrits
(Paris: L’Arche, 12, 121–128). [translated by H.L.].

Letter to the author from Dr. Ulrich Kostenbader, Office of Public Relations and
Economic Policy at Daimler Benz AG, February 1, 1991.

18.

Xenakis was a big fan of science fiction literature. It was also a frequent
conversational topic of his. I fondly remember him introducing me to the
delights of the hard-boiled eggs you can buy at the bar of any Parisian café while
discussing the ending of Stanley Kubrick’s 2001: A Space Odyssey (“The Starchild
appearing at the end is just a bit too melodramatic for my taste,” is a quote I
remember that still makes me chuckle).

19.

Iannis Xenakis, “Polytopes” in Festival d’Automne à Paris 1972–1982, eds. JeanPierre Léonardini, Marie Collin, and Joséphone Markovits (Paris: Messidor/Temps
Actuels, 1982), 218.

20.

Xenakis often spoke of his entire body of work as “one piece”. See: Iannis Xenakis,
Arts/Sciences: Alloys, trans. Sharon Kanach, Hillsdale, NY: Pendragon Press), 6,
where he refers to himself as a “mosaic artisan”: “For more than twenty years
now, I have strived like a mosaic artisan, unconsciously at first, then in a more
conscious way, to fill this philosophical space with an intelligence which becomes
real by the colored pebbles which are my musical, architectural and visual works
and my writings. These pebbles, at first very isolated, have found themselves
brought together by bonds of relationships, of affinities, but also by opposition,
gradually forming figures of local coherencies and then vaster fields summoning
each other with questions and then the resulting answers. Mathematics plays
an essential role here as a philosophical catalyst, as a molding tool for forming
auditory or visual edifices, but also as a springboard toward self-liberation.”

21.

http://www.robotfestival.it/en/

22.

https://it.wikipedia.org/wiki/RoBOt_Festival

CODA

The first robot theater art project was realized in Bologna in 2008 with
the roBOt Festival,[21] basically 20 years after Xenakis’s unrealized Robot
Ballet project, and they have been going strong every year ever since, with
other events and festivals[22] following suit. As the first robot was a figment
of the imagination of the writer Karel Čapek a hundred years ago, we now
have more and more artists actually utilizing robots to make art.

directed by Xenakis.

2.

5.

Xenakis Archives, Dossier OM 32/8, “La fabrique du corps humain et les droits de
l’homme”: documentation sur des conférences et débats au Centre G. Pompidou,
mai-juin 1988”, published as Ethique médicale et droits de l’homme, (Paris: Actes
Sud, 1988).

6.

See: https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs; Maslow
stated that people are motivated to achieve certain needs and that some needs
take precedence over others. Our most basic need is for physical survival, and this
will be the first thing that motivates our behavior. Once that level is fulfilled, the
next level up is what motivates us, and so on.

7.

Although Xenakis’s last passport stated 1922 as his year of birth, for most of his
life he celebrated his birthday as being on May 29, 1921.

8.

Written in 1920, premiered in Czechoslovakia on January 25, 1921.

9.

See: https://www.robotics.org/joseph-engelberger/unimate.cfm
The Unimate was the very first industrial robot. Conceived from a design for a
mechanical arm patented in 1954 (granted in 1961) by American inventor George
Devol, the Unimate was developed as a result of the foresight and business
acumen of Joseph Engelberger, who has been called the “father of robotics.”

10.

Le Corbusier developed the Modular as mathematical proportions to improve
both the appearance and function of architecture. For images see
http://www.fondationlecorbusier.fr/

THE ROAD
TO THE UPIC

PETER WEIBEL

THE ROAD TO THE UPIC.

FROM GRAPHIC

NOTATION

TO

GRAPHIC USER

PETER WEIBEL

INTERFACE

489

PETER WEIBEL

THE ROAD TO THE
UPIC. FROM GRAPHIC
NOTATION TO GRAPHIC
USER INTERFACE
The boldest technical and aesthetic revolutions of the twentieth century
in the world of arts probably took place in music. Music is the mother
of all technological and time-based arts. Therefore, the technical
innovations became mostly evident, audible, and observable in the radical
transformations of music. Pioneers, inventors, engineers, and musicians—
unique heroes—have built countless new musical instruments to expand
the cosmos of sound. Tape recorders, oscillators, generators, transistors,
transformers, resistors, ring modulators, filters, frequency converters,
sequencers, amplifiers, switches, diodes, oscilloscopes, synthesizers,
and computers have created a new (electric, electromechanical,
electromagnetic, optoelectronic, electroacoustic, electronic, acousmatic,
digital) music. In the following treatise I shall hint at some of the most
important steps in the evolution of advanced musical practices.
FIG. 1 Dynamos of the Third Telharmonium, Cabot Street Mill, Holyoke, Massachusetts.
In Electrical World, 55, 17 (1910): 1060
FIG. 2 Cover of the radio magazine Practical Electrics featuring the Staccatone,
March 1924

PETER WEIBEL

ELECTRIC AND ELECTROMECHANICAL INSTRUMENTS

Electrical instruments generate sounds by converting mechanical energy
into electrical energy. So called pick-ups (magnets) are used to pick up
the mechanical vibration of a string. One of the first electromechanical
instruments was Thaddeus Cahill’s Dynamophon (1900), later called
Telharmonium (1906). Cahill already used the term synthesizing. In his
Washington laboratory, which was the size of a machine hall, he used
alternating current generators to produce various stages of the tone scale.
The sounds produced were transmitted to keyboards via various transformers,
filter tracks, and switches. The sound was reproduced via electric arcs, but
also via telephone lines, for example in hotels and department stores.
In 1923 Hugo Gernsback promised “Electric Music” with his
Staccatone, based on pure sine wave tones. The engineer Laurens
Hammond succeeded in miniaturizing Cahill’s gigantic generators, and in
1934 he invented the first commercially successful electric instrument, the
Hammond organ, which Hammond had actually built for use in churches.
The most famous electromechanical instrument, however, is the
electric guitar, in which the vibrations are generated mechanically by strings
and the string vibrations are picked up electromagnetically. In 1932,

491

PETER WEIBEL

George D. Beauchamp and Adolph Rickenbacher launched their famous Hawaii
guitar model Frying Pan after experiments to amplify the sound of guitars.
FILM AND THE OPTOPHONIC APPROACH TO MUSIC

FIG. 3 Raoul Hausmann, sketch accompanying his Optophone patent, 1919
© VG Bild-Kunst, Bonn 2020
FIG. 4 Raoul Hausmann, diagram of the Optophone accompanying his Optophone patent,

1926, page from the patent specification 446338 © VG Bild-Kunst, Bonn 2020

FIG. 5 Raoul Hausmann, “Vom sprechenden Film zur Optophonetik” (From Sound Film
to Optophonetics), 1923. The article was first published in G—Material für elementare
Gestaltung © VG Bild-Kunst, Bonn 2020

lm played a special role in the development of electronic musical
instruments because film had two techniques to produce sound: one
was magnetic sound, and the other was optical sound. At the end of the
nineteenth century, the light sensitivity of selenium was discovered. With
the help of a selenium cell, the current flow could be varied by the intensity
of the illumination. The changes in light were intended to control the
production of sound. One could speak of photographic image and sound
recordings. At the edge of the filmstrip visual patterns were noted, which
controlled the changes of the light. This light writing, this graphic notation
of the light at the edge of the filmstrip, not only recorded the sound,
but also reproduced it. Blackened lines were the result when light fell
through an aperture onto a light-sensitive filmstrip. This is how the sound
filmstrip, the Photophonefilm, was created. The filmstrip with integrated
soundtrack, the “Bild-Ton-Streifen” (image-sound-strip), made practicable
by Joseph Massolle, Joseph Engl, and Hans Vogt, was first shown in 1922,
in Berlin. Numerous optical sound instruments were built on this basis:
The Selenophone by the physicist Hans Thirring (1929), the Cellulophone
by Pierre Toulon (1927), the Syntronic Organ, and the Photona by Ivan
Eremeef (1934/35).
The Dada artist Raoul Hausmann, in particular, is known for his
invention (together with Daniel Broido) of the Optophone, patented in
1936, which used selenium cells to electronically translate beams of
light into sound waves, and sound waves into light. In manifestos, he
investigated ways of synchronizing perceptions of light and sound: “We
demand electric, scientific painting!!! The waves of sound and light and
electricity differ only in their length and frequency,” he wrote in his 1921
manifesto “PRÉsentismus” (Presentism).[1] In another manifesto from
1933, “Die überzüchteten Künste” (The overbred arts), he wrote: “My dear
musicians, my dear painters: You will see through your ears and hear with
your eyes …! The electric spectrophone will obliterate your ideas of sound,
color, and form.”[2]
The optophone, or spectrophone, as Hausmann called the color
piano, was operated—much like a computer—by a keyboard comprising
about a hundred keys, which corresponded to a hundred fields, each with
a different chrome gelatin relief, whose spectral line shifts were beamed
by a fluorescent lamp into a converging prism. The resulting play of colors
was projected onto a screen, while photocells converted the variations in
luminance into electronic pulses that produced audio effects via speakers.

492

SYNESTHESIA: MUSIC AND COLOR

As the manifesto of Hausmann declares, with the spectrophone, or
optophone, the dreams of synesthesia—for example, the Color Organ
(Alexander Wallace Rimington, 1893),[3] the Sonchromatoscope (Alexander
László, 1925), the Chromatophone (Anatol Vietinghoof-Scheel, 1920er), as
well as the inventions of the Optophonic Piano (Vladimir Baranoff-Rossine,
1923), and the Clavilux (Thomas Wilfred, 1936)—entered the electronic age.
The artists looked for a scientific foundation between music and
painting, between music and graphics, that was not built on color, but
specifically on light and luminance. The idea was that variations of light
could be transformed into variations of sound. The relation between
moving images, moving machines, and music machines as the basis for
future musical instruments is declared and evidenced by the title of Raoul
Hausmann’s article “From Sound Film to Optophonetics” (1923). To confirm
the special role of film in the development of new musical instruments
I would also cite Louis Favre’s La musique des couleurs et le cinéma of
1927. After systematic explorations between color and music, mostly by
painters and musicians, the relation between light and music became
the source for synesthetic experiences. Film played a decisive role in the
future optophonic turn of music. Pierre Schaeffer, the inventor of Musique
concrète in the 1950s, also emphasized the influence of cinematographic
techniques like recording and montage on his own musical practice.

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

FROM SYNESTHESIA TO SYNTHETICS

By 1930, visual research into synesthesia was over; the emphasis shifted
from synesthetic to synthetic approaches. Sound and image were produced
synthetically. The relation between sight and sound, of visual and musical
elements, was built on the relation between light and sound.
For the filmmaker Oskar Fischinger, the desire for a scientific and
technological definition of the interrelationships between sound and image
was strengthened by the advent of new instruments such as Friedrich
Trautwein’s Trautonium (1930) and Maurice Martenot’s Ondes Martenot
(1928). The Trautonium was an important step in the development of
electronic instruments. Paul Hindemith, Hanns Eisler, Paul Dessau, and
Carl Orff took a keen interest in this instrument by writing compositions
for it. But the success of the Trautonium is owed to Oskar Sala, who was a
student in Hindemith’s composition class. Sala later became famous for
his soundtrack for Alfred Hitchcock’s film The Birds (1963). In 1930 the
brochure “Elektrische Musik” (electric music) by Trautwein was published.
Trautwein already had ideas for sound reinforcement systems serving large
rooms and therefore developed towers for assemblies of loudspeakers, Phil
Spector’s Wall of Sound (1962).

FIG. 6 Alexander Wallace Rimington and his Color-Organ, 1893. In Adrian Bernard

Klein, Color-Music. The Art of Light (Lockwood and Son: London, 1926), plate 11, 190

FIG. 7 Alexander László’s notation system for Die Farblichtmusik (Leipzig: Breitkopf &
Härtel, 1925), appendix: Die 24 Farbtonnormen nach Professor Ostwald
FIG. 8 Alexander László’s switching table of his Color-Light piano, 1925. In Peter Weibel,
Enzyklopädie der Medien, vol. 2: Musik und Medien (Berlin: Hatje Cantz, 2016), 158
FIG. 9 Thomas Wilfred, Light Projection Display Apparatus, 1924, technical drawing
of the patent. Thomas Wilfred papers (MS 1375). Manuscripts and Archives, Yale
University Library

494

Fischinger, who recognized the similarity of image and sound in
general, realized about 1930 that, broadly speaking, there was no
fundamental difference between the abstract visual ornaments he used
in his films and the patterns on the optical soundtrack that produced
sound. It must be recalled that in this era, optical sound was used rather
than magnetic recording, so visual and audio information were on the same
filmstrip, with no additional magnetic tape involved. Fischinger could thus
ask: What are the sounds in the objects (patterns)? He was concerned
with the relation between sounds and shapes, i. e. what sounds could be
generated by specific shapes, the visual patterns. Through an extensive
number of experiments, his Ornament Sound experiments, Fischinger
learned which patterns produced which sounds. He photographed the
drawn “ornaments” onto the soundtrack area of the filmstrip. When played
through a projector, they were translated into a kind of music. In 1932 he
wrote about his experiments in a press release that garnered a great deal
of attention and was widely distributed under the titles Tönende Ornamente
and Klingende Ornamente (Sounding Ornaments). In the July 28, 1932
edition of the Deutsche Allgemeine Zeitung, he wrote: “Between ornament
and music persist direct connections, which means that ornaments are
music. If you look at a strip of film from my experiments with synthetic sound,
you will see along one edge a thin stripe of jagged ornamental patterns.
These ornaments are drawn music—they are sound.”[4]
Instead of music being modeled on painting, now music was being
drawn directly onto a filmstrip; and by filming the drawn soundtrack frame
by frame, the drawing could be transformed directly into the sound of a film.
This “drawn music” on a filmstrip was the beginning of the graphic notation
that lead to Daphne Oram, Iannis Xenakis, and others.
“Drawn music” is just another word for graphic notation. However, the
graphic notation of the 1950s was interpreted by a person, whereas the
graphic notation on a filmstrip was interpreted by a machine. This idea of
music as graphic notation read by a machine was known and used around
800 CE. The three famous Islamic Banu Musa brothers (Muhammad,
Ahmad, and al-Hasan ibn Musa ibn Shakir), living in early ninth century
Baghdad, had already constructed a music automaton.[5]
GRAPHIC SOUND

The novelty in the 1930s was an optical track as source, graphically
controlled variations of light waves that could turn into sound waves. Graphic
patterns were turned by various devices into sound patterns. These ideas
opened the way to the UPIC and other music machines. However, another
film artist working in Munich had a very similar idea. In 1929, the animator
Rudolf Pfenninger had developed what he called “Tönende Handschrift”

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

FIG. 10 The manufacturing of “scrolls” of Ornament Sound, Hans and Elfriede Fischinger
are at the table on the left. Staged photograph for publicity purposes © Collection of
Center for Visual Music
FIG. 11 Oskar Fischinger, Sounding Ornaments (Tönende Ornamente), ca. 1932,
detail from larger display card © Collection of Center for Visual Music
FIG. 12 Reconstruction of the Banu Musa’s music automaton according to their
description, 2015, exhibition view Allah’s Automata at ZKM | Karlsruhe © ZKM | Center
for Art and Media Karlsruhe, photo: Harald Völkl

497

FIG. 13 Rudolf Pfenninger working on his “Tönende Handschrift” (sounding handwriting).
The strips show the drawn optical sound which was copied onto the film using a camera.
© Archives Thomas Y. Levin
FIG. 14 Arseny Avraamov, Drawings of ornamental soundtracks, Moscow 1930–1931.
Courtesy of Andrey Smirnov © Andrey Smirnov Archive
FIG. 15 Evgeny Sholpo, Variophone optical discs with cut wave shapes, 1932.

Courtesy and © Marina Sholpo

FIG. 16 The Talking Paper, tape recorder with photophonic tape, Polytechnic Museum,

Moscow. Courtesy and © Peter Donhauser

FIG. 17 Ivan Eremeeff, quality and pitch film from a Photona patent, Feb. 25, 1936,
page from the patent specification of the Photoelectric musical system, no. 2031764

PETER WEIBEL

(sounding handwriting), which he presented to the public in 1932. He
drew patterns on a strip of paper, filmed them directly with a movie
camera, and incorporated them into the optical soundtrack, making him
one of the first to produce “synthetic sound.” Like the Canadian animator
Norman McLaren after him, Pfenninger drew sound directly onto the film.
Similar experiments with synthetic sound had already been conducted
in Russia by Arseny Avraamov, Vladimir Popov[6], Mikhail Tsekhanovsky,
Evgeny Sholpo, Nikolai Voinov, and Boris Yankovsky. Voinov was the first
to synthesize piano sounds with his paper sound techniques. These were
based on the synthesis of sound waves by means of paper cutouts with
the carefully calculated sizes and shapes produced by his newly invented
tool, the Nivotone.[7] In 1930 he was involved in the production of the first
drawn ornamental soundtracks (“drawn music”) at Avraamov’s Multzvuk
laboratory. In 1932 Yankovsky wrote a proposal for a patent of his own
method of sound synthesis, based on Graphical Sound techniques. In
1933 he founded the Laboratory for Synthetic Sound Recording and
invented the Vibroexponator.
These different attempts to combine light and sound, graphics and
tone, took place on a manual-mechanical level in the first half of the
twentieth century. In the second half, the paradigmatic setting of such
synthetic dreams changed; they took place on the electronic level. The
development of electronic devices for the production of music and pictures,
the development of audiovisual synthesizers capable of synthetically
generating not just sounds, but also images, resulted in a completely
new possibility: the controlled transmission of any synthetically generated
sound or image, in any modulation, through space.
Mary Ellen Bute is also an important pioneer of the new synthetic
sound and image in cinema. She started to work with oscilloscopes to
synthetically create abstract images in the 1950s. She thus called one
of her films Abstronic (1952). With oscilloscopes there was for the first
time an electronic screen instead of paper or film available for the graphic
notation of sound. This idea became very influential for computer-generated
sound or images. Bute’s aesthetic credo was “seeing sound,” or “visual
music,”[8] which would later become a slogan of the music video industry.
After World War II, following the classic period of handmade
synthetic moving images and sounds, the era of the mechanically aided,
mechanically generated synthesis of image and sound began. In the late
1960s, video spawned the first attempts involving electronic images, which
culminated in the computer-aided and computer-generated images and
sounds of today.
James and John Whitney, the pioneers of computer art, produced
between 1943 and 1944 their Five Film Exercises. They created a special

499

PETER WEIBEL

machine, which generated synthetic optical sound for the abstract Five Film
Exercises. They used a graphic matrix, which delivered different patterns,
negative and positive masks. The optical soundtrack was controlled by
light through slits connected to a moving pendulum. With this method they
created a new kind of shutter. Their matrix predated the use of presets
in the later computer technology, a kind of keyboard to choose graphical
ways of seamless transition from one scene to another instead of cutting.
In the Viennese journal Die Reihe, Informationen über serielle Musik,
the Whitneys published in 1960 the important paper “Bewegungsbilder
und elektronische Musik” (moving images and electronic music), which
is about their work and the relation between moving machines, moving
images, and music. Again, this proves my point of how important film, with
its optical devices, was for the evolution of new musical instruments. I,
myself, also worked with optical sound and made it the central feature of
my Autogenerative Sound Screen (The Magic Eye, 1969). Normally, the
optical sound is located on the filmstrip and comes from the projector. I
took light-dependent resistors (LDRs), which transform light waves into
sound waves (bright light into high pitch sound and darkness into low pitch
sounds), and put these on a transparent screen. On the screen I projected
a film with optical patterns (e.g., Kurt Kren’s short 16mm film 11/65 Bild
Helga Philipp, 1965).[9] The projected film created the sound, the source
of which was the screen. Another variation was no projection, only the
shadows caused by moving spectators in front of the screen.
OPTOELECTRICAL INSTRUMENTS

FIG. 18 John and James Whitney, Five Film Excercises, 1944, film stills © J&J Whitney /
Cinédoc PFC
FIG. 19 Image illustrating John Whitney’s essay “Bewegungsbilder und elektronische
Musik” 1960. In Die Reihe. Informationen über serielle Musik, no. 7, 1960, 62–73,
here 64
FIG. 20 Peter Weibel, Autogenerative Sound Screen. The Magic Eye, Multi Media 1,
Galerie Junge Generation, Vienna, Austria, 1969 © Peter Weibel, photo: Joseph Tandl

Another musical instrument based on the optical sound principle was the
Rhythmicon or Polyrhythmophone (1931), developed by the American
avant-garde composer Henry Cowell. Two perforated discs positioned
one behind the other rotate simultaneously and, when the holes match,
release a light beam onto a photocell. On one disc there are 16 rows with
perforations for different rhythms, for example, a keyboard illuminates
different rows and makes them audible.
Among the many mechanical and electronic devices that created the
New Music of the twentieth century, the optophonic and screen approach
(photocells, lamps, luminance, light-dependent resistors, oscilloscopes,
etc.) played a decisive role in the emergence of the UPIC.
Another important optical sound experiment is the Variophone by
Evgeny Sholpo in 1930 with which sounds without musicians could be
produced automatically without a performer. Already between 1917 and
1918 Sholpo wrote a science fiction essay “The Enemy of Music” in which
he described a musical machine, capable of synthesizing complex sound
spectra according to a special graphical score.

501

PETER WEIBEL

Yankovsky founded with Sholpo in 1939 the new Laboratory for
Graphical Sound in Leningrad. In 1944, B. N. Skvortsov developed a device
with a paper tape on which eight tracks of optical sound were printed,
called the Talking Paper.
With devices like the Photona (or the WCAU organ by Ivan Eremeeff,
1935) and Talking Paper by B. N. Skvortsov, we were then very close
to electronic musical instruments, because both paper and pitch film
are already comparable to predigital technologies like Hollerith punch
cards, binary coded paper tapes, and so on. The process of optical sound
technology allowed different forms of vibration in the form of visual
blackening patterns, for example, on transparent films or on paper, to be
converted into current fluctuations and thus into audible signals.
After the intuitive phase of synesthesia, electrical devices were
actually built that could convert light fluctuations into power fluctuations
and then into sound fluctuations on a scientific basis. This is the basic idea
for the future computer-aided scanning systems for generating sound like
the UPIC. The optical methods for generating sound, which were able to
realize any waveforms and thus timbres, culminated in the introduction of
microprocessors in synthesizers.
The Light-tone Organ (Lichttonorgel), developed by Edwin Welte in
the 1930s, was another important step towards the machine version of
graphic notation. Optical sound on filmstrips had been the solution for
recording music for a long time. Oscillation curves were transferred to the
sound discs of the organ. In the process, recordings of sound oscillations
were used and these curves were artificially generated mathematically
and graphically by sound synthesis, as Rudolf Pfenninger had already
demonstrated with his painted sounds at the beginning of the 1930s. The
future of electric music thus seemed open by way of the Light-tone Organ.
ELECTRONIC MUSIC

FIG. 21 Edwin Welte, painted oscillogram as the basis for printing on sound discs.
Courtesy and © Augustinermuseum Freiburg
FIG. 22 Filmstrip with an oscillogram. Courtesy and © Peter Donhauser
FIG. 23 Harry F. Olson, Princeton, and Herbert Belar, Palmyra, NJ, assignors to Radio
Corporation of America, a corporation of Delaware, 1958, page from the patent
specification Music Synthesizer 2,855,816. Courtesy and © Peter Donhauser

The invention of purely electronic instruments began with the invention of the
Audion Three-electrode Vacuum Tube in 1906 by Lee de Forest, who presented
his own Audion Piano in 1915. The Dynaphon by René Betrand (1928), with
whom Edgar Varèse worked, is one of the most important instruments for
the development of electronic music. In 1929, Armand Givelet and Edouard
Coupleux introduced a Synthétiseur Polyphonique, an electronic organ.
Physicist and acoustician Werner Meyer-Eppler, from Bonn, took a
decisive step by establishing the term electronic music between 1949 and
1953. For him, music, in a strict sense, was only electronic if the range
of acoustically perceptible oscillation processes is extended by electronic
sound generators, like for example oscillators. The Siemens Studio for
Electronic Music in Munich from 1955 consisted of devices for generating

502

electronic sounds. One of Carl Orff’s students, Josef Riedl, specialized in
electronic sound design. For the documentary film Impuls unserer Zeit (The
impulsion of our time, 1959), Riedl used the first electronic music produced
with binary coded paper tape.
In the 1950s the Columbia-Princeton Electronic Music Center
(CPEMC) was established at New York’s Columbia University by the
composers Vladimir Ussachevsky and Otto Luening. Experiments were
conducted with Ampex tape recorders: Speed changes, feedback, reverse
playback, and so on. There already stood the famous first programmable
synthesizer Mark II, manufactured in 1957 by the Radio Corporation of
America (RCA) in its Sarnoff Lab in Princeton. Mark II was the successor to
Mark I built by Harry F. Olson and Herbert Belar between 1952 and 1955.
Mark I consisted of twelve oscillators controlled by four perforated paper
bands, frequency counters, and filters.
From 1962 to 1966 the San Francisco Tape Music Center involved
some composers, including Ramón Sender, Morton Subotnick, Pauline
Oliveros, Steve Reich, and others. The collaboration between Morton Subotnick
and Donald Buchla resulted in the modular synthesizer Buchla 100.

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

SCANNING PRINCIPLE, OSCILLOSCOPES, AND SYNTHESIZERS

In the years between 1945 and 1948 the Canadian physicist Hugh Le
Caine had already developed a kind of manual keyboard, a touch pad with
different surfaces for different instruments, as well as for waveforms. The
instruments were assigned to sensor fields. He named this instrument
Electronic Sackbut.[10]
The touchpad anticipated the new digital interface technology. The
use of scanners was a different method to control a sensor field. It was the
astronomers who began scanning star photographs with an oscilloscope
in 1946. On the oscilloscope screen, a vertical luminous line is generated,
which is quickly deflected from left to right, like the light source of the
photocopier. A photocell converts this light into electric current. Continuing
the work of Edwin Welte and Rudolf Pfenninger, with the scanner, which
transformed optical oscillation images into synthetic sounds, a new method
for the future was invented; namely, the scanning of drawn curves by the
light of an oscilloscope display. Since the illuminated dot on the oscilloscope
screen can be moved as quickly as desired, the instrument is referred to as
a “flying spot scanner”. Today we speak of “wavetable synthesizers”.
Two composers stood out in particular, Max Brand and Daphne Oram.
Born in Lemberg, Max Brand lived in the USA from 1940. There he developed
his “flying spot scanner” in 1957. In front of the oscilloscope screen,
cardboard or metal stencils with curved shapes could be pushed around. A
concave mirror concentrated the light of the oscilloscope on a light-sensitive

FIG. 24 Hugh Le Caine at his Electronic Sackbut, with his left hand controlling the
touchpad. Courtesy of Andrey Smirnov © Andrey Smirnov Archive
FIG. 25 Max Brand’s Synthesizer. Courtesy and © Peter Donhauser
FIG. 26 Daphne Oram’s timbre waveforms. Wikimedia commons © CC BY 2.0
FIG. 27 User interface of an Oramics composition machine, showing a set of 35 mm
films, a drawing board (center), film scanners (left label), and photomultiplier amplifiers
(rear units) which convert shapes on the films into signals that control the pitch, timbre,
amplitude, etc. of the generated sound. Wikimedia commons © CC-BY-SA-3.0

505

FIG. 28 Construction of the entire Oramics machine for an exhibition at the London

Science Museum: 1. Flying spot scanner, 2. programming machine, 3. power amplifiers.
Courtesy and © Peter Donhauser

FIG. 29 Programming unit of the Oramics machine, ORAM/7/9/044. Courtesy of

Goldsmiths Special Collections & Archives © Daphne Oram Trust, photo: Fred Wood
FIG. 30 Methods of light deflection, Shibata patent. Courtesy and © Peter Donhauser

PETER WEIBEL

germanium photocell or photomultiplier. This converts the drawn sound into
a synthetically produced real sound. Max Brand commissioned a synthesizer
from Robert Moog in 1966 with many special features, the Moogtonium, a
mixture of Oskar Sala’s Mixturtrautonium and a Moog Synthesizer.
Various patents for scanners were applied for: David E. Sunstein with
his Photoformer (1949), a mask controlled feedback system; Marlin Davis,
who combined two flying spot scanners in 1947 and Douglas R. Maure, who
invented the Function Generator in 1955 together with Robert W. Kettlety.
This was a stencil in front of an oscilloscope tube together with a photocell
allows the illuminated dot on the screen to follow the contour of the shutter.
From 1962 Daphe Oram used her own Oramics, her electronic
composition machine.[11] Because conventional staff notation with five lines
beginning with a treble or bass clef was no longer adequate, she proposed
graphic notation. Composers could draw onto transparent filmstrips. These
filmstrips covered a series of photoelectric cells that generated an electric
charge to control the frequency, timbre, amplitude, and duration of a sound.
Daphne Oram used four flying spot scanners in 1967, again placing the
stencil in front of the tube and the illuminated dot scanned the contour
using the photocell. Strips on transparent films switch on various functions,
such as audio frequency, by means of light barriers. She summarizes her
research in her book An Individual Note of Music, Sound and Electronics
(London: Galliard, 1972). Her goal was to use a pencil to design the desired
curve shapes, which would then be scanned and produce audiowaves.
Two further optoelectrical scanning methods should be mentioned: Mr.
Shibata’s patent in Japan in 1936 and Evgeny Murzin’s ANS synthesizer
(in honor of composer Alexander Nikolayevich Scriabin, with whom Murzin
worked with from 1937 to 1957.)[12] In Shibata’s case, for example, a
filmstrip containing slits was scanned through a beam of light.
The ANS Synthesizer consists of five rotating discs, each with 144
individual tracks, and an opaque glass plate covered in nondrying black
mastic, which constitutes a drawing surface. A glass plate covered in nondrying opaque black mastic, which constitutes a drawing surface. The user
makes marks by scratching through the mastic, and thus allows light to pass
through at those points. In front of the glass plate there is a vertical bank
of photocells that send signals to amplifiers and filters. The glass plate can
then be scanned left or right in front of the bank of photocells in order to
transcribe the drawing directly into pitches.
GRAPHIC NOTATION—MUSICAL GRAPHICS

The turn to New Music prompted by new sound and noise generators
brought with it a crisis of conventional notation. The notation of the
score can be understood both as documentation and as the composer’s

506

instructions for the vocalists and instrumentalists. The Benedictine monk
and music theorist Guido of Arezzo is regarded as the inventor of modern
musical notation. The notation system he invented, based on four lines, is
described in his major work, Micrologus de disciplina artis musicae, which
was written around the year 1025. Before Guido, musical notation involved
symbols known as neumes, which were usually written above the words of
a text to be sung but provided no information on a tone’s exact duration
or pitch; the actual melody was passed on orally.[13] Symbolic notation
using a system of lines enabled a concept of the work to be developed
that reached its first peak with the historicism of the nineteenth century
and the great editions of the collected works of Johann Sebastian Bach,
Wolfgang Amadeus Mozart, and Ludwig van Beethoven.
With the arrival of new instruments that produced new sounds,
conventional notation was no longer sufficient. Thus the development of
graphic notation and musical graphics began in the 1930s and burgeoned
in the 1950s. Musical notation became diagrammatic drawings on the
two-dimensional surface of the paper: graphic notation. With the help of
new technologies such as oscillographs and computers, this evolved into
the graphic user interface, the touchscreen, the point of contact between
human and machine. Running one’s fingers over this surface produced
music: The instructions of notation were simultaneously their execution.
The notation became the instrument. The user was composer and
performer rolled into one.
Attempts to improve, simplify, expand, and complete classical notation
got under way in the first half of the twentieth century, as evidenced by
Oskar Rainer’s Musikalische Graphik (Musical Graphics, 1925).
The new compositional techniques and principles led to musical
graphics as a form of notation, which completely abandoned notation
based on traditional interval theory.
Three books published in the mid-1960s took stock of the new
graphic musical notation revolution. First: In 1965, the ninth volume in
the series Darmstädter Beiträge zur Neuen Musik provided a summary
of what had been presented and discussed at 1964’s nineteenth annual
International Summer courses for New Music, with composers (György
Ligeti, Roman Haubenstock-Ramati, Mauricio Kagel, Earle Brown) as well
as instrumentalists (Siegfried Palm, Aloys Kontarsky, Christoph Caskel)
voicing their opinions on the topic of musical graphics. In the essay “Neue
Notation—Kommunikationsmittel oder Selbstzweck?” (New notation: A
means of communication or an end in itself?), Ligeti defines the differences
between conventional musical notation and musical graphics very clearly:
“Fundamentally, then, ‘notation’ and ‘musical graphics’ are (to make a
more precise distinction) two different realms. […] ‘Notation’ is not a

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

FIG. 31 Oskar Rainer, Musikalische Graphik. Studien und Versuche über die
Wechselbeziehungen zwischen Ton- und Farbharmonien (musical graphics. studies and
experiments on the interrelations between tone and color harmonies, Vienna, Austria:
Jugend & Volk, 1925), cover of the first edition
FIG. 32 Hans Kohn, Walkürenritt (Ride of the Valkyries), 1920, “Nachschrift zu

Richard Wagner (Postscript to Richard Wagner),” charcoal on paper. In Oskar Rainer,
Musikalische Graphik. Studien und Versuche über die Wechselbeziehungen zwischen
Ton- und Farbharmonien (Vienna, Austria: Jugend & Volk, 1925), 63

FIG. 33 Mauricio Kagel, Transición II | für Klavier, Schlagzeug und 2 Tonbänder (score
for piano, percussion, 2 tapes, 1958–1959). Courtesy of Universal Edition A.G., Vienna,
Austria and Sammlung Mauricio Kagel, Paul Sacher Stiftung, Basel, Switzerland ©
Universal Edition (London) Ltd., London/UE13809

508

‘representation’ of musical events, nor is it a ‘depiction’ of the movements
(actions) that lead to the creation of music (although a subset of notation
can relate to such actions); rather, it is a system of signs and at the same
time a system of relationships between these signs that brings music into
being in consequence of its correspondence to musical relationships. The
visual sign system of notation corresponds to a system of auditory events;
it denotes musical relationships.
A ‘musical graphic,’ on the other hand, is not a sign system. It does
not denote musical relationships. It can, however, be a representation
(depiction) of the events that lead to the creation of music; it can also
suggest musical ideas and implementations through association.
There is an interrelationship between music and the visual
configurations associated with it. A ‘musical graphic’ gives rise to an
entirely different kind of music than a ‘notation’ does.”[14]
Kagel closely investigates the inversion, brought about by new notation,
of the classical sequence “composition—notation—interpretation”:
‘It took a long evolution for musical notation to travel from
indistinctness, vagueness, and ambiguity to precision and an ever
more indelible clarity,’ wrote Willy Tappolet in 1949 in his book La
notation musicale. As we see today, it has taken a short evolution for
musical notation to find its way back to the indistinct, the vague, and
the ambiguous. […] The transformation to which musical notation is
today subjected has at the same time blown up the traditional structure:
AUDITORY IDEA (composition) => DOCUMENTATION (notation) =>
AUDITORY PROCESS (performance).
Notation no longer functions as a mediating element, but can now
occupy the first and last positions in the configuration. The reform efforts
of the past fifteen years have had such a radical effect on our thought
processes in the area of notation that the sequence of auditory idea,
documentation, and auditory process has by now been put through every
possible combination.[15]
And Earle Brown gives the most detailed statement in The Notation
and Performance of New Music: “The ‘decorative’ value of a score is
in itself a pleasure but I am more concerned with the possibilities of a
notational system that will produce an aural world which defies traditional
notation and analysis and creates a performance ‘reality’ which has not
existed before.”[16]
He continues: “The early development of musical notation proceeded,
of course, in the direction of more and more discrete control of all the
elements and did not achieve its ‘standard’ appearance until after 1600
and its standardization of performance practice (the function of the
conductor as we know it) until approximately 1800.”[17]

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

509

PETER WEIBEL

Brown gave a great deal of thought to the idea of direct contact
between composer and sounds. This led to an engagement with notation
and its execution that can perhaps best be seen and heard in Folio—and
is further developed in Available Forms I (1961) and II (1962)—in which
the conductor seems to paint “with a palette of [...] composed sound
events.”[18] Brown mentions Charles Ives as one of the first composers
whose conceptual approach and powers of musical imagination declared
war on traditional notation. Ives’s music made a genuine effort, he says, “to
disengage infinite sound from finite graphics.”[19]
But Ives was not the only one to mark out and follow new paths. Leo
Ornstein “devised notation for ‘tone clusters’ when the standard notation
(primarily developed for triadic vertical structures) made the clusters visually
contrary to the desired simultaneity. William Russell wrote much percussion
music in the 1930s and 1940s and devised a notation for playing on the
strings of a piano with a dining fork, and for all of the eighty-eight notes of
the piano to be struck simultaneously; Henry Cowell devised notations for
playing directly on the strings of the piano, as in Banshee.”[20]
So Ives, Cowell, and the others had already attempted, in the first half
of the twentieth century, to free music from the straitjacket of interval theory
and the vise of conventional notation. And Russell had apparently invented the
prepared piano (à la John Cage). Brown engaged with the notation problem
in 1952 in order to address “the problems of mobility and immediacy […]
throughout the composer–notation–performance process.”[21]
Two other books that heralded the graphic notation revolution in
music were Das Schriftbild der neuen Musik (Notation in New Music)
by the composer Erhard Karkoschka, which was published in 1966 and
contains the author’s enlightening explanations and commentaries;
and Notations, a collection of scores by 269 living composers, which
was compiled by John Cage with Alison Knowles and published by
Something Else Press in 1969. Rather than providing direct explanations
or commentaries, the accompanying texts were, like the typography, the
result of chance operations.
In the 1950s and 1960s, the phrase “musical graphics” became a
catchall for any radical experiment in New Music. Notation changed from
an extremely precise, clearly defined specification to an action for free
performers, to the indeterminacy of chance in Cage’s work. The score
became an arena of action for the performer.
The decisive factor was the evolution of the concept of notation from
pure documentation to action notation, i.e., instructions. Whether “graphic
notation” or “musical graphics,” “notational image” or “visual music,” all
these names point to a fundamental transformation of music in the midtwentieth century in response to the advent of technological devices.

511

PETER WEIBEL

FROM GRAPHIC NOTATION TO GRAPHIC USER INTERFACE

FIG. 34 Earle Brown, December 1952, 1952, musical graphics. Brown conducted from
this score at the Darmstadt Summer Courses for Music in 1964. © Associated Music
Publishers Inc., G. Schirmer Inc / Edition Wilhelm Hansen GmbH. Courtesy of Bosworth
Music GmbH
FIG. 35 Earle Brown, Available Forms I, 1961, score for chamber music ensembles

© Associated Music Publishers Inc., G. Schirmer Inc / Edition Wilhelm Hansen GmbH.
Courtesy of Bosworth Music GmbH

The composer or musician looked for a direct contact between notation
and sound. They invented different technologies for this purpose. Graphic
notation was a decisive step in this development. A classical score is
already a set of directions that tells the musician exactly what to do with
his or her instrument at specific moments. With a score, instead of an
interpreter’s second-by-second movements (with an instrument or a
machine) being photographically recorded and described, an interpreter’s
second-by-second movements (with an instrument) are graphically
defined and prescribed. A score is a set of instructions—work instructions,
performance instructions, instructions for use—for the performer, the
interpreter. On one side is the subject, the executing musician; on the other
is the object, the machine, the musical instrument. Between them stands
the score, in which the transformations of the parts of the subject’s body
(hands, mouth, etc.) are described, transcribed, and prescribed as phase
changes in the interaction with the object (violin, etc.). Musical notation
is therefore an interface between the subject and the world of objects,
created to realize a previously imagined or intended sound in the here and
now. The traditional score is an interface between human and instrument
(machine); as such, it is interaction design. But it is also an algorithm, a set
of directions, which consists of a finite number of rules and clearly defined
instructions, and which precisely and completely describes the solution to
a problem, or rather, a composition. The question, posed by Schoenberg,
of how a composer moves from one note to the next,[22] is answered by the
algorithm of the score.
An algorithm is a sequence of instructions, formulated according to
the rules of a language, which enables a computer to execute a task. In
the same way, a score is a set of instructions, formulated according to
rules, which enables humans to execute a task. In that respect, the score
is an early higher-order machine language, an algorithm. Graphic notation
introduced ideas into music as practices before they were technologically
feasible.
Under the guidance of the composer Milton Babbitt, a variety of
electronic musical instruments were already in use in the 1950s, such
as RCA’s Mark I and Mark II music synthesizers. Another composer was
Raymond Scott, born in the United States in 1908, who was also a pianist,
sound engineer, and electronic music pioneer. Less well known are Scott’s
achievements in inventing electronic musical instruments, which he had
already begun in the 1940s. He was the founder of Manhattan Research
in 1946, which became one of the most advanced studios for the creation
of electronic music. With ring-modulators, filters and other devices, he set
up the Wall of Sound with a built-in Circle Machine, a kind of sequencer.[23]

513

FIG. 36 Raymond Scott, Wall of Sound © Reckless Night Music LLC and RaymondScott.net
FIG. 37 Raymond Scott with his Clavivox © Reckless Night Music LLC and RaymondScott.net
FIG. 38 Don Buchla sitting in front of one of his instruments © Buchla U.S.A.

PETER WEIBEL

A rotating arm, at the end of which a photocell was attached, scanned 16
light bulbs during the circular movement, the brightness of which could
be individually adjusted. Various musical parameters could be influenced
by the photocurrent. Many of Scott’s inventions anticipated modules
that would later become parts of synthesizers. For example, he invented
an early trigger delay device, portable waveshape generators, preset
programming devices, and so on. In the late 1950s, Scott also developed
instruments, such as the Clavivox, a keyboard synthesizer, an automatic
composition machine called Electronium, and an electronic sequencer he
named Karloff.
The term “synthesizer” had already been introduced, such as the ANS
Synthesizer and Mark II, but it was Donald Buchla and Robert Moog who
made modular synthesizers financially affordable in the 1960s because
they were mass-produced. The Moog synthesizer could be operated in
real time and controlled via a normal keyboard. Moog had met Scott in
the 1950s, designed circuits for him in the 1960s, and acknowledged
him as an important influence.[24] Like Moog, Wendy Carlos (born Walter
Carlos) was a student of Vladimir Ussachevsky’s from the ColumbiaPrinceton Electronic Music Center. In 1968 her record Switched on Bach
was released, which she had recorded after experiments with Moog
Synthesizers. This record became a worldwide success and popularized
synthesizers. Many other synthesizers capable of generating tones
electronically through sound synthesis followed, from Tom Oberheim to
Yamaha, from Korg to Roland synthesizers.
The modules of Moog Synthesizers consisted of signal generators,
noise generators, voltage-controlled oscillators, modulators, and so on,
all connected by a circuit board. But it was not until these synthesizers
became polyphonic—that is, able to produce more than one tone at
a time— and capable of storing settings in memory that they gained
widespread popularity and mass appeal. With the Fairlight CMI, which
was also a sampler, and the Yamaha DX7 in 1983, digital synthesizers
displaced the analog models. The Roland D50, introduced in 1987, was
particularly popular.
Today, electronic music is largely computer music that is realized
on the basis of specially programmed algorithms and self-programmed
software. This development began in the 1950s. The first digital synthesis
(Silverscale) was made by Max Mathews and Newman Guttman in 1957.
Joseph Schillinger’s theories on the mathematical basis of the arts[25]
were taken up in 1963 by Robert Baker and Lejaren Hiller to create
MUSICOMP: a computer program based on standard programming
languages such as FORTRAN, which was designed to generate musical
scores. One of these was their Computer Cantata (1963);[26] later

514

compositions bore the telling titles Algorithms I (1968) and Algorithms II
(1972). Lejaren Hiller and Leonard Isaacson wrote the famous Illiac Suite
with their own software (MusiCOMP in FORTRAN) with the mainframe
ILLIAC in 1957. In 1946, Denis Gabor, the inventor of holography, created
a kind of short-time Fourier transform, the Gabor transform, named after
him. Small sections (tone quanta, or “grains”) of a maximum length of 20
msec are cut out of the sound material and form the basic material for
new sounds. This is why we speak of “granular synthesis.” Iannis Xenakis
developed a composition theory based on grains. He used numerous
pieces of tape up to 1 second in length for his first composition Concret
PH, which was performed at Expo 1958 in the Philips Pavilion in Brussels.
Curtis Roads was the first to use the computer for granular synthesis in
1981.
However, the use of computer programs to create sounds proved to
be quite laborious, prompting a search for better forms of human-computer
interaction. In 1963 Ivan E. Sutherland published his epochal work
Sketchpad. A Man–Machine Graphical Communication System.[27] This
opened the door to the interface technology of the future. His console was
also the decisive breakthrough in music from the changeover from graphic
notation to the Graphic User Interface in music. The “drawn music” was no
longer executed on paper or filmstrips, but through direct interaction with
the computer on the screen. This procedure is also the starting point for
the UPIC, mixed with scanner techniques.
Max Mathews and Lawrence Rosler used a graphic input computer
named Graphic 1 in 1965.[28] The Graphic 1 console was a computer
system with a light pen for real-time graphic input, a keyboard for
alphanumeric input, a card reader for binary input, and a cathode ray tube
for graphic output. It also included a DEC PDP-5 Computer, a DEC 340
oscilloscope, and the appropriate hardware interfaces. Tone sequences were
represented by graphs, and compositions were produced algorithmically.
The Graphic 1 enabled the user to enter images and symbols directly
into the computer’s memory by drawing them. The drawings could also be
retrieved, deleted, duplicated, and modified. The Graphic 1 was originally
intended as a tool for designers, but a musical composition can also
be understood as a design problem: Not only can computer sounds be
designed, they can also be produced with computers, and algorithms can
be useful for creating parts of the music with the aid of the computer. A
graphic notation language was invented so that the score of a piece could
be specified as a set of graphs. The heart of the system was the program
MUSIC IV for the IBM 7094 computer.
Mathews and Rosler developed their graphical language for the
scores of computer-generated sounds based on a computer language

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

FIG. 39 (left) Ivan E. Sutherland, Sketchpad console: The first graphic human–machine
communication system, 1962. In Peter Weibel, Enzyklopädie der Medien, vol. 3:
Kunst und Medien (Berlin: Hatje Cantz, 2019), 667
FIG. 40 (right) Graphic 1 terminal, 1965. The Graphic 1 was developed in 1965 by
William Ninke (together with Carl Christensen and Henry S. McDonald) at the Bell
Laboratories computation center at Murray Hill N. J.. Lawrence Rosler and Max Mathews
utilized the terminal to develop interactive graphical music. Reused with permission of
Nokia Corporation and AT&T Archives
FIG. 41 Max Mathews and Joan Miller, MUSIC IV for IBM 7094, 1963. Synthesis
software for computer music to be used on the Graphic 1. In Peter Weibel, Enzyklopädie
der Medien, vol. 2: Musik und Medien (Berlin: Hatje Cantz, 2016), 357

517

FIG. 42 Iannis Xenakis, UPIC whiteboard © CIX Archives
FIG. 43 Iannis Xenakis, Sample Screen of UPIC 3 © CIX Archives
FIG. 44 Iannis Xenakis, UPIC – Unité Polyagogique Informatique du Centre d’Etudes
de Mathématique et Automatique Musicales, 1977. Installation view, Art in Motion,
ZKM | Karlsruhe, 2018/2019 © ZKM I Center for Art and Media Karlsruhe, photo:
Tobias Wootton

PETER WEIBEL

called GRIN. The GRIN program they used to create graphic scores divided
the console display into two sections: an area for “light buttons” and
messages to the composer, and a grid on which the music functions were
displayed.
Conventional scores are an insufficient and inconvenient way of
describing sound sequences to computers. A procedure is described
for drawing scores as graphical functions of time by using a light pen
on a cathode ray tube attached to a small computer. The information is
transmitted digitally to a larger computer, which synthesizes the sound
and reproduces it immediately with a loudspeaker. […] The graphical
programs provide great flexibility for drawing, copying, erasing, and
altering functions. Thus it is easy to develop a sound sequence by a
succession of trials. Microfilm and punched-card versions of the score
are automatically provided. In addition to being compositional tools, the
graphical scores are effective representations of the sound to a listener. In
many ways they are easier to follow than conventional scores.[29]
In Buenos Aires, Argentina, important research was undertaken
and results achieved at the Electronic Music Lab, Laboratorio de Música
Electrónica del Centro Latinoamericano de Altos Estudios Musicales,
of the Instituto Torcuato Di Tella. In 1970 Pedro Caryevschi created
Analogías Paraboloides (for tape), which was the first composition that
used the Analog Graphic Converter (Convertidor Gráfico Analógico)
invented by Fernando von Reichenbach. This device could convert
graphic scores from a paper roll into electronic control signals adapted
for musical use with analog instruments, capturing the drawn images
with a camera. At the end of a long road, there it was: drawn music
instead of notes, not drawn on paper but on a screen, consoles instead
of instruments, a user interface instead of graphic notation, a direct
physical, interpreting device instead of a human interpreter. In the 1970s,
Xenakis’s UPIC (Unité Polyagogique Informatique de CEMAMu, Centre
d’Ètudes de Mathématique et Automatique Musicales) project captured
what was historically inevitable—that is, the transformation of graphic
notation into a computer-assisted graphic user interface. The UPIC system
used an AT 386 microcomputer and a mouse-controlled graphic interface
which enabled real-time drawings to generate and store music.
Once the necessary technology was available—specifically, a
touchscreen—tones could be generated simply by touching the score.
The performer did not have to translate the notes he or she had read
into fingerings on musical instruments, but could cause the notes to
sound by pressing a finger on them on the graphic user interface of the
touchscreen. Consequently, a favorite educational installation at music
museums involves a score that is placed behind a pane of glass and also

519

FIG. 45 Masaki Fujihata, Kiyoshi Furukawa, and Wolfgang Münch, Small Fish, interactive
sound installation, 1999 © ZKM I Center for Art and Media Karlsruhe and the artists

PETER WEIBEL

marked on the surface of the glass. Visitors can activate this haptic score
with the touch of a finger, which transmits the information to a computer,
so that touching the notes produces the corresponding sounds and
melodies.
Thus the promise of the revolution in graphic notation was only
realized later by the technological revolution of the graphic user interface,
the touchscreen. Today, the use of the interface as a graphic score
takes place on countless laptops, tablets, and smartphones.[30] The
profusion of music applications in the digital realm is the product of
graphic notation since the 1950s. A pioneering role was played here by
the interactive CD-ROM Small Fish, produced by Masaki Fujihata, Kiyoshi
Furukawa, and Wolfgang Münch at the ZKM | Karlsruhe in 1999.[31]
Small Fish includes fifteen different programs for activating and modifying
audiovisual compositions. Typically, shapes move across the display,
producing tones when they collide or reach the screen’s edge. In some
of the programs, the shapes can also be moved with the mouse to affect
the analog playback of the synthetically generated sounds. The music is
created on the graphically formatted score.
Machines, from optophones to computers, were the new instruments.
This new music was not suited to traditional notation. Therefore, new
forms of notation emerged. One of these new notations was the graphic
notation of the 1950s. Through the development of computer interfaces,
the idea arose that composers can directly interact with the computer
and create all kinds of sounds and music. Musicians have drawn directly
onto filmstrips and with this optical sound created music. Now, musicians
can draw with the mouse or a pen directly on a screen, and a scanner,
instead of a magnetic pick-up, generates the sound. The digest of one
hundred years of reflections about how to formalize music mathematically
with the help of machines was the implementation of graphic notation
as graphical user interface: the UPIC. With the UPIC, the notation was
already the instrument and the scanner became the new interpreter. The
composer just had to write the graphical notation, as the composition and
the machine created the music.
Building on these ideas, I created two apps, Music Board (2011, with
Jens Barth) and Sound Writer (2016, with Chikashi Miyama), in which tone
sequence and sounds are determined or generated by the positions of the
phone in space, that is, in the electromagnetic field. When someone plays
piano, it makes no difference whether the instrument is placed on the
floor, hanging from the ceiling, or mounted on the wall. The music does not
change in any way. The music remains independent of the piano’s position
in space. In my two apps the spatial position of the instrument—that is, the
smartphone—produces the score or causes the tone sequence to change.

520

I use the electromagnetic field as a screen and the movement of the
mobile phone in space as notation, which executes the notation, the code,
and produces the sound.
The apps employ the mobile phone as a universal sound instrument
whose position in space generates the music. After all, a mobile phone is,
among other things, a kind of compass that indicates the device’s position in
the electromagnetic field. Changing the phone’s position by means of hand
and arm movements creates the “notation” and the music. The graphic user
interface is no longer touched, but produces music by itself based on its
position in space. Rather than the movements of a hand on an instrument
or a two-dimensional user interface, it is the movements of the instrument
in space that generate the score and the sound. There is no longer any
difference between notation and sound event. Notation and sound occur in
real time. Notation, instrument, and sound event become one.
The transformations of musical practices, notations, and instruments
took place in different phases: magnetic, electric, electromagnetic,
electromechanical, electronic, and digital. The decisive steps were: 1. the
change from traditional notation to graphic notation, to “drawn music”;
2. the change of “drawn music” from a sheet of paper to a screen, be it
to an oscilloscope or to a computer from hand to pen; 3. the change to
optical techniques like optical sound in cinema or scanning methods in TV
for recording, reproducing, and producing sound; 4. the change to direct
physical interaction between machine and musician.
Finally, at the end of this progress, for the time being, the machine
(computer, the mobile phone, electromagnetic devices of all kinds,
data gloves, etc.) became all at once the notation, the instrument, the
interpreter—and the composer became a programmer. Music has always
been a temporal code. Nowadays, we have the technology available to
program music directly as code. The code replaces the notation. There
is a fundamental difference between analogue codes and digital codes:
analogue codes like traditional musical notation or alphabetical code are
just instructions. Digital codes are instructions and execution at the same
time. Therefore, the old idea of live music today turns into live coding. You
write a code, which can be projected, and you listen simultaneously to the
music that is created by this code and you can even see visuals created by
the same code. The synesthetic dream is completely realized as synthetic
programming.

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

FIG. 46 Peter Weibel and Jens Barth, Music Board, 2011. Schematic drawing
of the structure of the game board with the different layers for each instrument
as well as the individual sound triggering objects: (a) a sample object
triggers a single sample; (b) a sequencer object triggers several samples
in a chain one after the other by means of an internal pulse generator; (c)
a melody object changes its position by tilting the device and collides with
other objects. © ZKM I Center for Art and Media Karlsruhe and the artists
FIG. 47 Peter Weibel and Jens Barth, Music Board, 2011, mobile app © ZKM I Center for

Art and Media Karlsruhe and the artists

FIG. 48 Peter Weibel and Chikashi Miyama, Sound Writer, 2016, mobile app. Sound
Writer is a 3D virtual music box, which can be played with simple finger gestures: Rotate
the sphere in the middle of the screen by dragging it with your finger. When the pins on
the surface of the sphere hit the tone comb, sound will be played. You can also change
the sound color and the layout of the pins by two finger gestures © ZKM I Center for Art
and Media Karlsruhe and the artists

THE ROAD
TO THE UPIC.
FROM GRAPHIC
NOTATION TO
GRAPHIC USER
INTERFACE

522

523

PETER WEIBEL

FOOTNOTES
1.
Raoul Hausmann, “PRÉsentismus. Gegen den Puffkeismus der teutschen Seele,”

16.

2.

Raoul Hausmann, “Die überzüchteten Künste,” in Hausmann, Sieg Triumph Tabak
mit Bohnen (1982), 133–144, here 144. Translated from the German.

Earle Brown, “The Notation and Performance of New Music,” Musical Quarterly
72, no. 2 (1986), 180–201, here 181. Brown added in a footnote: “I am speaking
of new notations whose primary application is toward extending the musical sound
possibilities rather than those moving toward verbal or graphic descriptions of
more theatrical activities.”

17.

Ibid., 182.

3.

Already in 1895 the British painter Alexander Wallace Rimington regarded the
color organs and color pianos as the foundations of a new kind of art: Alexander
Wallace Rimington, Colour-Music. The Art of Mobile Colour (London: Hutchinson &
Co., 1912).

18.

Ibid., 186.

19.

Ibid.

20.

Ibid., 188.

Oskar Fischinger, “Sounding Ornaments,” (1932) in Optical Poetry: The Life and
Work of Oskar Fischinger by William Moritz (Bloomington: Indiana University Press,
2004), 179–181, here 179.

21.

Ibid., 192.

22.

Cf. Arnold Schoenberg, “Composition with ‘Twelve Tones’ (1),” in Style and Idea:
Selected Writings, ed. Leonard Stein, trans. Leo Black (Berkeley: University of
California Press, 2010), 214–45.

23.

Raymond Scott anticipated with this term the production formula Wall of Sound of
Phil Spector.

in Texte bis 1933, ed. Michael Erlhoff, vol. 2, Sieg Triumph Tabak mit Bohnen
(Munich: text+kritik, 1982), 24–30, here 27. Originally published in De Stijl 4, no. 9
(1921), 136–43. Translated from the German.

4.

5.

See Alllah’s Automata: Artifacts of the Arab-Islamic Renaissance (800–1200), ed.
Siegfried Zielinski and Peter Weibel (Ostfildern: Hatje Cantz, 2015).

6.

Vladimir Popov invented various noise tools for his Noise Orchestra in the 1920s.

7.

Andrey Smirnov, Sound in Z. Experiments in Sound and Electronic Music in Early
20th Century Russia (London: Walther König, 2013), 182.

24.

Tom Rhea, “Electronic Perspectives: Raymond Scott’s Clavivox and Electronium,”
Contemporary Keyboard, February (1981), 72.

8.

“Bute made a series of Visual Music films which she called ‘Seeing sound’ […]
Rhythm in Light, 1934; Synchromy No. 2, 1935; Dada, 1936; Parabola, 1937;
Escape, 1937; Spook Sport (animated by Norman McLaren), 1939; Tarantella,
1940; Polka Graph, 1947; Color Rhapsodie, 1948; Imagination, 1948; New
Sensations in Sound, 1949 (RCA Commercial); Pastorale, 1950; Abstronic, 1952;
and Mood Contrasts, 1953.” “CVM’s Bute Research Pages: About the Films /
Retrospective Program / Upcoming & Recent Screenings,” Center for Visual Music,
www.centerforvisualmusic.org/Bute.htm.

25.

Joseph Schillinger, The Mathematical Basis of the Arts (New York: Philosophical
Library, 1948).

26.

See Lejaren A. Hiller and Robert A. Baker, “Computer Cantata: A Study in
Compositional Method,” in Perspectives of New Music 3, no. 1 (1964), 62–90;
and also Lejaren A. Hiller, Informationstheorie und Computermusik. Zwei Vorträge,
gehalten auf den “Internationalen Ferienkursen für Neue Musik” Darmstadt,
1963, trans. Peter Jansen, Darmstädter Beiträge zur Neuen Musik 8 (Mainz:
Schott, 1964).

27.

Ivan E. Sutherland, “Sketchpad. A Man-Machine. Graphical Communication
System,” in Proceedings of the Spring Joint Computer Conference, Detroit,
Michigan, (May 1963), 507–524.

28.

Max V. Mathews and Lawrence Rosler, “Graphical Language for the Scores of
Computer-Generated Sounds,” in Music by Computers, ed. Heinz von Foerster and
James W. Beauchamp (New York: John Wiley and Sons, 1969), 84–114, here 107.

29.

Max V. Mathews and Lawrence Rosler, “Graphical Language for the Scores of
Computer-Generated Sounds,” in Music by Computers, ed. Heinz von Foerster and
James W. Beauchamp (New York: John Wiley and Sons, 1969), 84–114, here 84.

30.

At the 2013 AppArtAwards ceremony at the ZKM | Karlsruhe, Matthias Krebs, an
app musician and the founder of DigiEnsemble Berlin, gave a lecture entitled “App
Musik: Kunstwerke, Sound Toys und App Instrumente” about the potential uses of
smart devices for producing music.

31.

See also Furukawa, this volume.

9.

Kren’s film is based on the print of an Op art picture by Helga Philipp. The painting
or parts of the painting were filmed in single frames.

10.

For a discussion of Hugh Le Caine’s Spectrogram see Smirnov, this volume.

11.

For a more detailed discussion of Daphne Oram and her work, see Smirnov, this
volume.

12.

For a more detailed discussion of Evgeny Murzin, see Smirnov, this volume.

13.

Guido of Arezzo inspired the name GUIDO Music Notation, a digital format for the
representation of music scores.

14.

György Ligeti, “Neue Notation – Kommunikationsmittel oder Selbstzweck?”
in Notation Neuer Musik, Darmstädter Beiträge zur Neuen Musik 9, ed. Ernst
Thomas (Mainz: Schott, 1965) 35–50, here 36–37. Translated from the German.

15.

Mauricio Kagel, “Komposition – Notation – Interpretation,” in Notation Neuer
Musik, ed. Ernst Thomas, Darmstädter Beiträge zur Neuen Musik 9 (Mainz:
Schott, 1965), 55–63, here 55, 59. Translated from the German.

THE UPIC
AND
UTOPIA

KIYOSHI FURUKAWA
CHIKASHI MIYAMA
VICTORIA SIMON
JULIAN SCORDATO
KOSMAS GIANNOUTAKIS

THE
UPIC AND

KIYOSHI FURUKAWA

UTOPIA

531

KIYOSHI FURUKAWA

THE UPIC AND UTOPIA
THE AIM OF THIS ESSAY

We are able to infer that Iannis Xenakis’s creative acts are based on
visual, spatial, and graphic ideas, which derive from his experiences as an
architect. The UPIC (Unité Polyagogique Informatique du CEMAMu), which
generates sounds from visual images, was developed from his conception
in 1977. Utilizing an electromagnetic pen and a tablet to input the visual
images, which are then directly converted into sounds, this system is
a complete departure from traditional relationships between the score,
instruments, performance, and composition.
In 1999, we developed Smallfish FIG. 1, 2 [1], an interactive artwork
which generates music, in the technological environment at the time.
Recalling the discussions of the relationships between composition, score,
instruments, and audiovisual expressions that my team and I had with
regard to Smallfish, I would like to add our perspectives of today, and
unveil the potential of the direction the new artistic expressions can take.
SMALLFISH

KIYOSHI FURUKAWA

In 1999, I collaborated with media artists Masaki Fujihata and Wolfgang
Münch at the ZKM | Institute for Music and Acoustics (IMA)[2] to develop
Smallfish, an interactive artwork which generates music with a personal
computer. We produced it on a CD-ROM, and released it through the
publisher Hatje Cantz. This interactive artwork enabled us to control graphic
objects on computer screens with a computer mouse or fingers ,[3] which in
turn added alterations to the musical structures and the music generation
algorithms. This created an environment for audiences to enjoy visually the
alterations of the movements of the objects with the generated music.
Smallfish’s graphic user interface (GUI) screen can be thought of
as a musical score, because visual objects directly generate the music.
However, it can also be defined as a musical instrument, since users
can directly and intentionally control the objects, which results in the
interactive generation of music.
Additionally, the structures of the visual objects not only act as a
musical generator, but also as aesthetic targets alongside the music that
the users experience. We called this relationship between the music and
the visual structuration of the control objects Active Score Music; however,
we did not discuss in depth the new correlations of the score, visual
expression, and the instruments. I remember explaining Smallfish as a
musical instrument, just like the piano, in the discussion about its relation
to the German collecting society and performance rights organization

533

KIYOSHI FURUKAWA

GEMA with Johannes Goebel, who was then the director of the ZKM | IMA.
Today, this software is also sold as an iPad app, and this app is controlled
with the fingers.
MUSICAL SCORE AND INSTRUMENT

Before I consider the issues of the new relationship of the musical score
and the instrument in Smallfish, UPIC’s visual image of the GUI as a
functional musical score, and the possibilities and the potential that we
see of the GUI as a musical instrument, I would first like to set out some
preliminary ideas.
A musical score has been the product of the maturation and the
complications of musical cultures.[4] However, we do find music with
advanced complexity and musical theory, such as the traditional Indian
repertoires, which has an oral tradition, but no tradition in notating
scores.[5] From such cases, we can conclude that a musical score is not
indispensable to all musical cultures.
A musical score is believed to have been some sort of a memo for
performance purposes in the earlier stages of its development; however,
in Western music from the Middle Ages onward, a musical score was a
crucial tool for composition. It has been used for purposes of conservation
and elaboration of musical ideas, as well as a medium to deliver the ideas
to the performers. It is undeniable that the musical score in Western music
has had an important role in the development of culture.
Musical scores are presented in various forms: scores with visual
representations like lines of sound patterns and the movement of the
sounds, other scores with symbols and characters representing the sound
patterns, or the ones indicating their meaning and the aim of the music
with characters, symbols, or words. When we conceptualize the GUI’s
visual image in the UPIC as a musical score, it is close to the scores where
it notates the movements of the sounds with a line. However, when we
include the factors that the UPIC’s GUI can be thought of as an instrument,
we can see that it is close to a type of a tablature score,[6] a score that
reflects the instrument’s structure and the technicalities.[7]
FROM SCORE TO INSTRUMENT

FIG. 1 A screenshot of a constellation in Smallfish, 1999 © Kiyoshi Furukawa
FIG. 2 A screenshot from the "Factory" in Smallfish, 1999 © Kiyoshi Furukawa

The first version of the UPIC was developed in 1977, and until 1980, it was
hardware which used an electromagnetic pen and a tablet to input the data,
and also to record and regenerate the digital-to-analog converted sounds.
Users operated the system with an input pen to create arcs, where
a freely drawn line on the score acted as a trajectory, and multiple line
drawings created with the arcs were integrated into a musically higher
unit called pages. The visual image that is then expressed on the UPIC

534

screen acts similar to a graphic score; however, as the sound is generated
throughout the visual image itself, it is not a musical score by definition. In
addition to that, after the sound is generated, the sound can be recorded
on tape, waiving in the end the necessity of the visual image in further
performances. However, we can say that the visual image holds the
technicalities to be defined as a score as a compositional tool, due to the
fact that, before the final version of the sound is actually recorded on tape,
the visual image can be fixed as many times as one likes. By the mid1990s, the input source of the Windows software became the mouse, and
real time processing has become a possibility. Due to this fact, there was
a massive improvement in the working environment for composers, as we
could listen to the sound that resulted from the graphics as many times
as we liked, and repeat the compositional process on the system. From
here, we can state that the idea of the UPIC as a musical instrument has
unquestionably come close to reality.
THE INNOVATIVE ASPECTS OF THE UPIC

In the 1950s and the 1960s in the realm of contemporary music,
graphic representation of the music, such as graphic notation, became
commonplace in the scene. This phenomenon is due to the fact that much
electronic music, and music that cannot be expressed on the traditional
five-line scores, is no longer a rarity. György Ligeti’s Volumina for Organ
(1962), where he reflected his electronic music experiences, as well
as Krzysztof Penderecki’s graphic notations for the clusters he used in
his series of orchestral works, are just two of the many examples. The
founding principles of the works by Xenakis were decisively influenced by
his experiences as an architect, and I believe that his ideas are graphically
represented. From these examples mentioned, the graphic ideas of the
UPIC and the GUI’s visual image in the 1970s are not novelties. Rather,
the innovative aspect of the UPIC is the users’ direct control of inputting
the line-curve with a pen, and that the composite of the sounds are
generated from the visual image. Namely, this is the contrast between this
and the traditional notational system, where an instrumentalist performs
the score, and where the composer and the performer are assigned
divided tasks. Moreover, it can be contrasted with the computer music
at the time, for example, with the scores of Music-N, a popular family
of computer music programs, where the idea of a traditional sound is
utilized to notate the note list, and is defined and bundled as a traditional
instrumentational unit. In the case of the UPIC, the musical score and
the instrument coexists within the visual image, and it can be said that
the UPIC has excavated new potentials for instruments as a musical
score. This highlights the fact that the UPIC exhibited foresight regarding

THE UPIC
AND UTOPIA

535

KIYOSHI FURUKAWA

the issue of the relationship between a musical score and an instrument,
prior to my development of Smallfish in 1999. Here, the visual image of a
curve that was produced by a human’s physical act (input with free hands)
directly produces sounds. Here, the visual image of a curve is a medium
which converts the human physical act into sounds, but the conversion
itself is rather simple; the vertical axis of the trajectory represents the
pitch, and the horizontal axis represents the flow of time. In principle, the
system possesses the aspects of a musical instrument where a physical
act produces some kind of sound, as the system does not require the user
to have any prior musical knowledge, and the sound generation is possible
without processing by musical ideas. Of course, this simplicity is the result
of many expressive and musical abstractions.
BEYOND MUSICAL SCORE AND INSTRUMENT

As stated above, the input of data in the UPIC using the mouse, as well
as the possibility of real time processing in the 1990s, has found itself
representing an instrumental face. With the advances of technology today,
the techniques of integrating humans, GUIs, and sound has become
nothing extraordinary. As for myself, I have utilized the technology to
develop Smallfish, as well as its successive mobile app software Mucca
in 2017.[8] However, although I have pursued the story to this point, I
doubt the validity of applying the traditional concept of musical scores and
instruments to computer programs like the UPIC or Smallfish. We should
not merely apply new technologies to software, but should consider and
envision the new situation from diverse perspectives.
THE UPIC AND COMMUNITYWARE

We can infer that the UPIC has utilized the GUI as a musical score to
open new doors to possibilities for creative processes. However, the first
UPIC was implemented by Guy Médigue according to Xenakis’s ideas,[9]
for he himself says that the system was not built for composition, but
to grant a field of freedom.[10] As such, it was something that was
distanced from his compositional concepts. Nevertheless, the simplicity,
the directness of the input relations, and concreteness of the GUI were
taken into account during the development of UPIC. FIG. 3 The fact that
they were able to execute a workshop is meaningful, considering that
anyone without any basic knowledge of music can experience the creative
processes of electronic music, thus it was designed as a constituent of an
educational system. From today’s perspective, we can discard the premise
of “composer” or “musical work,” and imagine a system where a person
can make and enjoy sound using the GUI. We can catch a glimpse of the
utopia of what music has to offer. I created Smallfish not in order just to

537

KIYOSHI FURUKAWA

appreciate composers’ works, but to connect the process of art and the
process of making sound as one, and, moreover to build a bridge between
humans and community art. We can state that this was made possible
with the GUI used in Smallfish, and its model came from the UPIC.
PROSPECTS

Nowadays, automatic composition is not only used in computer music,
but also in entertainment contexts. I also utilize artificial intelligence
algorithms to develop a system of automatic composition called
Soundroid.[11] However, I am concerned about the passivity of the notion,
because the prerequisite suggests that music exists merely to be listened
to. There is joy in using one’s body, and performing on an instrument, as
well as in creating music, both as a composer and as a noncomposer. I
believe that today, the possibilities of the UPIC as a musical instrument
are essential. Technology is building and extending its possibilities day by
day, and I contemplate there will be immense developments. Regarding
the improvement of this technology, I hope that, without the idea of a
composer, a musical work, or an art work, a structural opportunity will
arise to enjoy electroacoustic music interactively, as if one was playing an
instrument. I am greatly interested in and enthusiastic about the potential
of the idea of the UPIC, as well as the way music is headed, from the
knowledge I have acquired through the development of Smallfish. This
might lead music to its primordial form, or it might create a whole new
structure of what music is and can be.
FOOTNOTES
1.
https://zkm.de/en/publication/small-fish

FIG. 3 Iannis Xenakis with Japanese pupils during the French Contemporary Music
Weeks, Yokohama, Japan 1984, UPIC graphic table in the background © CIX Archives

2.

https://zkm.de/de

3.

https://zkm.de/de/publikation/small-fish-app

4.

Die Musik in Geschichte und Gegenwart, vol. 7, (Kassel: Bärenreiter, 1997) 284–285.

5.

The New Grove Dictionary of Music and Musicians, 2 ed., vol. 12, (Oxford: Oxford
Universtiy Press, 2001), 162–168.

6.

Ibid., vol. 24, 905–906.

7.

In a wider context, the Western five-line score can be thought to have correlations
with the tablature scores. In brief, the notes on the five-line scores can be set
visually on the location of the key on a keyboard instrument, such as a piano.

8.

https://mucca.town/en/index.html

9.

François Delalande, “Il faut être constamment un immigré,” in Entretiens avec
Xenakis, (Paris: Buchet/Chastel, Institut national de l’audiovisuel, 1997), 142.

10.

Iannis Xenakis, Formalized Music [1971], (New York: Pendragon Press, revised
edition 1992), 146–147.

11.

https://soundroid.com

THE UPIC

CHIKASHI MIYAMA

2019

543

CHIKASHI MIYAMA

THE UPIC 2019
Around forty years have passed since the birth of the original UPIC system.
Today, Most of us have a smartphone in our pockets, communicate on
social networking systems, and talk to AI-backed smart speakers. Many
things that were technically impossible in 1977 are possible today.
In this article, we will analyze the UPIC system from the perspective of
a software developer, and introduce other UPIC-inspired systems realized
with the technologies evolved in the last forty years. Based on them we will
attempt to answer a hypothetical question: “What can we do if we make a
brand-new UPIC-like system from scratch with the technologies available
today, preserving the objectives that Xenakis envisioned forty years ago?”
THREE ELEMENTS OF THE UPIC

The original UPIC system can be interpreted as a combination of three
main elements; namely, Canvas, Player, and Instrument. The canvas is
an interface that allows composers to draw lines and shapes. The player
is the mechanics that read the graphics on the canvas at a specific
speed. The instrument is the component that generates the actual audio
signals. In this section, we will discuss the technical aspect of these
three elements of the UPIC individually.
CANVAS: RASTER GRAPHICS

In many cases, a computer stores the information of an image as a
collection of colored pixels. For example, a photo taken by a high-end
smartphone in 2019 consists of more than ten million pixels. Since
computers handle data of colors as a combination of numerical values, an
image is fundamentally a collection of an enormous amount of numbers
for them. These pixel-based images are called raster graphics.
This means that in raster graphics we have to deal with ten millions
of pixels if we draw a high-resolution image by hand. Raster image editing
applications often provide virtual tools, such as pen, brush, sponge, and
eraser that imitate the functionalities of painting tools used by painters in
the real world because it is practically impossible to manipulate and adjust
the numerical values of such a tremendous collection of pixels one by
one. With these tools, users can edit and process the numerical values of
countless pixels intuitively. FIG. 1

CHIKASHI MIYAMA

VECTOR GRAPHICS

In contrast to painting, we focus more on abstract and mathematical
properties of objects in the image when we draw geometrical shapes,

544

THE UPIC 2019

diagrams, or blueprints and we use different tools such as compasses,
rulers, and protractors for drawing them.
In such a case it is more efficient if the application comprehends
more abstract properties of the graphical elements, such as the length of
lines, the steepness of curves, and the size of polygons, and manipulates
pixels automatically based on those high-level data. Roughly speaking, this
approach is called vector graphics as opposed to raster graphics.
The benefit of this approach is that the application allows the users
to change flexibly the properties of lines and polygons after drawing them,
and encourages them to iterate trial and error at the higher abstraction
level. FIG. 2
GENERATIVE GRAPHICS

In vector graphics, the software generates pixels automatically based
on the provided properties of lines and polygons, but the power of
automation could be exploited further; we can also automate the process
of generation. FIG. 3 shows one thousand circles with different sizes and
colors automatically generated by a few lines of JavaScript code shown
on the left, utilizing some functions of p5.js, a library for creating images
and interactive experiences. Images created by this sort of program
are called generative graphics and this approach provides artists with
unprecedented systematic ways to create new images.[1] We can alter
the visual impression of the images dramatically by slightly changing the
parameters in the source code. For example, by just adding one zero at
line 4 in the source code, we can alter the number of circles in the image
from a thousand to ten thousand. This approach would be also a positive
addition in the context of the UPIC, in view of its counterpart in the musical
context, such as algorithmic or computer-aided composition.
AN IDEAL DIGITAL CANVAS FOR THE GRAPHIC NOTATION

What is the best canvas implementation for the UPIC-like system of
the three approaches mentioned above? On the one hand, the canvas
has to provide a way to draw lines and shapes as simply, directly, and
intuitively as possible because one of the objectives of the system is
musical education. On the other hand, it has to accompany the abstract,
mathematical, and structural thinking of professional composers. In
addition, the newly emerging generative approach would be an expected
feature for many artists. Because of these diverse requirements, it is
anticipated that the canvas implementation of a UPIC-like system will be
highly challenging for developers.
The original UPIC did provide ways to process images at a higher
abstraction level to some extent. Various modes, such as freehand,

FIG. 1 A raster image edited with open source software Gimp, 2019, screenshot. Various
virtual tools for drawing are available on the left. © Chikashi Miyama
FIG. 2 Interface of the Affinity Designer software, 2019. This vector graphic software
stores properties of each line and shape (e.g. color, thickness, length etc.) and lets the
users change them with the inspector on the right. Screenshot © Chikashi Miyama and
Affinity Designer UI copyright of Serif (Europe) Ltd, used with permission
FIG. 3 One thousand circles with different colors and sizes generated with the JavaScript
library p5.js, 2019, screenshot © Chikashi Miyama

546

segmented lines, are available for users and the drawn shapes can be
rotated or mirrored afterwards in the original system.[2] IanniX, a new
UPIC-inspired software launched in 2000, allows the users to create
graphics in the vector approach by default; all basic lines are stored as
Bézier curves even if the lines are drawn in the freehand mode in
IanniX.[3]
Not only the original UPIC and IanniX systems but also most of the
relevant applications process images basically in the vector approach;
the applications are aware of the properties of drawn objects and allow
the user to freely manipulate them later.
However, the potential of the pixel-level processing should not
be disregarded in the early stage of the software design. The original
UPIC offers a way to use recorded sound samples in the composition.
What would prevent us from doing the same thing in the visual world?
If the system were required to provide a way to use photos as parts of
graphical notation, and offers a way to collage them with standard linebased notation, the vector graphic-centered software design must be
revised to some extent.
The generative approach could be combined with both vector
and raster approaches relatively smoothly since they are essentially
automation of multiple operations. In fact, IanniX features an editor
in which the user can write JavaScript code for generating graphical
elements programmatically. However, the generative approach inevitably
involves some sort of coding that may contradict the original goal of the
UPIC system.
PLAYER

To listen to stored music on media, such as the disks of a music box, LP
records, or magnetic tapes, we need a mechanism to access a particular
part of the particular medium, for example, the teeth of a music box, the
stylus of an LP player, and the tape head of a magnetic tape player. In
this section, we will call all those mechanisms simply playhead.
Even in this digital era, playheads still exist. Digital Audio
Workstation (DAW) software shows playheads as a long vertical line in its
window for indicating a part currently being accessed, and it allows us to
playback from the middle of a piece by changing the position of it.
The original version of the UPIC system required a significant
amount of time for converting the drawn graphics into audio data.
However, by the end of the 1980s the system gained a capability to let
composers move the playhead freely and play music in the graphical
score in real time.[4] This technological development dramatically
changed the workflow of UPIC composers.

THE UPIC 2019

547

CHIKASHI MIYAMA

If a human musician plays the graphic notation in the UPIC with an
instrument, she or he moves their eyes as the playhead moves. In this
sense, a playhead symbolizes the eyes of musicians. If multiple human
musicians play a graphic notation, they may interpret the score differently.
We could also implement such differences of interpretation in the system,
for example, by changing the behavior and the shape of a playhead. Below
we will introduce a few different types of playheads implemented in UPICinspired systems. FIG. 4
CURVED PLAYHEAD

Rotating Scores (2016) by Ludger Brümmer and Anton Himstedt is an
interactive sound installation in which the system allows participants to
design the shape of the playhead freely with a mouse.[5] As soon as the
participant draws a playhead on a screen, it starts moving automatically
on the prestored graphic scores. When the playhead collides with the black
part of the score, the system produces sounds with different pitches based
on the part of the playhead that collided. Thus, the musical outcome differs
significantly according to the shapes of the drawn playheads. FIG. 5
MULTIPLE PLAYHEADS

In most systems with a playback function, only a single playhead is available;
only one part of the score can be accessed at a time. What if we could
use more than one playhead to access several different parts of a piece
simultaneously? Rhythm of Shapes (2016), by the author, is an interactive
installation that takes a photo of the participants, extracts the contours
of objects in the photo, and uses them as the elements of a graphic
score. Immediately after the contour extraction, multiple synchronized
playheads with different speeds and sizes move on the score and generate
sound when they collide with the extracted lines. As a result, the system
generates a gradually changing, complex rhythmic texture.[6] FIG. 6
PARTICLE PLAYHEAD

Rhythm of Shapes uses a maximum of six playheads at the same time.
However, with the computational power of modern hardware, it is also
possible to employ a massive number of playheads, say one hundred, at
the same time. In this case, manipulating the movement of each individual
playhead becomes cumbersome; it would be more practical to control meta
parameters, such as randomness or activeness, and control the behavioral
tendencies of playheads through these parameters.
Chris Carlson implements this idea in an iOS app called Borderlands
Granular (2015), in which randomly emerging particle-like playheads play
the waveform placed in the background.[7] FIG. 7

FIG. 4 The free DAW software Audacity, which visualizes the playhead as a vertical green
line, 2019, screenshot © Chikashi Miyama and 1999-2019 Audacity Team

FIG. 6 Chikashi Miyama, Rhythm of Shapes, 2016, screenshot. The interactive sound
installation takes a photo of the viewer and extracts the contours in it. Subsequently, multiple
playheads of different sizes and speeds move vertically and horizontally on the processed
photo and generate sound when they collide with those contours. © Chikashi Miyama

FIG. 5 Ludger Brümmer and Anton Himstedt, Rotating Scores, 2016, screenshot. The
interactive sound installation plays the graphic score in six different ways according to the
shapes drawn by participants. © Ludger Brümmer, Anton Himstedt and Chikashi Miyama

FIG. 7 Chris Carlson, Borderlands Granular, 2012-2020, screenshot. This iOS app
displays multiple playheads as red and white dots which playback the waveform behind
them. © Chikashi Miyama and Chris Carlson

550

REACTIVE PLAYHEADS

Although all the above-mentioned playheads either move constantly in
a particular direction or do not individually change their behavior during
their lifetime, it is also possible to implement a playhead that reacts to a
specific event, such as a collision with other objects. The mobile app Small
Fish (2011) by Kiyoshi Furukawa, Masaki Fujihata, and Wolfgang Münch
employs such reactive playheads.[8]
As these unique variations of playheads show, the functionality of
playback can be implemented in a variety of ways. Although we tend to
focus more on input devices and sound synthesis in the context of the
UPIC, playback mechanics also assume an important role for characterizing
individual systems.
INSTRUMENT: SOFTWARE SYNTHESIZER

Like images, sound is also a collection of numbers for a computer. In the
case of sound, it interprets sound waves as a collection of audio samples
and plays back sound by sending these samples to speakers via a digital to
analog converter (DAC).
Just as we do not change the value of each pixel one by one in image
editing applications, we do not usually manipulate audio samples manually
in audio programs. Most of the time we control parameters of software
synthesizers, such as pitch, timbre, loudness, or vibrato, and let them
generate audio samples automatically according to the parameters, just as
the virtual brushes and pencils generate pixels in raster graphic software.
INTERNAL SYNTHESIZER OF THE ORIGINAL UPIC

A software synthesizer was also embedded in the original UPIC and was
one of the most unique features of the system. It allowed composers
to draw waveforms and envelopes on the canvas and use them in a
composition. With this feature, the system enabled artists to access not
only the macrostructure but also microstructure of their compositions with
a consistent approach; namely, drawing.[9] However, today a tremendous
number of software synthesizers are available and some composers
develop their own personalized software instruments with dedicated audio
programming environments such as Max or Pd. It is not surprising that
they desire to connect the UPIC Canvas and Player with their own sound
generators instead of its internal one.
THE MAPPING BETWEEN GRAPHICS AND SOUND

In terms of software design, one of the greatest challenges of developing
UPIC-like software is to determine its mapping; that is, how the properties
of graphical elements are associated with the properties of sound.

THE UPIC 2019

551

CHIKASHI MIYAMA

Although the page view of the original UPIC system followed a western
style of notation by mapping the X-axis to time and the Y-axis to pitch, it
is also technically possible to map these axes to cut-off frequency of a
filter, predelay time of a reverb, or other numerous parameters of audio
processing modules. Furthermore, it is also viable to employ a scaling factor
or a particular transfer function as implemented in the original UPIC[2] and
those mappings can be changed during the playback.
For these issues, the connectivity to external synthesizers and the
configurability of mapping, IanniX proposes a drastic solution that will be
discussed later.
TOWARDS THE UPIC 2019

In this section, an outline is given of the technological evolution in the
past forty years in conjunction with the various descendants of the UPIC
system and the future possibilities of UPIC-like systems with the emerging
technologies will be discussed.
SPEED AND CAPACITY

The three core components of a computer are its processing unit, memory,
and storage. Their speed and capacity have evolved dramatically in the past
forty years and enable us to process audio in real time. Today the use of
DAW software, such as Logic, ProTools, Cubase, and Reaper are essential
for audio production and these applications have replaced dedicated
hardware, such as reverb racks, synthesizers, multitrack recorders, and
samplers. Along with this, graphic-based audio controls, such as automation
curves, piano roll editor, and waveform editor, have become widespread. It is
notable that many composers and audio engineers today are accustomed to
controlling sound using lines and curves, like in the UPIC system. FIG. 8
INPUT DEVICES

If we draw a picture on a computer display with a mouse, we lose
a significant amount of information. Firstly, computers do not store
information beyond a specific resolution. Secondly, a standard mouse
detects its position only 125 times per second. Thirdly, a mouse does not
deliver any auxiliary data such as the pressure on a pencil or the angle of a
brush that may characterize individual strokes.
Peter Nelson points out in his article that the use of a mouse for
drawing a graphic score produces poor user experiences and the size of the
drawing board significantly influences the clarity of connection between the
intellectual and the corporeal.[10]
Today, a large full-color tablet such as Wacom Cintiq Pro, allows us
to draw directly on a sizable colored display with a dedicated stylus.[11]

553

CHIKASHI MIYAMA

The tablet detects the pressure and the angle of the stylus and lets us
use these data for controlling details of the strokes, such as the opacity
of the color and the thickness of the lines. By mapping these properties
of strokes with audio parameters we can achieve a closer correlation
between graphics and sound, though it may require composers to have a
certain level of drawing skills to take full advantage of it.
THREE-DIMENSIONAL GRAPHICS

The computational performance of video cards and graphics libraries, such
as OpenGL or DirectX, have improved significantly in the past few decades.
Today, they allow us to render very detailed three-dimensional graphics in
real time. Consequently, we have the possibility to draw graphic scores in
three-dimensional space even with a small laptop or a tablet.
IanniX, the software mentioned previously, internally processes all
lines as lines in a three-dimensional space, even if the user utilizes them
solely as components of a two-dimensional score. This fact demonstrates
how trivial it has become to render polygons in a three-dimensional
space with modern hardware. FIG. 9
STANDARDIZATION

FIG. 8 Waveform editor, automation curves, and piano roll editor of software Reaper by
Cockos Incorporated, 2019, screenshot. The Graphic User Interface (GUI) of modern
DAW employs various graphical ways to visualize musical properties. © Chikashi Miyama
and 2004-2019 Cockos Incorporated
FIG. 9 Three-dimensional graphic score rendered in the graphical open source sequencer

software IanniX, 2019, screenshot © Chikashi Miyama and IanniX Association

The original UPIC system could be categorized as an E2ES (end-to-endsolution). In other words, the system offers everything needed for the
composition; other external components are not required.
On the one hand, an E2ES approach is more practical for users
because they do not have to prepare additional components to compose
musical works. On the other hand, this approach could be inflexible
because it does not allow users to use external components, such as
software synthesizers by other developers, instead of the internal one.
Why is it impossible to replace UPIC’s internal component with an
external one? Roughly speaking, this is because external synthesizers
are unable to understand the language used by the UPIC system. In other
words, a software synthesizer by another developer could play the graphic
scores drawn on the UPIC system, if the system could communicate in a
language that the synthesizer understands.
For the communication between digital synthesizers and sequencers
the MIDI specification 1.0 was published by a consortium of Japanese and
American synthesizer manufacturers in 1983.[12] This suggests that there
were not many standardized communication protocols between musical
hardware and software back in 1977.
Around 10 years later, software synthesizer vendors were able to
distribute their products in a standardized way, notably by the release
of VST 2.0 specification by Steinberg, which enabled developers to

554

THE UPIC 2019

implement virtual musical instruments, running on various hosting software.
Consequently, developers of systems like the UPIC, in which several
components are combined, no longer had to offer an E2ES and count on
users to prepare the software or hardware that conform to the standardized
specifications or protocols by themselves.
The development of IanniX utilizes this very trend. One of the unique
parts of the implementation of IanniX is that the software offers a canvas
and playheads but it does not provide instruments for generating sound at all.
Instead, it just sends messages to other programs and notifies them of events
happening in IanniX, such as the movement of playheads with a standardized
network communication protocol called Open Sound Control (OSC).
This approach liberates composers from limitations and allows them to
use all kinds of software that can accept OSC messages. Furthermore, the
OSC messages that IanniX sends are pure mathematical information, such
as 3D coordinates of playheads, etc. Thus, the mapping is entirely up to the
composers; they can map the X or Y axis to whatever parameter they want.
In addition, assigning them to parameters of non-musical equipment such
as a lighting system, a VJ application, or a drone controller, is also possible.
However, there are two downsides to this approach. One is the
overhead caused by the communication between OSC senders and
receivers. The other is the steeper learning curve due to the incomplete
workflow; composers need to have knowledge of OSC protocol and other
software synthesizers.
MOBILE AND WEB SOLUTIONS

Over a decade has passed since the release of the first generation iPhone
in 2007. Mobile devices such as smartphones and tablets have spread
at an enormous speed. Obviously, an application like the UPIC system
can run as an app on these devices, and this would be beneficial for
educational purposes since the haptic interaction on tablets would be
more intuitive for the younger generation, and in general the hardware is
more affordable. UPISketch, developed by the Centre Iannis Xenakis, is a
UPIC-like software that runs on iOS, OSX, and Windows. It focuses more on
sound creation based on audio sampling.[13] FIG. 10
Also in the realm of the web, the implementation of interactive media
contents on web browsers has become significantly simpler for developers
with the release of HTML5 and WebAudioAPI in 2014; it has enabled audio
synthesis and processing in real time on a webpage without any additional
plug-in components. Furthermore, WebGL allows the contents of a website
to utilize the resources of the GPU. The combination of these technologies
facilitates the implementation of a canvas which enables users to draw
complex shapes on a web page and a synthesizer that sonifies the

FIG. 10 Graphic score drawn on the canvas of the web-based software Synesthésie by
Guillaume Jacquemin, 2019, screenshot © Chikashi Miyama and Guillaume Jacquemin

THE UPIC 2019

556

lines on the canvas. The web-based software Synesthésie by Guillaume
Jacquemin, who also developed several software versions of IanniX,
realizes an UPIC-like system on a webpage by combining the previously
mentioned technologies. By accessing the web page, the user is able to
start sketching graphic scores with various preprepared drawing tools
and synthesizers, and can listen to them without installing any additional
software components.[14] Synesthésie would be very helpful to introduce
the concept of the UPIC to people who are not familiar with it.

Synesthésie

Author

Rodolphe Bourotte,
Sean Soraghan,
Daniel Walz

Guillaume Jacquemin

License

Unknown

Platform

iOS, MacOS, Win

Framework

High C

As discussed above, the use of graphic interfaces for controlling sound
parameters became recognized by sound artists along with the evolution
of DAW software. UPIC’s descendant applications are handier and more
accessible than ever thanks to the evolution of mobile devices and web
technology. Basic hardware capabilities have been rapidly improved and
this enables production of complex graphics and sound in real time. Many
things that were technically impossible in 1977 are possible today.
Given this situation, it is rather challenging to predict the
future of UPIC-like software in general. However, one possible future
implementation can be anticipated from the perspective of the field in
which the author is currently engaged.
IanniX

Thomas Baudel

Therry Coduys,
Guillaume
Jacquemin,
Matthieu Ranc

Unknown

Proprietary

GPL 3

HTML5 browser

Win, MacOS, Linux

Win, MacOS,
Linux

JUCE

WebAudioAPI,
Pixi.js

Undisclosed

Qt

Programming
Language

C++

JavaScript

Undisclosed

C++

URL

http://www.centreiannis-xenakis.org/
upisketch

https://synesthesie.
buzzinglight.com

https://highc.org

https://www.
iannix.org

Synthesizer

Granular synthesis/
PSOLA

Internal sound
generators

Internal sound
generators

External (OSC)

TABLE 1 DESCENDANTS OF THE UPIC

CHIKASHI MIYAMA

THE UPIC IN 2019?

UPIC DESCENDANTS
UPISketch

557

Table 1 summarizes four major applications whose newest versions were released after 2015.
As shown in the table, the descendants of the UPIC employ modern technologies to settle on various
platforms. UPISketch and Synesthésie offer easy access to the system in the mobile and the web
environment. HighC by Thomas Baudel highlights multiplatform compatibilities and has a strong focus
on musical education; it provides step-by-step tutorials for nonmusicians and includes various samples.
IanniX offers highly experimental features, such as three-dimensional notation, generative score, and
OSC output. This radical approach is justifiable only with the technologies available in 2019, in which
many audio specifications are standardized and matured.

VR AS A CANVAS

2016 is often called the year of Virtual Reality (VR) because Oculus Rift,
the first consumer VR headset was released and enabled the general
public to access immersive interactive three-dimensional experiences.
Although IanniX allows us to draw three-dimensional scores, mouses
and monitors are designed for two-dimensional control; specific sequences
of operation are required to draw complex three-dimensional lines and
polygons. However, VR technologies allow us to draw them in space in a
very natural way by pressing a button of a controller and moving our hands
in an actual space.
Some VR applications, such as Google Tilt Brush, have already
crystalized this idea. Tilt Brush allows users to draw lines in VR space,
using various brushes and painting tools. Furthermore, to encourage
artistic creation in VR, the Google Cultural Institute invited visual artists
with no previous experience with VR from all over the world and let them
create artworks in VR using Tilt Brush.[15] Through this sort of software
and encouragement, three-dimensional creation in the digital domain is
becoming rapidly accessible today. FIG. 11
This accessibility and ease of use that VR technology provides coincide
with what the original UPIC system envisioned. However, in addition to
conventional issues such as mapping and playheads, VR technology raises
diverse domain-specific challenges. How should the audience listen to a
score drawn in a VR space? Would it be possible to hold a concert? Should
the performances take place in the virtual or real world? Should they be
exhibited simply as a form of jukebox? As in the case of the Ateliers UPIC a
few decades ago, an intimate collaboration between artists and engineers
would still be essential to work on these challenges.

559

CHIKASHI MIYAMA

FOOTNOTES
1.
Hartmut Bohnacker, Benedikt Gross, Julia Laub, Claudius Lazzeroni, and Marie

Frohling, Generative Design: Visualize, Program, and Create with JavaScript in
P5.js (Hudson, NY: Princeton Architectural Press, 2018).

FIG. 11 Three-dimensional sketch by the author drawn in virtual space with the
software Google Tilt Brush, 2019, screenshot © Chikashi Miyama

2.

Gérard Marino, Marie-Hélène Serra, and Jean-Michel Raczinski, “The UPIC System:
Origins and Innovations,” in Perspectives of New Music 31: 1 (1993), 258–269.

3.

IanniX Association. “IanniX,” in IanniX. https://www.iannix.org For an in-depth
discussion of IanniX, see Julian Scordato, this volume.

4.

Jean-Michael Raczinski andGerard Marino. “A Real Time Synthesis Unit.” in
Proceedings of the International Computer Music Conference (ICMC) 1988,
Cologne, Germany, September 20–25, 1988.

5.

Ludger Brümmer, Anton Himstedt, Chikashi Miyama, and Alexandre Rodrigues,
“Rotating Scores,” ZKM. https://zkm.de/en/rotating-scores

6.

Chikashi Miyama, “Rhythm of Shapes.” ZKM. https://zkm.de/en/rhythm-of-shapes

7.

Chris Carlson, “Borderlands Granular” Borderlands
http://www.borderlands-granular.com/app/ ­For further comparison between UPIC
and Borderlands Granular, see also Simon, this volume.

8.

Kiyoshi Furukawa, Masaki Fujihata and Wolfgang Münch, “Small Fish.
Kammermusik in Bildern für Computer und Spieler,” 1999, ZKM | Center for Art
and Media Karlsruhe.
https://zkm.de/en/publication/small-fish

9.

Henning Lohner “The UPIC System: A User’s Report,” in Computer Music Journal
10, 4 (1986), 42–49.

10.

Peter Nelson, “The UPIC System as an Instrument of Learning,” in Organised
Sound 2, 1 (1997), 35–42.

11.

“Wacom Cintiq Pro,” Wacom. https://www.wacom.com/en-us/products/pendisplays/wacom-cintiq-pro-overview

12.

Curtis Roads, The Computer Music Tutorial, (Cambridge, MA: The MIT Press,
1996).

13.

“UPISketch,” Centre Iannis Xenakis, http://www.centre-iannis-xenakis.org/upisketch

14.

Buzzing Light, synesthesia, https://synesthesie.buzzinglight.com

15.

Google, “Tilt Brush Artist in Residence,” Tilt Brush by Google,
https://www.tiltbrush.com/air/

UNFLATTERING SOUNDS:

PARADIGMS OF
INTERACTIVITY IN

TACTILE

INTERFACES FOR SOUND
VICTORIA SIMON

PRODUCTION

565

FIG. 1 Iannis Xenakis, fragment of page 40 in notebook n°1, 1952. Here, he emphasizes

the importance of touch in music. Ref: OMS. 24357 © Iannis Xenakis Family

VICTORIA SIMON

VICTORIA SIMON

UNFLATTERING
SOUNDS: PARADIGMS
OF INTERACTIVITY IN
TACTILE INTERFACES
FOR SOUND
PRODUCTION
Written sometime during the years 1951 to 1953 in Xenakis’s journal, this
handwritten entry translates as: “It is necessary to relearn how to touch
sound with one’s fingers. That is the heart of music, its essence!” FIG. 1
This quotation underscores his way of thinking about the nature and
meaning of sound as a tactile experience. It indicates a desire to touch
sound and it foreshadows his later statements about the importance of
tactile knowledge that he consistently projected onto the UPIC system both
in interviews and in the paratextual media, which provided explanations of
it. The L’UPIC du CEMAMu pamphlet, a sort of user’s guide and tutorial, for
example, emphasized the importance of touch in the user’s interaction with
the computer, stating “when we touch the computer for the first time, it is
free from any musical element [...] everything goes through the hand which
draws.”[1] One could interpret this journal entry as a statement asserting
that the true essence of music is an embodied practice, one that is learned
and cultivated through a person’s fingers. Another interpretation might be
that a tactile engagement is the heart and essence of music, essentially
linking touch to the sonic experience.
Either interpretation supports Xenakis’s numerous statements about
touch in the form of drawing and it was the primary justification for the
UPIC’s drawing board interaction paradigm. It should be noted that the
romance surrounding a musician’s “touch” of an instrument has a history
that dates at least as far back as the eighteenth century.[2] The importance
of “touch” is bound up with a preexisting tradition in the manner in which
Western music culture has historically fantasized the unique relationship
between the musician and the instrument. Nevertheless, the quotation
taken from Xenakis’s journal also indicates his romanticizing of touch, and
the ability for people to encounter the heart and essence of music through
the hand was part of his thinking before subsequent developments of the
UPIC and applications of commercial touchscreen user interface design.[3]  

566

We can see the notion of “direct contact” with sound as a privileged
form of interaction and user-friendly music practice in the way that music
software companies market music applications (music apps) for Apple’s
iOS platform. In the present context of the iOS platform, the dominant
paradigm of app interface music touchscreen user experience is to
provide the feeling of instant mastery over a musical instrument through
touch. The most popular apps in the app store such as iMaschine 2 and
ThumbJam are those which focus on a smooth, seamless experience,
where users feel in control over the sound. Evident in the marketing of
these apps, the explicit goal of the interface is to create a “fun” musical
experience.[4] Fun, in this case, I define by instant gratification; where the
aesthetic outcome flatters the user and creates the semblance of instant
ease and competency with an instrument. In this article, I will argue that
the app Borderlands Granular presents an alternative paradigm of user
interaction, one defined by the same principles of user interaction and
musical experience that Xenakis attributed to the UPIC.
Borderlands Granular is a software program created by Chris
Carlson, initially as a graduate student at Stanford University, which
he later translated to the iOS platform.[5] The goal of the app is playful
experimentation and exploration of sound. In Borderlands, the user
receives feedback by listening to the results of their actions, and then
modifies how they use the app and the results they obtain. The user
records a sound sample or brings in a sound sample from another source,
which the app then visually renders into a metaphor for a sound wave.
Within the sound wave, the sound is broken up into tiny dots or “grains,”
which the user is encouraged to explore. This paradigm of sound synthesis
comes from Dennis Gabor’s theory of granular synthesis, which Xenakis
famously used in his music composition Analogique B.[6]
In our interview, Carlson explained why he opted for the touchscreen
over the mouse and desktop software paradigm. He described the
touchscreen as the optimal solution to the interactivity of the Digital
Audio Workstation. With the touchscreen, “suddenly you have the
ability to use all of your fingers simultaneously to manipulate these
objects on the screen in a way that you can’t with just a mouse and
a keyboard.”[7] Carlson faults the mouse and keyboard paradigm of
interaction for providing a “serial process” of interactivity: “you do
this, and now I’m going to move this thing over here, and I’m going to
edit this parameter, and I’m going to move the mouse and click this
thing.” He observes that with the mouse, the user must focus on one
thing at a time. For Carlson, the ability of the user to deploy all of their
fingers simultaneously to alter visual images on the screen was a crucial
reason to opt for the touchscreen. The user would have had to take too

UNFLATTERING
SOUNDS:
PARADIGMS OF
INTERACTIVITY
IN TACTILE
INTERFACES
FOR SOUND
PRODUCTION

567

VICTORIA SIMON

many steps to accomplish a task with the desktop format and to focus
on too many tasks, each requiring the user’s attention through bodily
engagement. Unlike desktop software, the touchscreen could embody
a more “realistic and natural” form of musical interactivity, with the
sounds changing based on a direct feedback loop with the user’s body.
The interaction paradigm of immediate feedback based on the user’s
tactile input, to Carlson, confers on the app its supposedly “natural” and
musically expressive qualities.
Borderland’s interface encourages users to explore different ways of
manipulating sound waves, playing with their variable textures and seeing
how they respond both visually and audibly to different sound effects
the user can select in the app. Carlson states that “the intention behind
Borderlands, and part of why the interface is so focused on just the
sound files and these grain clouds that you see, is that I really want the
focus of the interaction to be on engaging with sound files and exploring
those sounds files directly.” Without having any knowledge of music or the
Borderlands user interface, the user participates in a feedback loop as
they build skill within the app in a way similar to how they would learn a
musical instrument.
In the Borderlands app, the process of obtaining a desired outcome
may involve frustration or irritation. In my experience, as well as from
hearing the experience of others who have used the app, it is possible to
sound bad. Frequently, the app is recalcitrant. Efficiency and successful
completion of a track are not the goals of the app. Rather, the end goal is
to deepen the user’s exploration of sound and to play with alternative
possibilities of sound generation.  
Like Carlson, Xenakis saw hands-on direct manipulation as
paramount to an unmediated form of embodied musical expression.
When Xenakis was interviewed by Henning Lohner, he stated, in reference
to drawing: “With the UPIC you have the potential to enter into the problem
of composition in a much more simple and direct way—and by this I mean
direct to the mind. […] I think this more universal notation is possible for
everybody because it is the end of the hand that creates the drawings. The
hand is the organ of the body that is closest to the brain.”[8]
This statement attests to the idea that Xenakis saw the UPIC as a
medium that disappears, allowing for a natural production of music to
occur. For him, music would flow from the person’s mind, unaffected by
the medium—a technology of unadulterated creative authenticity. Xenakis
painted the UPIC as a way “to touch the sound with one’s fingers” and
engage with the unmediated essence of music itself. The sound drawn
on the page would be represented as a true expression of the user’s
thoughts. The logic was as follows: as the movement of the hand was

568

an unmediated and direct expression of the user’s brain, and as the GUI
(graphical user interface) of the UPIC system provided a direct translation
of the hand’s gesture to sound, then there was no intermediary between
the user’s hand/brain and the sonic output. To interact with sound—via a
drawing board—was also the most simple and natural form of interaction
for Xenakis. Due to its tactility and immediacy, he considered the UPIC to
be a user-friendly interface.
In the case of the earlier versions of the UPIC, however, users could
not attain proficiency with the interface so easily. While users could make
sound through the interface by directly drawing in lines and shapes, many
experienced difficulties interacting with the system, and it took time both
to obtain sound results and to achieve general competency. Today, the
Center Iannis Xenakis (CIX) has created a version of the UPIC in an app
format, UPISketch.[9] The UPIC in the iOS format maintains the values of
exploration and discovery of sound. What is lost, however, is the difficulty
the user initially experienced in gaining proficiency with the UPIC.
From the statements that Xenakis made about the UPIC, we
can infer that he viewed the experience of difficulty as integral to the
process of learning an instrument and making music. The pamphlet
that accompanied the first UPIC explicitly stated, “From the child to the
composer, everyone will use it in his own way, according to his knowledge,
abilities, job, and talent. [...] For all of them, the UPIC is a tool which leads
to sound concretization through a gesture. If the gesture is naive [...] the
music will be naive [...] if it is skillful, the UPIC will traduce the intelligence
of one’s art.”[10] From this account and from Xenakis’s own words, we
can see that the system was potentially easy to use, at first, but difficult
to master. Xenakis recognized that novice users would create musical
works that sounded different from those of more advanced users.  He
understood this issue as part of the process of learning an instrument
and making music. Xenakis described the act of drawing as a universal
approach to music because knowledge of the basic principles of sound
would be attained directly through the user’s body through the act of
drawing its basic electroacoustic components. Attaining a level of fluency
with the system required that the user spend time learning it.  
This image taken from the UPIC user’s manual FIG. 2 is an example
of what a score looks like using the UPIC system. At the CIX, I found
numerous examples of musicians’ graphical music compositions.
These elaborate drawings required knowledge of how to draw and
skill to produce, as seen, for example, in Xenakis’s score for Mycènes
Alpha. Xenakis saw the UPIC as a way to augment human capabilities and
intelligence through feedback from the system. For instance, the user
could learn about sound properties through the neuromuscular coding of

UNFLATTERING
SOUNDS:
PARADIGMS OF
INTERACTIVITY
IN TACTILE
INTERFACES
FOR SOUND
PRODUCTION

FIG. 2 Examples of intricate illustrations that composers Pierre Bernard and
Jean-Claude Eloy did with the UPIC. © CIX Archives id. 224/4

570

the hand and compose music through exploration, trial, and error.
Through drawing, the user could conceptualize and make sense of the
world of sound. This would occur through an embodied knowledge that
came from the connection between the gesture of the user’s hand and
the audible sound. Through the visual, tactile, and sonic feedback loop
of the UPIC, the user could process this knowledge of sound and music
in order to learn and grow as an artist.
What Borderlands Granular and the UPIC present to us is an
alternative paradigm of interface design where the user learns and grows
musically through embodied feedback from the interface. The dominant
user interface paradigm of music apps is an experience of instant success
and effortless musical mastery. The ability to attain a desirable sonic
outcome efficiently typifies what counts today as “user-friendly” interface
design in the app format. Tactility and immediacy in the app format mean
that with just a few swipes or taps on the screen, a person with limited
musical ability, skill, and knowledge can immediately create a professional
sounding outcome. The UPIC is a case study of user interface design that
historicizes the terms “tactility,” “immediacy,” and “user-friendliness.”
We can see Borderlands Granular as a present day iteration of the
UPIC’s paradigm of interactivity. At times the interaction may produce
disappointing sounds and frustration in the user. Nevertheless, these
recalcitrant interfaces promote the values of exploration and playful
discovery of sound as opposed to the goals of instant success and control
over the aesthetic outcome.

UNFLATTERING
SOUNDS:
PARADIGMS OF
INTERACTIVITY
IN TACTILE
INTERFACES
FOR SOUND
PRODUCTION

571

VICTORIA SIMON

FOOTNOTES
1.
Anonymous, L’UPIC du CEMAMU (ordinateur à composer conçu par

Iannis Xenakis), undated, CIX Archives id 224/4.

2.

Julia Kursell, “Experiments on Tone Color in Music and Acoustics:
Helmholtz, Schoenberg, and Klangfarbenmelodie,” in Osiris 28, (2013), 191–211.

3.

Victoria Simon, “From Difficulty to Delight: The History and Politics of
Touchscreens for Music Production,” McGill University, PhD Dissertation, 2018.

4.

Victoria Simon, “Guided by Delight: Music Apps and the Politics of User
Interface Design in the iOS Platform,” in Television & New Media, 2018,
doi:10.1177/1527476418794634.; Jonathan Wade Morris and Evan Elkins,
“There’s a History for That: Apps and Mundane Software as Commodity,” in
The Fibreculture Journal, 25, 2015,
http://twentyfive.fibreculturejournal.org/fcj-181-theres-a-history-for-that-apps-andmundane-software-as-commodity/

5.

http://www.borderlands-granular.com/app/

6.

Makis Solomos, “The Granular Connection (Xenakis, Vaggione, Di Scipio...)”:
The Creative and Scientific Legacies of Iannis Xenakis International Symposium,
2006 HAL Id: hal- 00770088, HAL archives-ouvertes,
https://hal.archives-ouvertes.fr/hal-00770088

7.

Chris Carlson, interviewed by Victoria Simon, April 8, 2016. All subsequent quotes
by Carlson are from this same interview.

8.

Henning Lohner, “Interview with Iannis Xenakis,” in Computer Music Journal 10,
(1986), 50–5.

9.

http://www.centre-iannis-xenakis.org/upisketch

10.

Brigitte Robindore, “The UPIC User’s Guide and Tutorial,” 1993, (unpublished),
CIX Archives.

NOVEL PERSPECTIVES

FOR GRAPHIC

NOTATION IN

JULIAN SCORDATO

IANNIX

577

JULIAN SCORDATO

NOVEL PERSPECTIVES
FOR GRAPHIC
NOTATION IN IANNIX
INTRODUCTION

JULIAN SCORDATO

With his mathematical approach to musical composition,[1, 11] Iannis
Xenakis proposed a pitch-time Cartesian space for the notation of
continuous motions—such as glissandi or “arcs”—which characterized
the premise for his conception of the UPIC. As an early computer system
capable of generating sounds from user drawings, this machine offered
an attempt to extend the notation from traditional solfège, a multi-formal
description of the score, and a gestural approach mediated by the
computer.
As the chronology of the UPIC unfolds, various tools and devices
participate actively in the same process of technological evolution and
democratization that led the UPIC to a prototype of a software-only
version in 2001—called UPIX—after passing through a continuous update
of its hardware design.
After Xenakis’s death, in 2001, the development of UPIX stopped.[2]
At that time, Thierry Coduys (La Kitchen), with the collaboration of Gérard
Pape (CCMIX) and Adrien Levèfre and supported by the French Ministry
of Culture, started to develop IanniX.[3] On one hand, this software
would be based on the UPIC, but on the other hand it would become
an interface devoted to a wider creative field by combining current
technological developments, new significant features, and a multimodal
approach.
In particular, at the foundation of IanniX, there was the willingness
to integrate part of the original framework of the UPIC conception with
a poly-temporal and multi-topological representation system: from
bi-dimensional arcs on the UPIC page, to three-dimensional curves
interpreted by different reading heads—namely, cursors—with their own
space-time behavior. Also, the sound synthesis engine was oriented to
plug-ins.[4]
In addition to the development of the concept of score, especially in
terms of dimensions, IanniX recovered an important feature for notation:
the ability to represent punctual events—called “triggers”—like MIDI
notes. Indeed, for control purposes, musical notes do not necessarily
foresee a continuous variation of a parameter—for example, their pitch
(glissando) or dynamics (crescendo or diminuendo).

578

At a further stage of development, the implementation of more
features and interaction modes allowed to go beyond the conception of
a predetermined and reproducible “control score,” thus paving the way
to new types of scores.[5]
A DEFINITION OF IANNIX

IanniX is a “graphical open source sequencer [...] for digital art”[6] that
operates in real time; in this sense, it is a tool for both graphic notation
and transmission of information for multimedia performance. Through
various communication protocols, it synchronizes punctual events as
well as continuous data to other environments—for example, Pure Data,
Max, Processing—and hardware such as MIDI devices and Arduino.
IanniX's package is free and multi-platform.
Its operation is based on the reception of commands for the
creation and management of a score, as well as on the transmission
of score-related messages for controlling other devices. Therefore,
it implements various communication protocols and technologies
(OSC, raw UDP, TCP, WebSocket, HTTP, MIDI, Syphon, and serial port
communication) in order to support interfacing with numerous software
and hardware.
Its main window shows a representation of a multidimensional and
multi-format score that is programmable via a Graphic User Interface
(GUI), JavaScript, and other applications that use a compatible network
protocol. This flexible configuration has an advantage over most software
environments in that it avoids forcing users to adopt a unique method
for the creation of a score, so they can benefit from the use of multiple
design strategies, also according to their expertise.
IanniX scores are based on three types of abstract objects to be
placed in a 3D virtual space: triggers, curves, and cursors. Triggers and
curves represent discrete and continuous events, respectively. Cursors
are time-based elements—playheads—that can move along the curves in
order to read a specific sequence of space-limited events. A theoretically
unlimited number of cursors can be added to a score, in contrast to the
single predetermined timeline of IanniX’s predecessor. Thus, a threedimensional and poly-temporal sequencer is proposed, unlike the UPIC
which was based on two-dimensional drawing and allowed for only one
timeline that could be normally read from left to right, as an emulation
of the conventional way of reading a music score. Also, IanniX runs
independent of any sound synthesis engine, in order to permit the use
of different instruments and plug-ins. The characteristics of the design
and interface, therefore, make it quite suitable for a broad variety of
applications.

NOVEL
PERSPECTIVES
FOR GRAPHIC
NOTATION IN
IANNIX

579

JULIAN SCORDATO

MAIN APPLICATIONS

Through the communication with audio environments or MIDI devices,
IanniX can be used as a tool for the creation and performance of musical
works designed using 2D or 3D graphic notation. Many object attributes
and four mapping modes allow the user to match the characteristics and
behavior of cursors, curves, and triggers with sound and music parameters
as well as several MIDI events. The capability to import external
graphics, as textures, into a IanniX project amplifies the representational
possibilities of basic objects. Furthermore, sketches and notes can be
integrated into the score as a background image, providing a tool to assist
the user in the creation of the final work; images can also be included in
the final version for display purposes. Overall, the GUI offers a compact
and simple work environment for accessing all IanniX functions without the
need of specific programming skills.
With an ad hoc scripting language based on JavaScript, users can
program IanniX scores using a procedure substantially different from the
UPIC. Constituting the content of the source file, in a sense, the script
actually is the score, as every IanniX command—which either produces
or is produced by an action in the GUI—is defined through a custom
JavaScript function (named “run”) and every reaction to external input
from network protocols or interfaces can be set in a Javascript method
called “onIncomingMessage.” Through this advanced approach, IanniX's
functionality goes far beyond a mere technologically evolved emulation of
the UPIC, thus facing the generation of scores by means of functions and
control structures which are more comprehensible to programmers.
The strong relation between sound and visual content that emerges
through the use of IanniX has often been a stimulus to reveal the score as
an integral part of the work, as is evident from the showcase of projects
on the IanniX website. Indeed, IanniX has been used in audiovisual works
as a tool for controlling specific parameters and events, and showing
their graphical representation to the public, even to facilitate their formal
intelligibility, such as in City Score (2012) by Julien Poidevin, (A-Z)² (2012)
by Guillaume Jacquemin and Matthieu Ranc, and Constellations (2014) by
Julian Scordato.[7]
An interesting field of application involves the development of
graphic artifacts for sound reactive systems, data visualization, or image
processing; among the known examples are, respectively, Neyma (2012)
by Stefano Alessandretti and Giovanni Sparano,[8] Fa Octothorp (2012)
by Guillaume Jacquemin & Matthieu Ranc, and Mille Plateaux (2014) by
Pascal Dusapin.
Other specific usages of IanniX include the control of sound
spatialization by means of the definition of virtual sound trajectories—

580

in Shin-ji-ke (2012) by Charles de Meaux, and Specter System by Bill
Manaris and Seth Stoudenmier [9]—and the sonification of graphic data
related to architecture.[10]
Several examples of completed projects and practical suggestions
are bundled into the IanniX software package, including the score
of Récurrences (2011) by Thierry Coduys, (A-Z)² (2012) by Guillaume
Jacquemin and Matthieu Ranc, Pulsar (2014) by Guillaume Jacquemin,
and a sketch from Xenakis’s Metastasis (1953–1954).
CLASSIFICATION OF IANNIX SCORES

According to their functionality, and to the interaction mode with other
applications and devices, various types of scores have been recognized.[5]
They can be summarized theoretically in the following five typologies.
CONTROL SCORE

As in the conventional practice of musical composition, a score is commonly
used to organize a system of graphical signs and symbols that represent
certain characteristics, subsequently interpretable to control instruments
in a performance. Still, instrumental notation has reached a specific and
shared definition, which only became systematic after centuries. Instead,
in the multiplicity of production techniques, parameters, and processes
involved in computer music and, in general, in time-based digital art, a more
abstract and generalized system would be needed to adapt to a wide range
of expressions interpretable by a computer. According to the nature of the
magnitudes involved and their articulation over a time frame, two general
categories can be distinguished: these stand for discrete and continuous
events. In order to be sequenced, the former may require one or two distinct
output messages—for isolated occurrences or for delimiting a time span—
while the latter are simulated through an interpolation of values at a certain
sampling rate. Hence, the distinction between triggers and curves exists to
represent graphically such events.
In IanniX, in a way comparable to the operation of the UPIC, once a
score has been set by the user and then started, a sequencing device reads
the events previously defined and produces a data output for controlling one
or more processes in real time (e.g., sound synthesis, sampling, and audio/
visual processing). Therefore, the performance of a control score can be
considered as “autonomous, reproducible, and determinist.”[5]

NOVEL
PERSPECTIVES
FOR GRAPHIC
NOTATION IN
IANNIX

581

JULIAN SCORDATO

the onIncomingMessage method are used to create entirely or to modify
partially the content of a score. This approach leads IanniX to an operation
which is independent from the sequencer, as long as event timing is
defined by an external input device that controls IanniX.
By reacting to external stimuli without causing any output of control
data, the primary purposes of the reactive score are visualization and
graphical representation of data received from software environments and
devices (e.g., a 3D path detected by a motion capture device, a variation of
a specific parameter against time, or the deformation of a curve expressed
by a parametric equation). Despite strong graphic limitations, such as
the lack of support for the representation of surfaces and numerous
restrictions in texture processing, IanniX's environment can be configured
for data visualization, implementing vector and raster graphics.
Moreover, the objects added to reactive scores (e.g., triggers related
to note messages received from a MIDI keyboard) can be subsequently
read by the sequencer in order to produce control messages. In this way,
IanniX may also work as a performance recording system.
INTERACTIVE SCORE

In an interactive score, the characteristics of the two typologies above are
joined together: the use of IanniX to control other tools is coupled with the
capability to edit the score from an input device during the performance.
A bidirectional data flow is involved and IanniX acts as a part of a humancomputer interface or a bridge for the connection of software and/or
hardware, exploiting the ample interfaceability supported.
Considering that interactivity is a very common aspect in the design of
multimedia performances and installations, this kind of score offers many
possible applications such as real time performance control by means of
user interaction (already implemented in later versions of the UPIC), the
interfacing of sensors and actuators that use a different communication
protocol and, more generally, the mapping of input data combined with time
management.
From a strictly technical point of view, a control score which receives
commands only for display purposes (e.g., change in object color, camera
rotation, vertical and horizontal scrolling, or zoom) can also be considered
an interactive score.
GENERATIVE SCORE

REACTIVE SCORE

In opposition to the control score, a reactive score foresees only the
reception of data from the input side; more specifically, commands
conforming to the IanniX scripting language or any message interpreted by

This type of score is produced or controlled by algorithms written in
JavaScript language. A generative approach can either cause the result
to evolve over time or arrange IanniX objects in a predetermined way
(outside-time). Therefore, in this case the score is the output.

582

The advantages of using a programming language to create a score
include the possibility to expand the basic functionality of GUI and automate
processes through iterative structures, conditional statements, functions,
and variables. Algorithms may speed up significantly object instances
and positioning when compositional rules are formalizable. For example,
aleatoric or stochastic processes can be implemented and executed once
when a score is loaded or repeatedly during the performance. In the script,
the function run for sending a command to IanniX may include arithmetic
operations, variables, and other functions along with fixed parameter values;
all of these are also applicable to output messages before sending them to
other devices.
For the reasons above, generative scores can take deterministic,
nondeterministic, or stochastic traits.
RECURSIVE SCORE

Through an ad hoc protocol called “direct,” IanniX proposes a way to
control itself during the performance of a score: an output message
related to an object can be reinserted into the system as an input
command at time t + x [ms], according to the scheduler period. In some
cases, this implicates recursion or deformation of the score as a function
of time; in other cases, it commands the application itself.
There are three common elements that may characterize a recursive
score: (1) the control of an object by means of an unrelated cursor/trigger,
thus establishing a univocal correspondence or a one-time instance; (2) a
stable or chaotic feedback between controlled object and controller, with the
involvement of an actual recursive function; (3) the control of the sequencer
(status, position, or speed) or viewport (camera rotation, position, or zoom)
through a cursor/trigger. In a practical application, a recursive score does
not exclude the possibility to integrate features from the other score types
discussed above. Different compositional approaches and communication
protocols may in fact work together.
GRAPHIC OBJECTS AS A MEANS OF NOTATION AND
PERFORMANCE

As a reference for the positioning of objects in the score, IanniX uses a
Cartesian coordinate system which does not establish a fixed relationship
with time. Being determined by the path of individual cursors along the
curves, the progression of time is freed from the constraint of a Cartesian
axis or a “straight line”, as instead proposed by Xenakis.[11] Or at least, a
linear time model could be applied to IanniX scores only as a special case.
Basically, in IanniX scores, temporal structures are multiple and variable,
and become the object of the notation itself.

NOVEL
PERSPECTIVES
FOR GRAPHIC
NOTATION IN
IANNIX

583

JULIAN SCORDATO

Besides the position on the XYZ axes, every object has a series of
general attributes that are configurable dynamically by the user: ID number,
group name, label, activation status, thickness/size, color, texture, and
syntax of output message/s (only for cursors and triggers). These attributes
are useful for identification, for setting the appearance and behavior of the
object itself, as well as for storing and managing data which are retrievable
through predefined variables to be included in a message. Furthermore,
objects hold specific properties, as described below.
CURVES

A curve is a graphical representation of a function or a vector-based path
within the score; it can be defined either by parametric equations (i.e., “math
curve”), by a set of 3D points (“straight curve” or “smooth curve”), or by a
tool for drawing ellipses (“circular curve”).
IanniX curves assume three possible functions in a score: (1) as tracks
for the path of a linked cursor, they outline a localized temporal pattern;
(2) as objects within the space-time range of a cursor, they describe the
variation of values in 3D space in relation to the temporal position of the
same cursor; (3) as graphic artifacts, they represent objects of visualization
with a formal and aesthetic value.
In a very simple example, assuming to have a straight timeline on the
X axis, it is possible to use a curve to represent graphically the continuous
variation of two one-dimensional quantities (e.g., audio frequency [Hz] and
amplitude) on Y and Z axis, respectively. In more complex cases, through
parametric equations or generative scores, sophisticated geometric shapes
and architectures can be drawn precisely to give formal consistency to the
notation. FIG. 1
CURSORS

A cursor is a time-based graphical object that moves along the path of a
linked curve and performs local and autonomous sequencing functions:
(1) it permits the activation of triggers located in its range; (2) it sends
continuous messages which may include variables related to its position
or status, to any collision point with curves, or to the sequencer. The size
of a cursor—in attributes of width and depth—determines its surface of
intervention in the score at instant t, according to a global timeline and to its
specific behavior.
Cursors are indeed subject to global Transport controls. However,
several attributes define their own temporal behavior in the score: speed/
duration, loop pattern, acceleration, offset, and message transmission
rate. For this reason, they represent the core of IanniX's poly-temporal
functionality.

585

GUY MÉDIGUE

FIG. 1 Julian Scordato, Study for a Cosmic City, 2019, score excerpt, graphical
sequencer and electronics © Julian Scordato
FIG. 2 Coordinate mapping for a cursor in a score in IanniX, 2019, screenshot
© Julian Scordato and IanniX Association

FIG. 3 Julian Scordato, Engi, 2017, score excerpt, grapical sequencer and electronics
© Julian Scordato

586

Through cursors, different portions of 3D space of the score can be
mapped conveniently to the range of values needed to control specific
parameters, in order to facilitate interfacing between devices and IanniX
objects. FIG. 2 This leads to multi-formal and multi-topological conceptions
of the score.

NOVEL
PERSPECTIVES
FOR GRAPHIC
NOTATION IN
IANNIX

587

JULIAN SCORDATO

and knowledge of networks and communication protocols. Inevitably, this
shifts the focus of an eventual pedagogical function from an artistic to a
technological approach.
FOOTNOTES
1.
Mihu Iliescu, “Glissandi and Traces. A Study of the Relationship between Musical

and Extra-musical Fields,” in Proceedings of the International Symposium Iannis
Xenakis (Athens, Greece: University of Athens, May 18–20, 2005),
http://cicm.mshparisnord.org/ColloqueXenakis/papers/Iliescu.pdf

TRIGGERS

In its default appearance, a trigger is a spherical object with the ability
to send individual output messages in the event of a spatial collision
with a cursor. By involving discrete events over time, in a musical context
triggers represent an extension of the notion of note within a 3D space.
Their duration—that is, the time between the activation and deactivation
message (note off)—is defined by a trigger-specific attribute. Thus, they
are well suited for communication via MIDI protocol. In addition, the fact
that triggers are placed in a 3D space inherently encourages the user to
explore unconventional ways of conceiving a score. FIG. 3
When applied to interactive or control scores, triggers are able to
control any sort of punctual event, from dataflow to final media, depending
on the software or hardware linked to IanniX.
Beyond that, triggers can be used to manage data presets, as score
self-control devices, or as tools for importing bitmap images, even to
enrich the semiographic aspect.
CONCLUSIONS

This text aimed to provide an overview of current possibilities and limits
of graphic notation and performance with IanniX. Developed in the wake
of the UPIC, IanniX has in many ways expanded its functionality and areas
of use, proposing to meet various expressive needs and focusing on the
critical aspect of notation in the age of New Media.
In an original way, this software proposes a generalized system for
the notation of relative space and time that challenges the concept of
score and opens up new possible applications within music, digital art and
design, and mixed technology contexts.
From a performative side, various user approaches are possible
through interactive scores, such as improvisation, live coding, collaborative
and network performances.
With the awareness that the role of composer nowadays may include
becoming “the programmer and constructor of the device that originates the
sound,”[12] IanniX intentionally did not offer an integrated sound synthesis
engine, favoring operational openness and flexibility at the expense of “ease
of use [...] and immediacy.”[2] In fact, to fully exploit IanniX features, the user
needs various technical skills, including interaction design, programming,

2.

Rodolphe Bourotte, “The UPIC and Its Descendants: Drawing Sound 2012,” in
Proceedings of the International Symposium “Xenakis. The Electroacoustic Music
(Paris, France: Paris 8 University, May 23–25, 2012),
http://www.cdmc.asso.fr/sites/default/files/texte/pdf/rencontres/
intervention18_xenakis_electroacoustique.pdf

3.

Thierry Coduys and Guillaume Ferry, “IanniX: Aesthetical/Symbolic Visualisations
for Hypermedia Composition,” in Proceedings of the 1st Sound and Music
Computing Conference (Paris, France: IRCAM, October 20–22, 2004),
http://recherche.ircam.fr/equipes/repmus/SMC04/scm04actes/P18.pdf

4.

Thierry Coduys, Adrien Lefèvre, and Gérard Pape, “IanniX,” in Actes des Journées
d’Informatique Musicale (Montbéliard, France: École nationale de Musique, June
4–6, 2003), 1–2, http://jim.afim-asso.org/jim2003/articles/iannix.pdf

5.

Thierry Coduys and Guillaume Jacquemin, “Partitions rétroactives avec IanniX,” in Actes
des Journées d’Informatique Musicale (Bourges, France: MUSINFO, May 21–23, 2014),
http://jim.afim-asso.org/jim2014/images/0040_01_03_PARTITIONS%20
RETROACTIVES%20AVEC%20IANNIX.pdf

6.

IanniX, What Is IanniX? (Paris, France: IanniX Association),
https://www.iannix.org/en/whatisiannix/

7.

Julian Scordato, “Composing with IanniX,” in Proceedings of the 5th International
Conference on Computation, Communication, Aesthetics and X (Lisbon, Portugal:
University of Lisbon, July 6–7, 2017), 152–4,
http://2017.xcoax.org/pdf/xCoAx2017-Scordato.pdf

8.

Stefano Alessandretti and Giovanni Sparano, “NEYMA: Interactive Soundscape
Composition Based on a low Budget Motion Capture System,” in Proceedings of
the 40th International Computer Music Conference (Athens, Greece: University of
Athens, September 14–20, 2014), 379–83,
https://quod.lib.umich.edu/i/icmc/bbp2372.2014.058/1

9.

Bill Manaris and Seth Stoudenmier, “Specter: Combining Music Information
Retrieval with Sound Spatialization,” in Proceedings of the 16th International
Society for Music Information Retrieval Conference (Malaga, Spain: University of
Malaga, October 26–30, 2015), 288–94,
http://ismir2015.uma.es/articles/270_Paper.pdf

10.

Jon Bellona, Sonification Study of San Giovanni Elemosinario (author’s website,
2014), http://jpbellona.com/public/writing/BellonaJon_SanGiovanni.pdf

11.

Iannis Xenakis, Formalized Music: Thought and Mathematics in Composition
(Stuyvesant, NY: Pendragon Press, 1992), 211–2.

12.

Ana Carvalho, “The Use of Visual Scores in Live Audiovisual Performance,”
in Avanca Cinema 2014 International Conference Cinema—Art, Technology,
Communication (Avanca, Portugal: Cine Clube de Avanca, 2014),
https://repositorio.ismai.pt/bitstream/10400.24/503/1/2014-avanca.pdf

EXPLORING VISUALIZATION

METHODS OF THE

DYNAMIC
BEHAVIORS
IN COMPUTER-BASED

KOSMAS GIANNOUTAKIS

MUSICAL WORKS

593

KOSMAS GIANNOUTAKIS

EXPLORING
VISUALIZATION
METHODS OF THE
DYNAMIC BEHAVIORS
IN COMPUTER-BASED
MUSICAL WORKS
ABSTRACT

The score plays a very important role in the tradition of Western
music. The recently developed computer-based practices challenge its
conservative status by assigning novel functionalities to it. The creative
output of the composer, which used to utilize symbolic and graphical
notation, tends nowadays to include computer code and programs that
produce multimedia content. This paper discusses the problem of scoring
computer-based musical works that emphasize dynamic behaviors, and
proposes visualization methods that could give an overview of the sonic
dynamics and assist the composer in order to articulate his/her intention.
Two works by the author are presented as case studies that demonstrate
early investigations.
CONTEXT

KOSMAS GIANNOUTAKIS

The traditional role of the music score is to communicate the articulated
musical ideas of a composer to the performers, who interpret the graphic
symbols and actualize them into concrete sound. This understanding of
the score appears to be solid in our current Western musical culture. It is
challenged, however, by recent technological innovations that investigate
novel ways of composing, performing, experiencing, and teaching music.
The function of the score has always been redefined by shifts in the
musical culture. For example, with the decline of the improvisation practice
during the nineteenth century, the added notes that decorated melodic
and harmonic structures known as ornamentation, started to be explicitly
written out.[1] In that historical period the musical work ceased to contain
improvisation elements and reached a status that is still predominant. The
pitch content, instrumentation, rhythmical proportions, tempo, dynamics,
and articulation were precisely defined, although the performance practice
of the nineteenth century permitted creative deviations on the last three

594

features. For a significant time period in the history of Western music, this
type of score was the principal creative output of the composer.
The piano roll, a continuous roll of paper with perforations punched
into it that served as a storage medium for operating the player piano,
brought a new perspective to the musicl score. Invented at the end of the
nineteenth century, it primarily functioned as reproducer, replicating piano
performances of famous pianists. Composers like Conlon Nancarrow went
beyond this utilitarian use and artistically explored the new possibilities
this medium had to offer.[2] Intricate rhythmical patterns were precisely
punctured and played by the player piano with an accuracy that was
impossible to achieve by even a virtuoso pianist. This practice brought a
more radical change to the concept of the score. It became a medium
that contains unambiguous instructions for performance by a mechanical
musical instrument.
Iannis Xenakis had a background in engineering and architecture
and a great interest in mathematics, philosophy, and computer science,
which influenced his unique artistic output immensely. From his early
creative period, he massively employed lines as his main compositional
material, denoting continuous sonic transformations.[3, 4] These features
could not be conveniently grasped by the traditional music notation system,
so Xenakis relied heavily on graphical sketching before transcribing his
compositional ideas into standard notation. Later, with the foundation
of the Centre d‘Etudes de Mathématique et Automatique Musicales
(CEMAMu), he saw the possibility of translating a graphical sketch into
sound directly by means of a computerized musical composition tool.
The development of the UPIC system embodied his vision[5] and brought
forth a new kind of music score. Bypassing the convoluted character of a
symbolic music notation system and a computer programming language,
a UPIC score is a drawing that maps the horizontal axis to time and the
vertical axis to a frequency range. It functions as an input program for
a computer music system that generates sound based on the additive
synthesis technique and as an outline, which contains the traces of the
compositional thought.
With the advent of personal computers and the Internet, computerbased musicking exploded into numerous fields, all of which explore new
identities for the composer, audience, composition, instrument, score, and
performance. In the fields of generative scores and real-time notation,
the algorithmically generated scores are often displayed during the
performance and portrayed as aesthetic objects that guide the audience’s
perception.[6, 7, 8, 9] In live-coding practices, the textual, visual, and
gestural qualities of the projected code explore an experimental format
that transforms the compositional process into a live event.[10]

EXPLORING
VISUALIZATION
METHODS OF
THE DYNAMIC
BEHAVIORS IN
COMPUTERBASED MUSICAL
WORKS

FIG. 1 Conlon Nancarrow, Study No. 49c, 1987, Perforated piano roll © Jürgen Hocker

596

SCORES FOR COMPUTER-BASED WORKS WITH AN
EMPHASIS ON DYNAMIC BEHAVIORS

The historic UPIC system epitomizes the graphical score as parameter data
for a computer algorithm that produces a fixed media composition. The
reverse approach, namely, the generation of parameter data by algorithmic
processes that can be applied to compositional processes, has also been
pioneered by Xenakis with his research on stochastic synthesis and computer
algorithms that generate micro- and macrostructures.[11] These innovations,
along with the full body of his instrumental and electroacoustic works[12]
have influenced numerous composers and sound artists like Agostino Di
Scipio, who has written extensively about Xenakis's work.[13]
Di Scipio has developed a series of electroacoustic works that he
calls audible ecosystems, which aspire to bridge the gap between sound
generation and music creation by following consistent principles as had
been envisioned by Xenakis and Stockhausen.[14] They are based on
dynamic couplings between performers, Digital Signal Processing (DSP)
algorithms, and acoustic environments, which produce ephemeral sonic
structures in various timescales.[15] Similar approaches characterize this
paradigm of music creation variously as interactive music composition,[16]
self-organized music,[17] and performance ecosystem.[18]
In this field, the composer does not intend intelligible listening of
preconceived music ideas, but the experience of dynamic behaviors that
produce ephemeral sonic structures. This radical shift in the composer’s
role is also manifested in the output artifact, of what used to be a score.
For the realization of an ecosystemic performance, the composer provides
various documents that serve multiple functions. Along with the computer
program, which can be a patch or code with accompanying libraries, the
composer typically delivers:

EXPLORING
VISUALIZATION
METHODS OF
THE DYNAMIC
BEHAVIORS IN
COMPUTERBASED MUSICAL
WORKS

– Instructions for the performers in the form of text and symbolic or
graphic music notation.
– A tech rider, which includes connectivity diagrams, descriptions
for the analog equipment, spatial setup, and detailed information
about custom instruments and interfaces.
– Flowchart diagrams for the digital signal flow. The values of some
crucial parameters can also be indicated.
– Description of the expected behavior and methods of driving the
system’s dynamics.
All this information is addressed to the performers, concert organizers,
technicians, and computer musicians, and should be sufficient for the
realization of a performance. Although the preservation of computer-based

FIG. 2 Agostino Di Scipio, Background Noise Study: SIGNAL FLOW 1 (network of control
signals), 2004-05, score excerpt © Agostino Di Scipio

598

musical performances is a complex topic that requires interdisciplinary
effort,[19] the composer could facilitate this process by formulating the
information in a detailed way that makes migration to new technologies
possible. The conventional role of the score is included only as a part of
this expanded manuscript, which I shall call the “handbook.”

EXPLORING
VISUALIZATION
METHODS OF
THE DYNAMIC
BEHAVIORS IN
COMPUTERBASED MUSICAL
WORKS

599

KOSMAS GIANNOUTAKIS

TWO EXAMPLES OF VISUAL REPRESENTATIONS IN WORKS
WITH DYNAMIC BEHAVIORS

In this section I will present two of my works that utilize visualizations as a
means of gaining an insight about the work’s conduct.
SONIC CURRENT

GRAPHIC NOTATION FOR THE HANDBOOK

The aforementioned features for the handbook seem adequate. It lacks,
however, an important feature that used to be an integral part of the
conventional score, namely, an overview of the temporal evolution of the
piece. This feature enables the mental recreation of the sound qualities
and dramaturgy intended by the composer, although the mastery of
this skill requires years of professional practice. It seems that this
feature does not have a place in a handbook of an ecosystemic work;
nevertheless I would argue that this could be very fruitful.
A musical work that puts an emphasis on dynamic and emergent
behaviors does not present a single narrative but it can evolve within a
continuous space of possibilities. The portrayal of that space and the
predominant evolutionary paths by means of graphical representations
may offer insights about the outcome of a performance. It could serve
as a tool for the composer to articulate his/her ideas and effectively
communicate them to his/her collaborators. With this feature the
performers can memorize desirable scenarios so that they can detect
early routes to desirable or undesirable states in order to carry out
supportive or subversive actions.
Ideally, the dynamic behaviors could be formalized and codified
by the rigorous language of mathematics, as Xenakis did for stochastic
compositional processes.[20] A mathematical description of the work’s
dynamics would make the creation of computational models and
simulations possible that can give an overview about the work’s behavior.
The graphic outputs of such programs can be incorporated into the
handbook restoring the full functionality that the score used to have.
These advancements could lead to new documentation media such
as computer and web applications that enable an interactive learning and
exploration of the work. An example of such an interactive documentation
is Gerhard Eckel’s sound environment Zeitraum, hosted in the Research
Catalogue—international database for artistic research website.[21] In this
work, a spatialized periodic pattern of percussive sounds is distorted by
the movement of the listener due to the differences in propagation time of
the sound sources. The website contains various multimedia sections that
allow the visitor to explore the work from various points of view, denoted
as formulations.

Sonic Current (2016) is a sound installation originally conceived and
implemented for the “Twist,” a central construction structure at the heart
of the House of Music and Music Drama (MUMUTH) at the University of
Music and Performance Graz, designed by the architectural design network
UNStudio. Loudspeakers and microphones are installed according to the
specific twisted geometry of the site creating an audio feedback network.
Sounds from visitors, the environment, or other exhibited installations, are
captured by the microphones and distributed over a digital, generative
feedback network. Inside the high-dimensionally dynamic, self-regulating
digital network, sound circulates recursively in multiple recurrent layers,
resulting in diversely fragile resonant frequencies. The digital network
output is assigned to the loudspeakers, which radiate the processed
resonances back to the Twist. The emitted sound flows tangentially
on the twisted surface and reenters the network, while it is reflected
simultaneously in a peculiar twisty manner to the surrounding space.
The digital network is implemented with the Pure Data programming
environment and utilizes nodes as junction points where the signal activity
is integrated, and edges as variable delay lines with self-modulating
mechanisms. In subsequent presentations of the installation in various
locations, the arrangement of the transducers and the topology of the
digital network are redesigned according to any peculiarities in the
exhibition sites. The digital network has an intricate structure, containing
three layers of feedback pathways. In order to illustrate the internal activity
of the digital network, I have used in recent presentations an algorithm
that implements a delay coordinate embedding,[22] which visualize
the node dynamics in three dimensions. With this visual extension, the
visitors can experience the internal activity visually and track where the
components of the audible output are generated.
BURSTY EXORBITANCE

Bursty Exorbitance (2018) is an eight-channel computer-generated
composition developed at the Hertz Lab at the ZKM | Center for Art and
Media Karlsruhe in Germany as part of a residency on graphic notation.
It explores the eruptive sonic qualities that emerge from a far-fromequilibrium drive of a Generative Feedback Network, implemented with the
Pure Data programming environment. Eight nodes with self-modulating

600

mechanisms were soft-coupled as nonlinear oscillators, which produced
continuous sonic streams of explosive and recalcitrant character. Some
crucial parameters of the self-modulating mechanisms were controlled by
a four-dimensional chaotic attractor, discovered by Mohammad Ababneh
in 2017.[23] The visualizations of the attractor served as a tool that
provided proper parameter mappings for the macro development of the
composition. Other important sets of parameters were randomized within
composed limits while others were manually adjusted during the unfolding
of the composition. FIG. 5
In diagram FIG 4, the boxes with the sine waveform represent
wavetable sine oscillators and the dashed lines modulating signals. It
is worth mentioning that the four-dimensional chaotic system is an
autonomous system without any influence from the generative feedback
network or the user, and functions as a control structure. The attractor
visualization is achieved by the numerical integration of the differential
equations, a trivial process that yields immediate graphic results. A
potential coupling with the generative feedback network would require
other methods for visually representing the dynamics, like algorithms that
implement delay coordinate embeddings.

EXPLORING
VISUALIZATION
METHODS OF
THE DYNAMIC
BEHAVIORS IN
COMPUTERBASED MUSICAL
WORKS

OUTLOOK

The mathematically inspired and computer-based music-making, as
established by Xenakis's pioneering work, is flourishing nowadays with
the abundance of computation devices. The prominent field of sonic
ecosystems departs from the stochastic models introduced by Xenakis,
and explores dynamic and emergent sonic behaviors. The difficulty of
describing and communicating such behaviors retard the development of
the field, in comparison with other fields that explore other possibilities
which the computation media enable. In order to address these difficulties,
visualization techniques borrowed from the mathematical field of
dynamical systems may accelerate advancement and assist the composer
in order to articulate clearly and communicate his/her intention. Further
research is required to appropriate these techniques in the context of
sonic ecosystems. The emigration of the composer’s output, namely,
the printed score, to new media such as computer simulations and web
applications that present the artwork with multimedia content, seems a
very promising direction.
A framework that would enable the interaction of the UPIC approach
(graphical notation as parameter data for sound synthesis) and the
algorithmic approach (computer algorithms that produce visualized
parameter data) would be a very interesting strategy. For example, the
multidimensional strange attractors generated by chaotic mathematical

FIG. 3 Internal activity of the digital network consisting of 12 node structures in 3 layers,
2018 © Kosmas Giannoutakis
FIG. 4 Flowchart of the network topology used for the composition Bursty Exorbitance,
2018 © Kosmas Giannoutakis

603

KOSMAS GIANNOUTAKIS

systems could be imported in an appropriated graphical editor program
that would make manual changes on the trajectories possible. This
development would require the integration of three main programs: a
numerical computing program, a graphical editor program, and a sound
synthesis engine, which would enable a smooth workflow on all different
levels. This framework would be ideal for creating control structures that
provide parameter data for exploring areas with distinctive sonic qualities.
Another possible direction could be the application of machine
learning (ML) to the computer-based compositional process. Personal or
collective databases of parameter data created visually by humans and
or numerically by algorithmic processes can be used to train ML models.
These models could be used to generate new parameter data, which could
be inserted into the aforementioned framework and facilitate an early
phase of sonic exploration.

FOOTNOTES
1.
Robin Moore, “The Decline of Improvisation in Western Art Music:

An Interpretation of Change,” in International Review of the Aesthetics and
Sociology of Music 23, (1992), 61–84, doi:10.2307/836956.

FIG. 5 Various three-dimensional phase space portraits of the four-dimensional chaotic

attractor, 2018. The four-dimensional chaotic attractor was discovered by Mohammad
Ababneh in 2017. © Kosmas Giannoutakis

2.

Kyle Gann, The Music of Conlon Nancarrow, Music in the 20th Century, Vol. 7,
(New York: Cambridge University Press, 2006).

3.

Mihu Iliescu, “Glissandi and Traces: A Study of the Relationship between
Musical and Extra-Musical Fields,” in Makis Solomos, Anastasia Georgaki,
Giorgos Zervos, Definitive Proceedings of the International Symposium Iannis
Xenakis, (Athens, May 2005).
http://cicm.mshparisnord.org/ColloqueXenakis/papers/Iliescu.pdf

4.

Cat Hope and Michael Terren, “The Possibilities of a Line: Marking the Glissando
in Western Art Music.” in Proceedings of the Second International Conference
on Technologies for Music Notation and Representation (TENOR), (Cambridge,
2016), 176.
http://tenor2016.tenor-conference.org/TENOR2016-Proceedings.pdf

5.

Henning Lohner, “The UPIC System: A User’s Report,” in Computer Music Journal
10, (1986), 42–49.

6.

Joel Eaton and Eduardo Miranda, “Real-time Notation Using Brainwave Control,” in
Proceedings of the Sound and Music Computing Conference, 2013.
http://cmr.soc.plymouth.ac.uk/pubs/SMC-BCI_Notation.pdf

7.

Jason Freeman, “Extreme Sight-reading, Mediated Expression, and Audience
Participation: Real-time Music Notation in Live Performance,” in Computer Music
Journal 32 (2008), 25–41.

8.

Georg Hajdu and Nick Didkovsky, “Maxscore: Current State of the Art,” in Proceedings
of the 38th International Computer Music Conference (ICMC), 2012, 9–15.
https://quod.lib.umich.edu/i/icmc/bbp2372.2012.030/--maxscore-current-stateof-the-art?view=image

EXPLORING
VISUALIZATION
METHODS OF
THE DYNAMIC
BEHAVIORS IN
COMPUTERBASED MUSICAL
WORKS

604

9.

Giovanni Santini. “Linear (Live-Generated Interface And Notation
Environment In Augmented Reality)”, 2018.
https://www.researchgate.net/publication/325824804_LINEAR_LIVEGENERATED_INTERFACE_AND_NOTATION_ENVIRONMENT_IN_AUGMENTED_
REALITY

10.

Thor Magnusson, “Algorithms as Scores: Coding Live Music,” in Leonardo Music
Journal (2011), 19–23.

11.

Marie-Hélène Serra, “Stochastic Composition and Stochastic Timbre: ‘GENDY3’ by
Iannis Xenakis,” in Perspectives of New Music 31, (1993), 236–258.

12.

James Harley, “The Electroacoustic Music of Iannis Xenakis,” in Computer Music
Journal 26, (2002), 33–57.

13.

Agostino Di Scipio, “Compositional Models in Xenakis’s Electroacoustic Music,” in
Perspectives of New Music 36, (1998), 201–201.

14.

Karlheinz Stockhausen and Elaine Barkin, “The Concept of Unity in Electronic
Music,” in Perspectives of New Music (1962), 39–48.

15.

Agostino Di Scipio, “‘Sound Is the Interface’: From Interactive to Ecosystemic
Signal Processing,” in Organised Sound 8, (2003), 269–277.

16.

Jonathan Impett, “Interaction, Simulation, and Invention: A Model for Interactive
Music,” in Proceedings of ALMMA 2001, Workshop on Artificial Models for
Musical Applications, (Cosenza: Editoriale Bios, 2001), 108–119.

17.

Tim Blackwell and Michael Young, “Self-organised Music,” in Organised Sound 9,
(2004), 123–136.

18.

Simon Waters, “Performance Ecosystems: Ecological Approaches to Musical
Interaction,” in EMS: Electroacoustic Music Studies Network (2007), 1–20.

19.

Guillaume Boutard, “Co-construction of Meaning, Creative Processes, and
Digital Curation: The Transmission of Music with Live Electronics,” in Journal of
Documentation 72, (2016), 755–780.

20.

Iannis Xenakis, Formalized Music: Thought and Mathematics in Composition.
(Hillsdale, NY: Pendragon Press, 1992).

21.

Gerhard Eckel, “Zeitraum” Research Catalogue
https://researchcatalogue.net/view/94547/141743

22.

Hong-guang Ma and Chong-zhao Han, “Selection of Embedding Dimension
and Delay Time in Phase Space Reconstruction,” in Frontiers of Electrical and
Electronic Engineering in China 1, (2006), 111–114.

23.

Mohammad Ababneh, “A New Four-dimensional Chaotic Attractor,” in Ain Shams
Engineering Journal 9, (2017), 1849–1854.

REFLECTIONS

MARCIN PIETRUSZEWSKI
JULIA JASMIN ROMMEL
LUKAS NOWOK

THE DIGITAL
INSTRUMENT AS AN

MARCIN PIETRUSZEWSKI

ARTIFACT

613

MARCIN PIETRUSZEWSKI

THE DIGITAL
INSTRUMENT
AS AN ARTIFACT
INTRODUCTION

MARCIN PIETRUSZEWSKI

At first, the computer program is neutral and exists only in terms devoid
of any reference other than to itself. The program is its function. It is a
tool. It does something; it instructs a computer to perform a task. Its
working is often imperceptible beyond the surface of its interface—screen
based or physical—and its material extension to the inner depths of
its digital structure, the code. Reduced to its substance, being digital
consists of one of two binary values, either 0 or 1—the bit—and its
multiples, the byte. These elementary values cannot by themselves
constitute an object of reflection; as Guerino Mazzola points out “The
digital age is not centered around ‘bits and bytes’ but around their
accessibility and handling.”[1] Opening up the contents of the software
and exposing its inner working enables theorizing about the relationships
within the code itself, the coding architecture, the functioning of the code,
and specific programming choices or expressions, upon which the code
acts, outputs, processes, and represents.
However, focusing solely on a functional aspect of software limits
our engagement with its wider assemblage of connotations. Beyond the
functional and ostensible neutrality of its interface the software is an
artifact, as Matthew Fuller points out: “software creates sensoriums” and
participates in constructing “ways of seeing, knowing and doing in the
world.”[2] The software both contains a model of a world it ostensibly
pertains to and it also shapes the world each time it is used. Subrata
Dasgupta defines artifacts as “useful things that are produced or consciously
conceived in response to some practical need, want or desire.”[3]
With the UPIC (Unité Polyagogique Informatique de CEMAMu) Iannis
Xenakis operationalized a multiscale approach to sound composition within
a standard user interface. An incessant interpolation between temporal
resolutions of the micro, meso, and macro scales[4] constituted a vital feature
of the vision behind the UPIC. The system incorporated a particular view of
sound composition which moved beyond the theory of Fourier[5] and took
as a starting point the pressure versus time curve together with a sound
conceived as quantum; a “phonon” imagined already by Einstein in 1910.[6,7]
Xenakis’s ambition was “to take possession of the sound in a more conscious
and thorough manner,” to conceive “the material of sound” as composable.[8]

614

The design of the UPIC mobilized a correlative gestural and conceptual
exploration of the temporal, physical, and perceptual parameters of sound.
In my practice as a composer and researcher, I have been developing a
computer program called the New Pulsar Generator (nuPG).[9] The program
produces a form of synthesis called pulsar synthesis; its design draws upon
and extends the original Pulsar Generator (PG) application by Curtis Roads
and Alberto de Campo as described in the publications Microsound[10] and
“Sound Composition with Pulsars.”[11] The technique generates a complex
hybrid of sounds across the perceptual time span between infrasonic
pulsations and audio frequencies, giving rise to a broad family of musical
structures: singular impulses, sequences, continuous tones, time-varying
phrases, and beating textures. Through its inherently multiscale character,
pulsar synthesis proposes a unique view on rhythm moving beyond a linear
series of points and intervals tied to a time grid, and introduces a notion of
rhythm as a continuously flowing temporal substrate. Both PG and nuPG
relate to the UPIC through their graphical parametrization of synthesis
data and systematic approach to composition across multiple temporal
levels; an attempt at fusion between micro and macro scales. The study of
pragmata of these systems and a reflection on their sonic output provokes
many fundamental questions about computing, listening and understanding,
creation, interaction, and computer music aesthetics.
This article aims to display how engaging with a digital instrument—
particular qualities and propensities of its design, functional and conceptual
encapsulation of sound and composition theories—contributes to a
mediated model of creative music practice. Such an approach fits within a
broader perspective viewing technology and its objects beyond their merely
functional and instrumental roles, but as mediators of human experiences
and practices.[12] Taking a comparative approach in which the UPIC and the
nuPG systems are engaged with as tools of a particular epistemic modality, I
propose a concept of an “epistemic tool” to further contextualize a practice
of composing with computers in a current multiply-mediated musical reality.[13]
I shall focus on a particular epistemic perspective prescribed within
the design of the UPIC, an integration between conceptual, sound and
visual realms under a notion of multitemporal sound composition. I
propose a parallel narrative of the UPIC and nuPG that display an osmosis
of concepts and technologies of design. Throughout, key themes of this
text are composition across multiple timescales and computer program as
an artifact.
THE UPIC AND A MULTITEMPORAL PARADIGM

A key idea behind the UPIC was that everything in the composition could
be solved in the time domain by working out various shapes, such as

THE DIGITAL
INSTRUMENT AS
AN ARTIFACT

615

MARCIN PIETRUSZEWSKI

waveforms, pitch curves, and dynamic envelopes. This concept, also
called “graphical synthesis”[14] can be linked back to early experiments in
optical synthesis from the early twentieth century.[15]
When working with the UPIC, the user is confronted with a clean
slate, a tabula rasa; the system is mute and to generate sound it
requires input. The whole aspect of compositional labor—requiring the
user to specify objects from the microstructure of sound, its dynamic
development in time, and to the overall form of the composition—should
be seen as an intentional aesthetic and conceptual stance.[16] At the
level of sound microstructure, the user specifies the waveform and a
shape of the dynamic envelope, which together can be thought of as an
elemental timbre of the instrument. At a higher level of organization, the
user operates the music page function, drawing shapes—lines, curves,
and points, called arcs—on a frequency (vertical) versus time (horizontal)
axis.[17] FIG. 1
These drawn shapes need to be assigned to previously specified
timbres. However, up to this point each input to the system—the waveform,
envelope, and frequency time shapes on a page—exist only as a simple
drawing. To use a Xenakian notion, these shapes exist outside-of-time—they
lack temporal boundaries. By defining a duration (or multiple divisions of it)
for the page, the user decides how to temporalize these drawings: how to
bring the outside-of-time abstract shapes into-time. Only when the duration
is defined are these shapes then converted to music waves.
An essential aspect of UPIC’s setup are the editing capabilities
that each of the arcs could be subjected to: the user can cut, copy, and
paste individual shapes, and compress or stretch them in time and
frequency. An example of all these procedures can be found in Xenakis’s
UPIC composition (1978), which consists of arborescent shapes, cut and
pasted, compressed and stretched in time and frequency.[18] The reading
position and direction on a page and between pages can be variable, too.
As observed by Curtis Roads,[19] arcs written to a page with a duration of a
second become a characteristic of the sound’s microstructure. An opposite
manipulation is possible as well; the microstructural pressure versus time
curve can be stretched in time and used as a structuring element at meso
or macro time levels.
The uniform treatment of composition data and objects at every
level mobilizes a creative grafting across and between the micro, meso,
and macro time resolutions, a dialectical couplet of local and global
perspectives. The design of the UPIC favored a flexible work between
two strands of conceptualization: the inductive—a bottom-up glueing
of the elemental into the global—and a deductive—a top-down carving
of the whole into smaller parts. As such, the UPIC might be described

617

MARCIN PIETRUSZEWSKI

as a system of "transparent stratification" rendering entirely open for a
pendular process of differentiation and reintegration of sound materials
and forms at all the levels of temporal organization.[20] Such a bimodal
process problematizes the duality between form and material: the same
object can be conceived as material or form (substance or container)
depending on the level of investigation.[21]
The design of the UPIC extended the temporal field of compositional
activity and attempted to functionalize a multiscale approach to musical
form. To operate within a full register of timescales is to shift the aesthetic
focus away from discrete sound entities occupying well-defined time frames
towards continuous and evolving objects with fuzzy boundaries. These new
objects rarely conform to traditional angular forms of musical structure, and
tend toward cloud-like evaporative and continuously evolving morphologies.
The multiscale approach favors flexibility, as Curtis Roads points out: it
mediates between a high-level abstract plan (the top-down global structure)
and opportunities emerging from a low-level of sound material operations
(the bottom-up local structures). All temporal levels are to be composed;
at any time in the compositional process, we can intervene by synthesis
and transformation at any timescale, from a macro scale of the whole
work, down to sections, phrases, sound objects, grains, and even individual
samples.[22] A dialectic of inductive and deductive processes, observed
within the workings of UPIC, forms a key characteristic of the multiscale
composition approach: to approach musical composition from a multiscale
perspective is to allow an interplay between inductive (specific and local)
and deductive (general and global) thinking. These issues are pertinent to
the theory and practice of pulsar synthesis.
PULSAR SYNTHESIS: FROM PG TO NUPG

FIG. 1 A workspace of UPIC 3 running on a PC displaying partial data of a composition
by French-American composer Brigitte Robindoré, 2003, screenshot. Notice a variety of
shapes used as envelope and waveform as well as complexity and richness of the page.
© Brigitte Robindoré

As an integral part of my artistic research practice, I have been involved
in a systematic exploration of the technique of pulsar synthesis. Over
the past two decades, the technique of pulsar synthesis and its various
software instrument implementation—such as, Pulsar Generator (2000)
by Curtis Roads and Alberto de Campo, Pulsar Generator (2004) by Tommi
Kerannen and Particularity (2010) by Chris Jeffs—acted as a material point
of connection, linking practitioners in and outside research institutions.
Whether as input sound material for further processing,[23] a raw synthetic
output,[24] or as a model for auditory display of data,[25] the practice of
pulsar synthesis activated discourse in a variety of functional, aesthetic,
and conceptual contexts.
The technique of pulsar synthesis is a powerful approach to digital
sound synthesis; it is named after a highly magnetized rotating neutron star
that emits a beam of electromagnetic radiation at a frequency between

FIG. 2 A workspace of the Pulsar Generator program designed by Curtis Roads and
Alberto de Campo in 2000, 2019, screenshot. Notice the complexity of the pulsaret and
the envelope tables, as well as the variation in fundamental frequency and three sets of
formant frequencies, panning, and amplitude trajectories. These could be designed in
advance of synthesis, or manipulated in real time as the instrument plays. The program
implemented a scheme for saving and loading these envelopes in groups called
settings. The program lets one crossfade at a variable rate between multiple settings,
which takes performance with Pulsar Generator to another level of synthesis complexity.
© Curtis Roads

FIG. 3 A workspace of the New Pulsar Generator with its various extensions (e.g.,
wavefold modulators of synthesis parameters via matrix, parameter linking, multiple
tables for micro and meso scale trajectories, and preset system), 2019, screenshot.
The user can control all parameters of synthesis via the graphic interface, as well as
through text of the programming language via a set of predefined functions.
© Marcin Pietruszewski

620

0.25 and 642 Hz.[26] Pulsar synthesis operationalizes the notion of rhythm
with its multitemporal affordances as a system of interconnected patterns
evolving on multiple time scales.
The fundamental functional unit at the microstructure level in pulsar
synthesis is called a pulsar. A spectrum of a single pulsar is a result of a
convolution between pulsaret and envelope. The pulsaret table can be
considered “a template of spectrum shape,”[27] while the envelope is a
function limiting it in time. An important generalization is that both tables,
pulsaret waveform and envelope tables, can be any shape. A repetition
of the pulsaret forms a pulsar train; a stream of pulses emitted at a
user-stipulated rate which can vary from infrasonic pulsations to audio
frequencies.
Developed in 2000 by Curtis Roads and Alberto de Campo, the PG
program generalized the technique of pulsar synthesis and provided a
powerful interface to control its various parameters.[28]
As part of my ongoing PhD research at the University of Edinburgh, I
have been developing a new version of the historic PG. The nuPG program
is developed in SuperCollider 3 programming language and incorporates
an extensive set of graphic interface tools to control various parameters
of synthesis.[29] Additionally, the underlying Just-In-Time programming
paradigm[30] used in the development of the program means that all
objects of the nuPG can be redefined in real time. A coupling between
graphic and textual interfaces allows for powerful control of visual and
formalized compositional models.
At the microstructure of the sound the New Pulsar Generator
provides a set of tools to manipulate the shape of the pulsaret waveform.
FIG. 4 The shape can be also generated using a harmonic or the
Chebyshev shaper function FIG. 5. The waveform has a fundamental effect
on the spectral shape of the generated pulsar stream.
Foundational for the discussion on the digital musical instrument
design is the concept of representation.[31] Roads and Wieneke[32]
distinguish between iconic (also called analog) and symbolic
representations. “A sign is said to be iconic when there is a topological
similarity between the signifier (the sign) and its denotata (i.e., what it
represents).” A sequence of numbers stored in the memory of a computer
corresponding in value to the shape of an acoustic signal is one example
of such representation. “A sign without either similarity or contiguity but
only a conventional link between its signifier and denotata is called a
symbol.”[33] A syntactic arrangement of symbols plays a functional role
within formal languages. Such symbols do not usually mirror the surface
structure of a composition; rather, they represent the “background”
interrelations or “deep structure.”

THE DIGITAL
INSTRUMENT AS
AN ARTIFACT

FIG. 4 An editor of the pulsaret waveform, 2019, screenshot. The shape can be
drawn directly or loaded from predefined functions. A sound sample can be used
as a waveform, too. Located at the bottom of the window, preset functionality
allows for saving and interpolating between waveforms. © Marcin Pietruszewski
FIG. 5 A simple tool allowing generation of various shapes for a pulsaret waveform, 2019,

screenshot. It can be thought of an incorporation of additive synthesis paradigm—where
multiple harmonics are added together—within pulsar synthesis. © Marcin Pietruszewski

622

The question of iconic versus symbolic, discrete versus continuous, as
well as graphical versus textual representation of musical information is a
perennial issue in the context of digital instrument design.
THE DIGITAL INSTRUMENT AS AN ARTIFACT

As a way of synthesizing the discussion about UPIC, PG, and nuPG I
propose to expand the notion of digital instrument as an artifact. the UPIC,
as well as PG and nuPG programs, as any other piece of human-made
technology, do not function in a vacuum. As Anne Sauvagnargues points
out:
A tool or a machine should not be studied in isolation without taking
into consideration the milieu of individuation that surrounds it and
allows it to function. No machine or technical tool exists by itself [...]
they only function in an assembled milieu of individuation, which
constitutes their conditions of possibility: there is no hammer without
a nail, and thus the interaction between a multitude of technical
objects makes the fabrication of hammers and nails possible, while
also forming the conditions of their utilisation and the practices and
habits associated with them.[34]
Systematic engagement with an artifact must acknowledge its
constituent multiplicity and contexts activated via its use. Artifacts are
complex conglomerates of things and composition of “components, which
are continuously rearranged and reassembled in their specific modes of
appearance throughout history”.[35] Artifacts are “like organisms, they
manifest evolution.”[36] Any artifact is surrounded by the knowledge that is
prior to its emergence and also by the knowledge that appears only after
the artifact was made.
Every artifact generates an interpretative cut. With a particular
perspective prescribed within its design and function, UPIC, PG, and nuPG
can all be thought of encapsulations of knowledge and carriers of a sound
theory. Moreover, engaging with such instruments is not limited only to
interaction with their physical dimension—the interface. These instruments
engage their user with a prescription of a compositional model; a projection
which embodies a particular epistemological perspective of what is to be
composed: what is the material, its possible transformation and formal
organization. By mediating their compositional model, UPIC, PG, and nuPG
framed the boundaries of perception and thought.
Don Ihde conceptualized a variety of phenomenological modalities of
instruments and their role in our relationship with the world. Among these
are embodied relations, where the instrument acts as an extension of the
body and amplification of the senses; and hermeneutic relations, where

THE DIGITAL
INSTRUMENT AS
AN ARTIFACT

623

MARCIN PIETRUSZEWSKI

the instrument provides us with data (e.g., a sonogram) which we have to
interpret (from Greek hermēneuein, interpret.)[37]
The underlying design technology of UPIC, PG, and nuPG correlates
the embodied and hermeneutical within one design based on a bimodal
evolution between gestural and conceptual. All the systems incorporated
embodied relation; the UPIC especially, through its corporeal interface
relying on the drawing capacity of the human hand and the proportion of a
CAD/CAM drawing board, ergonomically designed to follow the proportions
of the human body.[38] The ability to use the various objects (a waveform,
an envelope, the page, pulsaret editor, etc.) of these systems, however,
required interpretative work, and it is here that UPIC, PG, and nuPG
incorporated a hermeneutical relation. In this perspective, all three can
be seen as compound devices extending the body, eye, ear, and mind, as
instruments impregnated with knowledge, which can serve as a model
of how our conceptions of what is musical material and form are being
constructed.

FOOTNOTES
1.
Guerino Mazzola, The Topos of Music: Geometric Logic of Concepts, Theory, and

Performance (Basel: Birkhäuser, 2012), 105.

2.

M. Fuller, Behind the Blip: Essays on the Culture of Software (New York:
Autonomedia, 2003), 19.

3.

Subrata Dasgupta, Technology and creativity (New York: Oxford University Press,
1996), 9.

4.

For an extended discussion on temporal scales see Curtis Roads, Microsound
(Cambridge, MA: MIT Press, 2004).

5.

Iannis Xenakis, Formalized Music (Hillsdale, NY: Pendragon Press, 1992), 258.

6.

Ibid. xii.

7.

In the 1940s, British physicist Dennis Gabor proposed that all sounds can be
viewed as a succession of elementary particles of acoustic energy. The question
of “realness” of these particles is an attractive one and relates to the age-old
dilemma of pre-existence of all possible divisions within a whole.

8.

Bálint András Varga, Conversations with Iannis Xenakis (London: Faber and Faber,
1996), 44.

9.

For the documentation see
https://www.marcinpietruszewski.com/the-new-pulsar-generator.

10.

Curtis Roads, Microsound (Cambridge, MA: MIT Press, 2004), 137.

11.

Curtis Roads, “Sound Composition with Pulsars,” in Journal of the Audio
Engineering Society, 49, 3 (2001), 134–147.

THE DIGITAL
INSTRUMENT AS
AN ARTIFACT

624

12.

Such a view is grounded in theories of Feenberg, Fuller, and Manovich; see Roger
F. Malina and Sean Cubitt, Software Studies: A Lexicon (Cambridge, MA: MIT
Press, 2008).

13.

Georgina Born, “On Musical Mediation: Ontology, Technology, and Creativity,” in
Twentieth-century Music 2, (2005), 7–36.

14.

Curtis Roads, The Computer Music Tutorial (Cambridge, MA: MIT Press, 1996),
329–330.

15.

For an in-depth discussion on optical synthesis see Thomas Y. Levin, “Tones from
Out of Nowhere: Rudolph Pfenninger and the Archaeology of Synthetic Sound,” in
Grey Room, 12 (2003): 32–79; László Moholy-Nagy, “Production—Reproduction:
Potentialities of the Phonograph” [1922] in Audio Culture: Readings in Modern
Music, ed Christopher Cox and Daniel Warner (London: Continuum, 2004);
Luc Döbereiner, “Models of Constructed Sound: Nonstandard Synthesis as an
Aesthetic Perspective,” in Computer Music Journal 35, (2011), 28–39; Kristine
Helen Burns, The History and Development of Algorithms in Music Composition,
1957–1993, PhD thesis, Ball State University, Muncie, Indiana, Ann Arbor, 1994.

16.

Herbert Eimert related to this approach as the “absolute composition” through
which “real musical control of nature” can be asserted; see Herbert Eimert, “Von
der Entscheidungsfreiheit des Komponisten,” in die Reihe 3 (1957), 5–12.

17.

A detailed technical specification of various iterations of the UPIC system
have been already described in detail: Henning Lohner, “The UPIC System: A
User’s Report,” in Computer Music Journal 10, (1986), 42–49. Gérard Marino,
Jean-Michel Raczinski, and Marie-Hélène Serra, “The New UPIC System,” in
International Computer Music Conference Proceedings, vol. 1990,
https://quod.lib.umich.edu/i/icmc/bbp2372.1990?rgn=full+text; Gérard Marino,
Marie-Hélène Serra, and Jean-Michel Raczinski, “The UPIC System: Origins and
Innovations,” in Perspectives of New Music 31, (1993), 258–270.

18.

For an analysis see Benjamin R. Levy, “Clouds and arborescences in Mycenae
alpha and the Polytope de Mycènes,” in Xenakis Matters: Contexts, Processes,
Applications, ed. Sharon Kanach (Hillsdale, NY: Pendragon Press, 2012).

19.

Curtis Roads, Microsound (Cambridge, MA: MIT Press, 2004), 159.

20.

Robin Mackay, Russell Haswell, and Florian Hecker, “Blackest ever Black”,
Collapse 3 (2007), 109–139.

21.

Gottfried Michael Koenig, “Genesis of Form in Technically Conditioned
Environments,” in Journal of New Music Research 16, (1987), 165–175.

22.

See Chapter 9, “Multiscale Organization,” in Curtis Roads, Composing Electronic
Music: A New Aesthetic (New York: Oxford University Press, 2015). 283–317.

23.

For example, see the compositions by Curtis Roads: Half-Life (1998), Tenth Vortex
(2000), Eleventh Vortex (2001), and Kim Cascone’s Pulsar Studies (2004) EP.

24.

Florian Hecker, Recordings for Rephlex (2006), CD, Rephlex.

25.

Marcus Schmickler utilized a pulsar synthesis model in a sonification of pulsars in
the Bonner Durchmusterung project, for details see
http://piethopraxis.org/projects/bonner-durchmusterung/

26.

Pulsars are rotating neutron stars that appear to “pulse” because the beam of
light they emit can only be seen when it faces the Earth. Pulsars were discovered
by Jocelyn Bell Burnell, which is considered one of the greatest astronomical
discoveries of the twentieth century.

27.

Curtis Roads, Microsound (Cambridge, MA: MIT Press, 2004), 146.

625

MARCIN PIETRUSZEWSKI

28.

Ibid. 154.

29.

For the User Manual describing all objects of the New Pulsar Generator see:
https://www.marcinpietruszewski.com/the-new-pulsar-generator

30.

Julian Rohrhuber, Alberto de Campo, and Renate Wieser, “Algorithms Today: Notes
on Language Design for Just In Time Programming,” in International Computer
Music Conference Proceedings, vol. 2005, 291,
https://quod.lib.umich.edu/i/icmc/bbp2372.2005?rgn=full+text

31.

Meinhard Müller, Fundamentals of Music Processing: Audio, Analysis, Algorithms,
Applications (Heidelberg: Springer, 2015).

32.

Curtis Roads and Paul Wieneke, “Grammars as Representations for Music,” in
Computer Music Journal, 3, (1979), 48–55.

33.

Thomas A. Sebeok, “Six Species of Signs: Some Propositions and Strictures,” in
Semiotica, 13, (1975), 233–260.

34.

Anne Sauvagnargues, Artmachines: Deleuze, Guattari, Simondon (Edinburgh:
Edinburgh University Press, 2016), 186.

35.

Paulo de Assis, Logic of Experimentation. Rethinking Music Performance through
Artistic Research (Leuven: Leuven University Press, 2018), 107.

36.

Subrata Dasgupta, Technology and creativity (New York: Oxford University Press,
1996), 114.

37.

Don Ihde, Technology and the Lifeworld: From Garden to Earth (Bloomington, IN:
Indiana University Press, 1990).

38.

The drawing board featured in the early version of the UPIC system and later had
been replaced with an interaction on a computer’s screen with a mouse. In the
early version of the system, the drawing field of the board had a calibrated area of
60 cm high by 75 cm wide.

ZWISCHENRAUM
JULIA JASMIN ROMMEL

(INTERSPACE)

631

JULIA JASMIN ROMMEL

ZWISCHENRAUM
(INTERSPACE)
My work on the Zwischenraum (interspace), which is elaborated on in this
chapter, is based on an artistic exploration of an acoustic measurement
of space. I shall also address the close connection between the cultural
techniques of graphic notation and cartography.
To gain a more precise overview of my daily movement routine, that
is, the paths I take every day, I recorded every distance with at least a
duration of 3 minutes for a period of exactly one year, with precise details
of the duration, starting, and end points of the movement and the means
of transport. Although this documentation was not originally created for
the purpose of analysis, it became the starting point for reflecting on what
overcoming distance—the interspace—means to me.
The interspace actually describes a temporal-spatial interval, which
has to be traversed (in my case) by subway, train, car, or airplane, in order
to get from A to B. Even though this is a kind of by-product, I experience
this transitional situation as something very positive: in a constellation
of external framing conditions—being interned in repetition, routine, and
boredom—the space in between becomes a kind of state of mind, of
contemplation and distraction. Rhythm is the permanent confirmation of
continuity. The space in between contains neither the past nor the future,
thus no development, but rather the standstill in the present of passive
movement.
In my curiosity to understand this very inspiring spatial configuration,
I have begun to document cartographically the interspace and sonify it
with the graphical sequencer IanniX.
MAP PRODUCTION AND ROOM SURVEYING

JULIA JASMIN ROMMEL

A total of ten cards were created during my everyday sojourn in the
Zwischenraum. Some of them are long-term documentations of the relations
of different places to each other, others are concrete (but arbitrarily chosen)
snapshots of linear distances.
Each map deals with a certain aspect of the in between space that
is decisive for me, for example, Frequenz (frequency), FIG. 1 Übergänge
(transitions), FIG. 2 Orientierung (orientation), FIG. 3 Rastlosigkeit und
Kontinuität (restlessness and continuity), FIG. 4 Richtungswechsel
(changes of direction), FIG. 5 individuelle Distanzwahrnehmung,
Be- und Entschleunigung (individual perception of distance, acceleration
and deceleration), and so forth. To visualize these topics I developed

633

FIG. 1 Frequenz (frequency)
METHOD: Documentation of cities visited frequently during the past year and the total

amount of time spent travelling from one city to another.
LOCATION/MEANS OF TRANSPORT: Car, train, air travel between the cities Berlin, Zurich,
Dresden, Stuttgart and Schwäbisch Gmünd.
STRUCTURE/VISUALIZATION: The map contains several circular systems, each circular
center marks one city, the circular system around this city marks the distance to
another city. This distance calculates the time of all my travels between those two
places. Each city is positioned at the center of a system as well as on one orbit of each
of the other systems.
TOPIC: Individual sensation of distances caused by repetition; extension; contraction of
distances caused by repetition; boredom.

GUY MÉDIGUE

Stuttgart - Berlin

plane

55 min

3 × 165 min

Konstanz - Zurich
Sch. Gmünd - Stuttgart

car

70 min

4 × 280 min

car

45 min

6 × 270 min

Sch. Gmünd - Ulm

car

60 min

5 × 300 min

Zurich - Berlin

plane

75 min

8 × 600 min

Berlin - Dresden

train

125 min

5 × 625 min

Zurich - Sch. Gmünd

train

210 min

13 × 2730 min

Dresden - Zurich

train

720 min

7 × 5040 min

634

experimental but context-related criteria, parameters, and methods. For
this purpose, I captured space-structuring elements, such as tunnels
and bridge crossings, oncoming trains, flight booking data, curve angles,
window views, announcements in trains and planes, route repeats, local
time, and so on.
At first glance the contents of my maps seem banal. They were
created far outside any conventionally measurable quantities of
geographical cartography and can in some respects be regarded as
“meaningless” data that have no objective or scientific significance. The
question of which routes were documented is also relatively irrelevant.
For me, the meticulousness with which the respective documentation
methods were applied is decisive. I am interested in the aesthetics of
information and the relationship between local and temporary facts,
their context and connection, which makes information meaningful in
detail. By systematizing this abstract information and summarizing it in
corresponding structures and systems, I hope to be able to represent the
complexity and absurdity of the logic of my interspace.
Cartography as a cultural technique of space appropriation is
implemented here in an individual and very personal recording of
locomotion, a kind of field research as a self-experiment. It should be
understood as an interpretation of space that has arisen in the context of
a certain aesthetic attitude.
TRANSFORMATION OF THE CARDS INTO SOUND

The resulting cartographic survey makes it possible to experience the
interspace on a cognitive level. My aim, however, is to go beyond factual
analysis and express the poetic qualities of these specific spatial
configurations.
This motivation led me to examine translation into other media,
with a focus on a possible acoustic dimension of the maps. In a further
transformation process, my maps thus become the source material
for a spatialization of information into sound. The aim is not to revive
the original paths taken, but rather the graphic system of my spatial
measurements and to make it experienceable audibly.
The linearity on which some maps are based forms the framework of
a timeline, embedded in a classical coordinate system. I have tried to find
simple shape-describing sounds that vary in frequency and dynamics. The
sound material was selected intuitively; there were no musical models. It
ranges from a simple sinus tone to sound recordings (for instance, certain
vehicle noises from the interspace), which are linked to a certain card in
terms of content and method. In this way, facts that are not immediately
apparent from the visual image—such as the information that the arrows

ZWISCHENRAUM
(INTERSPACE)

635

JULIA JASMIN ROMMEL

are trains, or that the curves refer to impending air travel—are supplied as
auditory information.
In addition to working on the sound material, the focus of my work on
graphic notation at the Hertz Lab at the ZKM | Center for Art and Media
Karlsruhe was on the spatial arrangement of information using the ZKM’s
Sound Dome sound spatialization system. The direction of the sound
source becomes an important means of describing the properties of the
respective parameters of a map. The sound material was arranged in such
a way that an essential spatial factor of the corresponding spatial situation
becomes comprehensible. For example, parallel overlapping events are
distributed among different loudspeakers in order to make them more
differentiated and experienceable. In a corresponding arrangement of
the channels, the changes of direction repeatedly addressed in the maps
are translated as sounds moving towards or away from one another. They
circle around the listener at different speeds and in this way make it
possible to experience the information density of a map.
MUSICAL RENDERING FROM THE DESIGNER’S PERSPECTIVE

My competence as a graphic designer and scenographer lies in creating
strategies for structuring information to make it more easy to read.
Based on this approach, I have investigated which aesthetic qualities of
a graphic notation can play a role in the transformation into sound, and
which design parameters that increase the visual readability of data find a
correspondingly meaningful application in acoustics.
I assume that, as a person who works and thinks visually, I judge
data differently than a musician or composer. I am interested in these
differences in perception, and with my work I try to show where exciting
interfaces of possible cooperation open up.
GRAPHIC NOTATION FROM THE PERSPECTIVE OF THE DESIGNER

In order to be able to define this interface concretely, I must first describe
my perspective as a designer on the graphic work of composers.
In my opinion, it is remarkable what a large number of graphic
notations are created with very limited technical aids. In view of our
everyday communication, which allows everyone to communicate as
colorfully as possible using digital tools, these pencil drawings seem
antiquated with their rather inelegant aesthetics, although admittedly,
they are quite appealing. Perhaps it can be deduced from this that for
many composers the step into another medium represents a great
challenge, or that one consciously wishes to remain recognizable within
the context of a music score sketch. However, if one decides against using
a conventional sign system or consciously opts to use graphic images, in

FIG. 3

FIG. 3 Orientierung (orientation)
METHOD: Documentation of curves measured with a compass (171 curves).
LOCATION/MEANS OF TRANSPORT: Train journey from Zurich to Arosa, Switzerland.
STRUCTURE: Linear map; no timeline; every change of direction is visualized by one circle.
VISUALIZATION: One circle represents one curve; the marked part of the circle stands for

the angle from one direction to the other.
TOPIC: Orientation - disorientation; localization.

FIG. 4 Rastlosigkeit und Kontinuität (restlessness and continuity)
METHOD: Documentation of the time relation between the date of booking a flight and

FIG. 2 Übergänge (transitions)
METHOD: Documentation of tunnels and bridges on a train journey.
LOCATION/MEANS OF TRANSPORT: Train journey between Arosa and Chur, Switzerland.
STRUCTURE: Linear map; time line from 12:05 p.m. to 12:42 p.m.; duration of train

journey/five minutes per line; measurement in seconds.

VISUALIZATION: Black semicircles represent tunnels; arches represent bridges; the size

of the elements refers to the length of the bridge or the tunnel.

TOPIC: Link and transition; tunnels and bridges are spatial elements that connect places.

the date of departure.

LOCATION/MEANS OF TRANSPORT: Various flights with different airlines to different

destinations.

STRUCTURE: Linear map; timeline by dates.
VISUALIZATION: Each curve represents one flight; the beginning of the curve marks the

date of booking, the end of the curve marks the date of departure; the higher the curve
the longer the distance between booking and departure; erased dates represent the
time where there wasn’t any flight booked.
TOPIC: Restlessness, continuity, attempt to keep a certain level of interspace experiences.

638

my view it is lost potential not to engage intensely with the corresponding
technical and manual methods.
As already envisaged in Dieter Schnebel’s book Mo-No: Musik zum
Lesen (Music for Reading) (1969),[1] many contemporary composers regard
their graphic notation as an integral part of their works. Therefore, this
notation should reach both the medium of communication for the interpreter
of the music, and also the listener directly. In view of his book, Schnebel
was accused of only addressing an elite audience of contemporary music
interpretation with his scores, which are directed at the reader.[2] Might it be
possible that Schnebel’s idea of allowing music to develop solely in the mind
of the recipient would perhaps have been rendered more accessible to an
audience if he had collaborated for his notations with a graphic artist who
was able to communicate visually more effectively?
For me, of course, the outstanding examples that place a
differentiated visual expression of abstract forms and colors in direct
relation to a musical experience, such as György Ligeti’s Werk Artikulation
(1958) in its transcription by the graphic artist Rainer Wehinger, or
Cornelius Cardew’s legendary graphic composition Treatise (1963–1967),
are outstanding examples. Here I recognize clear creative intentions that
evoke interest and joy in contemplation.
Graphic notation cannot take on the function of classical notation. The
reception of script and image functions completely differently, as composer
and media designer Christian Fischer explains in a direct reference to
graphic notation: “Pictures cannot be read. They can only be analyzed and
interpreted. The more unspecific, unclear or abstract the image, the more
sketchy and difficult the interpretation. In this context, there is no right or
wrong interpretation as long as it is coherent and comprehensive.”[3]
RECEPTION IN CARTOGRAPHY AND GRAPHIC NOTATION

It is precisely in this question of the reception of signs, respectively
of images, that I find the connecting element of graphic notation and
cartography. As cultural techniques of information translation and mediation,
they exhibit parallels in their necessity to reflect on the interplay of the
different levels of information reception, and to open up to interpretation
at a decisive moment. The focus is no longer only on the question of the
precision of the tool, but on the possibility of giving the recipient a specific
approach and attitude to this information, and thus overcoming the
boundary between reading a sign and interpreting an image.
The task, therefore, consists in designing a sign as an image in such
a way that it does justice to both functions. It is important to take into
account this tension between the targeted conveying of information and
free interpretability in the communication process.

ZWISCHENRAUM
(INTERSPACE)

639

JULIA JASMIN ROMMEL

SYMMETRY OF HEARING AND SEEING

In the context of sonification as a scientific form of publication, it is
emphasized on the one hand that it allows an audience outside the field
of science easier access to complex data, but on the other hand that the
gathering of data by hearing is much less established in our society than
by the eye. There seems to be great potential here to cultivate consciously
an alternative level of information perception. My design of a “cartophony”
arises out of a similar motivation: the aim is to enable an exemplary form
of spatial experience through an alternative aesthetic approach.
I try to invent a sign system that can be read, but which at the
same time forms an aesthetic construct that can be interpreted in an
experiencable way, that at the same time addresses a rational as well as
an intuitive level. It is particularly this cognitive interface of reading signs
and interpreting images that interests me in information design.
Limited to their visual perception, the attention of the viewer of
my maps is probably focused primarily on density and repetition of the
documented elements and on the comparison of maximum and minimum
versions of the event.
The transformation into sound is not intended to replace what
can be experienced visually, but rather to expand it, thus opening up
readability to an expanded interpretation. The aim is not to place sound
and vision in a mutually illustrating relationship, but to enable a multilayered perception of information through the interaction between the two
different levels of perception.
In my work Zwischenraum I implement this through the graphic
sequencer IanniX, which triggers live acoustic events as a time-based
medium based on a visual combination of curve and cursor. In the
resulting comprehensibility of a self-referential system, a special
reference to reality is created after my experience: One waits for what one
sees; one hears what one expects and thus concentrates on the details
of the map.
This form of cartophony encourages me to look at individual
elements in a certain direction and at a certain tempo. In a way, the
sound leads through the graphics—or vice versa? The information is
thrown back and forth between acoustics and optics like a ping-pong
ball. I try to observe what effect this process of reciprocal reflection has
on the essence of the information and which parameters can be used to
determine which level of perception sets the tone in this process.
LEVELS OF PERCEPTION IN THE ORIENTATION PROCESS

The connection between eye contact and listening comprehension
in communication is familiar to us from everyday experience. Recent

FIG. 5 Richtungswechsel (changes of direction)
METHOD: Documentation of all oncoming trains on a journey.
LOCATION/MEANS OF TRANSPORT: Train journey from Bremen to Zurich.
STRUCTURE: Linear map; timeline from 8:20 a.m. to 4 p.m.; each line represents one hour.
VISUALIZATION: Arrows left to right: train that I am sitting in; arrows right to left:

oncoming trains; pointed arrow: fast encounter at high velocity; stub arrow: slow
encounter at low velocity.
TOPIC: Back and forth, interrelation of trip and return trip; departure and destination;
leaving a place and travelling towards a place.

ZWISCHENRAUM
(INTERSPACE)

642

research by neurologists at the University of Pittsburgh has shown that this
is not only a neurological coupling of eye and ear, but also a physiological
one. Accordingly, the alignment of the auditory system is oriented to the
direction of the gaze by an appropriate alignment of the eardrum.
The peripheral hearing system contains several motor mechanisms
that allow the brain to modify the auditory transduction process. [...]
Here, we report a form of eardrum motion produced by the brain via
these systems: oscillations synchronized with and covarying with the
direction and amplitude of saccades. These observations suggest
that a vision-related process modulates the first stage of hearing. In
particular, these eye movement-related eardrum oscillations may
help the brain connect sights and sounds despite changes in the
spatial relationship between the eyes and the ears.[4]
The ear as our balance-regulating organ is per se responsible for our
ability to orientate. Here, however, it is again explained how the visual
apparatus controls hearing, how strongly the stimuli overlap instead of
coexisting. Auditory perception, therefore, plays a fundamental role in
spatial orientation—the location and orientation of the self in space.
The cartographic studies are part of my extensive theoretical and
practical examination of spatial orientation processes. Thus the task
was to place the map, as a medium of overview on the one hand, and as
a linear route description on the other, in a verifiable relationship, thus
posing a fundamental question about the orientation process: To what
extent can strategies of parallel linking of sound and image be applied to
goal-oriented spatial navigation?
Orientation processes are supported by media in different ways: In
the form of classical signalling, in other words, through information that is
located directly in physical space; through the print medium of the map; or
as its extended version of a virtual navigation system.
The latter is directly related to my work: I see parallels between the
way in which acoustic and visual information in my maps overlap, and the
interaction between virtual information and physical reference in space
when using a navigation system. The IanniX cursor corresponds to an avatar
with the help of which I search for my position on the screen or the street.
In our everyday lives, purely acoustic spatial information is mainly
used where it is particularly important: as a warning signal. It rarely acts
as a substitute for a visual sign; for example, in an acoustic parking aid. A
further example are the train melodies of the Japanese local transport
companies, where both the stations and the trains of the individual lines
are distinguished by different melodies. This solves the problem posed by

643

JULIA JASMIN ROMMEL

overcrowded trains and platforms, where it is impossible for information to
be captured visually.
Unlike visual information, we cannot blank out acoustic information
so easily, and the danger is to classify it negatively as a flood of stimuli
(such as the endlessly repeating, somewhat annoying instructions of the
voice of a navigation system). In my opinion, however, this is largely due to
misuse. A specific investigation of this is planned for my future arts-based
research work.
After all, hearing is predestined as an orientation aid: Localization
as the task of auditory perception describes the determination of the
relationship between auditory event, direction, and distance of a sound
source. In contrast to the image, there is no nonspatial sound. Hearing
includes basic spatial aspects: How far can I hear? As a perspective
hearing and also a kind of acoustic horizon line definitely exist, in what
way do they form a promising alternative to the corresponding visual
parameters? My further work will focus on the question of which acoustic
navigation strategies can be developed in order to guide intuitively through
space, to reduce visual information in a meaningful way, and to make
paths interpretable.
The close relationship between graphic notation and cartography,
which I have established in my work, offers a concrete basis for
investigating these possibilities for developing acoustic information in
spatial orientation processes.

FOOTNOTES
1.
Dieter Schnebel, Mo-No:Musik zum Lesen (Ostfildern: DuMont Reiseverlag, 1982),

http://www.medienkunstnetz.de/werke/mo-no/

2.

Heinz Josef Herbort, “Und sieben Futurophone,” Die ZEIT, no, 15 (1970),
https://zeit.de/1970/15/und-sieben-futurophone

3.

Christian M. Fischer, “Understanding Animated Notation,” in Proceedings of
TENOR 2015, First International Conference on Technologies for Music Notation
and Representation, Paris (2015), 36,
http://tenor2015.tenor-conference.org/papers/05-Fischer-AnimatedNotation.pdf

4.

Kurtis G. Gruters, et al., “The Eardrums Move When the Eyes Move: A Multisensory
Effect on the Mechanics of Hearing,” in PNAS, 115, E1309-E1318 (2018); first
published January 23, 2018, https://www.pnas.org/content/115/6/E1309

FROM THE SYMBOLIC
TO THE REAL:

GRAPHIC

NOTATION
AS A SYMBOLIC
AND TECHNOLOGICAL
LUKAS NOWOK

MEDIUM

649

LUKAS NOWOK

FROM THE SYMBOLIC
TO THE REAL:
GRAPHIC NOTATION
AS A SYMBOLIC AND
TECHNOLOGICAL
MEDIUM
Given their function as a strictly one-way medium of communication
between composer and performer, musical notation systems would
seem to be quite inflexible. They play an imperative, instructive role on
behalf of the musical work, which makes their readability dependent on a
syntactical and grammatical agreement between composer and performer.
Notation, therefore, is fundamentally a reduction or quantization of the
concrete/real to the symbolic, with the ostensible goal of subsequent
reproduction: realization. The basic prerequisite for such a quantization is
to determine a framework that captures the dimensions required for an
adequate representation of the work to be realized—while simultaneously
excluding parameters that do not fit the framework and are not
represented, thereby giving the performance a certain flexibility, on the
one hand, and a certain indeterminacy on the other (in traditional notation,
for example, timbre is merely implied by the choice of instrument or the
specification of a particular way of playing).[1] For that reason alone, one
would assume that the form of notation must serve and be subordinate to
the musical, compositional, or aural idea—and indeed, the concept of the
musical idea’s independence from the way it is written down is persistently
underscored in traditional musical ontology. For example, Roman Ingarden
wrote:
As every symbol (sign) is distinct from the symbolized (signified) object,
so also is the score distinct from the work defined by it. No univocal
correlation exists between it and the work, since the same work can
be written down by means of different systems of notation.[2]

LUKAS NOWOK

In reality, this independence and flexibility is only somewhat
observable in the history of music. The symbolic framework of traditional
notation is pushed to its limits, in a constantly changing musical and

650

aesthetic language, to represent aural structures that are almost
impossible to represent in that framework as fundamentally constituted,
and yet even this transformation takes place only very slowly—perhaps
on account of the complex dependencies and functions the framework
has to fulfill. Cornelius Cardew addressed this subject in the handbook
accompanying his graphic work Treatise:
The writing down of music is in process of disintegrating. In the past
the notation of music was dependent on flexible conventions and
a performer could use these to correct the tendencies of an aural
tradition. [...] In the notation of music today two tendencies are
apparent: (1) to so reduce the flexibility of the conventions that they
become virtually inflexible (this means that and nothing else), and
(2) to so increase the flexibility of the conventions that they in fact
become non-conventional (this may mean this, that or the other, and
not necessarily any of these).[3]
My aim here is to illuminate this “disintegration” of musical writing
systems from a variety of perspectives, and to elaborate, via speculative
and exploratory lines of thinking, some possible methodological
paradigms that may be created by breaking up the rigid relationships and
dependencies that exist between idea, transcription, and realization in
notation. An introductory consideration of traditional musical notation
shall serve merely as a starting point, establishing the historical basis
from which new, nonconventional, graphic abstractions of musical writing
have diverged. The conventional categorization of notation, in musical
ontology, as “a medium through which is expressed the will of the artist
as to how the work created by him should be given form”—according to
which notation is to be viewed as merely a material object that makes
“the work that was composed at a certain point in time [...] intentionally
accessible”[4]—shall be turned on its head. Ingarden, and some of the
musical ontologists who came after him, saw in notation nothing more
than an instantiation of the musical work, which comes into being through
a creative process unconnected to notation, and which then exists from
the moment of its completion as a supratemporal, nonmaterial object.
According to Ingarden, there is no straightforward correspondence
between notation and work, “since the same work can be written down by
means of different systems of notation.”[5]
Countering this still widespread view, notation shall be regarded
here, in the context of our present-day artistic and musical culture, as
an integral part of conceptualization, form-finding, and the artistic
thought process itself, rather than a neutral communications and storage

FROM THE
SYMBOLIC
TO THE REAL:
GRAPHIC
NOTATION AS
SYMBOLIC AND
TECHNOLOGICAL
MEDIUM

651

LUKAS NOWOK

medium. This affords us, perhaps most importantly, analytical access
to the complex relationship between symbol and symbolized in spheres
such as computer music in particular, and artistic procedural work with
computers in general. In these fields, the reproduction of notation is no
longer bound to human limitations in communication and interpretation,
thus opening up syntactically flexible and individualized possibilities in
terms of the design of notation, and also blurring the boundaries between
notation as a symbolic medium and as a technological one. At the same
time, expanded or unconventional definitions of the (ontologically more or
less clearly defined) concept of notation also entail the risk of introducing
poorly defined boundaries between the functions of writing down and of
representation (that is, between notation and visualization). Notation, here,
is regarded not as the mere writing down of an independent idea or an
already existing aural phenomenon, but as a “visual form of thinking.”[6]
Ingarden was quite certain: The work cannot be properly identified
with the notation. Some forty years later, however, Cardew showed
how much the concept of the work and the relationship between idea/
conceptualization and realization had changed: Notation was now
essential to the work, with the potential to be elevated to the status of a
work in its own right. “The notation is more important than the sound. Not
the exactitude and success with which a notation notates a sound; but the
musicalness of the notation in its notating.”[7] The notation itself has the
potential to reconceive aural forms and compositions by other means. The
dissolution of the symbolic framework of traditional notation gives access
to “the immediacy of visual observation [of] one’s own creative process,
making that which ‘underlies’ it conscious and therefore analyzable.”[8]
In McLuhanian terms, forms of notation can be viewed as both
medium and message simultaneously.[9] In their essence, as symbolic
abstractions of the key parameters of the music to be represented, not
only do they reproduce the way a particular work is structured (supposedly
the true import of notation), they also tell us just as much about the
concept of music that the composer, or the epoch in which she is working,
has abstracted from perception. Notation as concept, independent of its
individual instances, answers the question “What is music and what is
not?” from the point of view of the composer who is defining that notation,
or of the period in which that notation was or is conventional. This is a
consequence, as noted above, of the necessity of defining a symbolic
framework. Any analytical examination must therefore focus (primarily
on account of media and technology-related changes in the process of
musical creation) on how the medium affects the musicultural and music
historical situation—not on that which is notated, but on the notation’s
influence upon it. In McLuhan’s words, “The ‘message’ of any medium

652

or technology is the change of scale or pace or pattern that it introduces
into human affairs.”[10] Given new and unconventional graphic forms of
notation and representation, this recontextualization of notation, from
a concept of music theory or musical ontology to one of media theory,
opens up freer analytical and speculative perspectives, initially releasing
notation from its traditional imperative function and giving it access to
other possible functions—for example, in computer art. But to what extent
is notation truly a medium and a technological object?
One obvious way to try to categorize notation as a medium would
be by comparing it with graphic representations of language (and
of aural phenomena in general)—which, according to Ferdinand de
Saussure, can be divided into two systems.[11] On the one hand there
are ideographic systems, which use a separate symbol to represent
each word. The symbol itself has no relation to the phonetic sound of
the word it represents; rather, it symbolizes the entire word, and thus the
idea that the word conveys. Chinese characters are a classic example of
ideographic writing. By contrast, phonetic writing systems use elemental
phonetic or alphabetic symbols to represent the sound sequences that
make up words. However, what is significant for the comparison with
musical notation is not the division of linguistic symbol systems into
ideographic and phonetic, but rather the characteristics brought to light by
contrasting the differences between the various graphic representations.
One characteristic that stands out especially clearly in relation to the
difference between ideographic and phonetic systems is the granularity
of the abstraction, which not only plays a part in the writing down of aural
(phonetic or musical) phenomena, but has also had a significant influence
on our analysis and theoretical understanding of them:
Linguistic analysis [...] came to resolve oral speech into a finite series
of elementary informational units. These ultimate discrete units,
the so-called “distinctive features,” are aligned into simultaneous
bundles termed “phonemes,” which in turn are concatenated
into sequences. Thus form in language has a manifestly granular
structure and is subject to a quantal description.[12]
Consequently, it is no surprise that formal music-theoretical
considerations and analyses have focused overwhelmingly on the note
as the elemental unit of musical information. Using the parameters of
pitch (typically, the division of the octave into twelve semitones) and time
(the division inherent in meter), the note divides the physical continuity
of music into distinct aural events, in consequence of which music can
be described in discrete numerical and mathematical relationships—and

FROM THE
SYMBOLIC
TO THE REAL:
GRAPHIC
NOTATION AS
SYMBOLIC AND
TECHNOLOGICAL
MEDIUM

653

LUKAS NOWOK

is in fact described and analyzed in terms of these parameters in most
cases. Moreover, the granular structure of phonetic and alphabetic writing
systems, as a discretization of temporally continuous language, enables
us to identify a characteristic that is far more important for grammatology,
linguistics, and, later, for media theory: the spatial linearization of
temporal processes. As Saussure wrote, in reference to alphabetic writing:
Auditory signifiers have at their command only the dimension of
time. Their elements are presented in succession; they form a chain.
This feature becomes readily apparent when they are represented
in writing. [...] The signifier, being auditory, is unfolded solely in time,
from which it gets the following characteristics: (a) it represents a
span, and (b) the span is measurable in a single dimension; it is a
line.[13]
The dominance of the linear time axis in graphic abstractions of
“real” phenomena plays an especially important role in Friedrich Kittler’s
media theory.[14] Through the spatialization of signs, which represent
the smallest elements in the continuous flow of language, it becomes
possible, by symbolic means, not only to store and repeat this continuous,
irreversible flow, but also—and much more importantly—to manipulate it.
It is precisely this quality of notation—the possibility of manipulating time
axes—that makes it a symbolic medium in the first place:
The different arrangement of a stream of temporal data is precisely
what is meant by time axis manipulation. [...] Time axis manipulation
therefore presupposes (to the horror of philosophers) that time-serial
data be referred to spatial coordinates. [...] History’s first such time
manipulation technology was, of course, writing, especially in the
shape of an alphabet that assigns a spatial position to each graphic
sign representing a time-serial element in the chain of speech.[15]
This positioning of notation in the context of Kittler’s theory gives
rise to a new frame of reference for his analysis: On the one hand,
Kittler pays particularly close attention not just to storage, but to the
medium’s capacity for data processing. Storage is understood to be
merely a basis enabling the manipulation of the medium’s content. The
how of the symbolic medium is thus given greater significance than the
what, as a result of which media are no longer seen primarily as purely
the transmission of content, but as a technology for acting upon that
content. On the other hand, it is worth noting the way Kittler dissolves
the traditional media-historical understanding of the development of

654

media. Instead of the stereotypical conception of media evolution in three
phases—the invention and spread of the alphabet, the printing press, and
the computer—Kittler sees the invention of analog technological media
such as film and the gramophone as a more significant step.[16] The
qualitative shift initiated by analog technological media, in relation to
symbolic media, plays a central role in Kittler’s media theory. In the age
of handwriting and of the printing press, all forms of writing are bound up
in a symbolic universe—which in its most basic variant is that of everyday
speech transcribed by notation. Technological media, by contrast, attempt
to select, store, and produce the physical realities themselves.[17]
For example, if we consider traditional Western musical notation in
terms of the spatial abstraction of time, a direct relationship between real
and notated time can be identified only with difficulty. Notated time is
defined by the meter and its division into whole sections, generally even
in number (halves of a measure, quarters, eighths, etc.), and elapsing
time extends along a horizontal axis. The dominance of the time axis
is misleading, however: Neither the length of a measure on paper nor
the relationships between the lengths of the individual measures says
anything about the actual duration of the measure. This characteristic
makes it impossible to formulate time in terms of absolute points, or
to describe events occurring in real time periods. Points in time are
necessarily derived from the meter; manipulation and modification of
“real” time are impossible.
To be able to realize formulations and manipulations that go beyond
“symbolic time” and the syntactic structures of the symbolic framework,
some graphic forms of notation have developed a strictly isomorphic
way of representing time, in which the spatial qualities of the notation
have a constant relationship to the real time being represented. UPIC’s
design concept may be regarded as a qualitative approximation of the
symbolic to the technological medium, in that it offers an exact Cartesian
mapping between the spatiality of the notation and the time period being
notated (on the horizontal axis) and the spectral content (on the vertical),
thus seemingly presenting the possibility of acting directly upon the
unabstracted continuum of these dimensions. However, by describing the
two temporal dimensions of sound—its instants and its frequencies—
on linear axes, it circumvents the physical incompatibility between them
(as proposed by Dennis Gabor)[18] and thus cannot be considered a strictly
technological medium. In other words, a “sonic quality [...] is an oscillatory
movement, a movement that consists in nothing else but a cluster of
multiple moments or a spectrum of frequencies, which in itself have no
momentary existence. What and when are mutually incommensurable.”[19]
Therefore, a diagram interrelating the otherwise incommensurable

FROM THE
SYMBOLIC
TO THE REAL:
GRAPHIC
NOTATION AS
SYMBOLIC AND
TECHNOLOGICAL
MEDIUM

655

LUKAS NOWOK

dimensions of time and frequency (as is the case, for example, with the
frequency spectrum of Fourier analysis) can only refer to physical reality
by means of symbolic abstraction. However, UPIC’s successor, IanniX,
takes a different approach to the mode of temporality. By incorporating
real time into the interpretation of the notation, it eliminates the need
to symbolically reduce the notated time period to a single visual state.
Instead, it notates by means of “three-dimensional paths and ‘spheres’
with their own space-time behavior, read by ‘cursors.’”[20] Time enters the
notational space as its physical reality itself.
Kittler viewed the historical shift in the medium of writing from
the scroll to the codex (that is, the book) as a more significant media
transformation than that engendered by Gutenberg’s invention of the
printing press.[21] Whereas the scroll required that modifications to the
temporality of the material be strictly sequential and linear, the book,
with its separate spatial analogues to the time of the material, allowed
modifications to the medium to be nonchronological. “To use technical
jargon, one could say that this invention transforms the sections of the
text into ‘addresses.’”[22] This shift in media-historical focus illustrates,
once again, the significance to Kittler’s media theory of modalities of
manipulating and acting upon the medium, as opposed to purely storage
and communication-oriented functions. In that regard, graphic forms
of notation have the potential to approximate, through new graphic
abstractions, the reality of the material notated—but also, and equally,
the potential to regain their distance from that reality through symbolic
abstraction, making possible a variety of flexible modalities for acting
upon the material. The spatial abstraction of time, in particular, holds
untapped potential for breaking away from the dominance of the linear,
horizontal time axis and adopting ideas of temporality, developed in
visual, kinetic, and media art in the twentieth century, that go far beyond
traditional ideas of narratology (in visual art) and chronology (in media
art). These began with Robert Delaunay’s window pictures[23] and have
continued through Cubist and Futurist ideas of temporality and movement
(for example, in Naum Gabo’s 1920 The Realistic Manifesto, in which
he insisted on the necessity of integrating movement and rhythm as
an expression of time[24]) and Paul Klee’s polyphonic painting, which
Robert Kudielka described as images that define depth as a layering of
perceptual levels, in part through the superposition of various colored
glazes, and in part through a structural distinction between concealing
and revealing modes of presentation. Time is noted here as an alternation
between visible and hidden, not a continuous advance from here to there,
from “no longer” to “not yet,”[25] to the concept of “input/output time” in
the work of Nam June Paik.[26]

FROM THE
SYMBOLIC
TO THE REAL:
GRAPHIC
NOTATION AS
SYMBOLIC AND
TECHNOLOGICAL
MEDIUM

656

657

LUKAS NOWOK

FOOTNOTES
1.
Roman Pfeifer, “Schrift und Klang – zur Verschriftlichung von Tonbandmusik”

(Diplom thesis, Folkwang Universität, 2002).

2.

Roman Ingarden, Ontology of the Work of Art: The Musical Work, the Picture,
the Architectural Work, the Film, trans. Raymond Meyer and John T. Goldthwait
(Athens, OH: Ohio University Press, 1989), 26.

3.

Cornelius Cardew, Treatise Handbook (London: Peters, 1970), xiv.

4.

Ingarden, 25–26.

5.

Ibid., 26.

6.

Angela Lammert, “Von der Bildlichkeit der Notation,” in Notation: Kalkül und Form
in den Künsten, ed. Hubertus von Amelunxen, Dieter Appelt, Peter Weibel, and
Angela Lammert, exh. cat. (Berlin: Akademie der Künste; Karlsruhe: ZKM | Center
for Art and Media Karlsruhe, 2008), 52.

7.

Cardew, Treatise Handbook, vii.

8.

Sharon Kanach, “Sichtbare Musik: Notationsübertragung im Oeuvre von Iannis
Xenakis,” in Notation: Kalkül und Form in den Künsten, 212

9.

Marshall McLuhan, Understanding Media: The Extensions of Man (1964; repr.,
Cambridge, MA: MIT Press, 1994).

10.

Ibid.

11.

Ferdinand de Saussure, Course in General Linguistics, ed. Charles Bally, Albert
Sechehaye, and Albert Riedlinger, trans. Wade Baskin (1916; repr., New York:
McGraw-Hill, 1966), 25.

12.

Roman Jakobson, “Linguistics and Communication Theory,” in Selected Writings,
vol. 2, Word and Language (The Hague: Mouton, 1971), 570–59, here 570.

13.

Saussure, Course in General Linguistics (1916, repr. Illinois, Open Court, 1986), 70

14.

Friedrich Kittler, “Real Time Analysis, Time Axis Manipulation,” in, Cultural Politics
13, trans. Geoffrey Winthrop-Young, (2017), 1–18.

15.

Ibid., 5–6.

16.

Sybille Krämer, “The Cultural Techniques of Time Axis Manipulation: On Friedrich
Kittler’s Conception of Media,” in Theory, Culture & Society 23, 7–8 (2006),
93–109.

17.

Ibid., 94.

18.

Dennis Gabor, Theory of Communication (London: Institution of Electrical
Engineering, 1946), 429.

19.

Julian Rohrhuber, “Algorithmic Music and the Philosophy of Time,” in The Oxford
Handbook of Algorithmic Music, ed. Alex McLean and Roger T. Dean (Oxford:
Oxford University Press, 2018), 17–40, here 27–28.

20.

See Scordato, “Novel Perspectives for Graphic Notation in IanniX,” this volume.

21.

Krämer, “Cultural Techniques,” 100.

22.

Ibid.

23.

Barbara John, “The Sounding Image: About the Relationship between Art and
Music; An Art-Historical Retrospective View,” Media Art Net,
http://www.medienkunstnetz.de/themes/image-sound_relations/sounding_
mage/

24.

Brigitta Wolf, “Nam June Paik und die Zeit” (Diplom thesis, Technische Universität
Berlin, 2015), 8.

25.

Robert Kudielka, “Schichten: Zur Notation von Tiefe in der Zeit,” in Notation:
Kalkül und Form in den Künsten, 353.

26.

Lydia Haustein, Videokunst (Munich: C. H. Beck, 2003), 62.

APPENDIX

BIOGRAPHIES
SUPPLEMENTARY CREDITS
COLOPHON

661

EDITORS’ BIOGRAPHIES
LUDGER BRÜMMER (*1958 in Werne,
Germany) is a composer professor for
composition in digital media in Trossingen
and head of the ZKM | Hertz-Lab research
institute since 2017. As of 2003, as head
of the former ZKM | Institute for Music and
Acoustics, he initiated the Sound Dome
Project and important festivals on electronic
music. The central focus of his music is
the use of the computer, both as an artistic
means of composition and for electronic
sound production. Brümmer has also realized
a series of multimedia and interdisciplinary
projects, experimental music pieces,
compositions for dance and live electronics,
and is interested in the interaction between
acoustic instruments and live video.
SHARON KANACH (*1957 in New Jersey, USA)

has lived in France since 1976. She originally
went to Paris to study with Nadia Boulanger.
Very quickly, however, her path crossed that
of Iannis Xenakis with whom she collaborated
closely, especially on his writings. First, she
translated Arts/Sciences: Alloys, followed
by a new, revised, and enlarged edition of
his seminal Formalized Music, then Music
and Architecture, which Kanach coauthored
with Xenakis, published in French in 2006
and in 2008 in English. As General Editor
of the Xenakis Series at Pendragon Press,
Kanach has, so far, also edited two collective
volumes: Performing Xenakis and Xenakis
Matters. Since 2007, Kanach is vice-president
of the Centre Iannis Xenakis based at the
Université de Rouen. In 2010 Kanach founded
the Xenakis Project of the Americas under
the auspices of the Brook Center for Music
Research and Documentation at the CUNY
Graduate Center, New York City.

BIOGRAPHIES

PETER WEIBEL (*1944 in Odessa, Ukraine)
studied literature, medicine, logic, philosophy,
and film in Paris and Vienna. He became
a central figure in European media art on
account of his various activities as artist,
media theorist, curator, and as a nomad
between art and science. He has been granted
honorary doctorates by the University of Art
and Design Helsinki in 2007, and by the
University of Pécs, Hungary, in 2013. In 2008,
he was awarded the French distinction of
Officier dans l’Ordre des Arts et des Lettres.

Since 1999, Peter Weibel is Chairman and
CEO of the ZKM | Center for Art and Media
Karlsruhe, and since 2017 director of the Peter
Weibel Research Institute for Digital Cultures
at the University of Applied Arts Vienna.

AUTHORS’ BIOGRAPHIES
RICHARD BARRETT (*1959, Swansea, UK)
is internationally active as a composer and
a performer, ranging from intricately notated
orchestral and chamber music to free
improvisation with live electronics. He also
teaches at the Instituut voor Sonologie in Den
Haag and the University of Leiden. He was
awarded a PhD by Leeds University in 2018,
and in 2019 his book Music of Possibility was
published by Vision Edition.
RODOLPHE BOUROTTE (*1971 in Abidjan, Ivory
Coast) is a composer-researcher. He has been
writing and improvising electroacoustic and
instrumental music since 1998. He studied
composition with Allain Gaussin, Jean-Yves
Bosseur, Jean Balissat and Paul Méfano, and
electroacoustic composition at Les Ateliers
UPIC. He developed various programs linking
graphics and sound, notably for real-time
generated scores or picture-driven probability
sequences. His music is based on the view
that we humans should make the effort to
create things that cannot be modelled by a
computer.
PIERRE COUPRIE (*1970 in Poitiers, France)
holds a Ph.D. in musicology and is an
associate professor and a researcher qualified
for direct research at the Sorbonne University
and the Research Institute for Musicology.
His research fields are musical analysis,
representation and performance studies of
electroacoustic music, digital musicology,
and the development of tools for research
or musical performance (iAnalyse, EAnalysis,
MotusLab Tools). He teaches digital pedagogy,
musicology, and computer music at the
Sorbonne University. He collaborates with the
Music, Technology and Innovation Institute
for Sonic Creativity (MTI2) of De Montfort
University since 2004 on musical analysis
projects. In 2015, he won the Qwartz Max
Mathews Price of technological innovation for
his musical analysis software. As an improviser,
he is a member of The Phonogénistes and The
National Electroacoustic Orchestra (ONE).

662

CYRILLE DELHAYE (*1980 Evreux, France) is a
teacher, a documentalist, and musicologist. He
studied musicology at the Université de Rouen.
His work focuses on the history and analysis of
concrete and electroacoustic music and digital
humanities. In 2010, he defended his PhD on
Orphée by Pierre Henry and Pierre Schaeffer.
His thesis is based on the private archives
of the two composers and investigates
the different versions of this artwork
(1951–2015). Since 2010, he has been in
charge of the archives of the Centre Iannis
Xenakis (CIX), which include the material
on 120 composers who had composed
on the UPIC there: inventory, digitization,
editorialization, and online publishing of more
than 1000 unpublished items. In addition to
contributions to collective books, his work has
been published in the Revue Française de
Musicologie and in Organised Sound. He is
currently working on Pierre Henry’s catalogue
raisonné, to be published by the Philharmonie
de Paris.
ALAIN DÉSPRES (*1948 in Graçay, France)

was director of artistic and cultural structures
for more than 25 years. He notably created
and directed Les Ateliers UPIC alongside
Iannis Xenakis. In this context, over a hundred
composers were hosted and many groups of
amateurs coming to work on the UPIC in Paris.
He has also organized and initiated numerous
concerts, master classes, and workshops in
universities, art schools and at contemporary
art festivals in North America (Mexico, USA,
Canada), Japan, and in most countries of
Europe. He then created and directed Alpha
Centauri, a cultural structure whose purpose
was to foster collaborations between scientific
researchers and creative artists (CNRS,
CEA, Ecole Polytechnique, INRA, SUPELEC,
universities, ministries, and so on). For about
twenty years Alain Déspres has been pursuing
more personal work of stone sculpture in
direct carving (serpentines, marbles, basalts,
granites, etc.).

JULIO ESTRADA (*1943 in Mexico City,
Mexico). Estrada’s devise and researchcreation take network theory (Canto tejido,
Canto alterno) and interval classes (Canto
naciente) as their starting point, followed
by a series of innovations in the field of the
continuum: rhythm–sound continuum (eua’on,
eua’on’ome), rhythm–sound macro-timbre

663

polyphony (ensemble’yuunohui), topological
rhythm–sound continuum (ishini’ioni),
rhythm–sound space continuum macrotimbre (eolo’oolin), continuum–discontinuum
fusion (yuunohui’tlapoa), continuum noise
(yuunohui’wah), or vocal and instrumental
macro-timbre (mictlan, hum, yuunohui’ehecatl,
yuunohui’sa). He explores “live music
creations” (Quotidianus, Bajo el volcán)
and ground-breaking operas (Murmullos del
páramo, 1991–2006, and La nube en el
laberinto, a novel to be silently listened to
within the readers’ experience (2008–). At
the UNAM, Mexican National University, he
is coauthor with Jorge Gil of Music and Finite
Groups Theory: 3 Boolean Variables (1984);
author of Continuous Reality and Imagination
(2019); and The Scales Continuum (in press).
He has been the research director of the
eua’oolin projects, the intervallic classes
combinatorial theory MuSIIC (2000–2016),
and 21st Century UPIC (2000–2001, France).
His awards include chevalier and officier of
the French Arts et Lettres, the UNAM Prix,
a Mexican Fine Arts Medal and National
Scholars System Emeritus.
RUDOLF FRISIUS (*1941 in Celle, Germany)
studied musicology, philosophy, art, and
mathematics in Hamburg, Frankfurt, and
Göttingen. He was active in musicological and
music pedagogical teaching and research
in Oldenburg and Karlsruhe with a focus on
music theory and music pedagogy (studies
on the concept of chords, harmony in the
20th century, electroacoustic music). He
has published extensively, including in the
Handbuch der Musik im 20. Jahrhundert,
Neue Musik, on Xenakis (Musik-Konzepte
55/56), Stockhausen (3 volumes, numerous
radio broadcasts), Henry, Bayle, Kagel, Ligeti,
Riedl, and Rihm, and collaborated with
institutions such as the INMM Darmstadt
(1998–2004 as chairman), the Darmstadt
Summer Courses (1990 on Xenakis and Cage),
and the Centre Acanthes (Henry and Xenakis).
KIYOSHI FURUKAWA (*1959 in Tokyo, Japan)
studied composition in Tokyo with Yoshiro Irino,
in Berlin with Isang Yun, and in Hamburg with
György Ligeti. In 1991 he completed a study
stay at the CCRMA at Stanford University, USA.
He was a long-term artist-in-residence at the
ZKM | Center for Art and Media Karlsruhe
in 1992/93 and 1996/97, and premiered

the media opera Den ungeborenen Göttern
for the opening of the ZKM in 1997. For his
multimedia works, chamber music, and
orchestral music, he has received numerous
awards and scholarships, and his works
have been performed at international music
festivals (Warsaw Autumn, Inventionen Berlin,
Steierischer Herbst Graz, Interface Hamburg,
Multimediale Karlsruhe, amongst others).
Since 2000 he is a professor at the Tokyo
National University of the Arts (Inter-Media Art).
HUGUES GENEVOIS (*1958, Abidjan, Ivory

Coast) is a researcher in musical acoustics,
within the LAM team at the Institut d’Alembert
(Sorbonne Université — CNRS). With a
scientific background (Master of Science in
Physics and Telecom ParisTech Engineering
School), Hugues Genevois became interested
very early in music composition and the
possibilities offered by computers for sound
synthesis. However, if his tastes willingly led
him to musique concrète and music from the
Far East, it was through contact with Iannis
Xenakis that he decided to deepen his written
work. After having produced numerous pieces
of music on paper, his interest in instrumental
practice (electric guitar, synthesizers) led him
to explore the expressive possibilities of the
computer. His research focuses in particular
on new lutheries and musician–instrument
interaction. Also an improviser, he performs
in various formations: ONE (septet), Les
complémentaires (trio with György Kurtag Jr.
and Jean Haury) and Moon Module (duo with
Laurence Bouckaert).
KOSMAS GIANNOUTAKIS (*1985 in

Thessaloniki, Greece) studied piano and
percussion performance, composition,
and computer music in Greece, Germany,
and Austria. His artistic practice focuses
on emergent music outcomes brought
forth by self-organizing systems. These
include compositional, performative, and
algorithmic agencies that are organized as
non-hierarchical, decentralized networks
which exchange information on multiple
timescales through the medium of sound.
His works have been presented and received
awards at various international festivals
and conferences, such as inSonic at ZKM
Karlsruhe, ALIFE 2018 conference in Tokyo,
Junge SIGNALE concert series in Graz,
Soundislands Festival in Singapore, Toronto

International Electroacoustic Symposium,
New York City Electroacoustic Music Festival,
Gaudeamus Muziekweek 2015 and ICMC
2016 in Utrecht, REAL/UNREAL BEAST FEaST
2016 in Birmingham, klingt gut! 2016 in
Hamburg, 13th Athens Digital Arts Festival,
Sonic Realities 2018 in Aberdeen, Workshopin-Exposition: Thresholds of the Algorithmic in
Bergen, xCoAx 2017 in Lisbon, and The Digital
Body International Exhibition in Bucharest.
DIMITRIS KAMAROTOS (*1954 in Athens,
Greece) studied music and computer science
in Athens, musicology, composition, clarinet,
and electroacoustic music in Paris with
D. Charles, M. Battier, H. Vaggionne, and I.
Xenakis. From 1986 to 1995 he worked as
research manager in the CMRC (Center for
Contemporary Music Research of Athens),
founded by Xenakis. During this period he
planned and implemented the main activities
concerning the UPIC system of the CMRC.
As a researcher, he contributed to the field
of automated music pattern recognition. As
a composer, he is developing the use of
interactive sound control and generative
technologies in theatrical performance. Since
1990 he has contributed original music,
sound design, and sound dramaturgy to many
performances for the Hellenic Festival, in the
Epidaurus ancient theater, National Theater
of Greece, La Comédie-Française, Volksbühne
Theater, Riksteatern Stockholm, Shanghai
DAC, Seoul Arts Centre, and European theater
festivals.
HENNING LOHNER (*1961, Bremen, Germany)
is a German-American composer, filmmaker,
and digital media artist. Lohner’s creative
output embraces diverse fields within
the audiovisual arts. He has collaborated
extensively with artists such as Karlheinz
Stockhausen, Karl Lagerfeld, Louis Malle,
Gerhard Richter, Frank Zappa, Dennis Hopper,
and John Cage. Since 1996 Henning Lohner
has been a member of the Remote Control film
composers’ group founded by Hans Zimmer.
Lohner’s documentary Ninth November Night
was shortlisted for the Academy Awards
(the Oscars) in 2005. His active images
media artwork, Silences, has been screened,
exhibited, and acquired by museums such as
SFMoMA, the Centre Pompidou, the Louvre,
the German National Academy of Art, the
Venice Biennale, and many others. Iannis

664

Xenakis became Lohner’s life-long mentor
in 1985. Since then, Lohner has published
numerous articles on the composer’s work,
including initiating and contributing to the first
German language monograph on the composer,
as Volume 54 of the series MusikTexte.
FRANÇOIS-BERNARD MÂCHE (*1935 in
Clermont-Ferrand, France) was born into a
family of musicians and has pursued two
careers simultaneously. As a composer
(student of Messiaen and a founding member
of Pierre Schaeffer’s G.R.M.), he has been
invited to perform in some thirty countries. He
has received the Prix Italia (1977), the Grand
Prix National de la Musique (1988), and the
Grand Prix de la Sacem (2002) amongst other
awards. His catalogue now includes 115
works illustrating all genres and techniques.
In addition, Mâche graduated from the
prestigious Ecole Normale Supérieure, is an
agrégé and Doctor of the Arts. He headed
the Music Department of the University of
Strasbourg for ten years, published eight
books, and ended his academic career
as Director of Studies at the E.H.E.S.S.. A
Commander of Arts and Letters and Knight of
the Academic Palms, he was elected member
of the French Institute in 2002, in the chair
previously occupied by Iannis Xenakis, and
was appointed Doctor honoris causa of the
University of Athens in 2011.
GUY MÉDIGUE (*1935 in Algiers, Algeria)
studied mathematics, attended the Ecole
Polytechnique in Paris for one year, then
preferred to sing his songs in Paris until
1964. After that, he worked as a computer
engineer from 1965 until 1996. For nearly
eleven years, he worked for SEMA-METRA
International (traffic software), then for CERCI,
which subcontracted him out for several years
to participate in the IRIA CYCLADES project
(French premises of the Internet). Always
fascinated by the relationship between music
and computer science, he then gladly worked
as a freelancer with Iannis Xenakis at the
CEMAMu from 1976 to 1980, developing
and refining the first UPIC. From 1981 to
1996, he participated in the building of a
multi-microprocessor structure (SM90 project,
CNET), mainly on software aspects. Next, he
managed source programs for a team working
on a communication-based operating system
(Chorus system).

665

CHIKASHI MIYAMA (*1979 in Otsu, Japan)
is an artist and software developer who
utilizes diverse interactive digital media
technologies. He holds a Master’s degree
from the Kunitachi College of Music, Tokyo,
a Nachdiplom from the Music Academy of
Basel, and a Ph.D in composition from the
University at Buffalo, New York. His works have
received an ICMA award, a second prize in
SEAMUS commission competition, a special
prize in Destellos Competition, and the first
prize in Strom Festival Cologne. His works and
papers have been accepted by ICMC twelve
times, by NIME four times, and selected by
various international festivals in more than
20 countries. In 2011, he moved to Germany
as a DAAD scholar and worked as a research
associate at ZKM Karlsruhe between 2015
and 2017. He is currently working as a lecturer
at the Cologne University of Music and Dance
and an audio software developer at Dear
Reality GmbH in Düsseldorf.
LUKAS NOWOK (*1993 in Donaueschingen,
Germany) studied music technology and
design in Trossingen and Helsinki. Since
2016 he has been a sound director for
the SWR public broadcaster Experimental
Studio, a laboratory and international touring
ensemble for contemporary music with
live electronics. There he has worked with
composers such as Chaya Czernowin, Peter
Ablinger, and many others. Besides his work
as a sound director, he is active as a sound
and visual artist, working in a broad range of
disciplines including theater, electroacoustics,
performance and installation arts.
GERARD PAPE (*1955 in New York City, USA)
is a former director of the Ateliers UPIC/CCMIX,
from 1991 to 2007, and he founded the
C.L.S.I., a collective of composer-performers
playing instruments and computers “live”
in 2007. Two CDs of his music were
released in 2015 on Stradivarius and Mode
Records. A bilingual book of Pape’s texts
as well as musicological texts about his
work, MUSIPOESCI, was published in 2015
by Editions Michel de Maule in Paris. In
recent years, Pape has been working on a
large-scale opera cycle called SUNSET TIME.
He completed the first opera of the cycle,
Pourquoi des poètes?, in 2014. He is currently
working on the second opera L'Enfant et le
4e Monde. These two works for 4 soloists and

string ensemble are intended to be performed
as a diptych. Pape recently composed a music
theater work based on Sam Shepard’s and
Joseph Chaikin’s play The War in Heaven
(Angel’s Monologue) for bass voice and
electronics.
BRIGITTE CONDORCET (ROBINDORÉ) is a
French composer and researcher, who
worked from 1991 to 1997 at Iannis
Xenakis’s two Parisian centers, the CCMIX
(formerly Les Ateliers UPIC) and the
CEMAMu, as a composer, head of Musical
Production, and UPIC system beta tester and
manual author. She experienced firsthand
the intensity and authenticity of Xenakis’s
presence and conceptions and had a long
and unique compositional journey with the
UPIC system. Her compositions Autel de Ia
Perte et de Ia Transformation and Comme
Etrangers et Voyageurs sur la Terre were
selected for the 20th anniversary double
CD set of the CCMIX for Mode Records in
2001, and the latter was also excerpted by
the Computer Music Journal for its Sound
Anthology (Vol 20, 1996). Her composition
L'Enfant et le Phénix received the Prix Radio
France/La Muse en Circuit and featured
narration by French cinema icon Emmanuelle
Riva of Hiroshima mon Amour. She obtained
an Advanced Master's (DEA) degree from
the Université de Paris VIII in 1997, under
the direction of Horacio Vaggione, studying
the impact of electroacoustics on acoustic
composition and thought. She is currently
a doctoral candidate at the Université de
Rouen, researching syncretic and mystical
music traditions and their influence on postwar European composers.
MARCIN PIETRUSZEWSKI (*1984 in

Gniezno, Poland) is a composer and
researcher based in Edinburgh. He engages
with sound synthesis and composition
using computers, exploring specific
formal developments in the tradition of
electroacoustic music and contemporary
sound art, as well as extra-musical domains
of auditory design, computational linguistics,
and psychoacoustics. He works across
performance, multimedia installations, and
radio productions, probing the dynamics
between formalism of synthetic sound and
its material realization. He has collaborated
extensively with musicians and composers,

including Marcus Schmickler, Tristan
Clutterbuck (fancyyyyy), Jules Rawlinson,
and Lauren Sarah Hayes. Among his recent
projects are a collaboration with Florian
Hecker and graphic design company NORM
from Zurich, philosopher Chris Schambaugh
(The New School, New York), choreographer
and dancer Agnes Cebere (Martha Graham
School of Contemporary Dance, New York),
the Laboria Cubonics Collective (the authors
of Xenofeminist Manifesto).
JULIA JASMIN ROMMEL (*1979 in Mutlangen,
Germany) studied visual communication and
scenography in Berlin, Stockholm, and Zurich.
Her work focuses on developing spatial
concepts for contemporary music theater
productions (Follies for Fontane, Brandenburg
2019; Match Cut Music Convention, Berlin
2017; Die Nachtigall, Berlin 2017; Into
the Deep, Radialsystem Berlin 2017;
Mockumentary Altus, Bremen 2014; Orlando
UA Theater, Bielefeld 2013) as well as on
scenography for classical opera productions
(Dido & Aeneas, Cosi fan tutte, Acis &
Galatea, Antwerp 2015/16; Kinderzauberflöte
Berliner Philharmoniker, Baden-Baden
2013). Another focus of her work is creating
orientation systems for buildings and public
spaces (Elbphilharmonie Hamburg 2010
for Integral Zürich, Löwenbräu Areal Zürich,
Switzerland) and also corporate design and
cartography. Furthermore, she is participating
in a PhD program at the Offenbach University
of Art and Design, where she explores
the phenomena of ubiquity and space
constitution in the context of information and
communication technology.
JULIAN SCORDATO (*1985 in Pordenone, Italy)
studied composition and electronic music at
the Conservatory of Venice, and sound art at
the University of Barcelona. He is cofounder
of the Arazzi Laptop Ensemble and was a
research assistant at SaMPL — Sound and
Music Processing Lab, Padua. As a music
technologist, Scordato has presented results
related to interactive performance systems
and graphic notation tools in conferences
and lectures. He has worked as a professor
of electronic music at the conservatories
of Brescia, Salerno, and Cuneo. His awardwinning electroacoustic and audiovisual
works have been performed and exhibited at
international festivals and institutions.

666

TAKEHITO SHIMAZU (*1949 in Shimoda,
Japan) studied composition with Sesshu Kai
in Tokyo at Tokyo Gakugei University and with
Isang Yun in Berlin at Berlin University of the
Arts. He produced electronic and computer
music at the electronic studio of the Technical
University of Berlin, at IRCAM in Paris, at
Les Ateliers UPIC in Paris, and at INA-GRM
in Paris. His compositions were selected
and played several times at the Music Days
of ISCM and ICMC (International Computer
Music Conference) and many other festivals
in Asia, Europe, and America, including the
Saarbrücken Music Festival (2002) and
Dresden Music Festival (2005). He chaired
the music committee of ICMC '93 in Tokyo.
His scores are published by Breitkopf & Härtel
and F. Hofmaister in Germany, amongst
others. From 1985 to 2015 he was a
professor at Fukushima University, and since
2005 he has been the Artistic Director of the
Orchestra Pfirsich in Fukushima.
VICTORIA SIMON (*1983 in New York
City, United States) earned her PhD in
Communication Studies from McGill
University in 2019. Her research focuses
on the history and cultural politics of sound
technology and user interface design. She
has published in the journals Television and
New Media, Communication, Culture and
Critique, Amodern, and is a contributor to the
edited volume, Appified: Culture in the Age of
Apps (2018).
ANDREY SMIRNOV (*1956 in Moscow,

Russia) is an interdisciplinary artist,
independent curator, collector, writer,
composer, and researcher of new techniques
in computer music. He is the founder of
the Theremin Center, a research fellow at
the Center for Electroacoustic Music at
Moscow State Conservatory, the head of
the Rodchenko Sound Lab, and a lecturer
at the Rodchenko Art School in Moscow.
He teaches history and the aesthetics of
electroacoustic music, composition, and new
musical interfaces. His main ongoing project
is focused on restoring the censored history
of artistically utopian early twentieth-century
Russia. He is the author of the book Sound
In Z: Experiments In Sound and Electronic
Music in Early 20th Century Russia (Walther
König, Cologne, and Sound and Music,
London, 2013).

RONALD SQUIBBS (*1962 in Bridgeport,
Connecticut, USA) earned his undergraduate
and graduate degrees in music at Yale
University. He has presented his research on
the music of Iannis Xenakis at conferences
and in publications in journals and edited
collections, including Xenakis Matters (ed.
Sharon Kanach, Pendragon Press, 2012) and
Twentieth-Century Music and Mathematics (ed.
Roberto Illiano, Brepols, 2019). In addition to
his scholarly work, he is active as a performer
of twentieth and twenty-first-century music. His
recordings of piano music by Joji Yuasa and
Dane Rudhyar are available on the Aucourant
Records label. He is currently Associate
Professor of Music Theory at the University of
Connecticut, where he has taught since 2002.
KATERINA TSIOUKRA (*1993 in Kozani,
Greece) studied at the Department of Music
Studies of the Ionian University in Corfu,
Greece. She obtained her Master’s degree
in the history of neohellenic music and is
currently a doctoral candidate at the same
university. Her research interests lie primarily
in the area of post-war music history in Greece.
Since 2018, she has been collaborating both
with the Contemporary Music Research Center
(KSYME) and the Center of Research and
Documentation of the Athens Conservatoire
in their educational and research activities.
She is an Alexander S. Onassis Public Benefit
Foundation scholar.

669

SUPPLEMENTARY CREDITS
P 14 One of the original UPIC installations,
undated © CIX Archives
P 52 Marion Kalter, Iannis Xenakis at his
studio in Paris, undated © ZKM | Center for
Art and Media Karlsruhe and Marion Kalter
P 54 UPIC workshop for children in Mexico

City, Mexico, 1988 © Alain Després and
CIX Archives

P 56 The UPIC installed in the KSYME studio,
May 1986 © Dimitris Karageorgos
P 58 Portrait of Alain Després (left) and
François Bernard Mâche (right), undated
© CIX Archives
P 60 Iannis Xenakis on his last teaching

day at the Sorbonne, Paris, France, 1986
© Henning Lohner
P 62 François-Bernard Mâche, Hypérion,
page T1, 1981 © François-Bernard Mâche
P 64 Pierre Bernard, Peter Nelson and Alain

Després performing Un Alliage Rituel at the
world première at the ICMC, Glasgow, UK,
1990 © Alain Després and CIX Archives

P 66 Alain Despres (left) and Iannis Xenakis
(right) during a UPIC workshop, Centre
Acanthes, Aix-en-Provence, France, 1985
© Henning Lohner
P 68 A group of children stand over the
UPIC during a UPIC Atelier, Middelburg,
Netherlands, 1982 © CIX Archives
P 70 A woman drawing on the graphic table
of a UPIC with an electromagnetic stylus,
May 1980 © CIX Archives
P 72 Logarithmic spectrums of Iannis
Xenakis's Taurhiphanie, 1994 (top) and
Voyage absolu des Unari vers Andromède,
1987 (bottom), produced with software
iAnalyse, 2019, screenshot © Pierre Couprie

SUPPLEMENTARY CREDITS

P 74 Screen captured in the IanniX software
© Association IanniX

P 76 IanniX in use, ca. 2019
© Association IanniX
P 78 One thousand circles with different
colors and sizes generated with the JavaScript
library p5.js, 2019, screenshot
© Chikashi Miyama
P 80 A workspace of the New Pulsar
Generator with its various extensions (e.g.,
wavefold modulators of synthesis parameters
via matrix, parameter linking, multiple tables
for micro and meso scale trajectories, and
preset system), 2019, screenshot
© Marcin Pietruszewski
P 82 First UPISketch workshop for children,
Cyprus, 2018 © CIX Archives
P 84 Chikashi Miyama performs Modulations,
2013/2018, at the UPIC­— Graphic Interfaces
for Notation Conference, Karlsruhe, Germany,
September 29, 2018 © ZKM | Center for Art
and Media, photo: Dorte Becker and
Sophie Hesse
P 86 Julia Rommel, graphic notation
Übergänge (transitions) from Zwischenraum,
2019 © Julia Rommel
P 88 Chris Carlson, Borderlands Granular, iOS
app, 2012–2020 © Chris Carlson
P 19, 41, 401, 440, 444, 465, 467, 473, 475, 564

The personal archives of Iannis Xenakis
are property of the Iannis Xenakis Family and
they are available through the web page of
Les amis de Xenakis
https://www.iannis-xenakis.org.

COLOPHON
This book is initiated by the ZKM | Hertz-Lab in cooperation
with the Centre Iannis Xenakis in the framework of Interfaces,
a Creative Europe project supported by the European Union.

ZKM | Center for Art and Media Karlsruhe
Lorenzstraße 19
Karlsruhe, Germany
Phone: +49 (0)721/8100-1200
info@zkm.de
www.zkm.de

EDITORS: Peter Weibel, Ludger Brümmer, Sharon Kanach

CEO AND CHAIRMAN: Peter Weibel

EDITORIAL STAFF: Lisa Bensel

COO: Christiane Riedel

ASSISTANCE: Ana Henriques

HEAD OF ADMINISTRATION: Boris Kirchner

COPY EDITING: Gloria Custance

HEAD OF HERTZ-LAB: Ludger Brümmer

TRANSLATIONS: Patrick Hubenthal, Sharon Kanach,

Christian Liberty Marshall

IN COOPERATION WITH:

GRAPHIC DESIGN: Uta Kopp
ASSISTANCE: Victoria Herzog
WEBSITE: Sabine Jäger, Volker Sommerfeld
COORDINATION, HATJE CANTZ: Richard Victor Hagemann
PRODUCTION, HATJE CANTZ: Thomas Lemâitre

PUBLISHED BY:

PRINTED AND BOUND: Livonia Print, Riga
PAPER: Munken Kristall Rough, 100g/m2
TYPEFACE: Franklin Gothic
MANY THANKS TO: ZKM | Publications, Jens Lutz,
Dr. Anett Holzheid, Mâkhi Xenakis

© 2020 Hatje Cantz Verlag, Berlin,
ZKM | Center for Art and Media Karlsruhe, Germany

Unless otherwise indicated, all texts and images © by the
individual authors and their rights holders.

Hatje Cantz Verlag GmbH
Mommsenstraße 27
10629 Berlin, Germany
www.hatjecantz.com
A Ganske Publishing Group Company
FOUNDERS OF THE ZKM:

Despite intensive research and best intentions, it was not
possible in every case to establish the copyright holders.
We request the holders of such rights who feel they have not
been properly acknowledged to contact us.
OPEN ACCESS: all rights are reserved but all parts of this book
may be reproduced, especially in electronic means (including
photocopying, printing, downloading, linking, distributing,
recording, or information storage and retrieval) without
permission in writing from ZKM | Karlsruhe.

This publication has been funded with support from the
European Commission. It reflects the views only of the authors
and the Commission cannot be held responsible for any use
which may be made of the information contained herein.
FULL PUBLICATION AVAILABLE FOR FREE DOWNLOAD AT:

www.zkm.de/upic

ISBN 978-3-7757-4741-7

PARTNER OF THE ZKM:

SUPPORTED BY:
Co-funded by the
Creative Europe Programme
of the European Union

